<!DOCTYPE html>
<html  lang="en">
<head><meta charset="utf-8">
<title>Meta-Learning explained</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary_large_image">
<meta property="og:image:width" content="400">
<meta property="og:image:height" content="300">
<meta property="og:image:alt" content="An image showcasing my project.">
<meta property="og:title" content="Meta-Learning explained">
<meta name="description" content="Learn how to configure Alpine with the app.config.ts file.">
<meta property="og:description" content="Learn how to configure Alpine with the app.config.ts file.">
<meta property="og:image" content="/articles/configure-alpine.webp">
<link rel="preload" as="fetch" crossorigin="anonymous" href="/articles/2022-11-21-meta-learning/_payload.json">
<link rel="stylesheet" href="/_nuxt/entry.2b709d1c.css">
<link rel="stylesheet" href="/_nuxt/DocumentDrivenNotFound.aa939160.css">
<link rel="stylesheet" href="/_nuxt/article.06aa1a19.css">
<link rel="stylesheet" href="/_nuxt/ProseA.baee409d.css">
<link rel="stylesheet" href="/_nuxt/ProseH1.6d63403c.css">
<link rel="stylesheet" href="/_nuxt/ProseStrong.b01d4b3b.css">
<link rel="stylesheet" href="/_nuxt/ProseH2.3a63b076.css">
<link rel="stylesheet" href="/_nuxt/ProseP.b99f89cd.css">
<link rel="stylesheet" href="/_nuxt/ProseImg.eeea4224.css">
<link rel="stylesheet" href="/_nuxt/ProseBlockquote.3d074d56.css">
<link rel="stylesheet" href="/_nuxt/ProseUl.0edd7272.css">
<link rel="stylesheet" href="/_nuxt/ProseLi.a0b5f8a8.css">
<link rel="stylesheet" href="/_nuxt/ProseEm.35a26f4d.css">
<link rel="stylesheet" href="/_nuxt/ProseH3.36490a89.css">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.5b2fbc2b.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/NuxtImg.71ecd94d.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.02488242.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.33a0504c.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.ea978627.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.vue.233735c0.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.e61e620a.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/article.74583e02.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.b25940ab.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/date.824a539b.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.c50a67fb.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH1.0f011535.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.11c76ad1.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.106e00e3.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.df39db4a.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseImg.f7a26e58.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseBlockquote.0c8174d8.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseUl.98914a64.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseLi.377a25ce.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseEm.ab0e77c6.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH3.c663c5f8.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/default.9a1873bb.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/page.dfa15be1.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.b6bffc10.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/pipeline.b9c7be3a.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.33f4b423.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/debug.fde61575.js">
<link rel="prefetch" as="style" href="/_nuxt/useStudio.a92b5f33.css">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/useStudio.8bae12b1.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/asyncData.57510f6c.js">
<link rel="prefetch" as="style" href="/_nuxt/error-404.7910d5ca.css">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/error-404.3de20a2d.js">
<link rel="prefetch" as="style" href="/_nuxt/error-500.1db01289.css">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/error-500.2ac66414.js">
<script type="module" src="/_nuxt/entry.5b2fbc2b.js" crossorigin></script><style id="pinceau-runtime-hydratable">@media{.phy[--]{--puid:4wQQMs-v;}.pv-oj_SrG{max-width:var(--elements-container-maxWidth);padding-left:var(--elements-container-padding-mobile);padding-right:var(--elements-container-padding-mobile);}@media (min-width: 475px){.pv-oj_SrG{padding-left:var(--elements-container-padding-xs);padding-right:var(--elements-container-padding-xs);}}@media (min-width: 640px){.pv-oj_SrG{padding-left:var(--elements-container-padding-sm);padding-right:var(--elements-container-padding-sm);}}@media (min-width: 768px){.pv-oj_SrG{padding-left:var(--elements-container-padding-md);padding-right:var(--elements-container-padding-md);}}} </style><style id="pinceau-theme">@media { :root {--pinceau-mq: initial; --alpine-readableLine: 68ch;--alpine-backdrop-backgroundColor: #f4f4f5b3;--prose-code-inline-padding: 0.2rem 0.375rem 0.2rem 0.375rem;--prose-code-block-backdropFilter: contrast(1);--prose-code-block-border-style: solid;--prose-code-block-border-width: 1px;--prose-tbody-tr-borderBottom-style: dashed;--prose-tbody-tr-borderBottom-width: 1px;--prose-th-textAlign: inherit;--prose-thead-borderBottom-style: solid;--prose-thead-borderBottom-width: 1px;--prose-thead-border-style: solid;--prose-thead-border-width: 0px;--prose-table-textAlign: start;--prose-hr-width: 1px;--prose-hr-style: solid;--prose-li-listStylePosition: outside;--prose-ol-li-markerColor: currentColor;--prose-ol-paddingInlineStart: 21px;--prose-ol-listStyleType: decimal;--prose-ul-li-markerColor: currentColor;--prose-ul-paddingInlineStart: 21px;--prose-ul-listStyleType: disc;--prose-blockquote-border-style: solid;--prose-blockquote-border-width: 4px;--prose-blockquote-quotes: '201C' '201D' '2018' '2019';--prose-blockquote-paddingInlineStart: 24px;--prose-a-code-color-hover: currentColor;--prose-a-code-color-static: currentColor;--prose-a-hasCode-borderBottom: none;--prose-a-border-distance: 2px;--prose-a-border-color-hover: currentColor;--prose-a-border-color-static: currentColor;--prose-a-border-style-hover: solid;--prose-a-border-style-static: dashed;--prose-a-border-width: 1px;--prose-a-color-static: inherit;--prose-a-textDecoration: none;--prose-h6-margin: 3rem 0 2rem;--prose-h5-margin: 3rem 0 2rem;--prose-h4-margin: 3rem 0 2rem;--prose-h3-margin: 3rem 0 2rem;--prose-h2-margin: 3rem 0 2rem;--prose-h1-margin: 0 0 2rem;--prose-p-fontSize: 18px;--typography-lead-loose: 2;--typography-lead-relaxed: 1.625;--typography-lead-normal: 1.5;--typography-lead-snug: 1.375;--typography-lead-tight: 1.25;--typography-lead-none: 1;--typography-lead-10: 2.5rem;--typography-lead-9: 2.25rem;--typography-lead-8: 2rem;--typography-lead-7: 1.75rem;--typography-lead-6: 1.5rem;--typography-lead-5: 1.25rem;--typography-lead-4: 1rem;--typography-lead-3: .75rem;--typography-lead-2: .5rem;--typography-lead-1: .025rem;--typography-fontWeight-black: 900;--typography-fontWeight-extrabold: 800;--typography-fontWeight-bold: 700;--typography-fontWeight-semibold: 600;--typography-fontWeight-medium: 500;--typography-fontWeight-normal: 400;--typography-fontWeight-light: 300;--typography-fontWeight-extralight: 200;--typography-fontWeight-thin: 100;--typography-fontSize-9xl: 128px;--typography-fontSize-8xl: 96px;--typography-fontSize-7xl: 72px;--typography-fontSize-6xl: 60px;--typography-fontSize-5xl: 48px;--typography-fontSize-4xl: 36px;--typography-fontSize-3xl: 30px;--typography-fontSize-2xl: 24px;--typography-fontSize-xl: 20px;--typography-fontSize-lg: 18px;--typography-fontSize-base: 16px;--typography-fontSize-sm: 14px;--typography-fontSize-xs: 12px;--typography-letterSpacing-wide: 0.025em;--typography-letterSpacing-tight: -0.025em;--typography-verticalMargin-base: 24px;--typography-verticalMargin-sm: 16px;--elements-border-secondary-hover: [object Object];--elements-backdrop-background: #fffc;--elements-backdrop-filter: saturate(200%) blur(20px);--elements-container-maxWidth: 64rem;--lead-loose: 2;--lead-relaxed: 1.625;--lead-normal: 1.5;--lead-snug: 1.375;--lead-tight: 1.25;--lead-none: 1;--lead-10: 2.5rem;--lead-9: 2.25rem;--lead-8: 2rem;--lead-7: 1.75rem;--lead-6: 1.5rem;--lead-5: 1.25rem;--lead-4: 1rem;--lead-3: .75rem;--lead-2: .5rem;--lead-1: .025rem;--letterSpacing-widest: 0.1em;--letterSpacing-wider: 0.05em;--letterSpacing-wide: 0.025em;--letterSpacing-normal: 0em;--letterSpacing-tight: -0.025em;--letterSpacing-tighter: -0.05em;--fontSize-9xl: 8rem;--fontSize-8xl: 6rem;--fontSize-7xl: 4.5rem;--fontSize-6xl: 3.75rem;--fontSize-5xl: 3rem;--fontSize-4xl: 2.25rem;--fontSize-3xl: 1.875rem;--fontSize-2xl: 1.5rem;--fontSize-xl: 1.25rem;--fontSize-lg: 1.125rem;--fontSize-base: 1rem;--fontSize-sm: 0.875rem;--fontSize-xs: 0.75rem;--fontWeight-black: 900;--fontWeight-extrabold: 800;--fontWeight-bold: 700;--fontWeight-semibold: 600;--fontWeight-medium: 500;--fontWeight-normal: 400;--fontWeight-light: 300;--fontWeight-extralight: 200;--fontWeight-thin: 100;--font-mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, Liberation Mono, Courier New, monospace;--font-serif: ui-serif, Georgia, Cambria, Times New Roman, Times, serif;--font-sans: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Noto Sans, sans-serif, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, Noto Color Emoji;--opacity-total: 1;--opacity-high: 0.8;--opacity-medium: 0.5;--opacity-soft: 0.3;--opacity-light: 0.15;--opacity-bright: 0.1;--opacity-noOpacity: 0;--borderWidth-lg: 3px;--borderWidth-md: 2px;--borderWidth-sm: 1px;--borderWidth-noBorder: 0;--space-rem-875: 0.875rem;--space-rem-625: 0.625rem;--space-rem-375: 0.375rem;--space-rem-125: 0.125rem;--space-px: 1px;--space-128: 32rem;--space-96: 24rem;--space-80: 20rem;--space-72: 18rem;--space-64: 16rem;--space-60: 15rem;--space-56: 14rem;--space-52: 13rem;--space-48: 12rem;--space-44: 11rem;--space-40: 10rem;--space-36: 9rem;--space-32: 8rem;--space-28: 7rem;--space-24: 6rem;--space-20: 5rem;--space-16: 4rem;--space-14: 3.5rem;--space-12: 3rem;--space-11: 2.75rem;--space-10: 2.5rem;--space-9: 2.25rem;--space-8: 2rem;--space-7: 1.75rem;--space-6: 1.5rem;--space-5: 1.25rem;--space-4: 1rem;--space-3: 0.75rem;--space-2: 0.5rem;--space-1: 0.25rem;--space-0: 0px;--size-full: 100%;--size-7xl: 80rem;--size-6xl: 72rem;--size-5xl: 64rem;--size-4xl: 56rem;--size-3xl: 48rem;--size-2xl: 42rem;--size-xl: 36rem;--size-lg: 32rem;--size-md: 28rem;--size-sm: 24rem;--size-xs: 20rem;--size-200: 200px;--size-104: 104px;--size-80: 80px;--size-64: 64px;--size-56: 56px;--size-48: 48px;--size-40: 40px;--size-32: 32px;--size-24: 24px;--size-20: 20px;--size-16: 16px;--size-12: 12px;--size-8: 8px;--size-6: 6px;--size-4: 4px;--size-2: 2px;--size-0: 0px;--radii-full: 9999px;--radii-3xl: 1.75rem;--radii-2xl: 1.5rem;--radii-xl: 1rem;--radii-lg: 0.75rem;--radii-md: 0.5rem;--radii-sm: 0.375rem;--radii-xs: 0.25rem;--radii-2xs: 0.125rem;--radii-none: 0px;--shadow-none: 0px 0px 0px 0px transparent;--shadow-lg: 0px 10px 15px -3px #000000, 0px 4px 6px -4px #000000;--shadow-md: 0px 4px 6px -1px #000000, 0px 2px 4px -2px #000000;--shadow-sm: 0px 1px 3px 0px #000000, 0px 1px 2px -1px #000000;--shadow-xs: 0px 1px 2px 0px #000000;--height-screen: 100vh;--width-screen: 100vw;--color-primary-900: #002e38;--color-primary-800: #005c70;--color-primary-700: #008aa9;--color-primary-600: #00b9e1;--color-primary-500: #1ad6ff;--color-primary-400: #40ddff;--color-primary-300: #66e4ff;--color-primary-200: #8deaff;--color-primary-100: #b3f1ff;--color-primary-50: #d9f8ff;--color-ruby-900: #380011;--color-ruby-800: #700021;--color-ruby-700: #a90032;--color-ruby-600: #e10043;--color-ruby-500: #ff1a5e;--color-ruby-400: #ff4079;--color-ruby-300: #ff6694;--color-ruby-200: #ff8dae;--color-ruby-100: #ffb3c9;--color-ruby-50: #ffd9e4;--color-pink-900: #380025;--color-pink-800: #70004b;--color-pink-700: #a90070;--color-pink-600: #e10095;--color-pink-500: #ff1ab2;--color-pink-400: #ff40bf;--color-pink-300: #ff66cc;--color-pink-200: #ff8dd8;--color-pink-100: #ffb3e5;--color-pink-50: #ffd9f2;--color-purple-900: #190038;--color-purple-800: #330070;--color-purple-700: #4c00a9;--color-purple-600: #6500e1;--color-purple-500: #811aff;--color-purple-400: #9640ff;--color-purple-300: #ab66ff;--color-purple-200: #c08dff;--color-purple-100: #d5b3ff;--color-purple-50: #ead9ff;--color-royalblue-900: #0b0531;--color-royalblue-800: #160a62;--color-royalblue-700: #211093;--color-royalblue-600: #2c15c4;--color-royalblue-500: #4127e8;--color-royalblue-400: #614bec;--color-royalblue-300: #806ff0;--color-royalblue-200: #a093f3;--color-royalblue-100: #c0b7f7;--color-royalblue-50: #dfdbfb;--color-indigoblue-900: #001238;--color-indigoblue-800: #002370;--color-indigoblue-700: #0035a9;--color-indigoblue-600: #0047e1;--color-indigoblue-500: #1a62ff;--color-indigoblue-400: #407cff;--color-indigoblue-300: #6696ff;--color-indigoblue-200: #8db0ff;--color-indigoblue-100: #b3cbff;--color-indigoblue-50: #d9e5ff;--color-blue-900: #002438;--color-blue-800: #004870;--color-blue-700: #006ca9;--color-blue-600: #0090e1;--color-blue-500: #1aadff;--color-blue-400: #40bbff;--color-blue-300: #66c8ff;--color-blue-200: #8dd6ff;--color-blue-100: #b3e4ff;--color-blue-50: #d9f1ff;--color-lightblue-900: #002e38;--color-lightblue-800: #005c70;--color-lightblue-700: #008aa9;--color-lightblue-600: #00b9e1;--color-lightblue-500: #1ad6ff;--color-lightblue-400: #40ddff;--color-lightblue-300: #66e4ff;--color-lightblue-200: #8deaff;--color-lightblue-100: #b3f1ff;--color-lightblue-50: #d9f8ff;--color-teal-900: #062a28;--color-teal-800: #0b544f;--color-teal-700: #117d77;--color-teal-600: #16a79e;--color-teal-500: #1cd1c6;--color-teal-400: #36e4da;--color-teal-300: #5fe9e1;--color-teal-200: #87efe9;--color-teal-100: #aff4f0;--color-teal-50: #d7faf8;--color-pear-900: #2a2b09;--color-pear-800: #545512;--color-pear-700: #7e801b;--color-pear-600: #a8aa24;--color-pear-500: #d0d32f;--color-pear-400: #d8da52;--color-pear-300: #e0e274;--color-pear-200: #e8e997;--color-pear-100: #eff0ba;--color-pear-50: #f7f8dc;--color-red-900: #380300;--color-red-800: #700700;--color-red-700: #a90a00;--color-red-600: #e10e00;--color-red-500: #ff281a;--color-red-400: #ff4c40;--color-red-300: #ff7066;--color-red-200: #ff948d;--color-red-100: #ffb7b3;--color-red-50: #ffdbd9;--color-orange-900: #381800;--color-orange-800: #702f00;--color-orange-700: #a94700;--color-orange-600: #e15e00;--color-orange-500: #ff7a1a;--color-orange-400: #ff9040;--color-orange-300: #ffa666;--color-orange-200: #ffbd8d;--color-orange-100: #ffd3b3;--color-orange-50: #ffe9d9;--color-yellow-900: #362b03;--color-yellow-800: #6d5605;--color-yellow-700: #a38108;--color-yellow-600: #daac0a;--color-yellow-500: #f5c828;--color-yellow-400: #f7d14c;--color-yellow-300: #f8da70;--color-yellow-200: #fae393;--color-yellow-100: #fcedb7;--color-yellow-50: #fdf6db;--color-green-900: #003f25;--color-green-800: #005e38;--color-green-700: #007e4a;--color-green-600: #009d5d;--color-green-500: #00bd6f;--color-green-400: #00dc82;--color-green-300: #30ffaa;--color-green-200: #83ffcc;--color-green-100: #acffdd;--color-green-50: #d6ffee;--color-gray-900: #18181B;--color-gray-800: #27272A;--color-gray-700: #3f3f46;--color-gray-600: #52525B;--color-gray-500: #71717A;--color-gray-400: #a1a1aa;--color-gray-300: #D4d4d8;--color-gray-200: #e4e4e7;--color-gray-100: #f4f4f5;--color-gray-50: #fafafa;--color-black: #0c0c0d;--color-white: #FFFFFF;--media-portrait: only screen and (orientation: portrait);--media-landscape: only screen and (orientation: landscape);--media-rm: (prefers-reduced-motion: reduce);--media-2xl: (min-width: 1536px);--media-xl: (min-width: 1280px);--media-lg: (min-width: 1024px);--media-md: (min-width: 768px);--media-sm: (min-width: 640px);--media-xs: (min-width: 475px);--alpine-body-color: var(--color-gray-800);--alpine-body-backgroundColor: var(--color-white);--prose-code-inline-fontWeight: var(--typography-fontWeight-normal);--prose-code-inline-fontSize: var(--typography-fontSize-sm);--prose-code-inline-borderRadius: var(--radii-xs);--prose-code-block-pre-padding: var(--typography-verticalMargin-sm);--prose-code-block-margin: var(--typography-verticalMargin-base) 0;--prose-code-block-fontSize: var(--typography-fontSize-sm);--prose-tbody-code-inline-fontSize: var(--typography-fontSize-sm);--prose-tbody-td-padding: var(--typography-verticalMargin-sm);--prose-th-fontWeight: var(--typography-fontWeight-semibold);--prose-th-padding: 0 var(--typography-verticalMargin-sm) var(--typography-verticalMargin-sm) var(--typography-verticalMargin-sm);--prose-table-lineHeight: var(--typography-lead-6);--prose-table-fontSize: var(--typography-fontSize-sm);--prose-table-margin: var(--typography-verticalMargin-base) 0;--prose-hr-margin: var(--typography-verticalMargin-base) 0;--prose-li-margin: var(--typography-verticalMargin-sm) 0;--prose-ol-margin: var(--typography-verticalMargin-base) 0;--prose-ul-margin: var(--typography-verticalMargin-base) 0;--prose-blockquote-margin: var(--typography-verticalMargin-base) 0;--prose-a-code-border-style: var(--prose-a-border-style-static);--prose-a-code-border-width: var(--prose-a-border-width);--prose-a-fontWeight: var(--typography-fontWeight-medium);--prose-img-margin: var(--typography-verticalMargin-base) 0;--prose-strong-fontWeight: var(--typography-fontWeight-semibold);--prose-h6-iconSize: var(--typography-fontSize-base);--prose-h6-fontWeight: var(--typography-fontWeight-semibold);--prose-h6-lineHeight: var(--typography-lead-normal);--prose-h6-fontSize: var(--typography-fontSize-lg);--prose-h5-iconSize: var(--typography-fontSize-lg);--prose-h5-fontWeight: var(--typography-fontWeight-semibold);--prose-h5-lineHeight: var(--typography-lead-snug);--prose-h5-fontSize: var(--typography-fontSize-xl);--prose-h4-iconSize: var(--typography-fontSize-lg);--prose-h4-letterSpacing: var(--typography-letterSpacing-tight);--prose-h4-fontWeight: var(--typography-fontWeight-semibold);--prose-h4-lineHeight: var(--typography-lead-snug);--prose-h4-fontSize: var(--typography-fontSize-2xl);--prose-h3-iconSize: var(--typography-fontSize-xl);--prose-h3-letterSpacing: var(--typography-letterSpacing-tight);--prose-h3-fontWeight: var(--typography-fontWeight-semibold);--prose-h3-lineHeight: var(--typography-lead-snug);--prose-h3-fontSize: var(--typography-fontSize-3xl);--prose-h2-iconSize: var(--typography-fontSize-2xl);--prose-h2-letterSpacing: var(--typography-letterSpacing-tight);--prose-h2-fontWeight: var(--typography-fontWeight-semibold);--prose-h2-lineHeight: var(--typography-lead-tight);--prose-h2-fontSize: var(--typography-fontSize-4xl);--prose-h1-iconSize: var(--typography-fontSize-3xl);--prose-h1-letterSpacing: var(--typography-letterSpacing-tight);--prose-h1-fontWeight: var(--typography-fontWeight-bold);--prose-h1-lineHeight: var(--typography-lead-tight);--prose-h1-fontSize: var(--typography-fontSize-5xl);--prose-p-br-margin: var(--typography-verticalMargin-base) 0 0 0;--prose-p-margin: var(--typography-verticalMargin-base) 0;--prose-p-lineHeight: var(--typography-lead-normal);--typography-color-primary-900: var(--color-primary-900);--typography-color-primary-800: var(--color-primary-800);--typography-color-primary-700: var(--color-primary-700);--typography-color-primary-600: var(--color-primary-600);--typography-color-primary-500: var(--color-primary-500);--typography-color-primary-400: var(--color-primary-400);--typography-color-primary-300: var(--color-primary-300);--typography-color-primary-200: var(--color-primary-200);--typography-color-primary-100: var(--color-primary-100);--typography-color-primary-50: var(--color-primary-50);--typography-font-code: var(--font-mono);--typography-font-body: var(--font-sans);--typography-font-display: var(--font-sans);--typography-body-backgroundColor: var(--color-white);--typography-body-color: var(--color-black);--elements-state-danger-borderColor-secondary: var(--color-red-200);--elements-state-danger-borderColor-primary: var(--color-red-100);--elements-state-danger-backgroundColor-secondary: var(--color-red-100);--elements-state-danger-backgroundColor-primary: var(--color-red-50);--elements-state-danger-color-secondary: var(--color-red-600);--elements-state-danger-color-primary: var(--color-red-500);--elements-state-warning-borderColor-secondary: var(--color-yellow-200);--elements-state-warning-borderColor-primary: var(--color-yellow-100);--elements-state-warning-backgroundColor-secondary: var(--color-yellow-100);--elements-state-warning-backgroundColor-primary: var(--color-yellow-50);--elements-state-warning-color-secondary: var(--color-yellow-700);--elements-state-warning-color-primary: var(--color-yellow-600);--elements-state-success-borderColor-secondary: var(--color-green-200);--elements-state-success-borderColor-primary: var(--color-green-100);--elements-state-success-backgroundColor-secondary: var(--color-green-100);--elements-state-success-backgroundColor-primary: var(--color-green-50);--elements-state-success-color-secondary: var(--color-green-600);--elements-state-success-color-primary: var(--color-green-500);--elements-state-info-borderColor-secondary: var(--color-blue-200);--elements-state-info-borderColor-primary: var(--color-blue-100);--elements-state-info-backgroundColor-secondary: var(--color-blue-100);--elements-state-info-backgroundColor-primary: var(--color-blue-50);--elements-state-info-color-secondary: var(--color-blue-600);--elements-state-info-color-primary: var(--color-blue-500);--elements-state-primary-borderColor-secondary: var(--color-primary-200);--elements-state-primary-borderColor-primary: var(--color-primary-100);--elements-state-primary-backgroundColor-secondary: var(--color-primary-100);--elements-state-primary-backgroundColor-primary: var(--color-primary-50);--elements-state-primary-color-secondary: var(--color-primary-700);--elements-state-primary-color-primary: var(--color-primary-600);--elements-surface-secondary-backgroundColor: var(--color-gray-200);--elements-surface-primary-backgroundColor: var(--color-gray-100);--elements-surface-background-base: var(--color-gray-100);--elements-border-secondary-static: var(--color-gray-200);--elements-border-primary-hover: var(--color-gray-200);--elements-border-primary-static: var(--color-gray-100);--elements-container-padding-md: var(--space-16);--elements-container-padding-sm: var(--space-12);--elements-container-padding-xs: var(--space-8);--elements-container-padding-mobile: var(--space-6);--elements-text-secondary-color-hover: var(--color-gray-700);--elements-text-secondary-color-static: var(--color-gray-500);--elements-text-primary-color-static: var(--color-gray-900);--text-6xl-lineHeight: var(--lead-none);--text-6xl-fontSize: var(--fontSize-6xl);--text-5xl-lineHeight: var(--lead-none);--text-5xl-fontSize: var(--fontSize-5xl);--text-4xl-lineHeight: var(--lead-10);--text-4xl-fontSize: var(--fontSize-4xl);--text-3xl-lineHeight: var(--lead-9);--text-3xl-fontSize: var(--fontSize-3xl);--text-2xl-lineHeight: var(--lead-8);--text-2xl-fontSize: var(--fontSize-2xl);--text-xl-lineHeight: var(--lead-7);--text-xl-fontSize: var(--fontSize-xl);--text-lg-lineHeight: var(--lead-7);--text-lg-fontSize: var(--fontSize-lg);--text-base-lineHeight: var(--lead-6);--text-base-fontSize: var(--fontSize-base);--text-sm-lineHeight: var(--lead-5);--text-sm-fontSize: var(--fontSize-sm);--text-xs-lineHeight: var(--lead-4);--text-xs-fontSize: var(--fontSize-xs);--shadow-2xl: 0px 25px 50px -12px var(--color-gray-900);--shadow-xl: 0px 20px 25px -5px var(--color-gray-400), 0px 8px 10px -6px #000000;--color-secondary-900: var(--color-gray-900);--color-secondary-800: var(--color-gray-800);--color-secondary-700: var(--color-gray-700);--color-secondary-600: var(--color-gray-600);--color-secondary-500: var(--color-gray-500);--color-secondary-400: var(--color-gray-400);--color-secondary-300: var(--color-gray-300);--color-secondary-200: var(--color-gray-200);--color-secondary-100: var(--color-gray-100);--color-secondary-50: var(--color-gray-50);--prose-a-code-background-hover: var(--typography-color-primary-50);--prose-a-code-border-color-hover: var(--typography-color-primary-500);--prose-a-color-hover: var(--typography-color-primary-500);--typography-color-secondary-900: var(--color-secondary-900);--typography-color-secondary-800: var(--color-secondary-800);--typography-color-secondary-700: var(--color-secondary-700);--typography-color-secondary-600: var(--color-secondary-600);--typography-color-secondary-500: var(--color-secondary-500);--typography-color-secondary-400: var(--color-secondary-400);--typography-color-secondary-300: var(--color-secondary-300);--typography-color-secondary-200: var(--color-secondary-200);--typography-color-secondary-100: var(--color-secondary-100);--typography-color-secondary-50: var(--color-secondary-50);--prose-code-inline-backgroundColor: var(--typography-color-secondary-100);--prose-code-inline-color: var(--typography-color-secondary-700);--prose-code-block-backgroundColor: var(--typography-color-secondary-100);--prose-code-block-color: var(--typography-color-secondary-700);--prose-code-block-border-color: var(--typography-color-secondary-200);--prose-tbody-tr-borderBottom-color: var(--typography-color-secondary-200);--prose-th-color: var(--typography-color-secondary-600);--prose-thead-borderBottom-color: var(--typography-color-secondary-200);--prose-thead-border-color: var(--typography-color-secondary-300);--prose-hr-color: var(--typography-color-secondary-200);--prose-blockquote-border-color: var(--typography-color-secondary-200);--prose-blockquote-color: var(--typography-color-secondary-500);--prose-a-code-border-color-static: var(--typography-color-secondary-400); } }@media { :root.dark {--pinceau-mq: dark; --alpine-backdrop-backgroundColor: #18181bb3;--prose-code-block-backdropFilter: contrast(1);--prose-ol-li-markerColor: currentColor;--prose-ul-li-markerColor: currentColor;--prose-a-code-color-hover: currentColor;--prose-a-code-color-static: currentColor;--prose-a-border-color-hover: currentColor;--prose-a-border-color-static: currentColor;--prose-a-color-static: inherit;--elements-backdrop-background: #0c0d0ccc;--alpine-body-color: var(--color-gray-200);--alpine-body-backgroundColor: var(--color-black);--typography-body-backgroundColor: var(--color-black);--typography-body-color: var(--color-white);--elements-state-danger-borderColor-secondary: var(--color-red-700);--elements-state-danger-borderColor-primary: var(--color-red-800);--elements-state-danger-backgroundColor-secondary: var(--color-red-800);--elements-state-danger-backgroundColor-primary: var(--color-red-900);--elements-state-danger-color-secondary: var(--color-red-200);--elements-state-danger-color-primary: var(--color-red-300);--elements-state-warning-borderColor-secondary: var(--color-yellow-700);--elements-state-warning-borderColor-primary: var(--color-yellow-800);--elements-state-warning-backgroundColor-secondary: var(--color-yellow-800);--elements-state-warning-backgroundColor-primary: var(--color-yellow-900);--elements-state-warning-color-secondary: var(--color-yellow-200);--elements-state-warning-color-primary: var(--color-yellow-400);--elements-state-success-borderColor-secondary: var(--color-green-700);--elements-state-success-borderColor-primary: var(--color-green-800);--elements-state-success-backgroundColor-secondary: var(--color-green-800);--elements-state-success-backgroundColor-primary: var(--color-green-900);--elements-state-success-color-secondary: var(--color-green-200);--elements-state-success-color-primary: var(--color-green-400);--elements-state-info-borderColor-secondary: var(--color-blue-700);--elements-state-info-borderColor-primary: var(--color-blue-800);--elements-state-info-backgroundColor-secondary: var(--color-blue-800);--elements-state-info-backgroundColor-primary: var(--color-blue-900);--elements-state-info-color-secondary: var(--color-blue-200);--elements-state-info-color-primary: var(--color-blue-400);--elements-state-primary-borderColor-secondary: var(--color-primary-700);--elements-state-primary-borderColor-primary: var(--color-primary-800);--elements-state-primary-backgroundColor-secondary: var(--color-primary-800);--elements-state-primary-backgroundColor-primary: var(--color-primary-900);--elements-state-primary-color-secondary: var(--color-primary-200);--elements-state-primary-color-primary: var(--color-primary-400);--elements-surface-secondary-backgroundColor: var(--color-gray-800);--elements-surface-primary-backgroundColor: var(--color-gray-900);--elements-surface-background-base: var(--color-gray-900);--elements-border-secondary-static: var(--color-gray-800);--elements-border-primary-hover: var(--color-gray-800);--elements-border-primary-static: var(--color-gray-900);--elements-text-secondary-color-hover: var(--color-gray-200);--elements-text-secondary-color-static: var(--color-gray-400);--elements-text-primary-color-static: var(--color-gray-50);--prose-a-code-background-hover: var(--typography-color-primary-900);--prose-a-code-border-color-hover: var(--typography-color-primary-600);--prose-a-color-hover: var(--typography-color-primary-400);--prose-code-inline-backgroundColor: var(--typography-color-secondary-800);--prose-code-inline-color: var(--typography-color-secondary-200);--prose-code-block-backgroundColor: var(--typography-color-secondary-900);--prose-code-block-color: var(--typography-color-secondary-200);--prose-code-block-border-color: var(--typography-color-secondary-800);--prose-tbody-tr-borderBottom-color: var(--typography-color-secondary-800);--prose-th-color: var(--typography-color-secondary-400);--prose-thead-borderBottom-color: var(--typography-color-secondary-800);--prose-thead-border-color: var(--typography-color-secondary-600);--prose-hr-color: var(--typography-color-secondary-800);--prose-blockquote-border-color: var(--typography-color-secondary-700);--prose-blockquote-color: var(--typography-color-secondary-400);--prose-a-code-border-color-static: var(--typography-color-secondary-600); } }</style><script>"use strict";(()=>{const a=window,e=document.documentElement,m=["dark","light"],c=window.localStorage.getItem("nuxt-color-mode")||"system";let n=c==="system"?f():c;const l=e.getAttribute("data-color-mode-forced");l&&(n=l),i(n),a["__NUXT_COLOR_MODE__"]={preference:c,value:n,getColorScheme:f,addColorScheme:i,removeColorScheme:d};function i(o){const t=""+o+"",s="";e.classList?e.classList.add(t):e.className+=" "+t,s&&e.setAttribute("data-"+s,o)}function d(o){const t=""+o+"",s="";e.classList?e.classList.remove(t):e.className=e.className.replace(new RegExp(t,"g"),""),s&&e.removeAttribute("data-"+s)}function r(o){return a.matchMedia("(prefers-color-scheme"+o+")")}function f(){if(a.matchMedia&&r("").media!=="not all"){for(const o of m)if(r(":"+o).matches)return o}return"light"}})();
</script></head>
<body ><div id="__nuxt"><div class="container pv-oj_SrG pc-4wQQMs app-layout" data-v-93c22c3b data-v-6d327d86><!--[--><div class="nuxt-progress" style="width:0%;height:3px;opacity:0;background-size:Infinity% auto;" data-v-93c22c3b></div><header class="left" data-v-93c22c3b data-v-ebfd1e7c><div class="menu" data-v-ebfd1e7c><button aria-label="Navigation Menu" data-v-ebfd1e7c><svg width="24" height="24" viewBox="0 0 68 68" fill="currentColor" xmlns="http://www.w3.org/2000/svg" data-v-ebfd1e7c><path d="M8 34C8 32.1362 8 31.2044 8.30448 30.4693C8.71046 29.4892 9.48915 28.7105 10.4693 28.3045C11.2044 28 12.1362 28 14 28C15.8638 28 16.7956 28 17.5307 28.3045C18.5108 28.7105 19.2895 29.4892 19.6955 30.4693C20 31.2044 20 32.1362 20 34C20 35.8638 20 36.7956 19.6955 37.5307C19.2895 38.5108 18.5108 39.2895 17.5307 39.6955C16.7956 40 15.8638 40 14 40C12.1362 40 11.2044 40 10.4693 39.6955C9.48915 39.2895 8.71046 38.5108 8.30448 37.5307C8 36.7956 8 35.8638 8 34Z" data-v-ebfd1e7c></path><path d="M28 34C28 32.1362 28 31.2044 28.3045 30.4693C28.7105 29.4892 29.4892 28.7105 30.4693 28.3045C31.2044 28 32.1362 28 34 28C35.8638 28 36.7956 28 37.5307 28.3045C38.5108 28.7105 39.2895 29.4892 39.6955 30.4693C40 31.2044 40 32.1362 40 34C40 35.8638 40 36.7956 39.6955 37.5307C39.2895 38.5108 38.5108 39.2895 37.5307 39.6955C36.7956 40 35.8638 40 34 40C32.1362 40 31.2044 40 30.4693 39.6955C29.4892 39.2895 28.7105 38.5108 28.3045 37.5307C28 36.7956 28 35.8638 28 34Z" data-v-ebfd1e7c></path><path d="M48 34C48 32.1362 48 31.2044 48.3045 30.4693C48.7105 29.4892 49.4892 28.7105 50.4693 28.3045C51.2044 28 52.1362 28 54 28C55.8638 28 56.7956 28 57.5307 28.3045C58.5108 28.7105 59.2895 29.4892 59.6955 30.4693C60 31.2044 60 32.1362 60 34C60 35.8638 60 36.7956 59.6955 37.5307C59.2895 38.5108 58.5108 39.2895 57.5307 39.6955C56.7956 40 55.8638 40 54 40C52.1362 40 51.2044 40 50.4693 39.6955C49.4892 39.2895 48.7105 38.5108 48.3045 37.5307C48 36.7956 48 35.8638 48 34Z" data-v-ebfd1e7c></path></svg></button></div><div class="overlay" data-v-ebfd1e7c><nav data-v-ebfd1e7c data-v-47e45ff0><ul data-v-47e45ff0><!--[--><li data-v-47e45ff0><a href="/" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> About</a></li><li data-v-47e45ff0><a href="/articles" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> Articles</a></li><li data-v-47e45ff0><a href="/contact" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> Contact</a></li><!--]--></ul></nav></div><div class="logo" data-v-ebfd1e7c><a href="/" class="" data-v-ebfd1e7c><img src="/logo-dark.svg" class="dark-img" alt="alpine" width="89" height="31" data-v-ebfd1e7c><img src="/logo.svg" class="light-img" alt="alpine" width="89" height="31" data-v-ebfd1e7c></a></div><div class="main-nav" data-v-ebfd1e7c><nav data-v-ebfd1e7c data-v-47e45ff0><ul data-v-47e45ff0><!--[--><li data-v-47e45ff0><a href="/" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> About</a></li><li data-v-47e45ff0><a href="/articles" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> Articles</a></li><li data-v-47e45ff0><a href="/contact" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> Contact</a></li><!--]--></ul></nav></div></header><!--[--><div class="document-driven-page"><article data-v-f252e39d><a href="/articles" class="back" data-v-f252e39d><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-f252e39d style="" width="1em" height="1em" viewBox="0 0 256 256" data-v-121c6e7d><path fill="currentColor" d="M224 128a8 8 0 0 1-8 8H59.31l58.35 58.34a8 8 0 0 1-11.32 11.32l-72-72a8 8 0 0 1 0-11.32l72-72a8 8 0 0 1 11.32 11.32L59.31 120H216a8 8 0 0 1 8 8Z"/></svg><span data-v-f252e39d> Back </span></a><header data-v-f252e39d><h1 class="title" data-v-f252e39d>Meta-Learning explained</h1><time datetime="2022-11-21T00:00:00.000Z" data-v-f252e39d>November 21, 2022</time></header><div class="prose" data-v-f252e39d><!--[--><div><h1 id="meta-learning-explained" data-v-a5759516><a aria-current="page" href="/articles/2022-11-21-meta-learning#meta-learning-explained" class="router-link-active router-link-exact-active" data-v-a5759516><!--[--><strong data-v-9d7bd52e><!--[-->Meta-Learning explained<!--]--></strong><!--]--><!----></a></h1><h2 id="what-will-be-reviewed" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#what-will-be-reviewed" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->What will be reviewed<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[-->In this first post (aside from the Welcome one) I will expose a brief summary of <strong data-v-9d7bd52e><!--[-->Meta-Learning<!--]--></strong>. It was one of the topics I researched for <a href="https://upcommons.upc.edu/bitstream/handle/2117/179428/cMas.pdf;jsessionid=18807FB3EE2D5343E5F0DF9A5BA37D7F?sequence=1" rel="nofollow" data-v-af1c0c3b><!--[-->my Master&#39;s dissertation<!--]--></a> (and one of the main topics I actually developed it about) and since then, one of the topics I am more interested in.<!--]--></p><p data-v-63bfa697><!--[-->As you will see, the summary will not be the latest trend, because I want to give it a more <strong data-v-9d7bd52e><!--[-->historical explanation<!--]--></strong>. The <strong data-v-9d7bd52e><!--[-->State of the Art may be reviewed in a different post<!--]--></strong>. Instead, this post will focus on taking an interesting <strong data-v-9d7bd52e><!--[-->tour along the Meta-Learning evolution<!--]--></strong> and understanding the <strong data-v-9d7bd52e><!--[-->context<!--]--></strong> to build more efficiently in the future.<!--]--></p><p data-v-63bfa697><!--[-->No need to say, but the content does not end at this post. You can contact me at <a href="/articles/i.masmend@gmail.com" class="" data-v-af1c0c3b><!--[-->my mail<!--]--></a> (info is also below in the blog) if you have any doubt or suggestion and I&#39;ll be happy to discuss.<!--]--></p><h2 id="what-is-meta-learning" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#what-is-meta-learning" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->What is Meta-Learning?<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[-->Any <strong data-v-9d7bd52e><!--[-->task or process<!--]--></strong> can involve a <strong data-v-9d7bd52e><!--[-->process of learning<!--]--></strong> in order to <strong data-v-9d7bd52e><!--[-->improve performance<!--]--></strong> in it. Systems are no strangers to this, for example, imagine a system that has to perform some kind of face identification. The system will perform better when it has lived a learning process before. Well, that is exactly the point of Machine Learning, isn&#39;t it? But let&#39;s switch the focus. <strong data-v-9d7bd52e><!--[-->Learning itself is a process<!--]--></strong>. So according to the previous statement, it <strong data-v-9d7bd52e><!--[-->can also be learned<!--]--></strong>. And this is the exact <strong data-v-9d7bd52e><!--[-->definition of Meta-Learning: Learning to Learn<!--]--></strong>.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/Wc5zMl2.png" alt data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->| <b>Meme, credits to <a href="https://twitter.com/joavanschoren" rel="nofollow" data-v-af1c0c3b><!--[-->@joavanschoren<!--]--></a>... but I cut out the end since it contained a spoiler of content in the post below</b> |<!--]--></p><p data-v-63bfa697><!--[-->From another perspective, we <strong data-v-9d7bd52e><!--[-->humans do not learn most things from scratch<!--]--></strong>. For example, if I present you with a <strong data-v-9d7bd52e><!--[-->new bird species<!--]--></strong> (unknown to you) and tell you <strong data-v-9d7bd52e><!--[-->&quot;Have you seen this bird?&quot;<!--]--></strong> you will probably <strong data-v-9d7bd52e><!--[-->learn its patterns with just a quick look<!--]--></strong>. This is because <strong data-v-9d7bd52e><!--[-->you have seen so many birds<!--]--></strong> in your life, and you&#39;ll directly look at the differential features (feathers color, feet, beak shape...) to absorb the information. Also, <strong data-v-9d7bd52e><!--[-->you may understand the context<!--]--></strong> (e.g. identify how does it fly with respect to the ground, wind, etc) because you already know things about this context. In contrast, if you present it to a <strong data-v-9d7bd52e><!--[-->baby<!--]--></strong>, he will <strong data-v-9d7bd52e><!--[-->not understand at all because he still has to learn everything<!--]--></strong>. Another simple example is how before analyzing a book from a literature perspective a kid has to learn how to read.<!--]--></p><p data-v-63bfa697><!--[-->Thus, <strong data-v-9d7bd52e><!--[-->Meta-Learning<!--]--></strong> is <strong data-v-9d7bd52e><!--[-->extending the Learning process to one level above<!--]--></strong>, and <strong data-v-9d7bd52e><!--[-->Learning to Learn<!--]--></strong>. And, how does that contribute? To make it simple, it makes the <strong data-v-9d7bd52e><!--[-->Learning process more efficient<!--]--></strong> (in any way, which could be faster, more stable, more qualitative...), and this allows us to overcome some important issues (we&#39;ll discuss that later). When looking at that, we could say we work at <strong data-v-9d7bd52e><!--[-->2 levels<!--]--></strong>, the <strong data-v-9d7bd52e><!--[-->Learning level<!--]--></strong> and the <strong data-v-9d7bd52e><!--[-->Meta-Learning level<!--]--></strong>. You may also note that this can be even extended one level above since Learning to Learn is another process. You are right, this can be done and we then would achieve the Meta-meta-Learning level, thus working at 3 levels. And this is also <strong data-v-9d7bd52e><!--[-->extendible to any level until infinity<!--]--></strong> (so yes, you could learn how to learn how to learn how to learn...how to learn). However, such a process is obviously limited by our capacity. We as <strong data-v-9d7bd52e><!--[-->humans, apply this at many levels<!--]--></strong>, but it is also <strong data-v-9d7bd52e><!--[-->limited by our brain capacity<!--]--></strong>. From a <strong data-v-9d7bd52e><!--[-->system<!--]--></strong> perspective, it is limited by its <strong data-v-9d7bd52e><!--[-->computational power<!--]--></strong>.<!--]--></p><p data-v-63bfa697><!--[-->So that said, how does this fit in out** Machine Learning** (ML) interest? Well, there are <strong data-v-9d7bd52e><!--[-->different ways<!--]--></strong> of applying <strong data-v-9d7bd52e><!--[-->Meta-Learning<!--]--></strong> in ML that will be reviewed in this post, but keep in mind a setting where an <strong data-v-9d7bd52e><!--[-->inner algorithm<!--]--></strong> works for a <strong data-v-9d7bd52e><!--[-->prediction task<!--]--></strong>. This algorithm learns under some <strong data-v-9d7bd52e><!--[-->conditions<!--]--></strong>, by updating some <strong data-v-9d7bd52e><!--[-->model<!--]--></strong> by some <strong data-v-9d7bd52e><!--[-->Learning Rule<!--]--></strong> depending in some <strong data-v-9d7bd52e><!--[-->data<!--]--></strong>. However, in a <strong data-v-9d7bd52e><!--[-->vanilla ML<!--]--></strong> setting this decisions are usually taken <strong data-v-9d7bd52e><!--[-->manually<!--]--></strong> and <strong data-v-9d7bd52e><!--[-->suboptimal<!--]--></strong>. In <strong data-v-9d7bd52e><!--[-->Meta-learning<!--]--></strong> there would also be an <strong data-v-9d7bd52e><!--[-->outer optimizer<!--]--></strong> whose task is to <strong data-v-9d7bd52e><!--[-->optimize these decisions<!--]--></strong>. Some ways to achieve it could be updating the Learning Rule, selecting the model (architecture or initial parameters) or rescheduling the data.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/zyRBmGS.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->Until this point, there could be a bit of <strong data-v-9d7bd52e><!--[-->confusion between Meta-Learning and other techniques<!--]--></strong>. The difference is how is the <strong data-v-9d7bd52e><!--[-->schedule<!--]--></strong> built and where is the <strong data-v-9d7bd52e><!--[-->data<!--]--></strong> taken from. In Meta-Learning the flow works as follows:<!--]--></p><blockquote data-v-40e15040><!--[--><p data-v-63bfa697><!--[-->Pretend we are aiming to solve an specific <strong data-v-9d7bd52e><!--[-->task<!--]--></strong>. This <strong data-v-9d7bd52e><!--[-->task<!--]--></strong> may be drawn from a bigger <strong data-v-9d7bd52e><!--[-->domain of tasks<!--]--></strong>. In the example below, imagine we face a binary image classification task among a series of animal classes (monkey, dog, cat, elephant, fish, snake, hippo...). For example, imagine that we in the end will end up having to classify between dogs and snakes. We want to <strong data-v-9d7bd52e><!--[-->learn how to learn<!--]--></strong> efficiently this specific task. We could define the domain as binary animal image classification tasks. The domain also includes a <strong data-v-9d7bd52e><!--[-->series of conditions<!--]--></strong> below (RGB camera images, full body, denoised, real...). Now, along all the <strong data-v-9d7bd52e><!--[-->domain<!--]--></strong> we may draw a <strong data-v-9d7bd52e><!--[-->series of tasks<!--]--></strong> different than the one we are aiming to solve. To avoid this happening we may drop both dog and snake classes from a bag with all <strong data-v-9d7bd52e><!--[-->classes<!--]--></strong>, and build <strong data-v-9d7bd52e><!--[-->tasks<!--]--></strong> by picking combinations of two classes. Thus, for each task, we will have to classify images between both classes and then that will be a binary animal image classification task. These <strong data-v-9d7bd52e><!--[-->tasks<!--]--></strong> will be <strong data-v-9d7bd52e><!--[-->equivalent<!--]--></strong> to the <strong data-v-9d7bd52e><!--[-->samples<!--]--></strong> in the <strong data-v-9d7bd52e><!--[-->Learning level<!--]--></strong> (or <strong data-v-9d7bd52e><!--[-->task level<!--]--></strong>) but in the <strong data-v-9d7bd52e><!--[-->Meta-Learning level<!--]--></strong>. So, equivalently to what we would do at the <strong data-v-9d7bd52e><!--[-->training level<!--]--></strong> we will build two <strong data-v-9d7bd52e><!--[-->(meta-)sets<!--]--></strong>. One will have <strong data-v-9d7bd52e><!--[-->Meta-training tasks<!--]--></strong> while the other <strong data-v-9d7bd52e><!--[-->Meta-test tasks<!--]--></strong>. And yeah, if you do things correctly you would also have a <strong data-v-9d7bd52e><!--[-->Meta-validation meta-set<!--]--></strong>, of course. Then, for each <strong data-v-9d7bd52e><!--[-->task<!--]--></strong> we will work as always at the <strong data-v-9d7bd52e><!--[-->Learning Level<!--]--></strong>, getting <strong data-v-9d7bd52e><!--[-->samples<!--]--></strong> for the <strong data-v-9d7bd52e><!--[-->task<!--]--></strong> and splitting them between **train, validation and test (as always). At this level, we will <strong data-v-9d7bd52e><!--[-->train the model as usual<!--]--></strong>, evaluate, etc., so we will end up having some <strong data-v-9d7bd52e><!--[-->performance measure<!--]--></strong> (usually a Loss value). These individual task results will serve in the <strong data-v-9d7bd52e><!--[-->Meta-Learning level<!--]--></strong> to <strong data-v-9d7bd52e><!--[-->evaluate the outer optimizer<!--]--></strong> and making the corresponding <strong data-v-9d7bd52e><!--[-->updates<!--]--></strong>. Below in the example, each task updates the model, but it is just an example. Actually, just like at the Learning level, it can work by batches (in this case, batches of tasks). Just good luck with your hardware limitations. Then the Meta-test meta-set is used to evaluate by any given metric.<!--]--></p><!--]--></blockquote><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/a9Fr97l.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->Note that all this process is <strong data-v-9d7bd52e><!--[-->designed from the beginning<!--]--></strong> to optimize the process of Learning in our target task. So our Meta-Learning schedule is indeed a <strong data-v-9d7bd52e><!--[-->schedule for Learning to Learn<!--]--></strong>. Any approach that falls into that definition is a Meta-Learning approach. You must also notice the difference between that and other similar techniques. For example, in <strong data-v-9d7bd52e><!--[-->Transfer Learning<!--]--></strong> (another different whole topic) you do not learn how to learn for an specific task (or a task from an specific domain), but instead <strong data-v-9d7bd52e><!--[-->use old knowledge to get closer to the optimal solution<!--]--></strong> (when you learned that old knowledge, you learned it for a whole different solution and was not intended to extend to any other different problem, thus there doesn&#39;t exist a Meta-Learning level). Some related topics are:<!--]--></p><ul data-v-5feda7b5><!--[--><li data-v-996e086c><!--[-->Transfer Learning: using old knowledge optimized to solve another task to solve the current target task.<!--]--></li><!--]--></ul><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/4kN4Xu8.png" alt="Imgur" data-v-e5a4106d><!--]--></p><ul data-v-5feda7b5><!--[--><li data-v-996e086c><!--[-->Domain adaptation: learning from a different domain with some common conditions (e.g. in our example above learning the dog vs snake task from synthetic images).<!--]--></li><!--]--></ul><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/FLTKEbi.png" alt="Imgur" data-v-e5a4106d><!--]--></p><ul data-v-5feda7b5><!--[--><li data-v-996e086c><!--[-->Multimodal Learning: learning from different modes of data (e.g. a text description), although it can be viewed from a Meta-Learning level it covers a different topic and is treated differently (since it builds a different setting).<!--]--></li><!--]--></ul><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/rTmjzmU.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->Ok, so now we have an idea of what is Meta-Learning and how to use it. But why use it? Motivations are diverse and have varied over time. Actually, one can use it whenever it is beneficial for his task. But the important question is what did raise the interest of researchers to present schedules, definitions and solutions that include Meta-Learning? To do so, we may have a quick recap of Meta-Learning history.<!--]--></p><h2 id="origins-of-meta-learning" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#origins-of-meta-learning" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->Origins of Meta-Learning<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[-->The term arose in a publication in Jrgen Schmidhuber&#39;s thesis called <a href="https://people.idsia.ch/~juergen/diploma1987ocr.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Evolutionary Principles in Self-Referential Learning<!--]--></em><!--]--></a> (1987). The paper is incredibly dense, but a mine of knowledge and talks about some deep topics such as Information, Entropy, Evolution... We may talk specifically about this paper in future posts, but what concerns us now is that it <strong data-v-9d7bd52e><!--[-->presented the idea of Meta-Learning<!--]--></strong> as a way to modify the <strong data-v-9d7bd52e><!--[-->plans<!--]--></strong> (the equivalent of what the <strong data-v-9d7bd52e><!--[-->schedulers + optimizers<!--]--></strong> in ML mean nowadays) in order to generalize to a <strong data-v-9d7bd52e><!--[-->whole group of domains<!--]--></strong>. This group is again some kind of <strong data-v-9d7bd52e><!--[-->(meta-)domain<!--]--></strong>, so it also needed some <strong data-v-9d7bd52e><!--[-->(meta-)plan<!--]--></strong>. The hypothesis that Schmidhuber did back in 1987 is that this concept was extendable to <strong data-v-9d7bd52e><!--[-->infinite levels of abstraction<!--]--></strong>, thus allowing the definition (apart from the domain level and the meta-level) of a meta-meta-level, a meta-meta-meta-level, and so on, although the paper also points the compromise that the realization has with the <strong data-v-9d7bd52e><!--[-->computation capacity of the hardware<!--]--></strong> (plus recall we are in 1987, there were no NVIDIA RTX 4090... actually <a href="https://en.wikipedia.org/wiki/GeForce_256" rel="nofollow" data-v-af1c0c3b><!--[-->the first GPU<!--]--></a> came out 12 years later). He proposed <strong data-v-9d7bd52e><!--[-->2 ways<!--]--></strong> to implement Meta-Learning:<!--]--></p><ul data-v-5feda7b5><!--[--><li data-v-996e086c><!--[-->First, as a <strong data-v-9d7bd52e><!--[-->Genetic Algorithm<!--]--></strong>. My interpretation is that he was wondering about what nowadays is <strong data-v-9d7bd52e><!--[-->Curriculum Learning<!--]--></strong>, but from a Meta-Learning perspective. He proposed that at the Meta-Level the plan should schedule the best samples for the domain level. His own concerns? About &quot;<strong data-v-9d7bd52e><!--[-->nature<!--]--></strong>&quot; (AI then aimed more to mimic true intelligence) and <strong data-v-9d7bd52e><!--[-->feasibility<!--]--></strong>.<!--]--></li><li data-v-996e086c><!--[-->Second, as a <strong data-v-9d7bd52e><!--[-->hierarchy of classifiers<!--]--></strong> building the Genetic Algorithm, which will act at the <strong data-v-9d7bd52e><!--[-->meta-level<!--]--></strong>. Schmidhuber pointed out that this way the mechanism could work with a <strong data-v-9d7bd52e><!--[-->fixed number of levels<!--]--></strong>, just the domain level (each classifier) and the meta-level (the Genetic Algorithm).<!--]--></li><!--]--></ul><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/KWobPej.png" alt="Imgur" data-v-e5a4106d><img src="https://i.imgur.com/blCSh2S.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->Another interesting interpretation from the paper is the way a plan works in a Genetic Algorithm, which is similar to the environment in <strong data-v-9d7bd52e><!--[-->Reinforcement Learning<!--]--></strong>. Thus, <strong data-v-9d7bd52e><!--[-->surviving<!--]--></strong> a plan in a Genetic Algorithm can be viewed as getting a <strong data-v-9d7bd52e><!--[-->reward<!--]--></strong> in Reinforcement Learning.<!--]--></p><p data-v-63bfa697><!--[-->5 years later, Schmidhuber made another important contribution to Meta-Learning in <a href="https://people.idsia.ch/~juergen/FKI-147-91ocr.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks<!--]--></em><!--]--></a>. He defined a series of sequential (by episodes or plain timesteps) problems. To make you an idea, one of these problems consisted in predicting the parking slot where some car parked given a series of sensor states (distributed along the parking ground) at different time instants. In this case, no episodes were used as it was an online problem (prediction was made at the same training time). Instead, a prediction network was used for the task. The particularity is that another <strong data-v-9d7bd52e><!--[-->network at a level above learned the weights updates<!--]--></strong> that the domain one should experiment. Thus, the sequence could be seen as an <strong data-v-9d7bd52e><!--[-->artificial meta-level<!--]--></strong>, while at each timestep the inner network performed the task. In the offline setting, the behavior was the same, just defining the sequence through bounded episodes. This was the <strong data-v-9d7bd52e><!--[-->first published Meta-Learning approach<!--]--></strong> that worked for <strong data-v-9d7bd52e><!--[-->practical tasks<!--]--></strong>. Surprisingly, <a href="https://imgur.com/9uvwpUb" rel="nofollow" data-v-af1c0c3b><!--[-->the word meta is missing<!--]--></a> in that paper, but the interpretation seems clear to me to give the idea of an inner and an outer model that Schmidhuber was working around at that time, isn&#39;t it? When I researched about that, <a href="https://people.idsia.ch/~juergen/metalearning.html" rel="nofollow" data-v-af1c0c3b><!--[-->Schmidhuber himself considered this as a way of Meta-Learning<!--]--></a>.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/tDtaaKC.jpg" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->But that was not the only meaningful publication of Meta-Learning in 1992. Bengio (both Samy and Yoshua) et al. published this same year the paper called <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/bengio_1995_oban.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->On the Optimization of a Synaptic Learning Rule<!--]--></em><!--]--></a>, which probably is the first definition of a <strong data-v-9d7bd52e><!--[-->Meta-Learning setting<!--]--></strong> how we imagine that nowadays (although again they do not refer to the word meta!). They just defined a framework with an <strong data-v-9d7bd52e><!--[-->inner prediction algorithm<!--]--></strong> (the previously called domain level), which actually was a <strong data-v-9d7bd52e><!--[-->Neural Network<!--]--></strong> (yes, Neural Networks existed before LeNet, didn&#39;t you know?) and was <strong data-v-9d7bd52e><!--[-->optimized through a Synaptic Learning Rule<!--]--></strong>, which again was <strong data-v-9d7bd52e><!--[-->optimized by an outer optimization algorithm<!--]--></strong> (what would be the meta-level). The point of the paper is that this Synaptic Learning Rule should be <strong data-v-9d7bd52e><!--[-->parametric<!--]--></strong>, so the outer optimizer should just <strong data-v-9d7bd52e><!--[-->update its parameters<!--]--></strong>. Thus, by defining well the episodic nature of the updates at the beginning of the whole process, the Synaptic Learning Rule should be able to learn from the task results a generalization of the whole domain of tasks.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/aw60MAG.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->For sure 1992 was an important year for Meta-Learning! It was also the year I was born, so maybe it was my destiny to study this field.<!--]--></p><p data-v-63bfa697><!--[-->Later on, Schmidhuber continued his study in Meta-Learning by extending it to <strong data-v-9d7bd52e><!--[-->Meta-Reinforcement Learning<!--]--></strong> with publications such as <a href="https://people.idsia.ch/~juergen/fki198-94.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->On learning how to learn learning strategies<!--]--></em><!--]--></a> (1994) or <a href="https://people.idsia.ch/~juergen/interest.html" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->What&#39;s interesting<!--]--></em><!--]--></a> (1997), but we will skip this part since it falls more into the domain of Reinforcement Learning. Just recall the analogy I mentioned above between Meta-Learning in Reinforcement-Learning and Meta-Learning in Genetic Algorithms. It seems he was already pointing in that direction, and that was actually one of the main trends of Meta-Learning at that time. However, another direction was the one initiated by Bengio brothers back in 1992, and that was the one that brought us to the point we are nowadays.<!--]--></p><p data-v-63bfa697><!--[-->In that sense, Hochreiter made another interesting publication in 2001, called <a href="https://www.researchgate.net/publication/225182080_Learning_To_Learn_Using_Gradient_Descent" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Learning To Learn Using Gradient Descent<!--]--></em><!--]--></a>, where they used the aforementioned paradigm of the inner prediction algorithm and the outer optimizer (of the parametric Learning Rule) and proposed that this <strong data-v-9d7bd52e><!--[-->outer optimizer should be updated by a Gradient Descent<!--]--></strong>. Oh, and finally they called that Meta-Learning. They proposed for this a task with sequences and used a Neural Network (don&#39;t be surprised, LeNet already existed) to perform the experiments. Both the inner predictor (task level) and the outer optimizer (meta-level) were RNNs. Before this publication, a similar approach was already studied called Adaptive Learning, which already used a Neural Network to optimize a learning rule. However, the setting there is different (no Meta-Learning at all).<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/8bSfzGl.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->After that, obviously more publications about Meta-Learning appeared. However, until 2015 the focus of interest in <strong data-v-9d7bd52e><!--[-->Machine Learning was on other topics<!--]--></strong> (you know that it was a time of big changes, where the first truly big Neural Networks arrived, and everything began to explode), and I don&#39;t feel that this publications repercussion on the evolution of Meta-Learning is worth enough to include in this basic summary. So with this, I think we already have an idea of how the knowledge about Meta-Learning arrived in 2015, and how it was viewed back then when the interest returned with new motivations.<!--]--></p><h2 id="the-comeback-of-meta-learning-and-its-relation-to-few-shot-learning" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#the-comeback-of-meta-learning-and-its-relation-to-few-shot-learning" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->The comeback of Meta-Learning and its relation to Few-Shot Learning<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[-->The interest in Meta-Learning returned when ML research gazed a further step than plain basic ML tasks. Before 2015, most of the applications <strong data-v-9d7bd52e><!--[-->relied on vast amounts of data<!--]--></strong>, but at the time of making <strong data-v-9d7bd52e><!--[-->ML accessible to anyone<!--]--></strong> (not just the big fishes in the industry), that scenario <strong data-v-9d7bd52e><!--[-->was not realistic<!--]--></strong>. Yes, there were already public datasets, but when trying to make some slightly ambiguous applications, it was needed some data conditions that were not easy to find. Not all small companies or particular researchers had access to a batch of 1 million images of, let&#39;s say, water impurities, and it was a too concrete phenomenon to find a huge open dataset about it.<!--]--></p><p data-v-63bfa697><!--[-->In 2015, Koch et al. presented the publication <a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Siamese Neural Networks for One-shot Image Recognition<!--]--></em><!--]--></a>. As the title says, they introduced the concept of <strong data-v-9d7bd52e><!--[-->One-shot Learning<!--]--></strong> where they proposed to solve a <strong data-v-9d7bd52e><!--[-->task<!--]--></strong> (in the paper an image classification task) with just <strong data-v-9d7bd52e><!--[-->one single sample (image) per class<!--]--></strong>. They argued that humans are able to do so (e.g., in the example we made before about recognizing a new bird, we may recognize it after seeing it just one time, at least with a good memory capacity!) so why couldn&#39;t a system do so automatically? In this paper Meta-Learning was not mentioned (they just described a method to match patterns efficiently with one single image in the Omniglot dataset), but the seed of curiosity was already planted to raise interest in this topic. It is not hard to imagine that the Meta-Learning term returned to action after that. In the end, we defined before that Meta-Learning was intended to use in order to make systems able to learn tasks more efficiently, and that included several interests. One of that interests may be precisely One-shot Learning. So from the more generic old definition, now we have a concrete motivation.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/OktLV6n.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[-->We will continue in the next section reviewing how Meta-learning was proposed after that, but first I would like to discuss the <strong data-v-9d7bd52e><!--[-->feasibility of One-shot Learning<!--]--></strong>. Solving One-shot Learning problems using Meta-Learning is yet another, although possible, <strong data-v-9d7bd52e><!--[-->ideal case<!--]--></strong>. One will not always dispose of enough data from the task domain that will allow performing Meta-Learning efficiently, and not always a representative enough task domain may be defined. Reality may be sometimes demoralizing, and yes, expecting to approach an ideal solution with another ideal approach is not exactly a guarantee of success. But there is still a motivation behind. One-shot Learning may be a too ambitious purpose in some cases, but if the term One-shot comes from one single sample, doesn&#39;t exist a Two-shot, or a Three-shot, and so on? Yes, it does. Actually, One-shot Learning is a particularization of <strong data-v-9d7bd52e><!--[-->Few-shot Learning<!--]--></strong> or <strong data-v-9d7bd52e><!--[-->K-shot Learning<!--]--></strong>, which mean <strong data-v-9d7bd52e><!--[-->learning with just few or K samples respectively<!--]--></strong>. Thus, the <strong data-v-9d7bd52e><!--[-->level of ambition is adjustable to the resources and needs<!--]--></strong> in each case. For example, maybe we would not be able to have 1 million images of water impurities, but getting 100 labeled images of them may be more accessible, as well as a 100-shot learning problem may be more realistic to solve than a One-shot one.<!--]--></p><p data-v-63bfa697><!--[-->So to conclude this section, Meta-Learning re-arose as a solution to Few-shot Learning. Said that I think it is important to not lose the old, more general perspective of it. That allows us to apply Meta-Learning for several problems such as <strong data-v-9d7bd52e><!--[-->Active Learning<!--]--></strong>, <strong data-v-9d7bd52e><!--[-->Curriculum Learning<!--]--></strong>, etc. But let&#39;s continue the story.<!--]--></p><h2 id="the-modern-meta-learning-approaches-presented" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#the-modern-meta-learning-approaches-presented" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->The modern Meta-Learning approaches presented<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[-->If you search for <a href="https://imgur.com/fzTtsDP" rel="nofollow" data-v-af1c0c3b><!--[-->Meta-Learning publications since 2016<!--]--></a>, you may fall off your seat. However, what actually happened is that the modern strategies to perform Meta-Learning (most of them focused on One-Shot Learning) exploded. The <strong data-v-9d7bd52e><!--[-->main Meta-Learning strategies<!--]--></strong> nowadays are divided into 3 or 4 &quot;families&quot;. Apart from the solutions that we will review in this section, the rest of the publications focus on experimenting with them and studying the behavior, modifying them with some witty hacks, or, what is most common nowadays, trying to use them in specific scenarios.<!--]--></p><h3 id="usage-of-memories" data-v-4ddca5e2><a aria-current="page" href="/articles/2022-11-21-meta-learning#usage-of-memories" class="router-link-active router-link-exact-active" data-v-4ddca5e2><!--[-->Usage of memories<!--]--><!----></a></h3><p data-v-63bfa697><!--[-->Santoro et al. were the first (as far as I know) to refer to <strong data-v-9d7bd52e><!--[-->Meta-Learning for solving the One-shot Learning<!--]--></strong> issue with <a href="https://proceedings.mlr.press/v48/santoro16.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Meta-Learning with Memory-Augmented Neural Networks<!--]--></em><!--]--></a> (2016). They propose the architecture <strong data-v-9d7bd52e><!--[-->MANN<!--]--></strong> as a modification of <strong data-v-9d7bd52e><!--[-->Neural Turing Machine<!--]--></strong> (Graves et al. 2014)  to achieve Meta-Learning by reducing complexity of the original mechanism, thus allowing to <strong data-v-9d7bd52e><!--[-->learn in fewer steps<!--]--></strong>. Recall that one of the requirements of Deep Learning refers to the size of the dataset. There&#39;s a great post about <a href="https://rylanschaeffer.github.io/content/research/one_shot_learning_with_memory_augmented_nn/main.html" rel="nofollow" data-v-af1c0c3b><!--[-->NTM and MANN<!--]--></a>. It is a complex mechanism and we may talk a lot about this, but I&#39;d suggest to skip this part yet (the topic is interesting but may be better to learn about this another day, you don&#39;t want to overwhelm today after reading this post) and only have in mind this first approach to achieve <strong data-v-9d7bd52e><!--[-->Meta-Learning by learning a storage mechanism<!--]--></strong>. There&#39;s a discussion about if this may be considered Meta-Learning or not.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/muJQ04p.png" alt="Imgur" data-v-e5a4106d><!--]--></p><h3 id="metric-learning" data-v-4ddca5e2><a aria-current="page" href="/articles/2022-11-21-meta-learning#metric-learning" class="router-link-active router-link-exact-active" data-v-4ddca5e2><!--[-->Metric Learning<!--]--><!----></a></h3><p data-v-63bfa697><!--[-->This idea of &quot;<strong data-v-9d7bd52e><!--[-->reducing the complexity<!--]--></strong> of the algorithm to reduce the need for data&quot; is also used in the second family of approaches we will review, <strong data-v-9d7bd52e><!--[-->Metric Learning<!--]--></strong>. This idea was proposed by Vinayls et al. in <a href="https://arxiv.org/pdf/1606.04080.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Matching Networks for One-Shot Learning<!--]--></em><!--]--></a> (2016). The authors aimed to switch from a Computer Vision space, where the problem is and which is typically solved through Deep Learning to <strong data-v-9d7bd52e><!--[-->another space<!--]--></strong> more likely to be solved by <strong data-v-9d7bd52e><!--[-->non-parametric approaches<!--]--></strong> (which don&#39;t need further training, e.g. kNN). To do so, they just train an <strong data-v-9d7bd52e><!--[-->embedding Network with attention<!--]--></strong>, where attention acts as the final non-parametric matching algorithm (relates a given test image to each training one, related to one class each since we are working with One-shot Learning). The encoder network they propose is a RNN, the attention they use is Cosine Similarity and the loss they train with is a log one at Learning level while this is projected to the Meta-Learning level. This idea was also followed in <a href="https://arxiv.org/pdf/1703.05175.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Prototypical Networks for Few-Shot Learning<!--]--></em><!--]--></a> in 2017, where Snell et al. proposed a <strong data-v-9d7bd52e><!--[-->similar pipeline<!--]--></strong> but instead of using a kNN-like algorithm (which Vinyals&#39;s attention mechanism stands for), they use a soft view of it, being <strong data-v-9d7bd52e><!--[-->each class in the space a Gaussian distribution instead of a discrete frontier<!--]--></strong>. Each class distribution is called prototype in this paper, and it allows to use more than one sample per class, thus extending the problem to a Few-shot Learning problem instead of a One-shot one. The embedding function is learned from minimizing the negative log probability of the true class of the test samples. This approach of Meta-Learning is still popular nowadays due to its <strong data-v-9d7bd52e><!--[-->simplicity<!--]--></strong>, and usually a good first step to experiment with Meta-Learning.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/Yi60wou.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/hSDCqyd.png" alt="Imgur" data-v-e5a4106d><!--]--></p><h3 id="optimizer-meta-learning" data-v-4ddca5e2><a aria-current="page" href="/articles/2022-11-21-meta-learning#optimizer-meta-learning" class="router-link-active router-link-exact-active" data-v-4ddca5e2><!--[-->Optimizer Meta-Learning<!--]--><!----></a></h3><p data-v-63bfa697><!--[-->Another way to achieve Meta-Learning recovers the old idea that Schmidhuber played with, <strong data-v-9d7bd52e><!--[-->learning an optimal optimizer<!--]--></strong> (do you remember?). I think this idea need no longer presentation. Andrychowicz et al. presented in 2016 <a href="https://arxiv.org/pdf/1606.04474.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Learning to Learn By Gradient Descent By Gradient Descent<!--]--></em><!--]--></a>, which is not a typo but its true name. Does this sound to you? If it doesn&#39;t, I&#39;ll remind you the Hochreiter publication in 2001 called Learning to Learn Using Gradient Descent. The idea is pretty similar. As well as you have an inner algorithm to solve the task, you also have an outer training algorithm. This <strong data-v-9d7bd52e><!--[-->training algorithm may also be optimized<!--]--></strong> by training at the <strong data-v-9d7bd52e><!--[-->Meta-Learning level<!--]--></strong>. So Andrychowicz calls them <strong data-v-9d7bd52e><!--[-->optimizee<!--]--></strong> and <strong data-v-9d7bd52e><!--[-->optimizer<!--]--></strong>. The <strong data-v-9d7bd52e><!--[-->optimizee is a parametric algorithm<!--]--></strong> so it is actually optimized by its parameters (called <strong data-v-9d7bd52e><!--[-->Meta-parameters<!--]--></strong>). Wait, isn&#39;t this the same than Hochreiter proposed? This gave me a bit of confusion and to be honest is one of the things I&#39;m less sure about in the whole Meta-Learning topic. But my interpretation is that Hochreiter&#39;s idea was just a <strong data-v-9d7bd52e><!--[-->generalization<!--]--></strong> that <strong data-v-9d7bd52e><!--[-->allowed<!--]--></strong> to use <strong data-v-9d7bd52e><!--[-->gradient descent in both the optimizer and the optimizee<!--]--></strong>, while this paper present <strong data-v-9d7bd52e><!--[-->architectures for specifically that<!--]--></strong>. However, the most important idea for you here is that this view is still one of the main approaches of Meta-Learning. Later on, Larochelle et al. presented in 2017 the publication <a href="https://openreview.net/pdf?id=rJY0-Kcll" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Optimization as a model for Few-Shot Learning<!--]--></em><!--]--></a>, which builds on the <strong data-v-9d7bd52e><!--[-->same idea<!--]--></strong> but in this case the <strong data-v-9d7bd52e><!--[-->optimizer is the Gradient Descent itself<!--]--></strong>, and instead of modifying Meta-Parameters acts as a <strong data-v-9d7bd52e><!--[-->weight predictor<!--]--></strong>. The other important publication about that was done by Mishra et al in 2018, called <a href="https://arxiv.org/pdf/1707.03141.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->A simple Neural Attentive Meta-Learner<!--]--></em><!--]--></a>, where they <strong data-v-9d7bd52e><!--[-->extend<!--]--></strong> the idea of Andrychowicz by <strong data-v-9d7bd52e><!--[-->instead of an RNN using an (soft) Attentional NN as the optimizer<!--]--></strong> of Meta-parameters.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/ZXAsypi.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/MN8bSAL.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/AVs0R5k.png" alt="Imgur" data-v-e5a4106d><!--]--></p><h3 id="initialization-meta-learning" data-v-4ddca5e2><a aria-current="page" href="/articles/2022-11-21-meta-learning#initialization-meta-learning" class="router-link-active router-link-exact-active" data-v-4ddca5e2><!--[-->Initialization Meta-Learning<!--]--><!----></a></h3><p data-v-63bfa697><!--[-->However, the probably <strong data-v-9d7bd52e><!--[-->most popular<!--]--></strong> approach of Meta-Learning is the one presented by Finn et al. in <a href="https://arxiv.org/pdf/1703.03400.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks<!--]--></em><!--]--></a> (2017). These authors have made HUGE contributions to Meta-Learning, but this was the most iconic one. There, they presented <strong data-v-9d7bd52e><!--[-->MAML<!--]--></strong>, a popular algorithm that aims to <strong data-v-9d7bd52e><!--[-->find a proper initialization for the whole domain of tasks<!--]--></strong>.  This is applicable to <strong data-v-9d7bd52e><!--[-->any combination of parameters<!--]--></strong>, thus becoming (as the title says) <strong data-v-9d7bd52e><!--[-->Model-Agnostic<!--]--></strong>. At the <strong data-v-9d7bd52e><!--[-->Meta-Learning level<!--]--></strong>, weights follow a <strong data-v-9d7bd52e><!--[-->path guided by a batch of tasks<!--]--></strong> at each <strong data-v-9d7bd52e><!--[-->meta-step<!--]--></strong>, where at each <strong data-v-9d7bd52e><!--[-->task<!--]--></strong> the model learns and gives a <strong data-v-9d7bd52e><!--[-->final loss<!--]--></strong> (after the desired few updates). This way it becomes able to (desirably) <strong data-v-9d7bd52e><!--[-->learn quickly when facing a new task<!--]--></strong>. This algorithm is also pretty popular in Meta-Reinforcement Learning. But aside from MAML, we also have <strong data-v-9d7bd52e><!--[-->Reptile<!--]--></strong>, presented by Nichol et al. in <a href="https://arxiv.org/pdf/1803.02999.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->On First-Order Meta-Learning Algorithms<!--]--></em><!--]--></a> (2018), where basically the <strong data-v-9d7bd52e><!--[-->Meta-Learning trajectory follows also the individual tasks<!--]--></strong> Learning one (what they find out to be the optimal path). Furthermore, Finn&#39;s team also presented in 2018 <a href="https://arxiv.org/pdf/1806.02817.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Probabilistic Model-Agnostic Meta-Learning<!--]--></em><!--]--></a> (<strong data-v-9d7bd52e><!--[-->Probabilistic MAML<!--]--></strong>), while Kim et al. presented <a href="https://arxiv.org/pdf/1806.03836.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Bayesian Model-Agnostic Meta-Learning<!--]--></em><!--]--></a> (<strong data-v-9d7bd52e><!--[-->BMAML<!--]--></strong>). To be honest, I&#39;m not sure about the conceptual difference between both, but the conclusion is that the flexibility of MAML allowed even to introduce <strong data-v-9d7bd52e><!--[-->uncertainty<!--]--></strong>, where the learned (and therefore initialized in MAML) <strong data-v-9d7bd52e><!--[-->weights worked in probabilistic frameworks<!--]--></strong>, thus being <strong data-v-9d7bd52e><!--[-->distributions<!--]--></strong>. Also Finn&#39;s team (again) presented <a href="https://arxiv.org/pdf/1902.08438.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Online Meta-Learning<!--]--></em><!--]--></a> (2019), where they used <strong data-v-9d7bd52e><!--[-->MAML in an Online scenario<!--]--></strong>**, where tasks were presented in a manner in which no information about future tasks was available at each batch.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/6f3Fw6i.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/cLdIkro.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/XJ2Y8cG.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/fpWeEt4.png" alt="Imgur" data-v-e5a4106d><!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/wX4paDu.png" alt="Imgur" data-v-e5a4106d><!--]--></p><h3 id="modular-meta-learning" data-v-4ddca5e2><a aria-current="page" href="/articles/2022-11-21-meta-learning#modular-meta-learning" class="router-link-active router-link-exact-active" data-v-4ddca5e2><!--[-->Modular Meta-Learning<!--]--><!----></a></h3><p data-v-63bfa697><!--[-->Last, in 2020 Chen et al. published <a href="https://arxiv.org/pdf/1909.05557.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Modular Meta-Learning with Shrinkage<!--]--></em><!--]--></a>, where they referred to what I think was the last of the big Meta-Learning approaches. They formalized the popular procedure when pretraining + fine-tuning is done by <strong data-v-9d7bd52e><!--[-->modules<!--]--></strong> (e.g. the typical frozen backbone while fine-tuning heads). What they proposed is <strong data-v-9d7bd52e><!--[-->(meta-)learning the priors<!--]--></strong> in which <strong data-v-9d7bd52e><!--[-->each module<!--]--></strong> has to <strong data-v-9d7bd52e><!--[-->shrink<!--]--></strong> (i.e. the strength to adapt to the task training). This way, they opened a door for new publications.<!--]--></p><p data-v-63bfa697><!--[--><img src="https://i.imgur.com/qUL4xKq.png" alt="Imgur" data-v-e5a4106d><!--]--></p><h3 id="summary" data-v-4ddca5e2><a aria-current="page" href="/articles/2022-11-21-meta-learning#summary" class="router-link-active router-link-exact-active" data-v-4ddca5e2><!--[-->Summary<!--]--><!----></a></h3><p data-v-63bfa697><!--[-->So, summarizing, the main strategies proposed to perform Meta-Learning are:<!--]--></p><ul data-v-5feda7b5><!--[--><li data-v-996e086c><!--[-->Usage of memories<!--]--></li><li data-v-996e086c><!--[-->Metric Learning (converting to non-parametric algorithm)<!--]--></li><li data-v-996e086c><!--[-->Optimizer Learning<!--]--></li><li data-v-996e086c><!--[-->Initialization Learning<!--]--></li><li data-v-996e086c><!--[-->Modular Meta-Learning<!--]--></li><!--]--></ul><h2 id="meta-learning-interesting-uses" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#meta-learning-interesting-uses" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->Meta-Learning interesting uses<!--]--></strong><!--]--><!----></a></h2><ul data-v-5feda7b5><!--[--><li data-v-996e086c><!--[-->Few-Shot Learning: the first motivation of this wave of Meta-Learning publications. Learning from few data becomes possible when you learn how to learn with few data.<!--]--></li><li data-v-996e086c><!--[-->Active Learning: I&#39;m planning another post for this topic, but the problem stands for learning when human supervision has some costs. Again, possible if you learn how to solve this kind of problem.<!--]--></li><li data-v-996e086c><!--[-->Unsupervised Learning: this is an interesting matter since we have defined everything under a supervised view, i.e. assuming we are able to design a Meta-Learning pipeline depending on a domain we will define usually knowing the classes. However, when we miss this information, we may find for an alternative way to define this schedule. In this direction, Metz et al. presented <a href="https://arxiv.org/pdf/1804.00222.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Meta-Learning Update Rules for Unsupervised Representation Learning<!--]--></em><!--]--></a> (2019), where they propose a way to achieve that by finding an (unknown) class space from which to build artificial tasks and train the model from them, thus projecting it to the new unsupervised tasks. The authors perform several experiments with the different main Meta-Learning approaches.<!--]--></li><!--]--></ul><h2 id="the-future-of-meta-learning" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#the-future-of-meta-learning" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->The future of Meta-Learning<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[-->No, I&#39;m not a prophet, but I have some ideas on what would be the natural <strong data-v-9d7bd52e><!--[-->direction<!--]--></strong> of all this.<!--]--></p><p data-v-63bfa697><!--[-->First, Meta-Learning has <strong data-v-9d7bd52e><!--[-->already presented<!--]--></strong> the most intuitive <strong data-v-9d7bd52e><!--[-->approaches<!--]--></strong> to be performed. As they still can be improved (just like any approach has received publications responding to it), the most important work there is presumably done.<!--]--></p><p data-v-63bfa697><!--[-->However, Meta-learning just began. All Machine Learning problems that may potentially be affected by the (at least temporal) amount of data, may follow a Meta-Learning strategy. Probably, the <strong data-v-9d7bd52e><!--[-->Online scenario will gain strength<!--]--></strong> in Meta-Learning research in the following years, since a common case is that a project begins with few data and later adds more and more. Furthermore, <strong data-v-9d7bd52e><!--[-->building good schedules<!--]--></strong> is still not accomplished, so <strong data-v-9d7bd52e><!--[-->Curriculum Learning<!--]--></strong> and <strong data-v-9d7bd52e><!--[-->Unsupervised scenarios<!--]--></strong> will study in depth the application of Meta-Learning, for sure. Also, Meta-Learning still has a lot to say in other kinds of <strong data-v-9d7bd52e><!--[-->data limitations<!--]--></strong> such as <strong data-v-9d7bd52e><!--[-->Incremental Learning<!--]--></strong> (temporal bias issues), <strong data-v-9d7bd52e><!--[-->Active Learning<!--]--></strong> (annotation issues), <strong data-v-9d7bd52e><!--[-->Federated Learning<!--]--></strong> (privacy issues)...<!--]--></p><p data-v-63bfa697><!--[-->Last, but not less important, Meta-Learning still has to deliver strong <strong data-v-9d7bd52e><!--[-->frameworks<!--]--></strong> and <strong data-v-9d7bd52e><!--[-->stable implementations<!--]--></strong> so it becomes more and more popular. So, congratulations for reading this post and preparing for the future!<!--]--></p><h2 id="additional-resources" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#additional-resources" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->Additional resources<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[-->To complete this recap, I&#39;m including a couple of summaries I did some time ago in two formats. First, a slide presentation which may be useful for a shorter <a href="https://drive.google.com/file/d/12xTctbkXcOHNX-ZtTA3ZaKUEi5Ulj_vc/view?usp=sharing" rel="nofollow" data-v-af1c0c3b><!--[-->summary<!--]--></a>. Second, a sheet with <a href="https://docs.google.com/spreadsheets/d/1IcaGSqPEVuF8iHD5G2wfl8xwpJmVuvnDOwrkZHIK1IU/edit?usp=sharing" rel="nofollow" data-v-af1c0c3b><!--[-->a collection of important papers and notes<!--]--></a>.<!--]--></p><h2 id="thank-you-reader" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#thank-you-reader" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->Thank you reader<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[-->This is my first post, and writing it has been tough and has given me more work that I initially thought. However, the experience has filled me with more interest in continue making this blog live. As far as my life permits me to do it, I will be adding more content. This has just began!<!--]--></p><h2 id="references" data-v-1daf0210><a aria-current="page" href="/articles/2022-11-21-meta-learning#references" class="router-link-active router-link-exact-active" data-v-1daf0210><!--[--><strong data-v-9d7bd52e><!--[-->References<!--]--></strong><!--]--><!----></a></h2><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>1</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://upcommons.upc.edu/bitstream/handle/2117/179428/cMas.pdf;jsessionid=18807FB3EE2D5343E5F0DF9A5BA37D7F?sequence=1" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Picking groups instead of samples: A close look at Static Pool-based Meta-Active Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>2</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://people.idsia.ch/~juergen/diploma1987ocr.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Evolutionary Principles in Self-Referential Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>3</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://people.idsia.ch/~juergen/FKI-147-91ocr.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>4</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://people.idsia.ch/~juergen/metalearning.html" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Metalearning Machines Learn to Learn<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>5</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="http://www.iro.umontreal.ca/~lisa/pointeurs/bengio_1995_oban.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->On the Optimization of a Synaptic Learning Rule<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>6</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://people.idsia.ch/~juergen/fki198-94.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->On learning how to learn learning strategies<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>7</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://people.idsia.ch/~juergen/interest.html" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->What&#39;s interesting<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>8</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://www.researchgate.net/publication/225182080_Learning_To_Learn_Using_Gradient_Descent" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Learning To Learn Using Gradient Descent<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>9</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Siamese Neural Networks for One-shot Image Recognition<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>10</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://proceedings.mlr.press/v48/santoro16.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Meta-Learning with Memory-Augmented Neural Networks<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>11</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://rylanschaeffer.github.io/content/research/one_shot_learning_with_memory_augmented_nn/main.html" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Explanation of One-shot Learning with Memory-Augmented Neural Networks<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>12</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1606.04080.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Matching Networks for One-Shot Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>13</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1703.05175.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Prototypical Networks for Few-Shot Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>14</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1606.04474.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Learning to Learn By Gradient Descent By Gradient Descent<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>15</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://openreview.net/pdf?id=rJY0-Kcll" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Optimization as a model for Few-Shot Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>16</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1707.03141.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->A simple Neural Attentive Meta-Learner<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>17</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1703.03400.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Model-Agnostic Meta-Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>18</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1803.02999.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->On First-Order Meta-Learning Algorithms<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>19</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1806.02817.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Probabilistic Model-Agnostic Meta-Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>20</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1806.03836.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Bayesian Model-Agnostic Meta-Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>21</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1902.08438.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Online Meta-Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>22</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1909.05557.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Modular Meta-Learning with Shrinkage<!--]--></em><!--]--></a><!--]--></strong><!--]--></p><p data-v-63bfa697><!--[--><em data-v-177b5f01><!--[--><span>23</span><!--]--></em> <strong data-v-9d7bd52e><!--[--><a href="https://arxiv.org/pdf/1804.00222.pdf" rel="nofollow" data-v-af1c0c3b><!--[--><em data-v-177b5f01><!--[-->Meta-Learning Update Rules for Unsupervised Representation Learning<!--]--></em><!--]--></a><!--]--></strong><!--]--></p></div><!--]--><div class="back-to-top" data-v-f252e39d><a data-v-f252e39d data-v-af1c0c3b><!--[-->Back to top <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-f252e39d style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-121c6e7d><path fill="currentColor" d="M11 20V7.825l-5.6 5.6L4 12l8-8l8 8l-1.4 1.425l-5.6-5.6V20h-2Z"/></svg><!--]--></a></div></div></article></div><!--]--><footer class="" data-v-93c22c3b data-v-d63b5c07><a href="https://github.com/Metabloggism/metabloggism.github.io" rel="noopener noreferrer" class="credits" data-v-d63b5c07>Metabloggism</a><div class="navigation" data-v-d63b5c07><nav data-v-d63b5c07 data-v-47e45ff0><ul data-v-47e45ff0><!--[--><li data-v-47e45ff0><a href="/" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> About</a></li><li data-v-47e45ff0><a href="/articles" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> Articles</a></li><li data-v-47e45ff0><a href="/contact" class="" data-v-47e45ff0><span class="underline-fx" data-v-47e45ff0></span> Contact</a></li><!--]--></ul></nav></div><p class="message" data-v-d63b5c07>Follow me on</p><div class="icons" data-v-d63b5c07><div class="social" data-v-d63b5c07><!--[--><a href="https://github.com/https://github.com/MrLeylo" rel="noopener noreferrer" target="_blank" title="https://github.com/MrLeylo" aria-label="https://github.com/MrLeylo" data-v-ddf2f94a><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-ddf2f94a style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-121c6e7d><path fill="currentColor" d="M12 2.247a10 10 0 0 0-3.162 19.487c.5.088.687-.212.687-.475c0-.237-.012-1.025-.012-1.862c-2.513.462-3.163-.613-3.363-1.175a3.636 3.636 0 0 0-1.025-1.413c-.35-.187-.85-.65-.013-.662a2.001 2.001 0 0 1 1.538 1.025a2.137 2.137 0 0 0 2.912.825a2.104 2.104 0 0 1 .638-1.338c-2.225-.25-4.55-1.112-4.55-4.937a3.892 3.892 0 0 1 1.025-2.688a3.594 3.594 0 0 1 .1-2.65s.837-.262 2.75 1.025a9.427 9.427 0 0 1 5 0c1.912-1.3 2.75-1.025 2.75-1.025a3.593 3.593 0 0 1 .1 2.65a3.869 3.869 0 0 1 1.025 2.688c0 3.837-2.338 4.687-4.563 4.937a2.368 2.368 0 0 1 .675 1.85c0 1.338-.012 2.413-.012 2.75c0 .263.187.575.687.475A10.005 10.005 0 0 0 12 2.247Z"/></svg></a><a href="https://www.linkedin.com/company/nuxtlabs" rel="noopener noreferrer" target="_blank" title="LinkedIn" aria-label="LinkedIn" data-v-ddf2f94a><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-ddf2f94a style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-121c6e7d><path fill="currentColor" d="M20.47 2H3.53a1.45 1.45 0 0 0-1.47 1.43v17.14A1.45 1.45 0 0 0 3.53 22h16.94a1.45 1.45 0 0 0 1.47-1.43V3.43A1.45 1.45 0 0 0 20.47 2ZM8.09 18.74h-3v-9h3ZM6.59 8.48a1.56 1.56 0 1 1 0-3.12a1.57 1.57 0 1 1 0 3.12Zm12.32 10.26h-3v-4.83c0-1.21-.43-2-1.52-2A1.65 1.65 0 0 0 12.85 13a2 2 0 0 0-.1.73v5h-3v-9h3V11a3 3 0 0 1 2.71-1.5c2 0 3.45 1.29 3.45 4.06Z"/></svg></a><!--]--></div><div class="color-mode-switch" data-v-d63b5c07><button aria-label="Color Mode" data-v-d63b5c07 data-v-693a1e33><span data-v-693a1e33></span></button></div></div></footer><!--]--></div></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true" data-src="/articles/2022-11-21-meta-learning/_payload.json">[{"state":1,"_errors":16979,"serverRendered":16940,"path":7,"prerenderedAt":-1},["Reactive",2],{"$sdd-pages":3,"$sdd-surrounds":2833,"$sdd-globals":16937,"$scolor-mode":16939,"$sdd-navigation":16941,"$sicons":16968},["ShallowRef",4],["ShallowReactive",5],{"/articles/2022-11-21-meta-learning":6},{"_path":7,"_dir":8,"_draft":9,"_partial":9,"_locale":10,"title":11,"description":12,"cover":13,"author":14,"date":18,"layout":19,"body":20,"_type":2828,"_id":2829,"_source":2830,"_file":2831,"_extension":2832},"/articles/2022-11-21-meta-learning","articles",false,"","Meta-Learning explained","Learn how to configure Alpine with the app.config.ts file.","/articles/configure-alpine.webp",{"name":15,"avatarUrl":16,"link":17},"Clment Ollivier","https://pbs.twimg.com/profile_images/1370286658432724996/ZMSDzzIi_400x400.jpg","https://twitter.com/clemcodes","2022-11-21T00:00:00.000Z","article",{"type":21,"children":22,"toc":2807},"root",[23,35,45,69,102,115,124,171,179,201,262,349,451,459,484,688,695,728,738,745,753,760,768,775,780,789,879,940,951,977,1039,1046,1112,1119,1124,1160,1184,1191,1203,1212,1238,1275,1282,1329,1347,1356,1377,1384,1445,1452,1458,1542,1549,1556,1562,1712,1719,1726,1733,1739,1934,1941,1948,1955,1962,1969,1975,2020,2027,2033,2038,2064,2073,2103,2112,2124,2143,2201,2219,2228,2249,2258,2263,2272,2298,2321,2344,2368,2391,2414,2437,2460,2483,2506,2530,2553,2576,2599,2622,2645,2669,2692,2715,2738,2761,2784],{"type":24,"tag":25,"props":26,"children":28},"element","h1",{"id":27},"meta-learning-explained",[29],{"type":24,"tag":30,"props":31,"children":32},"strong",{},[33],{"type":34,"value":11},"text",{"type":24,"tag":36,"props":37,"children":39},"h2",{"id":38},"what-will-be-reviewed",[40],{"type":24,"tag":30,"props":41,"children":42},{},[43],{"type":34,"value":44},"What will be reviewed",{"type":24,"tag":46,"props":47,"children":48},"p",{},[49,51,56,58,67],{"type":34,"value":50},"In this first post (aside from the Welcome one) I will expose a brief summary of ",{"type":24,"tag":30,"props":52,"children":53},{},[54],{"type":34,"value":55},"Meta-Learning",{"type":34,"value":57},". It was one of the topics I researched for ",{"type":24,"tag":59,"props":60,"children":64},"a",{"href":61,"rel":62},"https://upcommons.upc.edu/bitstream/handle/2117/179428/cMas.pdf;jsessionid=18807FB3EE2D5343E5F0DF9A5BA37D7F?sequence=1",[63],"nofollow",[65],{"type":34,"value":66},"my Master's dissertation",{"type":34,"value":68}," (and one of the main topics I actually developed it about) and since then, one of the topics I am more interested in.",{"type":24,"tag":46,"props":70,"children":71},{},[72,74,79,81,86,88,93,95,100],{"type":34,"value":73},"As you will see, the summary will not be the latest trend, because I want to give it a more ",{"type":24,"tag":30,"props":75,"children":76},{},[77],{"type":34,"value":78},"historical explanation",{"type":34,"value":80},". The ",{"type":24,"tag":30,"props":82,"children":83},{},[84],{"type":34,"value":85},"State of the Art may be reviewed in a different post",{"type":34,"value":87},". Instead, this post will focus on taking an interesting ",{"type":24,"tag":30,"props":89,"children":90},{},[91],{"type":34,"value":92},"tour along the Meta-Learning evolution",{"type":34,"value":94}," and understanding the ",{"type":24,"tag":30,"props":96,"children":97},{},[98],{"type":34,"value":99},"context",{"type":34,"value":101}," to build more efficiently in the future.",{"type":24,"tag":46,"props":103,"children":104},{},[105,107,113],{"type":34,"value":106},"No need to say, but the content does not end at this post. You can contact me at ",{"type":24,"tag":59,"props":108,"children":110},{"href":109},"i.masmend@gmail.com",[111],{"type":34,"value":112},"my mail",{"type":34,"value":114}," (info is also below in the blog) if you have any doubt or suggestion and I'll be happy to discuss.",{"type":24,"tag":36,"props":116,"children":118},{"id":117},"what-is-meta-learning",[119],{"type":24,"tag":30,"props":120,"children":121},{},[122],{"type":34,"value":123},"What is Meta-Learning?",{"type":24,"tag":46,"props":125,"children":126},{},[127,129,134,136,141,143,148,150,155,157,162,164,169],{"type":34,"value":128},"Any ",{"type":24,"tag":30,"props":130,"children":131},{},[132],{"type":34,"value":133},"task or process",{"type":34,"value":135}," can involve a ",{"type":24,"tag":30,"props":137,"children":138},{},[139],{"type":34,"value":140},"process of learning",{"type":34,"value":142}," in order to ",{"type":24,"tag":30,"props":144,"children":145},{},[146],{"type":34,"value":147},"improve performance",{"type":34,"value":149}," in it. Systems are no strangers to this, for example, imagine a system that has to perform some kind of face identification. The system will perform better when it has lived a learning process before. Well, that is exactly the point of Machine Learning, isn't it? But let's switch the focus. ",{"type":24,"tag":30,"props":151,"children":152},{},[153],{"type":34,"value":154},"Learning itself is a process",{"type":34,"value":156},". So according to the previous statement, it ",{"type":24,"tag":30,"props":158,"children":159},{},[160],{"type":34,"value":161},"can also be learned",{"type":34,"value":163},". And this is the exact ",{"type":24,"tag":30,"props":165,"children":166},{},[167],{"type":34,"value":168},"definition of Meta-Learning: Learning to Learn",{"type":34,"value":170},".",{"type":24,"tag":46,"props":172,"children":173},{},[174],{"type":24,"tag":175,"props":176,"children":178},"img",{"alt":10,"src":177},"https://i.imgur.com/Wc5zMl2.png",[],{"type":24,"tag":46,"props":180,"children":181},{},[182,184,199],{"type":34,"value":183},"| ",{"type":24,"tag":185,"props":186,"children":187},"b",{},[188,190,197],{"type":34,"value":189},"Meme, credits to ",{"type":24,"tag":59,"props":191,"children":194},{"href":192,"rel":193},"https://twitter.com/joavanschoren",[63],[195],{"type":34,"value":196},"@joavanschoren",{"type":34,"value":198},"... but I cut out the end since it contained a spoiler of content in the post below",{"type":34,"value":200}," |",{"type":24,"tag":46,"props":202,"children":203},{},[204,206,211,213,218,220,225,227,232,234,239,241,246,248,253,255,260],{"type":34,"value":205},"From another perspective, we ",{"type":24,"tag":30,"props":207,"children":208},{},[209],{"type":34,"value":210},"humans do not learn most things from scratch",{"type":34,"value":212},". For example, if I present you with a ",{"type":24,"tag":30,"props":214,"children":215},{},[216],{"type":34,"value":217},"new bird species",{"type":34,"value":219}," (unknown to you) and tell you ",{"type":24,"tag":30,"props":221,"children":222},{},[223],{"type":34,"value":224},"\"Have you seen this bird?\"",{"type":34,"value":226}," you will probably ",{"type":24,"tag":30,"props":228,"children":229},{},[230],{"type":34,"value":231},"learn its patterns with just a quick look",{"type":34,"value":233},". This is because ",{"type":24,"tag":30,"props":235,"children":236},{},[237],{"type":34,"value":238},"you have seen so many birds",{"type":34,"value":240}," in your life, and you'll directly look at the differential features (feathers color, feet, beak shape...) to absorb the information. Also, ",{"type":24,"tag":30,"props":242,"children":243},{},[244],{"type":34,"value":245},"you may understand the context",{"type":34,"value":247}," (e.g. identify how does it fly with respect to the ground, wind, etc) because you already know things about this context. In contrast, if you present it to a ",{"type":24,"tag":30,"props":249,"children":250},{},[251],{"type":34,"value":252},"baby",{"type":34,"value":254},", he will ",{"type":24,"tag":30,"props":256,"children":257},{},[258],{"type":34,"value":259},"not understand at all because he still has to learn everything",{"type":34,"value":261},". Another simple example is how before analyzing a book from a literature perspective a kid has to learn how to read.",{"type":24,"tag":46,"props":263,"children":264},{},[265,267,271,273,278,280,285,287,292,294,299,301,306,308,313,315,320,322,327,329,334,336,341,343,348],{"type":34,"value":266},"Thus, ",{"type":24,"tag":30,"props":268,"children":269},{},[270],{"type":34,"value":55},{"type":34,"value":272}," is ",{"type":24,"tag":30,"props":274,"children":275},{},[276],{"type":34,"value":277},"extending the Learning process to one level above",{"type":34,"value":279},", and ",{"type":24,"tag":30,"props":281,"children":282},{},[283],{"type":34,"value":284},"Learning to Learn",{"type":34,"value":286},". And, how does that contribute? To make it simple, it makes the ",{"type":24,"tag":30,"props":288,"children":289},{},[290],{"type":34,"value":291},"Learning process more efficient",{"type":34,"value":293}," (in any way, which could be faster, more stable, more qualitative...), and this allows us to overcome some important issues (we'll discuss that later). When looking at that, we could say we work at ",{"type":24,"tag":30,"props":295,"children":296},{},[297],{"type":34,"value":298},"2 levels",{"type":34,"value":300},", the ",{"type":24,"tag":30,"props":302,"children":303},{},[304],{"type":34,"value":305},"Learning level",{"type":34,"value":307}," and the ",{"type":24,"tag":30,"props":309,"children":310},{},[311],{"type":34,"value":312},"Meta-Learning level",{"type":34,"value":314},". You may also note that this can be even extended one level above since Learning to Learn is another process. You are right, this can be done and we then would achieve the Meta-meta-Learning level, thus working at 3 levels. And this is also ",{"type":24,"tag":30,"props":316,"children":317},{},[318],{"type":34,"value":319},"extendible to any level until infinity",{"type":34,"value":321}," (so yes, you could learn how to learn how to learn how to learn...how to learn). However, such a process is obviously limited by our capacity. We as ",{"type":24,"tag":30,"props":323,"children":324},{},[325],{"type":34,"value":326},"humans, apply this at many levels",{"type":34,"value":328},", but it is also ",{"type":24,"tag":30,"props":330,"children":331},{},[332],{"type":34,"value":333},"limited by our brain capacity",{"type":34,"value":335},". From a ",{"type":24,"tag":30,"props":337,"children":338},{},[339],{"type":34,"value":340},"system",{"type":34,"value":342}," perspective, it is limited by its ",{"type":24,"tag":30,"props":344,"children":345},{},[346],{"type":34,"value":347},"computational power",{"type":34,"value":170},{"type":24,"tag":46,"props":350,"children":351},{},[352,354,359,361,365,367,372,374,379,381,386,388,393,395,400,402,407,409,414,416,421,423,428,430,435,437,442,444,449],{"type":34,"value":353},"So that said, how does this fit in out** Machine Learning** (ML) interest? Well, there are ",{"type":24,"tag":30,"props":355,"children":356},{},[357],{"type":34,"value":358},"different ways",{"type":34,"value":360}," of applying ",{"type":24,"tag":30,"props":362,"children":363},{},[364],{"type":34,"value":55},{"type":34,"value":366}," in ML that will be reviewed in this post, but keep in mind a setting where an ",{"type":24,"tag":30,"props":368,"children":369},{},[370],{"type":34,"value":371},"inner algorithm",{"type":34,"value":373}," works for a ",{"type":24,"tag":30,"props":375,"children":376},{},[377],{"type":34,"value":378},"prediction task",{"type":34,"value":380},". This algorithm learns under some ",{"type":24,"tag":30,"props":382,"children":383},{},[384],{"type":34,"value":385},"conditions",{"type":34,"value":387},", by updating some ",{"type":24,"tag":30,"props":389,"children":390},{},[391],{"type":34,"value":392},"model",{"type":34,"value":394}," by some ",{"type":24,"tag":30,"props":396,"children":397},{},[398],{"type":34,"value":399},"Learning Rule",{"type":34,"value":401}," depending in some ",{"type":24,"tag":30,"props":403,"children":404},{},[405],{"type":34,"value":406},"data",{"type":34,"value":408},". However, in a ",{"type":24,"tag":30,"props":410,"children":411},{},[412],{"type":34,"value":413},"vanilla ML",{"type":34,"value":415}," setting this decisions are usually taken ",{"type":24,"tag":30,"props":417,"children":418},{},[419],{"type":34,"value":420},"manually",{"type":34,"value":422}," and ",{"type":24,"tag":30,"props":424,"children":425},{},[426],{"type":34,"value":427},"suboptimal",{"type":34,"value":429},". In ",{"type":24,"tag":30,"props":431,"children":432},{},[433],{"type":34,"value":434},"Meta-learning",{"type":34,"value":436}," there would also be an ",{"type":24,"tag":30,"props":438,"children":439},{},[440],{"type":34,"value":441},"outer optimizer",{"type":34,"value":443}," whose task is to ",{"type":24,"tag":30,"props":445,"children":446},{},[447],{"type":34,"value":448},"optimize these decisions",{"type":34,"value":450},". Some ways to achieve it could be updating the Learning Rule, selecting the model (architecture or initial parameters) or rescheduling the data.",{"type":24,"tag":46,"props":452,"children":453},{},[454],{"type":24,"tag":175,"props":455,"children":458},{"alt":456,"src":457},"Imgur","https://i.imgur.com/zyRBmGS.png",[],{"type":24,"tag":46,"props":460,"children":461},{},[462,464,469,471,476,478,482],{"type":34,"value":463},"Until this point, there could be a bit of ",{"type":24,"tag":30,"props":465,"children":466},{},[467],{"type":34,"value":468},"confusion between Meta-Learning and other techniques",{"type":34,"value":470},". The difference is how is the ",{"type":24,"tag":30,"props":472,"children":473},{},[474],{"type":34,"value":475},"schedule",{"type":34,"value":477}," built and where is the ",{"type":24,"tag":30,"props":479,"children":480},{},[481],{"type":34,"value":406},{"type":34,"value":483}," taken from. In Meta-Learning the flow works as follows:",{"type":24,"tag":485,"props":486,"children":487},"blockquote",{},[488],{"type":24,"tag":46,"props":489,"children":490},{},[491,493,498,500,504,506,511,513,518,520,525,527,532,534,539,541,546,548,553,555,559,561,566,568,573,575,579,581,586,588,592,594,599,601,606,608,613,615,620,622,627,629,633,635,640,642,646,648,652,654,659,661,666,668,672,674,679,681,686],{"type":34,"value":492},"Pretend we are aiming to solve an specific ",{"type":24,"tag":30,"props":494,"children":495},{},[496],{"type":34,"value":497},"task",{"type":34,"value":499},". This ",{"type":24,"tag":30,"props":501,"children":502},{},[503],{"type":34,"value":497},{"type":34,"value":505}," may be drawn from a bigger ",{"type":24,"tag":30,"props":507,"children":508},{},[509],{"type":34,"value":510},"domain of tasks",{"type":34,"value":512},". In the example below, imagine we face a binary image classification task among a series of animal classes (monkey, dog, cat, elephant, fish, snake, hippo...). For example, imagine that we in the end will end up having to classify between dogs and snakes. We want to ",{"type":24,"tag":30,"props":514,"children":515},{},[516],{"type":34,"value":517},"learn how to learn",{"type":34,"value":519}," efficiently this specific task. We could define the domain as binary animal image classification tasks. The domain also includes a ",{"type":24,"tag":30,"props":521,"children":522},{},[523],{"type":34,"value":524},"series of conditions",{"type":34,"value":526}," below (RGB camera images, full body, denoised, real...). Now, along all the ",{"type":24,"tag":30,"props":528,"children":529},{},[530],{"type":34,"value":531},"domain",{"type":34,"value":533}," we may draw a ",{"type":24,"tag":30,"props":535,"children":536},{},[537],{"type":34,"value":538},"series of tasks",{"type":34,"value":540}," different than the one we are aiming to solve. To avoid this happening we may drop both dog and snake classes from a bag with all ",{"type":24,"tag":30,"props":542,"children":543},{},[544],{"type":34,"value":545},"classes",{"type":34,"value":547},", and build ",{"type":24,"tag":30,"props":549,"children":550},{},[551],{"type":34,"value":552},"tasks",{"type":34,"value":554}," by picking combinations of two classes. Thus, for each task, we will have to classify images between both classes and then that will be a binary animal image classification task. These ",{"type":24,"tag":30,"props":556,"children":557},{},[558],{"type":34,"value":552},{"type":34,"value":560}," will be ",{"type":24,"tag":30,"props":562,"children":563},{},[564],{"type":34,"value":565},"equivalent",{"type":34,"value":567}," to the ",{"type":24,"tag":30,"props":569,"children":570},{},[571],{"type":34,"value":572},"samples",{"type":34,"value":574}," in the ",{"type":24,"tag":30,"props":576,"children":577},{},[578],{"type":34,"value":305},{"type":34,"value":580}," (or ",{"type":24,"tag":30,"props":582,"children":583},{},[584],{"type":34,"value":585},"task level",{"type":34,"value":587},") but in the ",{"type":24,"tag":30,"props":589,"children":590},{},[591],{"type":34,"value":312},{"type":34,"value":593},". So, equivalently to what we would do at the ",{"type":24,"tag":30,"props":595,"children":596},{},[597],{"type":34,"value":598},"training level",{"type":34,"value":600}," we will build two ",{"type":24,"tag":30,"props":602,"children":603},{},[604],{"type":34,"value":605},"(meta-)sets",{"type":34,"value":607},". One will have ",{"type":24,"tag":30,"props":609,"children":610},{},[611],{"type":34,"value":612},"Meta-training tasks",{"type":34,"value":614}," while the other ",{"type":24,"tag":30,"props":616,"children":617},{},[618],{"type":34,"value":619},"Meta-test tasks",{"type":34,"value":621},". And yeah, if you do things correctly you would also have a ",{"type":24,"tag":30,"props":623,"children":624},{},[625],{"type":34,"value":626},"Meta-validation meta-set",{"type":34,"value":628},", of course. Then, for each ",{"type":24,"tag":30,"props":630,"children":631},{},[632],{"type":34,"value":497},{"type":34,"value":634}," we will work as always at the ",{"type":24,"tag":30,"props":636,"children":637},{},[638],{"type":34,"value":639},"Learning Level",{"type":34,"value":641},", getting ",{"type":24,"tag":30,"props":643,"children":644},{},[645],{"type":34,"value":572},{"type":34,"value":647}," for the ",{"type":24,"tag":30,"props":649,"children":650},{},[651],{"type":34,"value":497},{"type":34,"value":653}," and splitting them between **train, validation and test (as always). At this level, we will ",{"type":24,"tag":30,"props":655,"children":656},{},[657],{"type":34,"value":658},"train the model as usual",{"type":34,"value":660},", evaluate, etc., so we will end up having some ",{"type":24,"tag":30,"props":662,"children":663},{},[664],{"type":34,"value":665},"performance measure",{"type":34,"value":667}," (usually a Loss value). These individual task results will serve in the ",{"type":24,"tag":30,"props":669,"children":670},{},[671],{"type":34,"value":312},{"type":34,"value":673}," to ",{"type":24,"tag":30,"props":675,"children":676},{},[677],{"type":34,"value":678},"evaluate the outer optimizer",{"type":34,"value":680}," and making the corresponding ",{"type":24,"tag":30,"props":682,"children":683},{},[684],{"type":34,"value":685},"updates",{"type":34,"value":687},". Below in the example, each task updates the model, but it is just an example. Actually, just like at the Learning level, it can work by batches (in this case, batches of tasks). Just good luck with your hardware limitations. Then the Meta-test meta-set is used to evaluate by any given metric.",{"type":24,"tag":46,"props":689,"children":690},{},[691],{"type":24,"tag":175,"props":692,"children":694},{"alt":456,"src":693},"https://i.imgur.com/a9Fr97l.png",[],{"type":24,"tag":46,"props":696,"children":697},{},[698,700,705,707,712,714,719,721,726],{"type":34,"value":699},"Note that all this process is ",{"type":24,"tag":30,"props":701,"children":702},{},[703],{"type":34,"value":704},"designed from the beginning",{"type":34,"value":706}," to optimize the process of Learning in our target task. So our Meta-Learning schedule is indeed a ",{"type":24,"tag":30,"props":708,"children":709},{},[710],{"type":34,"value":711},"schedule for Learning to Learn",{"type":34,"value":713},". Any approach that falls into that definition is a Meta-Learning approach. You must also notice the difference between that and other similar techniques. For example, in ",{"type":24,"tag":30,"props":715,"children":716},{},[717],{"type":34,"value":718},"Transfer Learning",{"type":34,"value":720}," (another different whole topic) you do not learn how to learn for an specific task (or a task from an specific domain), but instead ",{"type":24,"tag":30,"props":722,"children":723},{},[724],{"type":34,"value":725},"use old knowledge to get closer to the optimal solution",{"type":34,"value":727}," (when you learned that old knowledge, you learned it for a whole different solution and was not intended to extend to any other different problem, thus there doesn't exist a Meta-Learning level). Some related topics are:",{"type":24,"tag":729,"props":730,"children":731},"ul",{},[732],{"type":24,"tag":733,"props":734,"children":735},"li",{},[736],{"type":34,"value":737},"Transfer Learning: using old knowledge optimized to solve another task to solve the current target task.",{"type":24,"tag":46,"props":739,"children":740},{},[741],{"type":24,"tag":175,"props":742,"children":744},{"alt":456,"src":743},"https://i.imgur.com/4kN4Xu8.png",[],{"type":24,"tag":729,"props":746,"children":747},{},[748],{"type":24,"tag":733,"props":749,"children":750},{},[751],{"type":34,"value":752},"Domain adaptation: learning from a different domain with some common conditions (e.g. in our example above learning the dog vs snake task from synthetic images).",{"type":24,"tag":46,"props":754,"children":755},{},[756],{"type":24,"tag":175,"props":757,"children":759},{"alt":456,"src":758},"https://i.imgur.com/FLTKEbi.png",[],{"type":24,"tag":729,"props":761,"children":762},{},[763],{"type":24,"tag":733,"props":764,"children":765},{},[766],{"type":34,"value":767},"Multimodal Learning: learning from different modes of data (e.g. a text description), although it can be viewed from a Meta-Learning level it covers a different topic and is treated differently (since it builds a different setting).",{"type":24,"tag":46,"props":769,"children":770},{},[771],{"type":24,"tag":175,"props":772,"children":774},{"alt":456,"src":773},"https://i.imgur.com/rTmjzmU.png",[],{"type":24,"tag":46,"props":776,"children":777},{},[778],{"type":34,"value":779},"Ok, so now we have an idea of what is Meta-Learning and how to use it. But why use it? Motivations are diverse and have varied over time. Actually, one can use it whenever it is beneficial for his task. But the important question is what did raise the interest of researchers to present schedules, definitions and solutions that include Meta-Learning? To do so, we may have a quick recap of Meta-Learning history.",{"type":24,"tag":36,"props":781,"children":783},{"id":782},"origins-of-meta-learning",[784],{"type":24,"tag":30,"props":785,"children":786},{},[787],{"type":34,"value":788},"Origins of Meta-Learning",{"type":24,"tag":46,"props":790,"children":791},{},[792,794,805,807,812,814,819,821,826,828,833,835,840,842,847,849,854,856,861,863,870,872,877],{"type":34,"value":793},"The term arose in a publication in Jrgen Schmidhuber's thesis called ",{"type":24,"tag":59,"props":795,"children":798},{"href":796,"rel":797},"https://people.idsia.ch/~juergen/diploma1987ocr.pdf",[63],[799],{"type":24,"tag":800,"props":801,"children":802},"em",{},[803],{"type":34,"value":804},"Evolutionary Principles in Self-Referential Learning",{"type":34,"value":806}," (1987). The paper is incredibly dense, but a mine of knowledge and talks about some deep topics such as Information, Entropy, Evolution... We may talk specifically about this paper in future posts, but what concerns us now is that it ",{"type":24,"tag":30,"props":808,"children":809},{},[810],{"type":34,"value":811},"presented the idea of Meta-Learning",{"type":34,"value":813}," as a way to modify the ",{"type":24,"tag":30,"props":815,"children":816},{},[817],{"type":34,"value":818},"plans",{"type":34,"value":820}," (the equivalent of what the ",{"type":24,"tag":30,"props":822,"children":823},{},[824],{"type":34,"value":825},"schedulers + optimizers",{"type":34,"value":827}," in ML mean nowadays) in order to generalize to a ",{"type":24,"tag":30,"props":829,"children":830},{},[831],{"type":34,"value":832},"whole group of domains",{"type":34,"value":834},". This group is again some kind of ",{"type":24,"tag":30,"props":836,"children":837},{},[838],{"type":34,"value":839},"(meta-)domain",{"type":34,"value":841},", so it also needed some ",{"type":24,"tag":30,"props":843,"children":844},{},[845],{"type":34,"value":846},"(meta-)plan",{"type":34,"value":848},". The hypothesis that Schmidhuber did back in 1987 is that this concept was extendable to ",{"type":24,"tag":30,"props":850,"children":851},{},[852],{"type":34,"value":853},"infinite levels of abstraction",{"type":34,"value":855},", thus allowing the definition (apart from the domain level and the meta-level) of a meta-meta-level, a meta-meta-meta-level, and so on, although the paper also points the compromise that the realization has with the ",{"type":24,"tag":30,"props":857,"children":858},{},[859],{"type":34,"value":860},"computation capacity of the hardware",{"type":34,"value":862}," (plus recall we are in 1987, there were no NVIDIA RTX 4090... actually ",{"type":24,"tag":59,"props":864,"children":867},{"href":865,"rel":866},"https://en.wikipedia.org/wiki/GeForce_256",[63],[868],{"type":34,"value":869},"the first GPU",{"type":34,"value":871}," came out 12 years later). He proposed ",{"type":24,"tag":30,"props":873,"children":874},{},[875],{"type":34,"value":876},"2 ways",{"type":34,"value":878}," to implement Meta-Learning:",{"type":24,"tag":729,"props":880,"children":881},{},[882,914],{"type":24,"tag":733,"props":883,"children":884},{},[885,887,892,894,899,901,906,908,913],{"type":34,"value":886},"First, as a ",{"type":24,"tag":30,"props":888,"children":889},{},[890],{"type":34,"value":891},"Genetic Algorithm",{"type":34,"value":893},". My interpretation is that he was wondering about what nowadays is ",{"type":24,"tag":30,"props":895,"children":896},{},[897],{"type":34,"value":898},"Curriculum Learning",{"type":34,"value":900},", but from a Meta-Learning perspective. He proposed that at the Meta-Level the plan should schedule the best samples for the domain level. His own concerns? About \"",{"type":24,"tag":30,"props":902,"children":903},{},[904],{"type":34,"value":905},"nature",{"type":34,"value":907},"\" (AI then aimed more to mimic true intelligence) and ",{"type":24,"tag":30,"props":909,"children":910},{},[911],{"type":34,"value":912},"feasibility",{"type":34,"value":170},{"type":24,"tag":733,"props":915,"children":916},{},[917,919,924,926,931,933,938],{"type":34,"value":918},"Second, as a ",{"type":24,"tag":30,"props":920,"children":921},{},[922],{"type":34,"value":923},"hierarchy of classifiers",{"type":34,"value":925}," building the Genetic Algorithm, which will act at the ",{"type":24,"tag":30,"props":927,"children":928},{},[929],{"type":34,"value":930},"meta-level",{"type":34,"value":932},". Schmidhuber pointed out that this way the mechanism could work with a ",{"type":24,"tag":30,"props":934,"children":935},{},[936],{"type":34,"value":937},"fixed number of levels",{"type":34,"value":939},", just the domain level (each classifier) and the meta-level (the Genetic Algorithm).",{"type":24,"tag":46,"props":941,"children":942},{},[943,947],{"type":24,"tag":175,"props":944,"children":946},{"alt":456,"src":945},"https://i.imgur.com/KWobPej.png",[],{"type":24,"tag":175,"props":948,"children":950},{"alt":456,"src":949},"https://i.imgur.com/blCSh2S.png",[],{"type":24,"tag":46,"props":952,"children":953},{},[954,956,961,963,968,970,975],{"type":34,"value":955},"Another interesting interpretation from the paper is the way a plan works in a Genetic Algorithm, which is similar to the environment in ",{"type":24,"tag":30,"props":957,"children":958},{},[959],{"type":34,"value":960},"Reinforcement Learning",{"type":34,"value":962},". Thus, ",{"type":24,"tag":30,"props":964,"children":965},{},[966],{"type":34,"value":967},"surviving",{"type":34,"value":969}," a plan in a Genetic Algorithm can be viewed as getting a ",{"type":24,"tag":30,"props":971,"children":972},{},[973],{"type":34,"value":974},"reward",{"type":34,"value":976}," in Reinforcement Learning.",{"type":24,"tag":46,"props":978,"children":979},{},[980,982,992,994,999,1001,1006,1008,1013,1015,1020,1022,1029,1031,1038],{"type":34,"value":981},"5 years later, Schmidhuber made another important contribution to Meta-Learning in ",{"type":24,"tag":59,"props":983,"children":986},{"href":984,"rel":985},"https://people.idsia.ch/~juergen/FKI-147-91ocr.pdf",[63],[987],{"type":24,"tag":800,"props":988,"children":989},{},[990],{"type":34,"value":991},"Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks",{"type":34,"value":993},". He defined a series of sequential (by episodes or plain timesteps) problems. To make you an idea, one of these problems consisted in predicting the parking slot where some car parked given a series of sensor states (distributed along the parking ground) at different time instants. In this case, no episodes were used as it was an online problem (prediction was made at the same training time). Instead, a prediction network was used for the task. The particularity is that another ",{"type":24,"tag":30,"props":995,"children":996},{},[997],{"type":34,"value":998},"network at a level above learned the weights updates",{"type":34,"value":1000}," that the domain one should experiment. Thus, the sequence could be seen as an ",{"type":24,"tag":30,"props":1002,"children":1003},{},[1004],{"type":34,"value":1005},"artificial meta-level",{"type":34,"value":1007},", while at each timestep the inner network performed the task. In the offline setting, the behavior was the same, just defining the sequence through bounded episodes. This was the ",{"type":24,"tag":30,"props":1009,"children":1010},{},[1011],{"type":34,"value":1012},"first published Meta-Learning approach",{"type":34,"value":1014}," that worked for ",{"type":24,"tag":30,"props":1016,"children":1017},{},[1018],{"type":34,"value":1019},"practical tasks",{"type":34,"value":1021},". Surprisingly, ",{"type":24,"tag":59,"props":1023,"children":1026},{"href":1024,"rel":1025},"https://imgur.com/9uvwpUb",[63],[1027],{"type":34,"value":1028},"the word meta is missing",{"type":34,"value":1030}," in that paper, but the interpretation seems clear to me to give the idea of an inner and an outer model that Schmidhuber was working around at that time, isn't it? When I researched about that, ",{"type":24,"tag":59,"props":1032,"children":1035},{"href":1033,"rel":1034},"https://people.idsia.ch/~juergen/metalearning.html",[63],[1036],{"type":34,"value":1037},"Schmidhuber himself considered this as a way of Meta-Learning",{"type":34,"value":170},{"type":24,"tag":46,"props":1040,"children":1041},{},[1042],{"type":24,"tag":175,"props":1043,"children":1045},{"alt":456,"src":1044},"https://i.imgur.com/tDtaaKC.jpg",[],{"type":24,"tag":46,"props":1047,"children":1048},{},[1049,1051,1061,1063,1068,1070,1075,1077,1082,1084,1089,1091,1096,1098,1103,1105,1110],{"type":34,"value":1050},"But that was not the only meaningful publication of Meta-Learning in 1992. Bengio (both Samy and Yoshua) et al. published this same year the paper called ",{"type":24,"tag":59,"props":1052,"children":1055},{"href":1053,"rel":1054},"http://www.iro.umontreal.ca/~lisa/pointeurs/bengio_1995_oban.pdf",[63],[1056],{"type":24,"tag":800,"props":1057,"children":1058},{},[1059],{"type":34,"value":1060},"On the Optimization of a Synaptic Learning Rule",{"type":34,"value":1062},", which probably is the first definition of a ",{"type":24,"tag":30,"props":1064,"children":1065},{},[1066],{"type":34,"value":1067},"Meta-Learning setting",{"type":34,"value":1069}," how we imagine that nowadays (although again they do not refer to the word meta!). They just defined a framework with an ",{"type":24,"tag":30,"props":1071,"children":1072},{},[1073],{"type":34,"value":1074},"inner prediction algorithm",{"type":34,"value":1076}," (the previously called domain level), which actually was a ",{"type":24,"tag":30,"props":1078,"children":1079},{},[1080],{"type":34,"value":1081},"Neural Network",{"type":34,"value":1083}," (yes, Neural Networks existed before LeNet, didn't you know?) and was ",{"type":24,"tag":30,"props":1085,"children":1086},{},[1087],{"type":34,"value":1088},"optimized through a Synaptic Learning Rule",{"type":34,"value":1090},", which again was ",{"type":24,"tag":30,"props":1092,"children":1093},{},[1094],{"type":34,"value":1095},"optimized by an outer optimization algorithm",{"type":34,"value":1097}," (what would be the meta-level). The point of the paper is that this Synaptic Learning Rule should be ",{"type":24,"tag":30,"props":1099,"children":1100},{},[1101],{"type":34,"value":1102},"parametric",{"type":34,"value":1104},", so the outer optimizer should just ",{"type":24,"tag":30,"props":1106,"children":1107},{},[1108],{"type":34,"value":1109},"update its parameters",{"type":34,"value":1111},". Thus, by defining well the episodic nature of the updates at the beginning of the whole process, the Synaptic Learning Rule should be able to learn from the task results a generalization of the whole domain of tasks.",{"type":24,"tag":46,"props":1113,"children":1114},{},[1115],{"type":24,"tag":175,"props":1116,"children":1118},{"alt":456,"src":1117},"https://i.imgur.com/aw60MAG.png",[],{"type":24,"tag":46,"props":1120,"children":1121},{},[1122],{"type":34,"value":1123},"For sure 1992 was an important year for Meta-Learning! It was also the year I was born, so maybe it was my destiny to study this field.",{"type":24,"tag":46,"props":1125,"children":1126},{},[1127,1129,1134,1136,1146,1148,1158],{"type":34,"value":1128},"Later on, Schmidhuber continued his study in Meta-Learning by extending it to ",{"type":24,"tag":30,"props":1130,"children":1131},{},[1132],{"type":34,"value":1133},"Meta-Reinforcement Learning",{"type":34,"value":1135}," with publications such as ",{"type":24,"tag":59,"props":1137,"children":1140},{"href":1138,"rel":1139},"https://people.idsia.ch/~juergen/fki198-94.pdf",[63],[1141],{"type":24,"tag":800,"props":1142,"children":1143},{},[1144],{"type":34,"value":1145},"On learning how to learn learning strategies",{"type":34,"value":1147}," (1994) or ",{"type":24,"tag":59,"props":1149,"children":1152},{"href":1150,"rel":1151},"https://people.idsia.ch/~juergen/interest.html",[63],[1153],{"type":24,"tag":800,"props":1154,"children":1155},{},[1156],{"type":34,"value":1157},"What's interesting",{"type":34,"value":1159}," (1997), but we will skip this part since it falls more into the domain of Reinforcement Learning. Just recall the analogy I mentioned above between Meta-Learning in Reinforcement-Learning and Meta-Learning in Genetic Algorithms. It seems he was already pointing in that direction, and that was actually one of the main trends of Meta-Learning at that time. However, another direction was the one initiated by Bengio brothers back in 1992, and that was the one that brought us to the point we are nowadays.",{"type":24,"tag":46,"props":1161,"children":1162},{},[1163,1165,1175,1177,1182],{"type":34,"value":1164},"In that sense, Hochreiter made another interesting publication in 2001, called ",{"type":24,"tag":59,"props":1166,"children":1169},{"href":1167,"rel":1168},"https://www.researchgate.net/publication/225182080_Learning_To_Learn_Using_Gradient_Descent",[63],[1170],{"type":24,"tag":800,"props":1171,"children":1172},{},[1173],{"type":34,"value":1174},"Learning To Learn Using Gradient Descent",{"type":34,"value":1176},", where they used the aforementioned paradigm of the inner prediction algorithm and the outer optimizer (of the parametric Learning Rule) and proposed that this ",{"type":24,"tag":30,"props":1178,"children":1179},{},[1180],{"type":34,"value":1181},"outer optimizer should be updated by a Gradient Descent",{"type":34,"value":1183},". Oh, and finally they called that Meta-Learning. They proposed for this a task with sequences and used a Neural Network (don't be surprised, LeNet already existed) to perform the experiments. Both the inner predictor (task level) and the outer optimizer (meta-level) were RNNs. Before this publication, a similar approach was already studied called Adaptive Learning, which already used a Neural Network to optimize a learning rule. However, the setting there is different (no Meta-Learning at all).",{"type":24,"tag":46,"props":1185,"children":1186},{},[1187],{"type":24,"tag":175,"props":1188,"children":1190},{"alt":456,"src":1189},"https://i.imgur.com/8bSfzGl.png",[],{"type":24,"tag":46,"props":1192,"children":1193},{},[1194,1196,1201],{"type":34,"value":1195},"After that, obviously more publications about Meta-Learning appeared. However, until 2015 the focus of interest in ",{"type":24,"tag":30,"props":1197,"children":1198},{},[1199],{"type":34,"value":1200},"Machine Learning was on other topics",{"type":34,"value":1202}," (you know that it was a time of big changes, where the first truly big Neural Networks arrived, and everything began to explode), and I don't feel that this publications repercussion on the evolution of Meta-Learning is worth enough to include in this basic summary. So with this, I think we already have an idea of how the knowledge about Meta-Learning arrived in 2015, and how it was viewed back then when the interest returned with new motivations.",{"type":24,"tag":36,"props":1204,"children":1206},{"id":1205},"the-comeback-of-meta-learning-and-its-relation-to-few-shot-learning",[1207],{"type":24,"tag":30,"props":1208,"children":1209},{},[1210],{"type":34,"value":1211},"The comeback of Meta-Learning and its relation to Few-Shot Learning",{"type":24,"tag":46,"props":1213,"children":1214},{},[1215,1217,1222,1224,1229,1231,1236],{"type":34,"value":1216},"The interest in Meta-Learning returned when ML research gazed a further step than plain basic ML tasks. Before 2015, most of the applications ",{"type":24,"tag":30,"props":1218,"children":1219},{},[1220],{"type":34,"value":1221},"relied on vast amounts of data",{"type":34,"value":1223},", but at the time of making ",{"type":24,"tag":30,"props":1225,"children":1226},{},[1227],{"type":34,"value":1228},"ML accessible to anyone",{"type":34,"value":1230}," (not just the big fishes in the industry), that scenario ",{"type":24,"tag":30,"props":1232,"children":1233},{},[1234],{"type":34,"value":1235},"was not realistic",{"type":34,"value":1237},". Yes, there were already public datasets, but when trying to make some slightly ambiguous applications, it was needed some data conditions that were not easy to find. Not all small companies or particular researchers had access to a batch of 1 million images of, let's say, water impurities, and it was a too concrete phenomenon to find a huge open dataset about it.",{"type":24,"tag":46,"props":1239,"children":1240},{},[1241,1243,1253,1255,1260,1262,1266,1268,1273],{"type":34,"value":1242},"In 2015, Koch et al. presented the publication ",{"type":24,"tag":59,"props":1244,"children":1247},{"href":1245,"rel":1246},"https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf",[63],[1248],{"type":24,"tag":800,"props":1249,"children":1250},{},[1251],{"type":34,"value":1252},"Siamese Neural Networks for One-shot Image Recognition",{"type":34,"value":1254},". As the title says, they introduced the concept of ",{"type":24,"tag":30,"props":1256,"children":1257},{},[1258],{"type":34,"value":1259},"One-shot Learning",{"type":34,"value":1261}," where they proposed to solve a ",{"type":24,"tag":30,"props":1263,"children":1264},{},[1265],{"type":34,"value":497},{"type":34,"value":1267}," (in the paper an image classification task) with just ",{"type":24,"tag":30,"props":1269,"children":1270},{},[1271],{"type":34,"value":1272},"one single sample (image) per class",{"type":34,"value":1274},". They argued that humans are able to do so (e.g., in the example we made before about recognizing a new bird, we may recognize it after seeing it just one time, at least with a good memory capacity!) so why couldn't a system do so automatically? In this paper Meta-Learning was not mentioned (they just described a method to match patterns efficiently with one single image in the Omniglot dataset), but the seed of curiosity was already planted to raise interest in this topic. It is not hard to imagine that the Meta-Learning term returned to action after that. In the end, we defined before that Meta-Learning was intended to use in order to make systems able to learn tasks more efficiently, and that included several interests. One of that interests may be precisely One-shot Learning. So from the more generic old definition, now we have a concrete motivation.",{"type":24,"tag":46,"props":1276,"children":1277},{},[1278],{"type":24,"tag":175,"props":1279,"children":1281},{"alt":456,"src":1280},"https://i.imgur.com/OktLV6n.png",[],{"type":24,"tag":46,"props":1283,"children":1284},{},[1285,1287,1292,1294,1299,1301,1306,1308,1313,1315,1320,1322,1327],{"type":34,"value":1286},"We will continue in the next section reviewing how Meta-learning was proposed after that, but first I would like to discuss the ",{"type":24,"tag":30,"props":1288,"children":1289},{},[1290],{"type":34,"value":1291},"feasibility of One-shot Learning",{"type":34,"value":1293},". Solving One-shot Learning problems using Meta-Learning is yet another, although possible, ",{"type":24,"tag":30,"props":1295,"children":1296},{},[1297],{"type":34,"value":1298},"ideal case",{"type":34,"value":1300},". One will not always dispose of enough data from the task domain that will allow performing Meta-Learning efficiently, and not always a representative enough task domain may be defined. Reality may be sometimes demoralizing, and yes, expecting to approach an ideal solution with another ideal approach is not exactly a guarantee of success. But there is still a motivation behind. One-shot Learning may be a too ambitious purpose in some cases, but if the term One-shot comes from one single sample, doesn't exist a Two-shot, or a Three-shot, and so on? Yes, it does. Actually, One-shot Learning is a particularization of ",{"type":24,"tag":30,"props":1302,"children":1303},{},[1304],{"type":34,"value":1305},"Few-shot Learning",{"type":34,"value":1307}," or ",{"type":24,"tag":30,"props":1309,"children":1310},{},[1311],{"type":34,"value":1312},"K-shot Learning",{"type":34,"value":1314},", which mean ",{"type":24,"tag":30,"props":1316,"children":1317},{},[1318],{"type":34,"value":1319},"learning with just few or K samples respectively",{"type":34,"value":1321},". Thus, the ",{"type":24,"tag":30,"props":1323,"children":1324},{},[1325],{"type":34,"value":1326},"level of ambition is adjustable to the resources and needs",{"type":34,"value":1328}," in each case. For example, maybe we would not be able to have 1 million images of water impurities, but getting 100 labeled images of them may be more accessible, as well as a 100-shot learning problem may be more realistic to solve than a One-shot one.",{"type":24,"tag":46,"props":1330,"children":1331},{},[1332,1334,1339,1341,1345],{"type":34,"value":1333},"So to conclude this section, Meta-Learning re-arose as a solution to Few-shot Learning. Said that I think it is important to not lose the old, more general perspective of it. That allows us to apply Meta-Learning for several problems such as ",{"type":24,"tag":30,"props":1335,"children":1336},{},[1337],{"type":34,"value":1338},"Active Learning",{"type":34,"value":1340},", ",{"type":24,"tag":30,"props":1342,"children":1343},{},[1344],{"type":34,"value":898},{"type":34,"value":1346},", etc. But let's continue the story.",{"type":24,"tag":36,"props":1348,"children":1350},{"id":1349},"the-modern-meta-learning-approaches-presented",[1351],{"type":24,"tag":30,"props":1352,"children":1353},{},[1354],{"type":34,"value":1355},"The modern Meta-Learning approaches presented",{"type":24,"tag":46,"props":1357,"children":1358},{},[1359,1361,1368,1370,1375],{"type":34,"value":1360},"If you search for ",{"type":24,"tag":59,"props":1362,"children":1365},{"href":1363,"rel":1364},"https://imgur.com/fzTtsDP",[63],[1366],{"type":34,"value":1367},"Meta-Learning publications since 2016",{"type":34,"value":1369},", you may fall off your seat. However, what actually happened is that the modern strategies to perform Meta-Learning (most of them focused on One-Shot Learning) exploded. The ",{"type":24,"tag":30,"props":1371,"children":1372},{},[1373],{"type":34,"value":1374},"main Meta-Learning strategies",{"type":34,"value":1376}," nowadays are divided into 3 or 4 \"families\". Apart from the solutions that we will review in this section, the rest of the publications focus on experimenting with them and studying the behavior, modifying them with some witty hacks, or, what is most common nowadays, trying to use them in specific scenarios.",{"type":24,"tag":1378,"props":1379,"children":1381},"h3",{"id":1380},"usage-of-memories",[1382],{"type":34,"value":1383},"Usage of memories",{"type":24,"tag":46,"props":1385,"children":1386},{},[1387,1389,1394,1396,1406,1408,1413,1415,1420,1422,1427,1429,1436,1438,1443],{"type":34,"value":1388},"Santoro et al. were the first (as far as I know) to refer to ",{"type":24,"tag":30,"props":1390,"children":1391},{},[1392],{"type":34,"value":1393},"Meta-Learning for solving the One-shot Learning",{"type":34,"value":1395}," issue with ",{"type":24,"tag":59,"props":1397,"children":1400},{"href":1398,"rel":1399},"https://proceedings.mlr.press/v48/santoro16.pdf",[63],[1401],{"type":24,"tag":800,"props":1402,"children":1403},{},[1404],{"type":34,"value":1405},"Meta-Learning with Memory-Augmented Neural Networks",{"type":34,"value":1407}," (2016). They propose the architecture ",{"type":24,"tag":30,"props":1409,"children":1410},{},[1411],{"type":34,"value":1412},"MANN",{"type":34,"value":1414}," as a modification of ",{"type":24,"tag":30,"props":1416,"children":1417},{},[1418],{"type":34,"value":1419},"Neural Turing Machine",{"type":34,"value":1421}," (Graves et al. 2014)  to achieve Meta-Learning by reducing complexity of the original mechanism, thus allowing to ",{"type":24,"tag":30,"props":1423,"children":1424},{},[1425],{"type":34,"value":1426},"learn in fewer steps",{"type":34,"value":1428},". Recall that one of the requirements of Deep Learning refers to the size of the dataset. There's a great post about ",{"type":24,"tag":59,"props":1430,"children":1433},{"href":1431,"rel":1432},"https://rylanschaeffer.github.io/content/research/one_shot_learning_with_memory_augmented_nn/main.html",[63],[1434],{"type":34,"value":1435},"NTM and MANN",{"type":34,"value":1437},". It is a complex mechanism and we may talk a lot about this, but I'd suggest to skip this part yet (the topic is interesting but may be better to learn about this another day, you don't want to overwhelm today after reading this post) and only have in mind this first approach to achieve ",{"type":24,"tag":30,"props":1439,"children":1440},{},[1441],{"type":34,"value":1442},"Meta-Learning by learning a storage mechanism",{"type":34,"value":1444},". There's a discussion about if this may be considered Meta-Learning or not.",{"type":24,"tag":46,"props":1446,"children":1447},{},[1448],{"type":24,"tag":175,"props":1449,"children":1451},{"alt":456,"src":1450},"https://i.imgur.com/muJQ04p.png",[],{"type":24,"tag":1378,"props":1453,"children":1455},{"id":1454},"metric-learning",[1456],{"type":34,"value":1457},"Metric Learning",{"type":24,"tag":46,"props":1459,"children":1460},{},[1461,1463,1468,1470,1474,1476,1486,1488,1493,1495,1500,1502,1507,1509,1519,1521,1526,1528,1533,1535,1540],{"type":34,"value":1462},"This idea of \"",{"type":24,"tag":30,"props":1464,"children":1465},{},[1466],{"type":34,"value":1467},"reducing the complexity",{"type":34,"value":1469}," of the algorithm to reduce the need for data\" is also used in the second family of approaches we will review, ",{"type":24,"tag":30,"props":1471,"children":1472},{},[1473],{"type":34,"value":1457},{"type":34,"value":1475},". This idea was proposed by Vinayls et al. in ",{"type":24,"tag":59,"props":1477,"children":1480},{"href":1478,"rel":1479},"https://arxiv.org/pdf/1606.04080.pdf",[63],[1481],{"type":24,"tag":800,"props":1482,"children":1483},{},[1484],{"type":34,"value":1485},"Matching Networks for One-Shot Learning",{"type":34,"value":1487}," (2016). The authors aimed to switch from a Computer Vision space, where the problem is and which is typically solved through Deep Learning to ",{"type":24,"tag":30,"props":1489,"children":1490},{},[1491],{"type":34,"value":1492},"another space",{"type":34,"value":1494}," more likely to be solved by ",{"type":24,"tag":30,"props":1496,"children":1497},{},[1498],{"type":34,"value":1499},"non-parametric approaches",{"type":34,"value":1501}," (which don't need further training, e.g. kNN). To do so, they just train an ",{"type":24,"tag":30,"props":1503,"children":1504},{},[1505],{"type":34,"value":1506},"embedding Network with attention",{"type":34,"value":1508},", where attention acts as the final non-parametric matching algorithm (relates a given test image to each training one, related to one class each since we are working with One-shot Learning). The encoder network they propose is a RNN, the attention they use is Cosine Similarity and the loss they train with is a log one at Learning level while this is projected to the Meta-Learning level. This idea was also followed in ",{"type":24,"tag":59,"props":1510,"children":1513},{"href":1511,"rel":1512},"https://arxiv.org/pdf/1703.05175.pdf",[63],[1514],{"type":24,"tag":800,"props":1515,"children":1516},{},[1517],{"type":34,"value":1518},"Prototypical Networks for Few-Shot Learning",{"type":34,"value":1520}," in 2017, where Snell et al. proposed a ",{"type":24,"tag":30,"props":1522,"children":1523},{},[1524],{"type":34,"value":1525},"similar pipeline",{"type":34,"value":1527}," but instead of using a kNN-like algorithm (which Vinyals's attention mechanism stands for), they use a soft view of it, being ",{"type":24,"tag":30,"props":1529,"children":1530},{},[1531],{"type":34,"value":1532},"each class in the space a Gaussian distribution instead of a discrete frontier",{"type":34,"value":1534},". Each class distribution is called prototype in this paper, and it allows to use more than one sample per class, thus extending the problem to a Few-shot Learning problem instead of a One-shot one. The embedding function is learned from minimizing the negative log probability of the true class of the test samples. This approach of Meta-Learning is still popular nowadays due to its ",{"type":24,"tag":30,"props":1536,"children":1537},{},[1538],{"type":34,"value":1539},"simplicity",{"type":34,"value":1541},", and usually a good first step to experiment with Meta-Learning.",{"type":24,"tag":46,"props":1543,"children":1544},{},[1545],{"type":24,"tag":175,"props":1546,"children":1548},{"alt":456,"src":1547},"https://i.imgur.com/Yi60wou.png",[],{"type":24,"tag":46,"props":1550,"children":1551},{},[1552],{"type":24,"tag":175,"props":1553,"children":1555},{"alt":456,"src":1554},"https://i.imgur.com/hSDCqyd.png",[],{"type":24,"tag":1378,"props":1557,"children":1559},{"id":1558},"optimizer-meta-learning",[1560],{"type":34,"value":1561},"Optimizer Meta-Learning",{"type":24,"tag":46,"props":1563,"children":1564},{},[1565,1567,1572,1574,1584,1586,1591,1593,1597,1599,1604,1605,1610,1611,1616,1618,1623,1625,1630,1632,1637,1639,1644,1646,1651,1653,1663,1665,1670,1672,1677,1679,1684,1686,1696,1698,1703,1705,1710],{"type":34,"value":1566},"Another way to achieve Meta-Learning recovers the old idea that Schmidhuber played with, ",{"type":24,"tag":30,"props":1568,"children":1569},{},[1570],{"type":34,"value":1571},"learning an optimal optimizer",{"type":34,"value":1573}," (do you remember?). I think this idea need no longer presentation. Andrychowicz et al. presented in 2016 ",{"type":24,"tag":59,"props":1575,"children":1578},{"href":1576,"rel":1577},"https://arxiv.org/pdf/1606.04474.pdf",[63],[1579],{"type":24,"tag":800,"props":1580,"children":1581},{},[1582],{"type":34,"value":1583},"Learning to Learn By Gradient Descent By Gradient Descent",{"type":34,"value":1585},", which is not a typo but its true name. Does this sound to you? If it doesn't, I'll remind you the Hochreiter publication in 2001 called Learning to Learn Using Gradient Descent. The idea is pretty similar. As well as you have an inner algorithm to solve the task, you also have an outer training algorithm. This ",{"type":24,"tag":30,"props":1587,"children":1588},{},[1589],{"type":34,"value":1590},"training algorithm may also be optimized",{"type":34,"value":1592}," by training at the ",{"type":24,"tag":30,"props":1594,"children":1595},{},[1596],{"type":34,"value":312},{"type":34,"value":1598},". So Andrychowicz calls them ",{"type":24,"tag":30,"props":1600,"children":1601},{},[1602],{"type":34,"value":1603},"optimizee",{"type":34,"value":422},{"type":24,"tag":30,"props":1606,"children":1607},{},[1608],{"type":34,"value":1609},"optimizer",{"type":34,"value":80},{"type":24,"tag":30,"props":1612,"children":1613},{},[1614],{"type":34,"value":1615},"optimizee is a parametric algorithm",{"type":34,"value":1617}," so it is actually optimized by its parameters (called ",{"type":24,"tag":30,"props":1619,"children":1620},{},[1621],{"type":34,"value":1622},"Meta-parameters",{"type":34,"value":1624},"). Wait, isn't this the same than Hochreiter proposed? This gave me a bit of confusion and to be honest is one of the things I'm less sure about in the whole Meta-Learning topic. But my interpretation is that Hochreiter's idea was just a ",{"type":24,"tag":30,"props":1626,"children":1627},{},[1628],{"type":34,"value":1629},"generalization",{"type":34,"value":1631}," that ",{"type":24,"tag":30,"props":1633,"children":1634},{},[1635],{"type":34,"value":1636},"allowed",{"type":34,"value":1638}," to use ",{"type":24,"tag":30,"props":1640,"children":1641},{},[1642],{"type":34,"value":1643},"gradient descent in both the optimizer and the optimizee",{"type":34,"value":1645},", while this paper present ",{"type":24,"tag":30,"props":1647,"children":1648},{},[1649],{"type":34,"value":1650},"architectures for specifically that",{"type":34,"value":1652},". However, the most important idea for you here is that this view is still one of the main approaches of Meta-Learning. Later on, Larochelle et al. presented in 2017 the publication ",{"type":24,"tag":59,"props":1654,"children":1657},{"href":1655,"rel":1656},"https://openreview.net/pdf?id=rJY0-Kcll",[63],[1658],{"type":24,"tag":800,"props":1659,"children":1660},{},[1661],{"type":34,"value":1662},"Optimization as a model for Few-Shot Learning",{"type":34,"value":1664},", which builds on the ",{"type":24,"tag":30,"props":1666,"children":1667},{},[1668],{"type":34,"value":1669},"same idea",{"type":34,"value":1671}," but in this case the ",{"type":24,"tag":30,"props":1673,"children":1674},{},[1675],{"type":34,"value":1676},"optimizer is the Gradient Descent itself",{"type":34,"value":1678},", and instead of modifying Meta-Parameters acts as a ",{"type":24,"tag":30,"props":1680,"children":1681},{},[1682],{"type":34,"value":1683},"weight predictor",{"type":34,"value":1685},". The other important publication about that was done by Mishra et al in 2018, called ",{"type":24,"tag":59,"props":1687,"children":1690},{"href":1688,"rel":1689},"https://arxiv.org/pdf/1707.03141.pdf",[63],[1691],{"type":24,"tag":800,"props":1692,"children":1693},{},[1694],{"type":34,"value":1695},"A simple Neural Attentive Meta-Learner",{"type":34,"value":1697},", where they ",{"type":24,"tag":30,"props":1699,"children":1700},{},[1701],{"type":34,"value":1702},"extend",{"type":34,"value":1704}," the idea of Andrychowicz by ",{"type":24,"tag":30,"props":1706,"children":1707},{},[1708],{"type":34,"value":1709},"instead of an RNN using an (soft) Attentional NN as the optimizer",{"type":34,"value":1711}," of Meta-parameters.",{"type":24,"tag":46,"props":1713,"children":1714},{},[1715],{"type":24,"tag":175,"props":1716,"children":1718},{"alt":456,"src":1717},"https://i.imgur.com/ZXAsypi.png",[],{"type":24,"tag":46,"props":1720,"children":1721},{},[1722],{"type":24,"tag":175,"props":1723,"children":1725},{"alt":456,"src":1724},"https://i.imgur.com/MN8bSAL.png",[],{"type":24,"tag":46,"props":1727,"children":1728},{},[1729],{"type":24,"tag":175,"props":1730,"children":1732},{"alt":456,"src":1731},"https://i.imgur.com/AVs0R5k.png",[],{"type":24,"tag":1378,"props":1734,"children":1736},{"id":1735},"initialization-meta-learning",[1737],{"type":34,"value":1738},"Initialization Meta-Learning",{"type":24,"tag":46,"props":1740,"children":1741},{},[1742,1744,1749,1751,1761,1763,1768,1770,1775,1777,1782,1784,1789,1791,1795,1797,1802,1804,1809,1811,1815,1817,1822,1824,1829,1831,1836,1838,1848,1850,1855,1857,1867,1869,1874,1876,1886,1887,1892,1894,1899,1901,1906,1908,1913,1915,1925,1927,1932],{"type":34,"value":1743},"However, the probably ",{"type":24,"tag":30,"props":1745,"children":1746},{},[1747],{"type":34,"value":1748},"most popular",{"type":34,"value":1750}," approach of Meta-Learning is the one presented by Finn et al. in ",{"type":24,"tag":59,"props":1752,"children":1755},{"href":1753,"rel":1754},"https://arxiv.org/pdf/1703.03400.pdf",[63],[1756],{"type":24,"tag":800,"props":1757,"children":1758},{},[1759],{"type":34,"value":1760},"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",{"type":34,"value":1762}," (2017). These authors have made HUGE contributions to Meta-Learning, but this was the most iconic one. There, they presented ",{"type":24,"tag":30,"props":1764,"children":1765},{},[1766],{"type":34,"value":1767},"MAML",{"type":34,"value":1769},", a popular algorithm that aims to ",{"type":24,"tag":30,"props":1771,"children":1772},{},[1773],{"type":34,"value":1774},"find a proper initialization for the whole domain of tasks",{"type":34,"value":1776},".  This is applicable to ",{"type":24,"tag":30,"props":1778,"children":1779},{},[1780],{"type":34,"value":1781},"any combination of parameters",{"type":34,"value":1783},", thus becoming (as the title says) ",{"type":24,"tag":30,"props":1785,"children":1786},{},[1787],{"type":34,"value":1788},"Model-Agnostic",{"type":34,"value":1790},". At the ",{"type":24,"tag":30,"props":1792,"children":1793},{},[1794],{"type":34,"value":312},{"type":34,"value":1796},", weights follow a ",{"type":24,"tag":30,"props":1798,"children":1799},{},[1800],{"type":34,"value":1801},"path guided by a batch of tasks",{"type":34,"value":1803}," at each ",{"type":24,"tag":30,"props":1805,"children":1806},{},[1807],{"type":34,"value":1808},"meta-step",{"type":34,"value":1810},", where at each ",{"type":24,"tag":30,"props":1812,"children":1813},{},[1814],{"type":34,"value":497},{"type":34,"value":1816}," the model learns and gives a ",{"type":24,"tag":30,"props":1818,"children":1819},{},[1820],{"type":34,"value":1821},"final loss",{"type":34,"value":1823}," (after the desired few updates). This way it becomes able to (desirably) ",{"type":24,"tag":30,"props":1825,"children":1826},{},[1827],{"type":34,"value":1828},"learn quickly when facing a new task",{"type":34,"value":1830},". This algorithm is also pretty popular in Meta-Reinforcement Learning. But aside from MAML, we also have ",{"type":24,"tag":30,"props":1832,"children":1833},{},[1834],{"type":34,"value":1835},"Reptile",{"type":34,"value":1837},", presented by Nichol et al. in ",{"type":24,"tag":59,"props":1839,"children":1842},{"href":1840,"rel":1841},"https://arxiv.org/pdf/1803.02999.pdf",[63],[1843],{"type":24,"tag":800,"props":1844,"children":1845},{},[1846],{"type":34,"value":1847},"On First-Order Meta-Learning Algorithms",{"type":34,"value":1849}," (2018), where basically the ",{"type":24,"tag":30,"props":1851,"children":1852},{},[1853],{"type":34,"value":1854},"Meta-Learning trajectory follows also the individual tasks",{"type":34,"value":1856}," Learning one (what they find out to be the optimal path). Furthermore, Finn's team also presented in 2018 ",{"type":24,"tag":59,"props":1858,"children":1861},{"href":1859,"rel":1860},"https://arxiv.org/pdf/1806.02817.pdf",[63],[1862],{"type":24,"tag":800,"props":1863,"children":1864},{},[1865],{"type":34,"value":1866},"Probabilistic Model-Agnostic Meta-Learning",{"type":34,"value":1868}," (",{"type":24,"tag":30,"props":1870,"children":1871},{},[1872],{"type":34,"value":1873},"Probabilistic MAML",{"type":34,"value":1875},"), while Kim et al. presented ",{"type":24,"tag":59,"props":1877,"children":1880},{"href":1878,"rel":1879},"https://arxiv.org/pdf/1806.03836.pdf",[63],[1881],{"type":24,"tag":800,"props":1882,"children":1883},{},[1884],{"type":34,"value":1885},"Bayesian Model-Agnostic Meta-Learning",{"type":34,"value":1868},{"type":24,"tag":30,"props":1888,"children":1889},{},[1890],{"type":34,"value":1891},"BMAML",{"type":34,"value":1893},"). To be honest, I'm not sure about the conceptual difference between both, but the conclusion is that the flexibility of MAML allowed even to introduce ",{"type":24,"tag":30,"props":1895,"children":1896},{},[1897],{"type":34,"value":1898},"uncertainty",{"type":34,"value":1900},", where the learned (and therefore initialized in MAML) ",{"type":24,"tag":30,"props":1902,"children":1903},{},[1904],{"type":34,"value":1905},"weights worked in probabilistic frameworks",{"type":34,"value":1907},", thus being ",{"type":24,"tag":30,"props":1909,"children":1910},{},[1911],{"type":34,"value":1912},"distributions",{"type":34,"value":1914},". Also Finn's team (again) presented ",{"type":24,"tag":59,"props":1916,"children":1919},{"href":1917,"rel":1918},"https://arxiv.org/pdf/1902.08438.pdf",[63],[1920],{"type":24,"tag":800,"props":1921,"children":1922},{},[1923],{"type":34,"value":1924},"Online Meta-Learning",{"type":34,"value":1926}," (2019), where they used ",{"type":24,"tag":30,"props":1928,"children":1929},{},[1930],{"type":34,"value":1931},"MAML in an Online scenario",{"type":34,"value":1933},"**, where tasks were presented in a manner in which no information about future tasks was available at each batch.",{"type":24,"tag":46,"props":1935,"children":1936},{},[1937],{"type":24,"tag":175,"props":1938,"children":1940},{"alt":456,"src":1939},"https://i.imgur.com/6f3Fw6i.png",[],{"type":24,"tag":46,"props":1942,"children":1943},{},[1944],{"type":24,"tag":175,"props":1945,"children":1947},{"alt":456,"src":1946},"https://i.imgur.com/cLdIkro.png",[],{"type":24,"tag":46,"props":1949,"children":1950},{},[1951],{"type":24,"tag":175,"props":1952,"children":1954},{"alt":456,"src":1953},"https://i.imgur.com/XJ2Y8cG.png",[],{"type":24,"tag":46,"props":1956,"children":1957},{},[1958],{"type":24,"tag":175,"props":1959,"children":1961},{"alt":456,"src":1960},"https://i.imgur.com/fpWeEt4.png",[],{"type":24,"tag":46,"props":1963,"children":1964},{},[1965],{"type":24,"tag":175,"props":1966,"children":1968},{"alt":456,"src":1967},"https://i.imgur.com/wX4paDu.png",[],{"type":24,"tag":1378,"props":1970,"children":1972},{"id":1971},"modular-meta-learning",[1973],{"type":34,"value":1974},"Modular Meta-Learning",{"type":24,"tag":46,"props":1976,"children":1977},{},[1978,1980,1990,1992,1997,1999,2004,2006,2011,2013,2018],{"type":34,"value":1979},"Last, in 2020 Chen et al. published ",{"type":24,"tag":59,"props":1981,"children":1984},{"href":1982,"rel":1983},"https://arxiv.org/pdf/1909.05557.pdf",[63],[1985],{"type":24,"tag":800,"props":1986,"children":1987},{},[1988],{"type":34,"value":1989},"Modular Meta-Learning with Shrinkage",{"type":34,"value":1991},", where they referred to what I think was the last of the big Meta-Learning approaches. They formalized the popular procedure when pretraining + fine-tuning is done by ",{"type":24,"tag":30,"props":1993,"children":1994},{},[1995],{"type":34,"value":1996},"modules",{"type":34,"value":1998}," (e.g. the typical frozen backbone while fine-tuning heads). What they proposed is ",{"type":24,"tag":30,"props":2000,"children":2001},{},[2002],{"type":34,"value":2003},"(meta-)learning the priors",{"type":34,"value":2005}," in which ",{"type":24,"tag":30,"props":2007,"children":2008},{},[2009],{"type":34,"value":2010},"each module",{"type":34,"value":2012}," has to ",{"type":24,"tag":30,"props":2014,"children":2015},{},[2016],{"type":34,"value":2017},"shrink",{"type":34,"value":2019}," (i.e. the strength to adapt to the task training). This way, they opened a door for new publications.",{"type":24,"tag":46,"props":2021,"children":2022},{},[2023],{"type":24,"tag":175,"props":2024,"children":2026},{"alt":456,"src":2025},"https://i.imgur.com/qUL4xKq.png",[],{"type":24,"tag":1378,"props":2028,"children":2030},{"id":2029},"summary",[2031],{"type":34,"value":2032},"Summary",{"type":24,"tag":46,"props":2034,"children":2035},{},[2036],{"type":34,"value":2037},"So, summarizing, the main strategies proposed to perform Meta-Learning are:",{"type":24,"tag":729,"props":2039,"children":2040},{},[2041,2045,2050,2055,2060],{"type":24,"tag":733,"props":2042,"children":2043},{},[2044],{"type":34,"value":1383},{"type":24,"tag":733,"props":2046,"children":2047},{},[2048],{"type":34,"value":2049},"Metric Learning (converting to non-parametric algorithm)",{"type":24,"tag":733,"props":2051,"children":2052},{},[2053],{"type":34,"value":2054},"Optimizer Learning",{"type":24,"tag":733,"props":2056,"children":2057},{},[2058],{"type":34,"value":2059},"Initialization Learning",{"type":24,"tag":733,"props":2061,"children":2062},{},[2063],{"type":34,"value":1974},{"type":24,"tag":36,"props":2065,"children":2067},{"id":2066},"meta-learning-interesting-uses",[2068],{"type":24,"tag":30,"props":2069,"children":2070},{},[2071],{"type":34,"value":2072},"Meta-Learning interesting uses",{"type":24,"tag":729,"props":2074,"children":2075},{},[2076,2081,2086],{"type":24,"tag":733,"props":2077,"children":2078},{},[2079],{"type":34,"value":2080},"Few-Shot Learning: the first motivation of this wave of Meta-Learning publications. Learning from few data becomes possible when you learn how to learn with few data.",{"type":24,"tag":733,"props":2082,"children":2083},{},[2084],{"type":34,"value":2085},"Active Learning: I'm planning another post for this topic, but the problem stands for learning when human supervision has some costs. Again, possible if you learn how to solve this kind of problem.",{"type":24,"tag":733,"props":2087,"children":2088},{},[2089,2091,2101],{"type":34,"value":2090},"Unsupervised Learning: this is an interesting matter since we have defined everything under a supervised view, i.e. assuming we are able to design a Meta-Learning pipeline depending on a domain we will define usually knowing the classes. However, when we miss this information, we may find for an alternative way to define this schedule. In this direction, Metz et al. presented ",{"type":24,"tag":59,"props":2092,"children":2095},{"href":2093,"rel":2094},"https://arxiv.org/pdf/1804.00222.pdf",[63],[2096],{"type":24,"tag":800,"props":2097,"children":2098},{},[2099],{"type":34,"value":2100},"Meta-Learning Update Rules for Unsupervised Representation Learning",{"type":34,"value":2102}," (2019), where they propose a way to achieve that by finding an (unknown) class space from which to build artificial tasks and train the model from them, thus projecting it to the new unsupervised tasks. The authors perform several experiments with the different main Meta-Learning approaches.",{"type":24,"tag":36,"props":2104,"children":2106},{"id":2105},"the-future-of-meta-learning",[2107],{"type":24,"tag":30,"props":2108,"children":2109},{},[2110],{"type":34,"value":2111},"The future of Meta-Learning",{"type":24,"tag":46,"props":2113,"children":2114},{},[2115,2117,2122],{"type":34,"value":2116},"No, I'm not a prophet, but I have some ideas on what would be the natural ",{"type":24,"tag":30,"props":2118,"children":2119},{},[2120],{"type":34,"value":2121},"direction",{"type":34,"value":2123}," of all this.",{"type":24,"tag":46,"props":2125,"children":2126},{},[2127,2129,2134,2136,2141],{"type":34,"value":2128},"First, Meta-Learning has ",{"type":24,"tag":30,"props":2130,"children":2131},{},[2132],{"type":34,"value":2133},"already presented",{"type":34,"value":2135}," the most intuitive ",{"type":24,"tag":30,"props":2137,"children":2138},{},[2139],{"type":34,"value":2140},"approaches",{"type":34,"value":2142}," to be performed. As they still can be improved (just like any approach has received publications responding to it), the most important work there is presumably done.",{"type":24,"tag":46,"props":2144,"children":2145},{},[2146,2148,2153,2155,2160,2162,2166,2167,2172,2174,2179,2181,2186,2188,2192,2194,2199],{"type":34,"value":2147},"However, Meta-learning just began. All Machine Learning problems that may potentially be affected by the (at least temporal) amount of data, may follow a Meta-Learning strategy. Probably, the ",{"type":24,"tag":30,"props":2149,"children":2150},{},[2151],{"type":34,"value":2152},"Online scenario will gain strength",{"type":34,"value":2154}," in Meta-Learning research in the following years, since a common case is that a project begins with few data and later adds more and more. Furthermore, ",{"type":24,"tag":30,"props":2156,"children":2157},{},[2158],{"type":34,"value":2159},"building good schedules",{"type":34,"value":2161}," is still not accomplished, so ",{"type":24,"tag":30,"props":2163,"children":2164},{},[2165],{"type":34,"value":898},{"type":34,"value":422},{"type":24,"tag":30,"props":2168,"children":2169},{},[2170],{"type":34,"value":2171},"Unsupervised scenarios",{"type":34,"value":2173}," will study in depth the application of Meta-Learning, for sure. Also, Meta-Learning still has a lot to say in other kinds of ",{"type":24,"tag":30,"props":2175,"children":2176},{},[2177],{"type":34,"value":2178},"data limitations",{"type":34,"value":2180}," such as ",{"type":24,"tag":30,"props":2182,"children":2183},{},[2184],{"type":34,"value":2185},"Incremental Learning",{"type":34,"value":2187}," (temporal bias issues), ",{"type":24,"tag":30,"props":2189,"children":2190},{},[2191],{"type":34,"value":1338},{"type":34,"value":2193}," (annotation issues), ",{"type":24,"tag":30,"props":2195,"children":2196},{},[2197],{"type":34,"value":2198},"Federated Learning",{"type":34,"value":2200}," (privacy issues)...",{"type":24,"tag":46,"props":2202,"children":2203},{},[2204,2206,2211,2212,2217],{"type":34,"value":2205},"Last, but not less important, Meta-Learning still has to deliver strong ",{"type":24,"tag":30,"props":2207,"children":2208},{},[2209],{"type":34,"value":2210},"frameworks",{"type":34,"value":422},{"type":24,"tag":30,"props":2213,"children":2214},{},[2215],{"type":34,"value":2216},"stable implementations",{"type":34,"value":2218}," so it becomes more and more popular. So, congratulations for reading this post and preparing for the future!",{"type":24,"tag":36,"props":2220,"children":2222},{"id":2221},"additional-resources",[2223],{"type":24,"tag":30,"props":2224,"children":2225},{},[2226],{"type":34,"value":2227},"Additional resources",{"type":24,"tag":46,"props":2229,"children":2230},{},[2231,2233,2239,2241,2248],{"type":34,"value":2232},"To complete this recap, I'm including a couple of summaries I did some time ago in two formats. First, a slide presentation which may be useful for a shorter ",{"type":24,"tag":59,"props":2234,"children":2237},{"href":2235,"rel":2236},"https://drive.google.com/file/d/12xTctbkXcOHNX-ZtTA3ZaKUEi5Ulj_vc/view?usp=sharing",[63],[2238],{"type":34,"value":2029},{"type":34,"value":2240},". Second, a sheet with ",{"type":24,"tag":59,"props":2242,"children":2245},{"href":2243,"rel":2244},"https://docs.google.com/spreadsheets/d/1IcaGSqPEVuF8iHD5G2wfl8xwpJmVuvnDOwrkZHIK1IU/edit?usp=sharing",[63],[2246],{"type":34,"value":2247},"a collection of important papers and notes",{"type":34,"value":170},{"type":24,"tag":36,"props":2250,"children":2252},{"id":2251},"thank-you-reader",[2253],{"type":24,"tag":30,"props":2254,"children":2255},{},[2256],{"type":34,"value":2257},"Thank you reader",{"type":24,"tag":46,"props":2259,"children":2260},{},[2261],{"type":34,"value":2262},"This is my first post, and writing it has been tough and has given me more work that I initially thought. However, the experience has filled me with more interest in continue making this blog live. As far as my life permits me to do it, I will be adding more content. This has just began!",{"type":24,"tag":36,"props":2264,"children":2266},{"id":2265},"references",[2267],{"type":24,"tag":30,"props":2268,"children":2269},{},[2270],{"type":34,"value":2271},"References",{"type":24,"tag":46,"props":2273,"children":2274},{},[2275,2284,2286],{"type":24,"tag":800,"props":2276,"children":2277},{},[2278],{"type":24,"tag":2279,"props":2280,"children":2281},"span",{},[2282],{"type":34,"value":2283},"1",{"type":34,"value":2285}," ",{"type":24,"tag":30,"props":2287,"children":2288},{},[2289],{"type":24,"tag":59,"props":2290,"children":2292},{"href":61,"rel":2291},[63],[2293],{"type":24,"tag":800,"props":2294,"children":2295},{},[2296],{"type":34,"value":2297},"Picking groups instead of samples: A close look at Static Pool-based Meta-Active Learning",{"type":24,"tag":46,"props":2299,"children":2300},{},[2301,2309,2310],{"type":24,"tag":800,"props":2302,"children":2303},{},[2304],{"type":24,"tag":2279,"props":2305,"children":2306},{},[2307],{"type":34,"value":2308},"2",{"type":34,"value":2285},{"type":24,"tag":30,"props":2311,"children":2312},{},[2313],{"type":24,"tag":59,"props":2314,"children":2316},{"href":796,"rel":2315},[63],[2317],{"type":24,"tag":800,"props":2318,"children":2319},{},[2320],{"type":34,"value":804},{"type":24,"tag":46,"props":2322,"children":2323},{},[2324,2332,2333],{"type":24,"tag":800,"props":2325,"children":2326},{},[2327],{"type":24,"tag":2279,"props":2328,"children":2329},{},[2330],{"type":34,"value":2331},"3",{"type":34,"value":2285},{"type":24,"tag":30,"props":2334,"children":2335},{},[2336],{"type":24,"tag":59,"props":2337,"children":2339},{"href":984,"rel":2338},[63],[2340],{"type":24,"tag":800,"props":2341,"children":2342},{},[2343],{"type":34,"value":991},{"type":24,"tag":46,"props":2345,"children":2346},{},[2347,2355,2356],{"type":24,"tag":800,"props":2348,"children":2349},{},[2350],{"type":24,"tag":2279,"props":2351,"children":2352},{},[2353],{"type":34,"value":2354},"4",{"type":34,"value":2285},{"type":24,"tag":30,"props":2357,"children":2358},{},[2359],{"type":24,"tag":59,"props":2360,"children":2362},{"href":1033,"rel":2361},[63],[2363],{"type":24,"tag":800,"props":2364,"children":2365},{},[2366],{"type":34,"value":2367},"Metalearning Machines Learn to Learn",{"type":24,"tag":46,"props":2369,"children":2370},{},[2371,2379,2380],{"type":24,"tag":800,"props":2372,"children":2373},{},[2374],{"type":24,"tag":2279,"props":2375,"children":2376},{},[2377],{"type":34,"value":2378},"5",{"type":34,"value":2285},{"type":24,"tag":30,"props":2381,"children":2382},{},[2383],{"type":24,"tag":59,"props":2384,"children":2386},{"href":1053,"rel":2385},[63],[2387],{"type":24,"tag":800,"props":2388,"children":2389},{},[2390],{"type":34,"value":1060},{"type":24,"tag":46,"props":2392,"children":2393},{},[2394,2402,2403],{"type":24,"tag":800,"props":2395,"children":2396},{},[2397],{"type":24,"tag":2279,"props":2398,"children":2399},{},[2400],{"type":34,"value":2401},"6",{"type":34,"value":2285},{"type":24,"tag":30,"props":2404,"children":2405},{},[2406],{"type":24,"tag":59,"props":2407,"children":2409},{"href":1138,"rel":2408},[63],[2410],{"type":24,"tag":800,"props":2411,"children":2412},{},[2413],{"type":34,"value":1145},{"type":24,"tag":46,"props":2415,"children":2416},{},[2417,2425,2426],{"type":24,"tag":800,"props":2418,"children":2419},{},[2420],{"type":24,"tag":2279,"props":2421,"children":2422},{},[2423],{"type":34,"value":2424},"7",{"type":34,"value":2285},{"type":24,"tag":30,"props":2427,"children":2428},{},[2429],{"type":24,"tag":59,"props":2430,"children":2432},{"href":1150,"rel":2431},[63],[2433],{"type":24,"tag":800,"props":2434,"children":2435},{},[2436],{"type":34,"value":1157},{"type":24,"tag":46,"props":2438,"children":2439},{},[2440,2448,2449],{"type":24,"tag":800,"props":2441,"children":2442},{},[2443],{"type":24,"tag":2279,"props":2444,"children":2445},{},[2446],{"type":34,"value":2447},"8",{"type":34,"value":2285},{"type":24,"tag":30,"props":2450,"children":2451},{},[2452],{"type":24,"tag":59,"props":2453,"children":2455},{"href":1167,"rel":2454},[63],[2456],{"type":24,"tag":800,"props":2457,"children":2458},{},[2459],{"type":34,"value":1174},{"type":24,"tag":46,"props":2461,"children":2462},{},[2463,2471,2472],{"type":24,"tag":800,"props":2464,"children":2465},{},[2466],{"type":24,"tag":2279,"props":2467,"children":2468},{},[2469],{"type":34,"value":2470},"9",{"type":34,"value":2285},{"type":24,"tag":30,"props":2473,"children":2474},{},[2475],{"type":24,"tag":59,"props":2476,"children":2478},{"href":1245,"rel":2477},[63],[2479],{"type":24,"tag":800,"props":2480,"children":2481},{},[2482],{"type":34,"value":1252},{"type":24,"tag":46,"props":2484,"children":2485},{},[2486,2494,2495],{"type":24,"tag":800,"props":2487,"children":2488},{},[2489],{"type":24,"tag":2279,"props":2490,"children":2491},{},[2492],{"type":34,"value":2493},"10",{"type":34,"value":2285},{"type":24,"tag":30,"props":2496,"children":2497},{},[2498],{"type":24,"tag":59,"props":2499,"children":2501},{"href":1398,"rel":2500},[63],[2502],{"type":24,"tag":800,"props":2503,"children":2504},{},[2505],{"type":34,"value":1405},{"type":24,"tag":46,"props":2507,"children":2508},{},[2509,2517,2518],{"type":24,"tag":800,"props":2510,"children":2511},{},[2512],{"type":24,"tag":2279,"props":2513,"children":2514},{},[2515],{"type":34,"value":2516},"11",{"type":34,"value":2285},{"type":24,"tag":30,"props":2519,"children":2520},{},[2521],{"type":24,"tag":59,"props":2522,"children":2524},{"href":1431,"rel":2523},[63],[2525],{"type":24,"tag":800,"props":2526,"children":2527},{},[2528],{"type":34,"value":2529},"Explanation of One-shot Learning with Memory-Augmented Neural Networks",{"type":24,"tag":46,"props":2531,"children":2532},{},[2533,2541,2542],{"type":24,"tag":800,"props":2534,"children":2535},{},[2536],{"type":24,"tag":2279,"props":2537,"children":2538},{},[2539],{"type":34,"value":2540},"12",{"type":34,"value":2285},{"type":24,"tag":30,"props":2543,"children":2544},{},[2545],{"type":24,"tag":59,"props":2546,"children":2548},{"href":1478,"rel":2547},[63],[2549],{"type":24,"tag":800,"props":2550,"children":2551},{},[2552],{"type":34,"value":1485},{"type":24,"tag":46,"props":2554,"children":2555},{},[2556,2564,2565],{"type":24,"tag":800,"props":2557,"children":2558},{},[2559],{"type":24,"tag":2279,"props":2560,"children":2561},{},[2562],{"type":34,"value":2563},"13",{"type":34,"value":2285},{"type":24,"tag":30,"props":2566,"children":2567},{},[2568],{"type":24,"tag":59,"props":2569,"children":2571},{"href":1511,"rel":2570},[63],[2572],{"type":24,"tag":800,"props":2573,"children":2574},{},[2575],{"type":34,"value":1518},{"type":24,"tag":46,"props":2577,"children":2578},{},[2579,2587,2588],{"type":24,"tag":800,"props":2580,"children":2581},{},[2582],{"type":24,"tag":2279,"props":2583,"children":2584},{},[2585],{"type":34,"value":2586},"14",{"type":34,"value":2285},{"type":24,"tag":30,"props":2589,"children":2590},{},[2591],{"type":24,"tag":59,"props":2592,"children":2594},{"href":1576,"rel":2593},[63],[2595],{"type":24,"tag":800,"props":2596,"children":2597},{},[2598],{"type":34,"value":1583},{"type":24,"tag":46,"props":2600,"children":2601},{},[2602,2610,2611],{"type":24,"tag":800,"props":2603,"children":2604},{},[2605],{"type":24,"tag":2279,"props":2606,"children":2607},{},[2608],{"type":34,"value":2609},"15",{"type":34,"value":2285},{"type":24,"tag":30,"props":2612,"children":2613},{},[2614],{"type":24,"tag":59,"props":2615,"children":2617},{"href":1655,"rel":2616},[63],[2618],{"type":24,"tag":800,"props":2619,"children":2620},{},[2621],{"type":34,"value":1662},{"type":24,"tag":46,"props":2623,"children":2624},{},[2625,2633,2634],{"type":24,"tag":800,"props":2626,"children":2627},{},[2628],{"type":24,"tag":2279,"props":2629,"children":2630},{},[2631],{"type":34,"value":2632},"16",{"type":34,"value":2285},{"type":24,"tag":30,"props":2635,"children":2636},{},[2637],{"type":24,"tag":59,"props":2638,"children":2640},{"href":1688,"rel":2639},[63],[2641],{"type":24,"tag":800,"props":2642,"children":2643},{},[2644],{"type":34,"value":1695},{"type":24,"tag":46,"props":2646,"children":2647},{},[2648,2656,2657],{"type":24,"tag":800,"props":2649,"children":2650},{},[2651],{"type":24,"tag":2279,"props":2652,"children":2653},{},[2654],{"type":34,"value":2655},"17",{"type":34,"value":2285},{"type":24,"tag":30,"props":2658,"children":2659},{},[2660],{"type":24,"tag":59,"props":2661,"children":2663},{"href":1753,"rel":2662},[63],[2664],{"type":24,"tag":800,"props":2665,"children":2666},{},[2667],{"type":34,"value":2668},"Model-Agnostic Meta-Learning",{"type":24,"tag":46,"props":2670,"children":2671},{},[2672,2680,2681],{"type":24,"tag":800,"props":2673,"children":2674},{},[2675],{"type":24,"tag":2279,"props":2676,"children":2677},{},[2678],{"type":34,"value":2679},"18",{"type":34,"value":2285},{"type":24,"tag":30,"props":2682,"children":2683},{},[2684],{"type":24,"tag":59,"props":2685,"children":2687},{"href":1840,"rel":2686},[63],[2688],{"type":24,"tag":800,"props":2689,"children":2690},{},[2691],{"type":34,"value":1847},{"type":24,"tag":46,"props":2693,"children":2694},{},[2695,2703,2704],{"type":24,"tag":800,"props":2696,"children":2697},{},[2698],{"type":24,"tag":2279,"props":2699,"children":2700},{},[2701],{"type":34,"value":2702},"19",{"type":34,"value":2285},{"type":24,"tag":30,"props":2705,"children":2706},{},[2707],{"type":24,"tag":59,"props":2708,"children":2710},{"href":1859,"rel":2709},[63],[2711],{"type":24,"tag":800,"props":2712,"children":2713},{},[2714],{"type":34,"value":1866},{"type":24,"tag":46,"props":2716,"children":2717},{},[2718,2726,2727],{"type":24,"tag":800,"props":2719,"children":2720},{},[2721],{"type":24,"tag":2279,"props":2722,"children":2723},{},[2724],{"type":34,"value":2725},"20",{"type":34,"value":2285},{"type":24,"tag":30,"props":2728,"children":2729},{},[2730],{"type":24,"tag":59,"props":2731,"children":2733},{"href":1878,"rel":2732},[63],[2734],{"type":24,"tag":800,"props":2735,"children":2736},{},[2737],{"type":34,"value":1885},{"type":24,"tag":46,"props":2739,"children":2740},{},[2741,2749,2750],{"type":24,"tag":800,"props":2742,"children":2743},{},[2744],{"type":24,"tag":2279,"props":2745,"children":2746},{},[2747],{"type":34,"value":2748},"21",{"type":34,"value":2285},{"type":24,"tag":30,"props":2751,"children":2752},{},[2753],{"type":24,"tag":59,"props":2754,"children":2756},{"href":1917,"rel":2755},[63],[2757],{"type":24,"tag":800,"props":2758,"children":2759},{},[2760],{"type":34,"value":1924},{"type":24,"tag":46,"props":2762,"children":2763},{},[2764,2772,2773],{"type":24,"tag":800,"props":2765,"children":2766},{},[2767],{"type":24,"tag":2279,"props":2768,"children":2769},{},[2770],{"type":34,"value":2771},"22",{"type":34,"value":2285},{"type":24,"tag":30,"props":2774,"children":2775},{},[2776],{"type":24,"tag":59,"props":2777,"children":2779},{"href":1982,"rel":2778},[63],[2780],{"type":24,"tag":800,"props":2781,"children":2782},{},[2783],{"type":34,"value":1989},{"type":24,"tag":46,"props":2785,"children":2786},{},[2787,2795,2796],{"type":24,"tag":800,"props":2788,"children":2789},{},[2790],{"type":24,"tag":2279,"props":2791,"children":2792},{},[2793],{"type":34,"value":2794},"23",{"type":34,"value":2285},{"type":24,"tag":30,"props":2797,"children":2798},{},[2799],{"type":24,"tag":59,"props":2800,"children":2802},{"href":2093,"rel":2801},[63],[2803],{"type":24,"tag":800,"props":2804,"children":2805},{},[2806],{"type":34,"value":2100},{"title":10,"searchDepth":2808,"depth":2808,"links":2809},2,[2810,2811,2812,2813,2814,2823,2824,2825,2826,2827],{"id":38,"depth":2808,"text":44},{"id":117,"depth":2808,"text":123},{"id":782,"depth":2808,"text":788},{"id":1205,"depth":2808,"text":1211},{"id":1349,"depth":2808,"text":1355,"children":2815},[2816,2818,2819,2820,2821,2822],{"id":1380,"depth":2817,"text":1383},3,{"id":1454,"depth":2817,"text":1457},{"id":1558,"depth":2817,"text":1561},{"id":1735,"depth":2817,"text":1738},{"id":1971,"depth":2817,"text":1974},{"id":2029,"depth":2817,"text":2032},{"id":2066,"depth":2808,"text":2072},{"id":2105,"depth":2808,"text":2111},{"id":2221,"depth":2808,"text":2227},{"id":2251,"depth":2808,"text":2257},{"id":2265,"depth":2808,"text":2271},"markdown","content:articles:2022-11-21-meta-learning.md","content","articles/2022-11-21-meta-learning.md","md",["ShallowRef",2834],["ShallowReactive",2835],{"/articles/2022-11-21-meta-learning":2836},[2837,3032],{"_path":2838,"_dir":8,"_draft":9,"_partial":9,"_locale":10,"title":2839,"description":12,"layout":19,"date":2840,"cover":2841,"author":2842,"body":2846,"_type":2828,"_id":3030,"_source":2830,"_file":3031,"_extension":2832},"/articles/2022-11-15-welcome-post","Welcome Post","2022-11-15T00:00:00.000Z","/articles/get-started.webp",{"name":2843,"avatarUrl":2844,"link":2845},"Ignasi Mas aka Mr. Leylo","https://pbs.twimg.com/profile_images/1042510623962275840/1Iw_Mvud_400x400.jpg","https://twitter.com/atinux",{"type":21,"children":2847,"toc":3024},[2848,2853,2859,2864,2868,2874,2888,2893,2915,2938,2943,2948,2971,2976,2986,2992,2997,3009,3014,3019],{"type":24,"tag":25,"props":2849,"children":2851},{"id":2850},"welcome-post",[2852],{"type":34,"value":2839},{"type":24,"tag":36,"props":2854,"children":2856},{"id":2855},"welcome",[2857],{"type":34,"value":2858},"Welcome",{"type":24,"tag":46,"props":2860,"children":2861},{},[2862],{"type":34,"value":2863},"My name is Ignasi Mas, I am a Machine Learning/AI Engineer with a broad interest in solving data issues. My background is built in Computer Vision, although my interest focus (which obviously includes Computer Vision) is wider.",{"type":24,"tag":2865,"props":2866,"children":2867},"hr",{"id":10},[],{"type":24,"tag":1378,"props":2869,"children":2871},{"id":2870},"about-me",[2872],{"type":34,"value":2873},"About me",{"type":24,"tag":46,"props":2875,"children":2876},{},[2877,2879,2886],{"type":34,"value":2878},"I studied Telecommunication Engineering at ",{"type":24,"tag":59,"props":2880,"children":2883},{"href":2881,"rel":2882},"https://telecos.upc.edu/acl_users/credentials_cookie_auth/require_login?came_from=https%3A//telecos.upc.edu/es",[63],[2884],{"type":34,"value":2885},"ETSETB, UPC",{"type":34,"value":2887},". Some day we may talk deeply about my experience studying this career, but for now let's just say that the content in it is acquiring the knowledge to understand each point in the signal lifecycle.",{"type":24,"tag":46,"props":2889,"children":2890},{},[2891],{"type":34,"value":2892},"What's the particularity about this? Well, our knowledge about signal has increased so much during the last decades, that more and more issues and solutions have flourished, thus becoming Telecommunication Engineering a vastly wide career. That is of course something good but is also more sensible to unrelated limitations. In the end, time is limited, and if you want to cover everything you lose granularity.",{"type":24,"tag":46,"props":2894,"children":2895},{},[2896,2898,2905,2907,2914],{"type":34,"value":2897},"During my progress in my career, I felt more and more attracted to the development of intelligent systems. In that context, I demanded more knowledge than what I was getting, but the loss of granularity mentioned above made that impossible. Once I graduated I felt incomplete about that. I missed something. And that something was Machine Learning. Based ",{"type":24,"tag":59,"props":2899,"children":2902},{"href":2900,"rel":2901},"https://www.andrewng.org/",[63],[2903],{"type":34,"value":2904},"Andrew NG",{"type":34,"value":2906}," opened my eyes through ",{"type":24,"tag":59,"props":2908,"children":2911},{"href":2909,"rel":2910},"https://www.coursera.org/learn/machine-learning",[63],[2912],{"type":34,"value":2913},"its course",{"type":34,"value":170},{"type":24,"tag":46,"props":2916,"children":2917},{},[2918,2920,2927,2929,2936],{"type":34,"value":2919},"I found the following piece in my career's puzzle as the ",{"type":24,"tag":59,"props":2921,"children":2924},{"href":2922,"rel":2923},"https://www.uab.cat/web/estudiar/official-master-s-degrees/general-information/computer-vision-1096480962610.html?param1=1345648392514",[63],[2925],{"type":34,"value":2926},"Master in Computer Vision",{"type":34,"value":2928}," from ",{"type":24,"tag":59,"props":2930,"children":2933},{"href":2931,"rel":2932},"http://www.cvc.uab.es/",[63],[2934],{"type":34,"value":2935},"Computer Vision Center",{"type":34,"value":2937},". There perhaps I may be able to merge two of my main academic interests, Machine Learning and Computer Vision. Two years later, I didn't regret that decision. This Master fed me with the seeds to gain further knowledge, and begin learning everything in the wild.",{"type":24,"tag":46,"props":2939,"children":2940},{},[2941],{"type":34,"value":2942},"But my adventure still had to deliver another incredible chapter. That was the development of my Master's thesis. I wanted to focus on something of my special interest, so I researched open and hot topics in Machine Learning. I had many interests so it was hard to choose, but I found in Few-Shot Learning one of my main focuses. There, I learned about Meta-Learning and found one of the potentially needed from Meta-Learning problems in ML: Active Learning.",{"type":24,"tag":46,"props":2944,"children":2945},{},[2946],{"type":34,"value":2947},"In this blog, we will have time to talk about Meta-Learning and Active Learning further, but just know that I developed my Master's thesis about Meta-Active Learning. I.e. using Meta-Learning to solve Active Learning problems. I focused on one concrete Active Learning scenario (again, we will study these scenarios someday in this space). I sweated blood just to replicate the State of the Art approaches. I remember the days trying to handle memory in my PyTorch tensors (in Meta-Learning, memory management works differently since you keep different gradients for different levels but no more spoilers). And I almost jumped out of joy the day I had some reasonable results in my proposed solutions.",{"type":24,"tag":46,"props":2949,"children":2950},{},[2951,2953,2960,2962,2969],{"type":34,"value":2952},"This chapter did not finish presenting my dissertation for the Master (which I obviously did and finally got), but I presented it to the MDALC Workshop at ",{"type":24,"tag":59,"props":2954,"children":2957},{"href":2955,"rel":2956},"https://iccv2019.thecvf.com/",[63],[2958],{"type":34,"value":2959},"ICCV 2019",{"type":34,"value":2961},", and they accepted it! We published ",{"type":24,"tag":59,"props":2963,"children":2966},{"href":2964,"rel":2965},"https://ieeexplore.ieee.org/document/9022361",[63],[2967],{"type":34,"value":2968},"the paper",{"type":34,"value":2970}," and it is accessible to anyone since then.",{"type":24,"tag":46,"props":2972,"children":2973},{},[2974],{"type":34,"value":2975},"Is my academic history finished yet? Of course not! I am actively thinking about a possible PhD that I may do someday. I actually had a couple of opportunities that in the end were not materialized at all, but for sure there will be more. It is not something time sensitive right now, but it would be another way to acquire and deliver more knowledge. Actually, this will not necessarily be my only path, I may find other ways to do so. So new adventures await!",{"type":24,"tag":46,"props":2977,"children":2978},{},[2979,2984],{"type":24,"tag":800,"props":2980,"children":2981},{},[2982],{"type":34,"value":2983},"Oh, but Ignasi, you didn't tell us about your professional trajectory",{"type":34,"value":2985},". Yes, indeed. I have plenty of experiences and cool projects along with incredible people that I participated in. But that is probably a story for another space. Or maybe another day",{"type":24,"tag":1378,"props":2987,"children":2989},{"id":2988},"about-this-blog",[2990],{"type":34,"value":2991},"About this blog",{"type":24,"tag":46,"props":2993,"children":2994},{},[2995],{"type":34,"value":2996},"In the current episode, I realized that I spend time browsing the State of the Art in some matters and playing with code, but it is something I have always done by myself. However, wait.... Why not share it with everyone? It is a good trade. You get my knowledge and I get your feedback. So, how can I share it with everyone? Oh, a blog! It is an easy tool where I may focus on the content, instead of the shape. If this grows, I may redefine it later. But at my beginnings, that is the idea.",{"type":24,"tag":46,"props":2998,"children":2999},{},[3000,3002,3007],{"type":34,"value":3001},"At the time I am writing this, I still have to do ",{"type":24,"tag":30,"props":3003,"children":3004},{},[3005],{"type":34,"value":3006},"everything",{"type":34,"value":3008}," in the blog. My idea here is to post in a more or less formal way (I want to make it easy to read for you) posts about different theory ML topics of my interest as well as maybe some practical exercises where I'll share my reasoning live.",{"type":24,"tag":46,"props":3010,"children":3011},{},[3012],{"type":34,"value":3013},"I can't tell you the frequency at which I will be posting. My idea first is to try to post every two weeks (time enough for researching some problem and preparing the post while I am working because I need to eat, you know?), but I can't promise anything yet.",{"type":24,"tag":46,"props":3015,"children":3016},{},[3017],{"type":34,"value":3018},"In the first weeks, I will post topics I already know about and focus on how to present them to you. This way, I will train myself for the future, in which I will deliver to you new topics.",{"type":24,"tag":46,"props":3020,"children":3021},{},[3022],{"type":34,"value":3023},"So just one more thing: let's have fun together!",{"title":10,"searchDepth":2808,"depth":2808,"links":3025},[3026],{"id":2855,"depth":2808,"text":2858,"children":3027},[3028,3029],{"id":2870,"depth":2817,"text":2873},{"id":2988,"depth":2817,"text":2991},"content:articles:2022-11-15-welcome-post.md","articles/2022-11-15-welcome-post.md",{"_path":3033,"_dir":8,"_draft":9,"_partial":9,"_locale":10,"title":3034,"description":3035,"cover":3036,"date":3037,"layout":19,"body":3038,"_type":2828,"_id":16935,"_source":2830,"_file":16936,"_extension":2832},"/articles/2022-12-20-meta-learning-implementation","Meta-Learning implementation","Writing Markdown articles in Alpine is straightforward.","/articles/write-articles.webp","2022-12-20T00:00:00.000Z",{"type":21,"children":3039,"toc":16916},[3040,3045,3063,3069,3095,3100,3105,3110,3116,3121,3127,3139,3144,3158,3163,3181,3186,3199,3205,3217,3284,3289,3295,3325,3331,3360,3366,3377,3383,3388,3393,3405,3439,3444,3449,3454,3477,3483,3488,3493,3499,3505,3510,3636,3644,3649,3802,3808,3813,3847,3938,3946,3951,3966,3974,3979,4004,4029,4037,4042,4074,4082,4087,4127,4135,4143,4148,4153,4216,4224,4229,4302,4310,4315,4342,4366,4390,4395,4415,4423,4442,4450,4455,4460,4558,4566,4572,4577,4646,4653,4692,4748,4754,4759,4764,4769,4781,4955,4960,5055,5060,5089,5097,5124,5132,5149,5227,5242,5250,5255,5270,5275,5459,5464,5469,5509,5514,5519,5636,5641,5713,5728,5736,5742,5753,5758,5763,5860,5865,5897,5912,5920,5938,5943,6102,6117,6125,6144,6152,6157,6179,6236,6248,6316,6340,6491,6499,6716,6724,6729,6734,6739,6751,6767,6819,6824,8960,8976,9066,9071,9248,9253,9294,9317,9325,9330,9614,9622,9627,10118,10124,10129,10169,10273,10438,10446,10451,11159,11164,11258,11285,11290,11411,11416,12360,12368,12373,12379,12412,12417,12425,13579,13584,13590,13595,13643,13864,13956,16881,16889,16894,16899,16905,16910],{"type":24,"tag":25,"props":3041,"children":3043},{"id":3042},"meta-learning-implementation",[3044],{"type":34,"value":3034},{"type":24,"tag":46,"props":3046,"children":3047},{},[3048,3053,3055,3062],{"type":24,"tag":30,"props":3049,"children":3050},{},[3051],{"type":34,"value":3052},"IMPORTANT NOTE:",{"type":34,"value":3054}," This post consists of a Python Notebook. I inserted the content in Markdown into the blog, so you'll find explanations, code and results. A copy of the Notebook itself ",{"type":24,"tag":59,"props":3056,"children":3059},{"href":3057,"rel":3058},"https://colab.research.google.com/drive/1MmAdSuQbB4kfUtEntL0PmQmtvbaR3QtU?usp=sharing",[63],[3060],{"type":34,"value":3061},"is also shared",{"type":34,"value":170},{"type":24,"tag":25,"props":3064,"children":3066},{"id":3065},"meta-learning-experiment-maml-implementation-by-metabloggism",[3067],{"type":34,"value":3068},"Meta-Learning: Experiment & MAML implementation by Metabloggism",{"type":24,"tag":46,"props":3070,"children":3071},{},[3072,3074,3080,3082,3086,3088,3093],{"type":34,"value":3073},"Welcome to this first Notebook by Metabloggism! This episode follows directly the post ",{"type":24,"tag":59,"props":3075,"children":3078},{"href":3076,"rel":3077},"https://metabloggism.github.io/2022/11/21/meta-learning.html",[63],[3079],{"type":34,"value":11},{"type":34,"value":3081},". As a recap from it, we reviewed the meaning of Meta-Learning, how it did appear and evolve and how is it approached nowadays. We concluded that today, we use Meta-Learning mostly as a tool against scenarios with few data in a specific problem we want to solve but where we are able to find data from related problems, thus building a domain of problems at a higher level from Learning called ",{"type":24,"tag":800,"props":3083,"children":3084},{},[3085],{"type":34,"value":55},{"type":34,"value":3087},". At this level you may learn how to learn efficiently in each problem, and that may be done in different ways. One of the most praised approaches in the last years, and the one which probably is more commonly used in these settings is ",{"type":24,"tag":59,"props":3089,"children":3091},{"href":1753,"rel":3090},[63],[3092],{"type":34,"value":1767},{"type":34,"value":3094},", which at the Meta-Learning level learns a proper general (in the problems domain) initialization of any (learnable by gradient descent) model at the Learning level. If you still have doubts, I would recommend reading the mentioned post again before reading this Notebook.",{"type":24,"tag":46,"props":3096,"children":3097},{},[3098],{"type":34,"value":3099},"The scope of this post is to materialize what we described in the previous one. First, we will take a tour of the experiment setting, defining what we want to solve in the end and building the scenario in which we will work on. Second, we will implement a MAML approach and train at Meta-Learning.",{"type":24,"tag":46,"props":3101,"children":3102},{},[3103],{"type":34,"value":3104},"This is a simple walkthrough of this process. We do not aim to engage in a performance analysis since we will let this be for a future post, with other variables deeply explored, a fair comparison with other approaches, with a proper hyperparameter exploration, etc.",{"type":24,"tag":46,"props":3106,"children":3107},{},[3108],{"type":34,"value":3109},"So that said, let's engage into work!",{"type":24,"tag":36,"props":3111,"children":3113},{"id":3112},"preliminaries-meta-learning-datasets",[3114],{"type":34,"value":3115},"Preliminaries: Meta-Learning datasets",{"type":24,"tag":46,"props":3117,"children":3118},{},[3119],{"type":34,"value":3120},"I need to introduce something I forgot in the previous post. We did not talk about Meta-Learning datasets!",{"type":24,"tag":1378,"props":3122,"children":3124},{"id":3123},"requirements-of-a-good-meta-learning-dataset",[3125],{"type":34,"value":3126},"Requirements of a good Meta-Learning dataset",{"type":24,"tag":46,"props":3128,"children":3129},{},[3130,3132,3137],{"type":34,"value":3131},"With all the previous theory, our definition of Meta-Learning could be something like ",{"type":24,"tag":800,"props":3133,"children":3134},{},[3135],{"type":34,"value":3136},"Learning tools that will allow to Learn to solve problems from a certain domain",{"type":34,"value":3138}," and we do so by repeatedly learning to solve these problems. Thus, any dataset which allows us to do so can be considered a Meta-Learning dataset.",{"type":24,"tag":46,"props":3140,"children":3141},{},[3142],{"type":34,"value":3143},"Meta-Learning datasets may be used to directly solve target problems, but since they don't always allow this, they are commonly used for making experiments with approaches for analysis.",{"type":24,"tag":46,"props":3145,"children":3146},{},[3147,3149,3156],{"type":34,"value":3148},"In general, any usual dataset can be used as a Meta-Learning dataset. Just think about ",{"type":24,"tag":59,"props":3150,"children":3153},{"href":3151,"rel":3152},"https://www.image-net.org/",[63],[3154],{"type":34,"value":3155},"Imagenet",{"type":34,"value":3157},", for example (let's think about the classification task). There you have a series of samples and labels belonging to a group of classes. There you can take the whole domain of classes and build a domain of problems consisting in binary classification problems, where you may have as many problems as combinations of 2 classes, and therefore Learn to Learn (Meta-Learn) to solve any binary classification problem there. Even more extreme, think of a simple dataset that a little Startup company which makes supervised face identification handles, consisting of faces of both people in the group to identify and out from it (labeled). One could make artificial groups of other people and build several problems of the same nature.",{"type":24,"tag":46,"props":3159,"children":3160},{},[3161],{"type":34,"value":3162},"However, you may have noted that these domains are forced and do not have a strong semantical relation, making the information extraction weak among problems, and almost not improving the performance in the target Learning one. There are some aspects that determine if a dataset is proper for Meta-Learning, which enable to exploit their relation to skip some steps in any target problem from the domain. Thus, in general any dataset can act as a Meta-Learning dataset, but not all of them will be able to become the desired Meta-learning tool. So, which ingredients must it contain?",{"type":24,"tag":729,"props":3164,"children":3165},{},[3166,3171,3176],{"type":24,"tag":733,"props":3167,"children":3168},{},[3169],{"type":34,"value":3170},"The ingredients of any Learning problem, e.g. for Supervised Classification problems, samples and labels.",{"type":24,"tag":733,"props":3172,"children":3173},{},[3174],{"type":34,"value":3175},"Labels should preferably be variated, to allow us to build a properly extensive schedule at the Meta-Learning level. Note that many classes can be converted to many problems. At least, should allow having more than one problem.",{"type":24,"tag":733,"props":3177,"children":3178},{},[3179],{"type":34,"value":3180},"A rich hierarchy/meta-information which should allow us to relate the instances and build meaningful domains",{"type":24,"tag":46,"props":3182,"children":3183},{},[3184],{"type":34,"value":3185},"Moreover, commonly the Meta-Learning datasets have some common traits:",{"type":24,"tag":729,"props":3187,"children":3188},{},[3189,3194],{"type":24,"tag":733,"props":3190,"children":3191},{},[3192],{"type":34,"value":3193},"As they aim to pose some challenge to you, they mostly have a limited number of samples per class to emulate a Few-Shot Learning scenario. In case they don't you can always enforce this limitation.",{"type":24,"tag":733,"props":3195,"children":3196},{},[3197],{"type":34,"value":3198},"Since they need lots of classes (and therefore lots of samples), they tend to work in light data (e.g. in Computer Vision in low-resolution).",{"type":24,"tag":1378,"props":3200,"children":3202},{"id":3201},"datasets",[3203],{"type":34,"value":3204},"Datasets",{"type":24,"tag":3206,"props":3207,"children":3209},"h4",{"id":3208},"omniglot",[3210],{"type":24,"tag":59,"props":3211,"children":3214},{"href":3212,"rel":3213},"https://omniglot.com/",[63],[3215],{"type":34,"value":3216},"Omniglot",{"type":24,"tag":46,"props":3218,"children":3219},{},[3220,3222,3229,3231,3236,3238,3250,3252,3256,3257,3263,3264,3270,3271,3276,3277,3282],{"type":34,"value":3221},"One of the most common datasets. ",{"type":24,"tag":59,"props":3223,"children":3226},{"href":3224,"rel":3225},"https://cims.nyu.edu/~brenden/papers/LakeEtAl2011CogSci.pdf",[63],[3227],{"type":34,"value":3228},"Presented by Lake et al. in 2015",{"type":34,"value":3230}," as a challenge to solve a Few-Shot Learning problem (although they didn't mention the term ",{"type":24,"tag":800,"props":3232,"children":3233},{},[3234],{"type":34,"value":3235},"Few-Shot",{"type":34,"value":3237},"), it was the dataset chosen by Koch et al. to describe a One-Shot Learning problem (remind ",{"type":24,"tag":59,"props":3239,"children":3241},{"href":3076,"rel":3240},[63],[3242,3244,3248],{"type":34,"value":3243},"the section ",{"type":24,"tag":800,"props":3245,"children":3246},{},[3247],{"type":34,"value":1211},{"type":34,"value":3249}," in the previous post",{"type":34,"value":3251},") and since then a benchmark in Meta-Learning. It has been used in most of the main Meta-Learning approaches, such as ",{"type":24,"tag":59,"props":3253,"children":3254},{"href":10},[3255],{"type":34,"value":1412},{"type":34,"value":1340},{"type":24,"tag":59,"props":3258,"children":3260},{"href":1478,"rel":3259},[63],[3261],{"type":34,"value":3262},"MatchingNets",{"type":34,"value":1340},{"type":24,"tag":59,"props":3265,"children":3267},{"href":1511,"rel":3266},[63],[3268],{"type":34,"value":3269},"Prototypical Networks",{"type":34,"value":1340},{"type":24,"tag":59,"props":3272,"children":3274},{"href":1753,"rel":3273},[63],[3275],{"type":34,"value":1767},{"type":34,"value":1307},{"type":24,"tag":59,"props":3278,"children":3280},{"href":1982,"rel":3279},[63],[3281],{"type":34,"value":1974},{"type":34,"value":3283},". An API for the dataset is also included in some top ML frameworks like Pytorch (in the torchvision package).",{"type":24,"tag":46,"props":3285,"children":3286},{},[3287],{"type":34,"value":3288},"It consists in a series of alphabets where in each alphabet there is a series of characters and for each character a limited group of samples (20 samples). A sample consists in a 105x105 (single-channel) image representing the character. The label of the sample is the character itself (related to an alphabet). This allows building semantically meaningful domains of problems, depending on the alphabet which the characters belong to.",{"type":24,"tag":3206,"props":3290,"children":3292},{"id":3291},"mini-imagenet",[3293],{"type":34,"value":3294},"Mini-Imagenet",{"type":24,"tag":46,"props":3296,"children":3297},{},[3298,3300,3306,3308,3315,3317,3323],{"type":34,"value":3299},"Introduced in the paper of ",{"type":24,"tag":59,"props":3301,"children":3304},{"href":3302,"rel":3303},"https://arxiv.org/pdf/1606.04080v2.pdf",[63],[3305],{"type":34,"value":3262},{"type":34,"value":3307},". ",{"type":24,"tag":59,"props":3309,"children":3312},{"href":3310,"rel":3311},"https://www.kaggle.com/datasets/arjunashok33/miniimagenet",[63],[3313],{"type":34,"value":3314},"It",{"type":34,"value":3316}," is probably the second benchmark for Meta-Learning. A modified version of the ",{"type":24,"tag":59,"props":3318,"children":3320},{"href":3151,"rel":3319},[63],[3321],{"type":34,"value":3322},"ImageNet",{"type":34,"value":3324}," Computer Vision dataset where a semantic selection has been performed. It is also used in some of the main approaches of Meta-Learning (aside from MatchingNets).",{"type":24,"tag":3206,"props":3326,"children":3328},{"id":3327},"imagenet-and-other-common-general-datasets-used-in-meta-learning",[3329],{"type":34,"value":3330},"Imagenet and other common general datasets used in Meta-Learning",{"type":24,"tag":46,"props":3332,"children":3333},{},[3334,3336,3342,3344,3351,3352,3359],{"type":34,"value":3335},"Most times, the Meta-Learning approaches are used in general datasets with enforced conditions. An example is found in ",{"type":24,"tag":59,"props":3337,"children":3339},{"href":1576,"rel":3338},[63],[3340],{"type":34,"value":3341},"Learning to learn by gradient descent by gradient descent",{"type":34,"value":3343},", where authors used common datasets like ",{"type":24,"tag":59,"props":3345,"children":3348},{"href":3346,"rel":3347},"https://yann.lecun.com/exdb/mnist/",[63],[3349],{"type":34,"value":3350},"MNIST",{"type":34,"value":1307},{"type":24,"tag":59,"props":3353,"children":3356},{"href":3354,"rel":3355},"https://www.cs.toronto.edu/~kriz/cifar.html",[63],[3357],{"type":34,"value":3358},"CIFAR-10",{"type":34,"value":170},{"type":24,"tag":3206,"props":3361,"children":3363},{"id":3362},"non-cv-datasets",[3364],{"type":34,"value":3365},"Non-CV datasets",{"type":24,"tag":46,"props":3367,"children":3368},{},[3369,3371,3376],{"type":34,"value":3370},"Note that we only considered CV datasets until now. I come from the CV field, but I do not pretend to focus in CV in this episode. However, these datasets are actually the ones mostly used when testing the main Meta-Learning approaches. Alternatively, some regression tasks are also tested like in ",{"type":24,"tag":59,"props":3372,"children":3374},{"href":1753,"rel":3373},[63],[3375],{"type":34,"value":1767},{"type":34,"value":170},{"type":24,"tag":36,"props":3378,"children":3380},{"id":3379},"experiment-definition",[3381],{"type":34,"value":3382},"Experiment definition",{"type":24,"tag":46,"props":3384,"children":3385},{},[3386],{"type":34,"value":3387},"There are two main components we may want to implement in the notebook: the challenge and the solution.",{"type":24,"tag":46,"props":3389,"children":3390},{},[3391],{"type":34,"value":3392},"We will work in the Omniglot dataset since it is the most standard benchmark as well as it provides a hierarchy we will use to build the domain.",{"type":24,"tag":46,"props":3394,"children":3395},{},[3396,3398,3403],{"type":34,"value":3397},"The challenge I propose to solve is ",{"type":24,"tag":800,"props":3399,"children":3400},{},[3401],{"type":34,"value":3402},"Learning to be able to solve, given a random alphabet, a character (within the alphabet) binary classification task with few samples",{"type":34,"value":3404},". Thus, our setting will go as follows:",{"type":24,"tag":729,"props":3406,"children":3407},{},[3408,3426],{"type":24,"tag":733,"props":3409,"children":3410},{},[3411,3413],{"type":34,"value":3412},"Build all the possible problems of this type in Omniglot:",{"type":24,"tag":729,"props":3414,"children":3415},{},[3416,3421],{"type":24,"tag":733,"props":3417,"children":3418},{},[3419],{"type":34,"value":3420},"Pick each combination of 2 characters within all alphabets",{"type":24,"tag":733,"props":3422,"children":3423},{},[3424],{"type":34,"value":3425},"For each combination, get all the samples and make common ML splits: train, validation and test",{"type":24,"tag":733,"props":3427,"children":3428},{},[3429,3431],{"type":34,"value":3430},"Make splits of alphabets at Meta-Learning level: Meta-train, Meta-validation and Meta-test:",{"type":24,"tag":729,"props":3432,"children":3433},{},[3434],{"type":24,"tag":733,"props":3435,"children":3436},{},[3437],{"type":34,"value":3438},"For each Meta-split (Meta-sets from now on) take all possible problems for all its alphabets",{"type":24,"tag":46,"props":3440,"children":3441},{},[3442],{"type":34,"value":3443},"We aim to be able to take any of the Meta-test problems and after a proper training of that problem, be able to solve its test set.",{"type":24,"tag":46,"props":3445,"children":3446},{},[3447],{"type":34,"value":3448},"We rely on the fact that the Meta-sets will be enough varied (they will be randomly sorted) to represent the whole domain each.",{"type":24,"tag":46,"props":3450,"children":3451},{},[3452],{"type":34,"value":3453},"As for the solution, we will use the MAML approach. Remember that this approach works by, at each meta-step, taking a meta-batch of problems and for each problem computing an individual training (over its training samples) and evaluating the loss in its test set, averaging it over all the problems in the meta-batch and thus resulting in the meta-step loss.",{"type":24,"tag":46,"props":3455,"children":3456},{},[3457,3459,3466,3468,3475],{"type":34,"value":3458},"I found in Github ",{"type":24,"tag":59,"props":3460,"children":3463},{"href":3461,"rel":3462},"https://github.com/cbfinn/maml",[63],[3464],{"type":34,"value":3465},"the official implementation",{"type":34,"value":3467}," of MAML by Chelsea Finn, in Tensorflow, as well as other unofficial implementations in Pytorch, like ",{"type":24,"tag":59,"props":3469,"children":3472},{"href":3470,"rel":3471},"https://github.com/dragen1860/MAML-Pytorch",[63],[3473],{"type":34,"value":3474},"this one",{"type":34,"value":3476},". However, we want to take control of the implementations to bring it to our own experiment, so we will develop it from scratch (but following the ideas there).",{"type":24,"tag":36,"props":3478,"children":3480},{"id":3479},"tools",[3481],{"type":34,"value":3482},"Tools",{"type":24,"tag":46,"props":3484,"children":3485},{},[3486],{"type":34,"value":3487},"For this Proof of Concept we will use Python and Pytorch as our ML framework.",{"type":24,"tag":46,"props":3489,"children":3490},{},[3491],{"type":34,"value":3492},"I developed it in a Google Collab so I may be able to use GPU's.",{"type":24,"tag":36,"props":3494,"children":3496},{"id":3495},"code",[3497],{"type":34,"value":3498},"Code",{"type":24,"tag":1378,"props":3500,"children":3502},{"id":3501},"imports-and-setting",[3503],{"type":34,"value":3504},"Imports and setting",{"type":24,"tag":46,"props":3506,"children":3507},{},[3508],{"type":34,"value":3509},"The following cell can be skipped since it is just necessary for running the Google Collab Notebook in my Drive environment.",{"type":24,"tag":3511,"props":3512,"children":3516},"pre",{"code":3513,"language":3514,"meta":10,"className":3515},"from google.colab import drive\ndrive.mount('/content/drive')   \n# WRITE PATH WHERE YOU WERE\n%cd drive/MyDrive/collab_space/metabloggism/meta-learning\n","python","language-python github-light_github-dark",[3517],{"type":24,"tag":3495,"props":3518,"children":3519},{"__ignoreMap":10},[3520,3547,3566,3575],{"type":24,"tag":2279,"props":3521,"children":3524},{"class":3522,"line":3523},"line",1,[3525,3531,3537,3542],{"type":24,"tag":2279,"props":3526,"children":3528},{"class":3527},"ct-149352",[3529],{"type":34,"value":3530},"from",{"type":24,"tag":2279,"props":3532,"children":3534},{"class":3533},"ct-553616",[3535],{"type":34,"value":3536}," google.colab ",{"type":24,"tag":2279,"props":3538,"children":3539},{"class":3527},[3540],{"type":34,"value":3541},"import",{"type":24,"tag":2279,"props":3543,"children":3544},{"class":3533},[3545],{"type":34,"value":3546}," drive\n",{"type":24,"tag":2279,"props":3548,"children":3549},{"class":3522,"line":2808},[3550,3555,3561],{"type":24,"tag":2279,"props":3551,"children":3552},{"class":3533},[3553],{"type":34,"value":3554},"drive.mount(",{"type":24,"tag":2279,"props":3556,"children":3558},{"class":3557},"ct-952708",[3559],{"type":34,"value":3560},"'/content/drive'",{"type":24,"tag":2279,"props":3562,"children":3563},{"class":3533},[3564],{"type":34,"value":3565},")   \n",{"type":24,"tag":2279,"props":3567,"children":3568},{"class":3522,"line":2817},[3569],{"type":24,"tag":2279,"props":3570,"children":3572},{"class":3571},"ct-086898",[3573],{"type":34,"value":3574},"# WRITE PATH WHERE YOU WERE\n",{"type":24,"tag":2279,"props":3576,"children":3578},{"class":3522,"line":3577},4,[3579,3584,3589,3594,3599,3603,3608,3612,3617,3621,3626,3631],{"type":24,"tag":2279,"props":3580,"children":3581},{"class":3527},[3582],{"type":34,"value":3583},"%",{"type":24,"tag":2279,"props":3585,"children":3586},{"class":3533},[3587],{"type":34,"value":3588},"cd drive",{"type":24,"tag":2279,"props":3590,"children":3591},{"class":3527},[3592],{"type":34,"value":3593},"/",{"type":24,"tag":2279,"props":3595,"children":3596},{"class":3533},[3597],{"type":34,"value":3598},"MyDrive",{"type":24,"tag":2279,"props":3600,"children":3601},{"class":3527},[3602],{"type":34,"value":3593},{"type":24,"tag":2279,"props":3604,"children":3605},{"class":3533},[3606],{"type":34,"value":3607},"collab_space",{"type":24,"tag":2279,"props":3609,"children":3610},{"class":3527},[3611],{"type":34,"value":3593},{"type":24,"tag":2279,"props":3613,"children":3614},{"class":3533},[3615],{"type":34,"value":3616},"metabloggism",{"type":24,"tag":2279,"props":3618,"children":3619},{"class":3527},[3620],{"type":34,"value":3593},{"type":24,"tag":2279,"props":3622,"children":3623},{"class":3533},[3624],{"type":34,"value":3625},"meta",{"type":24,"tag":2279,"props":3627,"children":3628},{"class":3527},[3629],{"type":34,"value":3630},"-",{"type":24,"tag":2279,"props":3632,"children":3633},{"class":3533},[3634],{"type":34,"value":3635},"learning",{"type":24,"tag":3511,"props":3637,"children":3639},{"code":3638},"Mounted at /content/drive\n/content/drive/MyDrive/collab_space/metabloggism/meta-learning\n",[3640],{"type":24,"tag":3495,"props":3641,"children":3642},{"__ignoreMap":10},[3643],{"type":34,"value":3638},{"type":24,"tag":46,"props":3645,"children":3646},{},[3647],{"type":34,"value":3648},"Imports, we'll skip explanations, I just came back here to import any module that we needed.",{"type":24,"tag":3511,"props":3650,"children":3652},{"code":3651,"language":3514,"meta":10,"className":3515},"import random\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler, BatchSampler\nimport torchvision\nimport matplotlib.pyplot as plt\n",[3653],{"type":24,"tag":3495,"props":3654,"children":3655},{"__ignoreMap":10},[3656,3668,3680,3702,3723,3745,3767,3780],{"type":24,"tag":2279,"props":3657,"children":3658},{"class":3522,"line":3523},[3659,3663],{"type":24,"tag":2279,"props":3660,"children":3661},{"class":3527},[3662],{"type":34,"value":3541},{"type":24,"tag":2279,"props":3664,"children":3665},{"class":3533},[3666],{"type":34,"value":3667}," random\n",{"type":24,"tag":2279,"props":3669,"children":3670},{"class":3522,"line":2808},[3671,3675],{"type":24,"tag":2279,"props":3672,"children":3673},{"class":3527},[3674],{"type":34,"value":3541},{"type":24,"tag":2279,"props":3676,"children":3677},{"class":3533},[3678],{"type":34,"value":3679}," torch\n",{"type":24,"tag":2279,"props":3681,"children":3682},{"class":3522,"line":2817},[3683,3687,3692,3697],{"type":24,"tag":2279,"props":3684,"children":3685},{"class":3527},[3686],{"type":34,"value":3541},{"type":24,"tag":2279,"props":3688,"children":3689},{"class":3533},[3690],{"type":34,"value":3691}," torch.nn ",{"type":24,"tag":2279,"props":3693,"children":3694},{"class":3527},[3695],{"type":34,"value":3696},"as",{"type":24,"tag":2279,"props":3698,"children":3699},{"class":3533},[3700],{"type":34,"value":3701}," nn\n",{"type":24,"tag":2279,"props":3703,"children":3704},{"class":3522,"line":3577},[3705,3709,3714,3718],{"type":24,"tag":2279,"props":3706,"children":3707},{"class":3527},[3708],{"type":34,"value":3541},{"type":24,"tag":2279,"props":3710,"children":3711},{"class":3533},[3712],{"type":34,"value":3713}," torch.nn.functional ",{"type":24,"tag":2279,"props":3715,"children":3716},{"class":3527},[3717],{"type":34,"value":3696},{"type":24,"tag":2279,"props":3719,"children":3720},{"class":3533},[3721],{"type":34,"value":3722}," F\n",{"type":24,"tag":2279,"props":3724,"children":3726},{"class":3522,"line":3725},5,[3727,3731,3736,3740],{"type":24,"tag":2279,"props":3728,"children":3729},{"class":3527},[3730],{"type":34,"value":3541},{"type":24,"tag":2279,"props":3732,"children":3733},{"class":3533},[3734],{"type":34,"value":3735}," torch.optim ",{"type":24,"tag":2279,"props":3737,"children":3738},{"class":3527},[3739],{"type":34,"value":3696},{"type":24,"tag":2279,"props":3741,"children":3742},{"class":3533},[3743],{"type":34,"value":3744}," optim\n",{"type":24,"tag":2279,"props":3746,"children":3748},{"class":3522,"line":3747},6,[3749,3753,3758,3762],{"type":24,"tag":2279,"props":3750,"children":3751},{"class":3527},[3752],{"type":34,"value":3530},{"type":24,"tag":2279,"props":3754,"children":3755},{"class":3533},[3756],{"type":34,"value":3757}," torch.utils.data ",{"type":24,"tag":2279,"props":3759,"children":3760},{"class":3527},[3761],{"type":34,"value":3541},{"type":24,"tag":2279,"props":3763,"children":3764},{"class":3533},[3765],{"type":34,"value":3766}," DataLoader, RandomSampler, SubsetRandomSampler, BatchSampler\n",{"type":24,"tag":2279,"props":3768,"children":3770},{"class":3522,"line":3769},7,[3771,3775],{"type":24,"tag":2279,"props":3772,"children":3773},{"class":3527},[3774],{"type":34,"value":3541},{"type":24,"tag":2279,"props":3776,"children":3777},{"class":3533},[3778],{"type":34,"value":3779}," torchvision\n",{"type":24,"tag":2279,"props":3781,"children":3783},{"class":3522,"line":3782},8,[3784,3788,3793,3797],{"type":24,"tag":2279,"props":3785,"children":3786},{"class":3527},[3787],{"type":34,"value":3541},{"type":24,"tag":2279,"props":3789,"children":3790},{"class":3533},[3791],{"type":34,"value":3792}," matplotlib.pyplot ",{"type":24,"tag":2279,"props":3794,"children":3795},{"class":3527},[3796],{"type":34,"value":3696},{"type":24,"tag":2279,"props":3798,"children":3799},{"class":3533},[3800],{"type":34,"value":3801}," plt",{"type":24,"tag":1378,"props":3803,"children":3805},{"id":3804},"exploring-torchvisions-omniglot-dataset",[3806],{"type":34,"value":3807},"Exploring torchvision's Omniglot dataset",{"type":24,"tag":46,"props":3809,"children":3810},{},[3811],{"type":34,"value":3812},"As mentioned before, torchvision offers an API for handling Omniglot. We'll dissect its composition now.",{"type":24,"tag":46,"props":3814,"children":3815},{},[3816,3818,3825,3827,3832,3834,3838,3840,3845],{"type":34,"value":3817},"First, we must initialize it following torchvision's Omniglot ",{"type":24,"tag":59,"props":3819,"children":3822},{"href":3820,"rel":3821},"https://pytorch.org/vision/stable/generated/torchvision.datasets.Omniglot.html",[63],[3823],{"type":34,"value":3824},"documentation",{"type":34,"value":3826},". We'll download the whole ZIP of images(",{"type":24,"tag":800,"props":3828,"children":3829},{},[3830],{"type":34,"value":3831},"download=True",{"type":34,"value":3833}," and specifying a ",{"type":24,"tag":800,"props":3835,"children":3836},{},[3837],{"type":34,"value":21},{"type":34,"value":3839}," directory, if you don't want it just set ",{"type":24,"tag":800,"props":3841,"children":3842},{},[3843],{"type":34,"value":3844},"download",{"type":34,"value":3846}," to *False) and the only transform we want is having it as tensors for our future NN.",{"type":24,"tag":3511,"props":3848,"children":3850},{"code":3849,"language":3514,"meta":10,"className":3515},"dataset = torchvision.datasets.Omniglot(\n    root=\"./dataset/omniglot\", download=True, transform=torchvision.transforms.ToTensor()\n)\n",[3851],{"type":24,"tag":3495,"props":3852,"children":3853},{"__ignoreMap":10},[3854,3872,3930],{"type":24,"tag":2279,"props":3855,"children":3856},{"class":3522,"line":3523},[3857,3862,3867],{"type":24,"tag":2279,"props":3858,"children":3859},{"class":3533},[3860],{"type":34,"value":3861},"dataset ",{"type":24,"tag":2279,"props":3863,"children":3864},{"class":3527},[3865],{"type":34,"value":3866},"=",{"type":24,"tag":2279,"props":3868,"children":3869},{"class":3533},[3870],{"type":34,"value":3871}," torchvision.datasets.Omniglot(\n",{"type":24,"tag":2279,"props":3873,"children":3874},{"class":3522,"line":2808},[3875,3880,3885,3889,3894,3898,3902,3906,3912,3916,3921,3925],{"type":24,"tag":2279,"props":3876,"children":3877},{"class":3533},[3878],{"type":34,"value":3879},"    ",{"type":24,"tag":2279,"props":3881,"children":3883},{"class":3882},"ct-157101",[3884],{"type":34,"value":21},{"type":24,"tag":2279,"props":3886,"children":3887},{"class":3527},[3888],{"type":34,"value":3866},{"type":24,"tag":2279,"props":3890,"children":3891},{"class":3557},[3892],{"type":34,"value":3893},"\"./dataset/omniglot\"",{"type":24,"tag":2279,"props":3895,"children":3896},{"class":3533},[3897],{"type":34,"value":1340},{"type":24,"tag":2279,"props":3899,"children":3900},{"class":3882},[3901],{"type":34,"value":3844},{"type":24,"tag":2279,"props":3903,"children":3904},{"class":3527},[3905],{"type":34,"value":3866},{"type":24,"tag":2279,"props":3907,"children":3909},{"class":3908},"ct-617022",[3910],{"type":34,"value":3911},"True",{"type":24,"tag":2279,"props":3913,"children":3914},{"class":3533},[3915],{"type":34,"value":1340},{"type":24,"tag":2279,"props":3917,"children":3918},{"class":3882},[3919],{"type":34,"value":3920},"transform",{"type":24,"tag":2279,"props":3922,"children":3923},{"class":3527},[3924],{"type":34,"value":3866},{"type":24,"tag":2279,"props":3926,"children":3927},{"class":3533},[3928],{"type":34,"value":3929},"torchvision.transforms.ToTensor()\n",{"type":24,"tag":2279,"props":3931,"children":3932},{"class":3522,"line":2817},[3933],{"type":24,"tag":2279,"props":3934,"children":3935},{"class":3533},[3936],{"type":34,"value":3937},")",{"type":24,"tag":3511,"props":3939,"children":3941},{"code":3940},"Files already downloaded and verified\n",[3942],{"type":24,"tag":3495,"props":3943,"children":3944},{"__ignoreMap":10},[3945],{"type":34,"value":3940},{"type":24,"tag":46,"props":3947,"children":3948},{},[3949],{"type":34,"value":3950},"Ok, with that loaded, let's check the object's appearance.",{"type":24,"tag":3511,"props":3952,"children":3954},{"code":3953,"language":3514,"meta":10,"className":3515},"dataset\n",[3955],{"type":24,"tag":3495,"props":3956,"children":3957},{"__ignoreMap":10},[3958],{"type":24,"tag":2279,"props":3959,"children":3960},{"class":3522,"line":3523},[3961],{"type":24,"tag":2279,"props":3962,"children":3963},{"class":3533},[3964],{"type":34,"value":3965},"dataset",{"type":24,"tag":3511,"props":3967,"children":3969},{"code":3968},"Dataset Omniglot\n    Number of datapoints: 19280\n    Root location: ./dataset/omniglot/omniglot-py\n    StandardTransform\nTransform: ToTensor()\n",[3970],{"type":24,"tag":3495,"props":3971,"children":3972},{"__ignoreMap":10},[3973],{"type":34,"value":3968},{"type":24,"tag":46,"props":3975,"children":3976},{},[3977],{"type":34,"value":3978},"Everything seems just as we asked, with a dataset of ~19k data points.",{"type":24,"tag":46,"props":3980,"children":3981},{},[3982,3984,4002],{"type":34,"value":3983},"Exploraing a bit the documentation, we'll see that the only way to use the dataset is ",{"type":24,"tag":59,"props":3985,"children":3988},{"href":3986,"rel":3987},"https://pytorch.org/vision/stable/generated/torchvision.datasets.Omniglot.html#torchvision.datasets.Omniglot.__getitem__",[63],[3989,3991],{"type":34,"value":3990},"through its ",{"type":24,"tag":800,"props":3992,"children":3993},{},[3994,3996,4001],{"type":34,"value":3995},"_",{"type":24,"tag":800,"props":3997,"children":3998},{},[3999],{"type":34,"value":4000},"getitem",{"type":34,"value":3995},{"type":34,"value":4003},", i.e. you can only get any of its elements (from its ~19k), so let's get for example the first one and review it.",{"type":24,"tag":3511,"props":4005,"children":4007},{"code":4006,"language":3514,"meta":10,"className":3515},"dataset[0]\n",[4008],{"type":24,"tag":3495,"props":4009,"children":4010},{"__ignoreMap":10},[4011],{"type":24,"tag":2279,"props":4012,"children":4013},{"class":3522,"line":3523},[4014,4019,4024],{"type":24,"tag":2279,"props":4015,"children":4016},{"class":3533},[4017],{"type":34,"value":4018},"dataset[",{"type":24,"tag":2279,"props":4020,"children":4021},{"class":3908},[4022],{"type":34,"value":4023},"0",{"type":24,"tag":2279,"props":4025,"children":4026},{"class":3533},[4027],{"type":34,"value":4028},"]",{"type":24,"tag":3511,"props":4030,"children":4032},{"code":4031},"(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          ...,\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.]]]), 0)\n",[4033],{"type":24,"tag":3495,"props":4034,"children":4035},{"__ignoreMap":10},[4036],{"type":34,"value":4031},{"type":24,"tag":46,"props":4038,"children":4039},{},[4040],{"type":34,"value":4041},"Ok, it seems to be a tuple as the documentation says. According to it, the first element is the image itself (a torch tensor) while the second one is the target label). Let's review both",{"type":24,"tag":3511,"props":4043,"children":4045},{"code":4044,"language":3514,"meta":10,"className":3515},"dataset[0][0].shape\n",[4046],{"type":24,"tag":3495,"props":4047,"children":4048},{"__ignoreMap":10},[4049],{"type":24,"tag":2279,"props":4050,"children":4051},{"class":3522,"line":3523},[4052,4056,4060,4065,4069],{"type":24,"tag":2279,"props":4053,"children":4054},{"class":3533},[4055],{"type":34,"value":4018},{"type":24,"tag":2279,"props":4057,"children":4058},{"class":3908},[4059],{"type":34,"value":4023},{"type":24,"tag":2279,"props":4061,"children":4062},{"class":3533},[4063],{"type":34,"value":4064},"][",{"type":24,"tag":2279,"props":4066,"children":4067},{"class":3908},[4068],{"type":34,"value":4023},{"type":24,"tag":2279,"props":4070,"children":4071},{"class":3533},[4072],{"type":34,"value":4073},"].shape",{"type":24,"tag":3511,"props":4075,"children":4077},{"code":4076},"torch.Size([1, 105, 105])\n",[4078],{"type":24,"tag":3495,"props":4079,"children":4080},{"__ignoreMap":10},[4081],{"type":34,"value":4076},{"type":24,"tag":46,"props":4083,"children":4084},{},[4085],{"type":34,"value":4086},"As expected, the image is a single channel one of 105x105. Let's plot its only channel.",{"type":24,"tag":3511,"props":4088,"children":4090},{"code":4089,"language":3514,"meta":10,"className":3515},"plt.imshow(dataset[0][0][0].numpy())\n",[4091],{"type":24,"tag":3495,"props":4092,"children":4093},{"__ignoreMap":10},[4094],{"type":24,"tag":2279,"props":4095,"children":4096},{"class":3522,"line":3523},[4097,4102,4106,4110,4114,4118,4122],{"type":24,"tag":2279,"props":4098,"children":4099},{"class":3533},[4100],{"type":34,"value":4101},"plt.imshow(dataset[",{"type":24,"tag":2279,"props":4103,"children":4104},{"class":3908},[4105],{"type":34,"value":4023},{"type":24,"tag":2279,"props":4107,"children":4108},{"class":3533},[4109],{"type":34,"value":4064},{"type":24,"tag":2279,"props":4111,"children":4112},{"class":3908},[4113],{"type":34,"value":4023},{"type":24,"tag":2279,"props":4115,"children":4116},{"class":3533},[4117],{"type":34,"value":4064},{"type":24,"tag":2279,"props":4119,"children":4120},{"class":3908},[4121],{"type":34,"value":4023},{"type":24,"tag":2279,"props":4123,"children":4124},{"class":3533},[4125],{"type":34,"value":4126},"].numpy())",{"type":24,"tag":3511,"props":4128,"children":4130},{"code":4129},"\u003Cmatplotlib.image.AxesImage at 0x7f1fca5129d0>\n\n\n\n\n",[4131],{"type":24,"tag":3495,"props":4132,"children":4133},{"__ignoreMap":10},[4134],{"type":34,"value":4129},{"type":24,"tag":46,"props":4136,"children":4137},{},[4138],{"type":24,"tag":175,"props":4139,"children":4142},{"alt":4140,"src":4141},"sample","https://i.imgur.com/zimxwVw.png",[],{"type":24,"tag":46,"props":4144,"children":4145},{},[4146],{"type":34,"value":4147},"So this is the appearance of an Omniglot symbol. Everything seems fine with the samples then, and we know how to get them. Let's go for the labels.",{"type":24,"tag":46,"props":4149,"children":4150},{},[4151],{"type":34,"value":4152},"We may review the first 100 labels.",{"type":24,"tag":3511,"props":4154,"children":4156},{"code":4155,"language":3514,"meta":10,"className":3515},"[dataset[ismp][1] for ismp in range(100)]\n",[4157],{"type":24,"tag":3495,"props":4158,"children":4159},{"__ignoreMap":10},[4160],{"type":24,"tag":2279,"props":4161,"children":4162},{"class":3522,"line":3523},[4163,4168,4172,4177,4182,4187,4192,4196,4201,4206,4211],{"type":24,"tag":2279,"props":4164,"children":4165},{"class":3533},[4166],{"type":34,"value":4167},"[dataset[ismp][",{"type":24,"tag":2279,"props":4169,"children":4170},{"class":3908},[4171],{"type":34,"value":2283},{"type":24,"tag":2279,"props":4173,"children":4174},{"class":3533},[4175],{"type":34,"value":4176},"] ",{"type":24,"tag":2279,"props":4178,"children":4179},{"class":3527},[4180],{"type":34,"value":4181},"for",{"type":24,"tag":2279,"props":4183,"children":4184},{"class":3533},[4185],{"type":34,"value":4186}," ismp ",{"type":24,"tag":2279,"props":4188,"children":4189},{"class":3527},[4190],{"type":34,"value":4191},"in",{"type":24,"tag":2279,"props":4193,"children":4194},{"class":3533},[4195],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4197,"children":4198},{"class":3908},[4199],{"type":34,"value":4200},"range",{"type":24,"tag":2279,"props":4202,"children":4203},{"class":3533},[4204],{"type":34,"value":4205},"(",{"type":24,"tag":2279,"props":4207,"children":4208},{"class":3908},[4209],{"type":34,"value":4210},"100",{"type":24,"tag":2279,"props":4212,"children":4213},{"class":3533},[4214],{"type":34,"value":4215},")]",{"type":24,"tag":3511,"props":4217,"children":4219},{"code":4218},"[0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4]\n",[4220],{"type":24,"tag":3495,"props":4221,"children":4222},{"__ignoreMap":10},[4223],{"type":34,"value":4218},{"type":24,"tag":46,"props":4225,"children":4226},{},[4227],{"type":34,"value":4228},"Do you realize the pattern? Labels are sequential and each label repeats for 20 samples. Which is the number of samples per character (class). To verify that, if we get a label every 2k samples, each label should add 100 to the previous.",{"type":24,"tag":3511,"props":4230,"children":4232},{"code":4231,"language":3514,"meta":10,"className":3515},"[dataset[ismp * 2000][1] for ismp in range(8)]\n",[4233],{"type":24,"tag":3495,"props":4234,"children":4235},{"__ignoreMap":10},[4236],{"type":24,"tag":2279,"props":4237,"children":4238},{"class":3522,"line":3523},[4239,4244,4249,4253,4258,4262,4266,4270,4274,4278,4282,4286,4290,4294,4298],{"type":24,"tag":2279,"props":4240,"children":4241},{"class":3533},[4242],{"type":34,"value":4243},"[dataset[ismp ",{"type":24,"tag":2279,"props":4245,"children":4246},{"class":3527},[4247],{"type":34,"value":4248},"*",{"type":24,"tag":2279,"props":4250,"children":4251},{"class":3533},[4252],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4254,"children":4255},{"class":3908},[4256],{"type":34,"value":4257},"2000",{"type":24,"tag":2279,"props":4259,"children":4260},{"class":3533},[4261],{"type":34,"value":4064},{"type":24,"tag":2279,"props":4263,"children":4264},{"class":3908},[4265],{"type":34,"value":2283},{"type":24,"tag":2279,"props":4267,"children":4268},{"class":3533},[4269],{"type":34,"value":4176},{"type":24,"tag":2279,"props":4271,"children":4272},{"class":3527},[4273],{"type":34,"value":4181},{"type":24,"tag":2279,"props":4275,"children":4276},{"class":3533},[4277],{"type":34,"value":4186},{"type":24,"tag":2279,"props":4279,"children":4280},{"class":3527},[4281],{"type":34,"value":4191},{"type":24,"tag":2279,"props":4283,"children":4284},{"class":3533},[4285],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4287,"children":4288},{"class":3908},[4289],{"type":34,"value":4200},{"type":24,"tag":2279,"props":4291,"children":4292},{"class":3533},[4293],{"type":34,"value":4205},{"type":24,"tag":2279,"props":4295,"children":4296},{"class":3908},[4297],{"type":34,"value":2447},{"type":24,"tag":2279,"props":4299,"children":4300},{"class":3533},[4301],{"type":34,"value":4215},{"type":24,"tag":3511,"props":4303,"children":4305},{"code":4304},"[0, 100, 200, 300, 400, 500, 600, 700]\n",[4306],{"type":24,"tag":3495,"props":4307,"children":4308},{"__ignoreMap":10},[4309],{"type":34,"value":4304},{"type":24,"tag":46,"props":4311,"children":4312},{},[4313],{"type":34,"value":4314},"Which happens.",{"type":24,"tag":46,"props":4316,"children":4317},{},[4318,4320,4327,4329,4334,4335,4340],{"type":34,"value":4319},"Ok, one last thing that will be useful for us. Going deeper, apart from the documentation we can also get to the ",{"type":24,"tag":59,"props":4321,"children":4324},{"href":4322,"rel":4323},"https://pytorch.org/vision/stable/_modules/torchvision/datasets/omniglot.html#Omniglot",[63],[4325],{"type":34,"value":4326},"source code",{"type":34,"value":4328}," and realize 2 useful attributes of the dataset object called ",{"type":24,"tag":800,"props":4330,"children":4331},{},[4332],{"type":34,"value":4333},"_alphabets",{"type":34,"value":422},{"type":24,"tag":800,"props":4336,"children":4337},{},[4338],{"type":34,"value":4339},"_characters",{"type":34,"value":4341},", which is the ordered list of each of them. This way, we'll have semantical information on each of the labels and therefore we may be able to build our scenario.",{"type":24,"tag":3511,"props":4343,"children":4345},{"code":4344,"language":3514,"meta":10,"className":3515},"alphabets = dataset._alphabets\n",[4346],{"type":24,"tag":3495,"props":4347,"children":4348},{"__ignoreMap":10},[4349],{"type":24,"tag":2279,"props":4350,"children":4351},{"class":3522,"line":3523},[4352,4357,4361],{"type":24,"tag":2279,"props":4353,"children":4354},{"class":3533},[4355],{"type":34,"value":4356},"alphabets ",{"type":24,"tag":2279,"props":4358,"children":4359},{"class":3527},[4360],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4362,"children":4363},{"class":3533},[4364],{"type":34,"value":4365}," dataset._alphabets",{"type":24,"tag":3511,"props":4367,"children":4369},{"code":4368,"language":3514,"meta":10,"className":3515},"characters = dataset._characters\n",[4370],{"type":24,"tag":3495,"props":4371,"children":4372},{"__ignoreMap":10},[4373],{"type":24,"tag":2279,"props":4374,"children":4375},{"class":3522,"line":3523},[4376,4381,4385],{"type":24,"tag":2279,"props":4377,"children":4378},{"class":3533},[4379],{"type":34,"value":4380},"characters ",{"type":24,"tag":2279,"props":4382,"children":4383},{"class":3527},[4384],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4386,"children":4387},{"class":3533},[4388],{"type":34,"value":4389}," dataset._characters",{"type":24,"tag":46,"props":4391,"children":4392},{},[4393],{"type":34,"value":4394},"Let's check how many alphabets and characters are there.",{"type":24,"tag":3511,"props":4396,"children":4398},{"code":4397,"language":3514,"meta":10,"className":3515},"len(alphabets)\n",[4399],{"type":24,"tag":3495,"props":4400,"children":4401},{"__ignoreMap":10},[4402],{"type":24,"tag":2279,"props":4403,"children":4404},{"class":3522,"line":3523},[4405,4410],{"type":24,"tag":2279,"props":4406,"children":4407},{"class":3908},[4408],{"type":34,"value":4409},"len",{"type":24,"tag":2279,"props":4411,"children":4412},{"class":3533},[4413],{"type":34,"value":4414},"(alphabets)",{"type":24,"tag":3511,"props":4416,"children":4418},{"code":4417},"30\n",[4419],{"type":24,"tag":3495,"props":4420,"children":4421},{"__ignoreMap":10},[4422],{"type":34,"value":4417},{"type":24,"tag":3511,"props":4424,"children":4426},{"code":4425,"language":3514,"meta":10,"className":3515},"len(characters)\n",[4427],{"type":24,"tag":3495,"props":4428,"children":4429},{"__ignoreMap":10},[4430],{"type":24,"tag":2279,"props":4431,"children":4432},{"class":3522,"line":3523},[4433,4437],{"type":24,"tag":2279,"props":4434,"children":4435},{"class":3908},[4436],{"type":34,"value":4409},{"type":24,"tag":2279,"props":4438,"children":4439},{"class":3533},[4440],{"type":34,"value":4441},"(characters)",{"type":24,"tag":3511,"props":4443,"children":4445},{"code":4444},"964\n",[4446],{"type":24,"tag":3495,"props":4447,"children":4448},{"__ignoreMap":10},[4449],{"type":34,"value":4444},{"type":24,"tag":46,"props":4451,"children":4452},{},[4453],{"type":34,"value":4454},"Which makes sense.",{"type":24,"tag":46,"props":4456,"children":4457},{},[4458],{"type":34,"value":4459},"The last thing, let's verify we can embed the dataset into a torch DataLoader.",{"type":24,"tag":3511,"props":4461,"children":4463},{"code":4462,"language":3514,"meta":10,"className":3515},"data_loader = torch.utils.data.DataLoader(dataset,\n                                          batch_size=4,\n                                          shuffle=True,\n                                          num_workers=8)\n",[4464],{"type":24,"tag":3495,"props":4465,"children":4466},{"__ignoreMap":10},[4467,4484,4510,4534],{"type":24,"tag":2279,"props":4468,"children":4469},{"class":3522,"line":3523},[4470,4475,4479],{"type":24,"tag":2279,"props":4471,"children":4472},{"class":3533},[4473],{"type":34,"value":4474},"data_loader ",{"type":24,"tag":2279,"props":4476,"children":4477},{"class":3527},[4478],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4480,"children":4481},{"class":3533},[4482],{"type":34,"value":4483}," torch.utils.data.DataLoader(dataset,\n",{"type":24,"tag":2279,"props":4485,"children":4486},{"class":3522,"line":2808},[4487,4492,4497,4501,4505],{"type":24,"tag":2279,"props":4488,"children":4489},{"class":3533},[4490],{"type":34,"value":4491},"                                          ",{"type":24,"tag":2279,"props":4493,"children":4494},{"class":3882},[4495],{"type":34,"value":4496},"batch_size",{"type":24,"tag":2279,"props":4498,"children":4499},{"class":3527},[4500],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4502,"children":4503},{"class":3908},[4504],{"type":34,"value":2354},{"type":24,"tag":2279,"props":4506,"children":4507},{"class":3533},[4508],{"type":34,"value":4509},",\n",{"type":24,"tag":2279,"props":4511,"children":4512},{"class":3522,"line":2817},[4513,4517,4522,4526,4530],{"type":24,"tag":2279,"props":4514,"children":4515},{"class":3533},[4516],{"type":34,"value":4491},{"type":24,"tag":2279,"props":4518,"children":4519},{"class":3882},[4520],{"type":34,"value":4521},"shuffle",{"type":24,"tag":2279,"props":4523,"children":4524},{"class":3527},[4525],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4527,"children":4528},{"class":3908},[4529],{"type":34,"value":3911},{"type":24,"tag":2279,"props":4531,"children":4532},{"class":3533},[4533],{"type":34,"value":4509},{"type":24,"tag":2279,"props":4535,"children":4536},{"class":3522,"line":3577},[4537,4541,4546,4550,4554],{"type":24,"tag":2279,"props":4538,"children":4539},{"class":3533},[4540],{"type":34,"value":4491},{"type":24,"tag":2279,"props":4542,"children":4543},{"class":3882},[4544],{"type":34,"value":4545},"num_workers",{"type":24,"tag":2279,"props":4547,"children":4548},{"class":3527},[4549],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4551,"children":4552},{"class":3908},[4553],{"type":34,"value":2447},{"type":24,"tag":2279,"props":4555,"children":4556},{"class":3533},[4557],{"type":34,"value":3937},{"type":24,"tag":3511,"props":4559,"children":4561},{"code":4560},"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n",[4562],{"type":24,"tag":3495,"props":4563,"children":4564},{"__ignoreMap":10},[4565],{"type":34,"value":4560},{"type":24,"tag":1378,"props":4567,"children":4569},{"id":4568},"load-raw-dataset",[4570],{"type":34,"value":4571},"Load raw dataset",{"type":24,"tag":46,"props":4573,"children":4574},{},[4575],{"type":34,"value":4576},"So with averything that we learned, let's load our dataset and its related info.",{"type":24,"tag":3511,"props":4578,"children":4580},{"code":4579,"language":3514,"meta":10,"className":3515},"omniglot_raw = torchvision.datasets.Omniglot(root=\"./dataset/omniglot\", download=True, transform=torchvision.transforms.ToTensor())\n",[4581],{"type":24,"tag":3495,"props":4582,"children":4583},{"__ignoreMap":10},[4584],{"type":24,"tag":2279,"props":4585,"children":4586},{"class":3522,"line":3523},[4587,4592,4596,4601,4605,4609,4613,4617,4621,4625,4629,4633,4637,4641],{"type":24,"tag":2279,"props":4588,"children":4589},{"class":3533},[4590],{"type":34,"value":4591},"omniglot_raw ",{"type":24,"tag":2279,"props":4593,"children":4594},{"class":3527},[4595],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4597,"children":4598},{"class":3533},[4599],{"type":34,"value":4600}," torchvision.datasets.Omniglot(",{"type":24,"tag":2279,"props":4602,"children":4603},{"class":3882},[4604],{"type":34,"value":21},{"type":24,"tag":2279,"props":4606,"children":4607},{"class":3527},[4608],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4610,"children":4611},{"class":3557},[4612],{"type":34,"value":3893},{"type":24,"tag":2279,"props":4614,"children":4615},{"class":3533},[4616],{"type":34,"value":1340},{"type":24,"tag":2279,"props":4618,"children":4619},{"class":3882},[4620],{"type":34,"value":3844},{"type":24,"tag":2279,"props":4622,"children":4623},{"class":3527},[4624],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4626,"children":4627},{"class":3908},[4628],{"type":34,"value":3911},{"type":24,"tag":2279,"props":4630,"children":4631},{"class":3533},[4632],{"type":34,"value":1340},{"type":24,"tag":2279,"props":4634,"children":4635},{"class":3882},[4636],{"type":34,"value":3920},{"type":24,"tag":2279,"props":4638,"children":4639},{"class":3527},[4640],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4642,"children":4643},{"class":3533},[4644],{"type":34,"value":4645},"torchvision.transforms.ToTensor())",{"type":24,"tag":3511,"props":4647,"children":4648},{"code":3940},[4649],{"type":24,"tag":3495,"props":4650,"children":4651},{"__ignoreMap":10},[4652],{"type":34,"value":3940},{"type":24,"tag":3511,"props":4654,"children":4656},{"code":4655,"language":3514,"meta":10,"className":3515},"alphabets = omniglot_raw._alphabets\ncharacters = omniglot_raw._characters\n",[4657],{"type":24,"tag":3495,"props":4658,"children":4659},{"__ignoreMap":10},[4660,4676],{"type":24,"tag":2279,"props":4661,"children":4662},{"class":3522,"line":3523},[4663,4667,4671],{"type":24,"tag":2279,"props":4664,"children":4665},{"class":3533},[4666],{"type":34,"value":4356},{"type":24,"tag":2279,"props":4668,"children":4669},{"class":3527},[4670],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4672,"children":4673},{"class":3533},[4674],{"type":34,"value":4675}," omniglot_raw._alphabets\n",{"type":24,"tag":2279,"props":4677,"children":4678},{"class":3522,"line":2808},[4679,4683,4687],{"type":24,"tag":2279,"props":4680,"children":4681},{"class":3533},[4682],{"type":34,"value":4380},{"type":24,"tag":2279,"props":4684,"children":4685},{"class":3527},[4686],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4688,"children":4689},{"class":3533},[4690],{"type":34,"value":4691}," omniglot_raw._characters",{"type":24,"tag":3511,"props":4693,"children":4695},{"code":4694,"language":3514,"meta":10,"className":3515},"num_alphabets = len(alphabets)\nnum_characters = len(characters)\n",[4696],{"type":24,"tag":3495,"props":4697,"children":4698},{"__ignoreMap":10},[4699,4724],{"type":24,"tag":2279,"props":4700,"children":4701},{"class":3522,"line":3523},[4702,4707,4711,4715,4719],{"type":24,"tag":2279,"props":4703,"children":4704},{"class":3533},[4705],{"type":34,"value":4706},"num_alphabets ",{"type":24,"tag":2279,"props":4708,"children":4709},{"class":3527},[4710],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4712,"children":4713},{"class":3533},[4714],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4716,"children":4717},{"class":3908},[4718],{"type":34,"value":4409},{"type":24,"tag":2279,"props":4720,"children":4721},{"class":3533},[4722],{"type":34,"value":4723},"(alphabets)\n",{"type":24,"tag":2279,"props":4725,"children":4726},{"class":3522,"line":2808},[4727,4732,4736,4740,4744],{"type":24,"tag":2279,"props":4728,"children":4729},{"class":3533},[4730],{"type":34,"value":4731},"num_characters ",{"type":24,"tag":2279,"props":4733,"children":4734},{"class":3527},[4735],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4737,"children":4738},{"class":3533},[4739],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4741,"children":4742},{"class":3908},[4743],{"type":34,"value":4409},{"type":24,"tag":2279,"props":4745,"children":4746},{"class":3533},[4747],{"type":34,"value":4441},{"type":24,"tag":1378,"props":4749,"children":4751},{"id":4750},"building-the-meta-splits",[4752],{"type":34,"value":4753},"Building the Meta-Splits",{"type":24,"tag":46,"props":4755,"children":4756},{},[4757],{"type":34,"value":4758},"Ok, at this point we want to build each Meta-Split (or Meta-set). The material needs of a Meta-set are the alphabets it will contain. Remember that each Meta-set will determine its problems, but that is interpretable from its alphabets, since the problems will be all the possible problems of binary classification between characters of a same alphabet within the Meta-set.",{"type":24,"tag":46,"props":4760,"children":4761},{},[4762],{"type":34,"value":4763},"We want to balance the Meta-set at character level, in a way in which each Meta-set will contain an approximation to a fixed ratio of characters, while respecting the constraint in which each whole alphabet must belong to a single Meta-set.",{"type":24,"tag":46,"props":4765,"children":4766},{},[4767],{"type":34,"value":4768},"The simplest way to do so is to take each empty Meta-set and add alphabets until the fixed ratio is reached, then the last Meta-set will get the remaining alphabets. This last Meta-set will be Meta-test, since losing a bit of its content doesn't seem a disaster aside from its statistical significance.",{"type":24,"tag":46,"props":4770,"children":4771},{},[4772,4774,4779],{"type":34,"value":4773},"So first we will define a ",{"type":24,"tag":800,"props":4775,"children":4776},{},[4777],{"type":34,"value":4778},"MetaSplit",{"type":34,"value":4780}," class that will contain this information. It will also contain some informative attributes such as the minimum number of characters, which will be computed at initialization depending on the Meta-set ratio and the total number of characters (these variables will be passed), the current number of characters (which will be updated out from the class when alphabets are added) and the number of problems, which will also be added from out of the class.",{"type":24,"tag":3511,"props":4782,"children":4784},{"code":4783,"language":3514,"meta":10,"className":3515},"class MetaSplit:\n  def __init__(self, ratio, total_num_characters):\n    self.alphabets = []\n    self.num_characters = 0\n    self.min_num_characters = total_num_characters * ratio\n    self.num_problems = None\n\n",[4785],{"type":24,"tag":3495,"props":4786,"children":4787},{"__ignoreMap":10},[4788,4810,4837,4863,4892,4926],{"type":24,"tag":2279,"props":4789,"children":4790},{"class":3522,"line":3523},[4791,4796,4800,4805],{"type":24,"tag":2279,"props":4792,"children":4793},{"class":3527},[4794],{"type":34,"value":4795},"class",{"type":24,"tag":2279,"props":4797,"children":4798},{"class":3533},[4799],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4801,"children":4803},{"class":4802},"ct-762058",[4804],{"type":34,"value":4778},{"type":24,"tag":2279,"props":4806,"children":4807},{"class":3533},[4808],{"type":34,"value":4809},":\n",{"type":24,"tag":2279,"props":4811,"children":4812},{"class":3522,"line":2808},[4813,4818,4823,4827,4832],{"type":24,"tag":2279,"props":4814,"children":4815},{"class":3533},[4816],{"type":34,"value":4817},"  ",{"type":24,"tag":2279,"props":4819,"children":4820},{"class":3527},[4821],{"type":34,"value":4822},"def",{"type":24,"tag":2279,"props":4824,"children":4825},{"class":3533},[4826],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4828,"children":4829},{"class":3908},[4830],{"type":34,"value":4831},"__init__",{"type":24,"tag":2279,"props":4833,"children":4834},{"class":3533},[4835],{"type":34,"value":4836},"(self, ratio, total_num_characters):\n",{"type":24,"tag":2279,"props":4838,"children":4839},{"class":3522,"line":2817},[4840,4844,4849,4854,4858],{"type":24,"tag":2279,"props":4841,"children":4842},{"class":3533},[4843],{"type":34,"value":3879},{"type":24,"tag":2279,"props":4845,"children":4846},{"class":3908},[4847],{"type":34,"value":4848},"self",{"type":24,"tag":2279,"props":4850,"children":4851},{"class":3533},[4852],{"type":34,"value":4853},".alphabets ",{"type":24,"tag":2279,"props":4855,"children":4856},{"class":3527},[4857],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4859,"children":4860},{"class":3533},[4861],{"type":34,"value":4862}," []\n",{"type":24,"tag":2279,"props":4864,"children":4865},{"class":3522,"line":3577},[4866,4870,4874,4879,4883,4887],{"type":24,"tag":2279,"props":4867,"children":4868},{"class":3533},[4869],{"type":34,"value":3879},{"type":24,"tag":2279,"props":4871,"children":4872},{"class":3908},[4873],{"type":34,"value":4848},{"type":24,"tag":2279,"props":4875,"children":4876},{"class":3533},[4877],{"type":34,"value":4878},".num_characters ",{"type":24,"tag":2279,"props":4880,"children":4881},{"class":3527},[4882],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4884,"children":4885},{"class":3533},[4886],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4888,"children":4889},{"class":3908},[4890],{"type":34,"value":4891},"0\n",{"type":24,"tag":2279,"props":4893,"children":4894},{"class":3522,"line":3725},[4895,4899,4903,4908,4912,4917,4921],{"type":24,"tag":2279,"props":4896,"children":4897},{"class":3533},[4898],{"type":34,"value":3879},{"type":24,"tag":2279,"props":4900,"children":4901},{"class":3908},[4902],{"type":34,"value":4848},{"type":24,"tag":2279,"props":4904,"children":4905},{"class":3533},[4906],{"type":34,"value":4907},".min_num_characters ",{"type":24,"tag":2279,"props":4909,"children":4910},{"class":3527},[4911],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4913,"children":4914},{"class":3533},[4915],{"type":34,"value":4916}," total_num_characters ",{"type":24,"tag":2279,"props":4918,"children":4919},{"class":3527},[4920],{"type":34,"value":4248},{"type":24,"tag":2279,"props":4922,"children":4923},{"class":3533},[4924],{"type":34,"value":4925}," ratio\n",{"type":24,"tag":2279,"props":4927,"children":4928},{"class":3522,"line":3747},[4929,4933,4937,4942,4946,4950],{"type":24,"tag":2279,"props":4930,"children":4931},{"class":3533},[4932],{"type":34,"value":3879},{"type":24,"tag":2279,"props":4934,"children":4935},{"class":3908},[4936],{"type":34,"value":4848},{"type":24,"tag":2279,"props":4938,"children":4939},{"class":3533},[4940],{"type":34,"value":4941},".num_problems ",{"type":24,"tag":2279,"props":4943,"children":4944},{"class":3527},[4945],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4947,"children":4948},{"class":3533},[4949],{"type":34,"value":2285},{"type":24,"tag":2279,"props":4951,"children":4952},{"class":3908},[4953],{"type":34,"value":4954},"None",{"type":24,"tag":46,"props":4956,"children":4957},{},[4958],{"type":34,"value":4959},"And let's initialize the Meta-splits (after this step they will still be empty)",{"type":24,"tag":3511,"props":4961,"children":4963},{"code":4962,"language":3514,"meta":10,"className":3515},"metasplits = {'metatrain': MetaSplit(0.7, num_characters),\n              'metaval': MetaSplit(0.15, num_characters),\n              'metatest': MetaSplit(0.15, num_characters)}\n",[4964],{"type":24,"tag":3495,"props":4965,"children":4966},{"__ignoreMap":10},[4967,5004,5030],{"type":24,"tag":2279,"props":4968,"children":4969},{"class":3522,"line":3523},[4970,4975,4979,4984,4989,4994,4999],{"type":24,"tag":2279,"props":4971,"children":4972},{"class":3533},[4973],{"type":34,"value":4974},"metasplits ",{"type":24,"tag":2279,"props":4976,"children":4977},{"class":3527},[4978],{"type":34,"value":3866},{"type":24,"tag":2279,"props":4980,"children":4981},{"class":3533},[4982],{"type":34,"value":4983}," {",{"type":24,"tag":2279,"props":4985,"children":4986},{"class":3557},[4987],{"type":34,"value":4988},"'metatrain'",{"type":24,"tag":2279,"props":4990,"children":4991},{"class":3533},[4992],{"type":34,"value":4993},": MetaSplit(",{"type":24,"tag":2279,"props":4995,"children":4996},{"class":3908},[4997],{"type":34,"value":4998},"0.7",{"type":24,"tag":2279,"props":5000,"children":5001},{"class":3533},[5002],{"type":34,"value":5003},", num_characters),\n",{"type":24,"tag":2279,"props":5005,"children":5006},{"class":3522,"line":2808},[5007,5012,5017,5021,5026],{"type":24,"tag":2279,"props":5008,"children":5009},{"class":3533},[5010],{"type":34,"value":5011},"              ",{"type":24,"tag":2279,"props":5013,"children":5014},{"class":3557},[5015],{"type":34,"value":5016},"'metaval'",{"type":24,"tag":2279,"props":5018,"children":5019},{"class":3533},[5020],{"type":34,"value":4993},{"type":24,"tag":2279,"props":5022,"children":5023},{"class":3908},[5024],{"type":34,"value":5025},"0.15",{"type":24,"tag":2279,"props":5027,"children":5028},{"class":3533},[5029],{"type":34,"value":5003},{"type":24,"tag":2279,"props":5031,"children":5032},{"class":3522,"line":2817},[5033,5037,5042,5046,5050],{"type":24,"tag":2279,"props":5034,"children":5035},{"class":3533},[5036],{"type":34,"value":5011},{"type":24,"tag":2279,"props":5038,"children":5039},{"class":3557},[5040],{"type":34,"value":5041},"'metatest'",{"type":24,"tag":2279,"props":5043,"children":5044},{"class":3533},[5045],{"type":34,"value":4993},{"type":24,"tag":2279,"props":5047,"children":5048},{"class":3908},[5049],{"type":34,"value":5025},{"type":24,"tag":2279,"props":5051,"children":5052},{"class":3533},[5053],{"type":34,"value":5054},", num_characters)}",{"type":24,"tag":46,"props":5056,"children":5057},{},[5058],{"type":34,"value":5059},"The following step is counting the number of characters in each alphabet. To do so, we need to parse the strings of the alphabets and the characters, which go as the following.",{"type":24,"tag":3511,"props":5061,"children":5063},{"code":5062,"language":3514,"meta":10,"className":3515},"print(alphabets[0])\n",[5064],{"type":24,"tag":3495,"props":5065,"children":5066},{"__ignoreMap":10},[5067],{"type":24,"tag":2279,"props":5068,"children":5069},{"class":3522,"line":3523},[5070,5075,5080,5084],{"type":24,"tag":2279,"props":5071,"children":5072},{"class":3908},[5073],{"type":34,"value":5074},"print",{"type":24,"tag":2279,"props":5076,"children":5077},{"class":3533},[5078],{"type":34,"value":5079},"(alphabets[",{"type":24,"tag":2279,"props":5081,"children":5082},{"class":3908},[5083],{"type":34,"value":4023},{"type":24,"tag":2279,"props":5085,"children":5086},{"class":3533},[5087],{"type":34,"value":5088},"])",{"type":24,"tag":3511,"props":5090,"children":5092},{"code":5091},"Alphabet_of_the_Magi\n",[5093],{"type":24,"tag":3495,"props":5094,"children":5095},{"__ignoreMap":10},[5096],{"type":34,"value":5091},{"type":24,"tag":3511,"props":5098,"children":5100},{"code":5099,"language":3514,"meta":10,"className":3515},"print(characters[0])\n",[5101],{"type":24,"tag":3495,"props":5102,"children":5103},{"__ignoreMap":10},[5104],{"type":24,"tag":2279,"props":5105,"children":5106},{"class":3522,"line":3523},[5107,5111,5116,5120],{"type":24,"tag":2279,"props":5108,"children":5109},{"class":3908},[5110],{"type":34,"value":5074},{"type":24,"tag":2279,"props":5112,"children":5113},{"class":3533},[5114],{"type":34,"value":5115},"(characters[",{"type":24,"tag":2279,"props":5117,"children":5118},{"class":3908},[5119],{"type":34,"value":4023},{"type":24,"tag":2279,"props":5121,"children":5122},{"class":3533},[5123],{"type":34,"value":5088},{"type":24,"tag":3511,"props":5125,"children":5127},{"code":5126},"Alphabet_of_the_Magi/character01\n",[5128],{"type":24,"tag":3495,"props":5129,"children":5130},{"__ignoreMap":10},[5131],{"type":34,"value":5126},{"type":24,"tag":46,"props":5133,"children":5134},{},[5135,5137,5142,5144,5148],{"type":34,"value":5136},"Ok, so easily we can see that a character goes as ",{"type":24,"tag":800,"props":5138,"children":5139},{},[5140],{"type":34,"value":5141},"alphabet/character_in_alphabet",{"type":34,"value":5143},". So, we will for each alphabet count in how many characters does it match the substring before the ",{"type":24,"tag":800,"props":5145,"children":5146},{},[5147],{"type":34,"value":3593},{"type":34,"value":170},{"type":24,"tag":3511,"props":5150,"children":5152},{"code":5151,"language":3514,"meta":10,"className":3515},"chars_per_alphabet = {alph: [char.split('/')[0] for char in characters].count(alph) for alph in alphabets}\n",[5153],{"type":24,"tag":3495,"props":5154,"children":5155},{"__ignoreMap":10},[5156],{"type":24,"tag":2279,"props":5157,"children":5158},{"class":3522,"line":3523},[5159,5164,5168,5173,5178,5183,5187,5191,5195,5200,5204,5209,5213,5218,5222],{"type":24,"tag":2279,"props":5160,"children":5161},{"class":3533},[5162],{"type":34,"value":5163},"chars_per_alphabet ",{"type":24,"tag":2279,"props":5165,"children":5166},{"class":3527},[5167],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5169,"children":5170},{"class":3533},[5171],{"type":34,"value":5172}," {alph: [char.split(",{"type":24,"tag":2279,"props":5174,"children":5175},{"class":3557},[5176],{"type":34,"value":5177},"'/'",{"type":24,"tag":2279,"props":5179,"children":5180},{"class":3533},[5181],{"type":34,"value":5182},")[",{"type":24,"tag":2279,"props":5184,"children":5185},{"class":3908},[5186],{"type":34,"value":4023},{"type":24,"tag":2279,"props":5188,"children":5189},{"class":3533},[5190],{"type":34,"value":4176},{"type":24,"tag":2279,"props":5192,"children":5193},{"class":3527},[5194],{"type":34,"value":4181},{"type":24,"tag":2279,"props":5196,"children":5197},{"class":3533},[5198],{"type":34,"value":5199}," char ",{"type":24,"tag":2279,"props":5201,"children":5202},{"class":3527},[5203],{"type":34,"value":4191},{"type":24,"tag":2279,"props":5205,"children":5206},{"class":3533},[5207],{"type":34,"value":5208}," characters].count(alph) ",{"type":24,"tag":2279,"props":5210,"children":5211},{"class":3527},[5212],{"type":34,"value":4181},{"type":24,"tag":2279,"props":5214,"children":5215},{"class":3533},[5216],{"type":34,"value":5217}," alph ",{"type":24,"tag":2279,"props":5219,"children":5220},{"class":3527},[5221],{"type":34,"value":4191},{"type":24,"tag":2279,"props":5223,"children":5224},{"class":3533},[5225],{"type":34,"value":5226}," alphabets}",{"type":24,"tag":3511,"props":5228,"children":5230},{"code":5229,"language":3514,"meta":10,"className":3515},"chars_per_alphabet\n",[5231],{"type":24,"tag":3495,"props":5232,"children":5233},{"__ignoreMap":10},[5234],{"type":24,"tag":2279,"props":5235,"children":5236},{"class":3522,"line":3523},[5237],{"type":24,"tag":2279,"props":5238,"children":5239},{"class":3533},[5240],{"type":34,"value":5241},"chars_per_alphabet",{"type":24,"tag":3511,"props":5243,"children":5245},{"code":5244},"{'Alphabet_of_the_Magi': 20,\n 'Anglo-Saxon_Futhorc': 29,\n 'Arcadian': 26,\n 'Armenian': 41,\n 'Asomtavruli_(Georgian)': 40,\n 'Balinese': 24,\n 'Bengali': 46,\n 'Blackfoot_(Canadian_Aboriginal_Syllabics)': 14,\n 'Braille': 26,\n 'Burmese_(Myanmar)': 34,\n 'Cyrillic': 33,\n 'Early_Aramaic': 22,\n 'Futurama': 26,\n 'Grantha': 43,\n 'Greek': 24,\n 'Gujarati': 48,\n 'Hebrew': 22,\n 'Inuktitut_(Canadian_Aboriginal_Syllabics)': 16,\n 'Japanese_(hiragana)': 52,\n 'Japanese_(katakana)': 47,\n 'Korean': 40,\n 'Latin': 26,\n 'Malay_(Jawi_-_Arabic)': 40,\n 'Mkhedruli_(Georgian)': 41,\n 'N_Ko': 33,\n 'Ojibwe_(Canadian_Aboriginal_Syllabics)': 14,\n 'Sanskrit': 42,\n 'Syriac_(Estrangelo)': 23,\n 'Tagalog': 17,\n 'Tifinagh': 55}\n",[5246],{"type":24,"tag":3495,"props":5247,"children":5248},{"__ignoreMap":10},[5249],{"type":34,"value":5244},{"type":24,"tag":46,"props":5251,"children":5252},{},[5253],{"type":34,"value":5254},"And finally let's shuffle the alphabets and split among the Meta-sets!",{"type":24,"tag":3511,"props":5256,"children":5258},{"code":5257,"language":3514,"meta":10,"className":3515},"random.shuffle(alphabets)\n",[5259],{"type":24,"tag":3495,"props":5260,"children":5261},{"__ignoreMap":10},[5262],{"type":24,"tag":2279,"props":5263,"children":5264},{"class":3522,"line":3523},[5265],{"type":24,"tag":2279,"props":5266,"children":5267},{"class":3533},[5268],{"type":34,"value":5269},"random.shuffle(alphabets)",{"type":24,"tag":46,"props":5271,"children":5272},{},[5273],{"type":34,"value":5274},"As said, we will take each alphabet and add it to its corresponding Meta-set. To do so, we will begin with a given Meta-set (in our case the order is Meta-train, Meta-validation and Meta-test) and check if its internal number of characters has reached its minimum value so in case it does we will switch to the next Meta-set. In any case we will add the current alphabet to the current Meta-set and update the number of characters.",{"type":24,"tag":3511,"props":5276,"children":5278},{"code":5277,"language":3514,"meta":10,"className":3515},"current_metasplit = 'metatrain'\nswitch_metasplit_from = {'metatrain': 'metaval', 'metaval': 'metatest'}\n\nfor alphabet in alphabets:\n  if not metasplits[current_metasplit].num_characters \u003C metasplits[current_metasplit].min_num_characters:\n    current_metasplit = switch_metasplit_from[current_metasplit]\n  metasplits[current_metasplit].alphabets.append(alphabet)\n  metasplits[current_metasplit].num_characters += chars_per_alphabet[alphabet]\n\n",[5279],{"type":24,"tag":3495,"props":5280,"children":5281},{"__ignoreMap":10},[5282,5303,5353,5359,5380,5416,5433,5441],{"type":24,"tag":2279,"props":5283,"children":5284},{"class":3522,"line":3523},[5285,5290,5294,5298],{"type":24,"tag":2279,"props":5286,"children":5287},{"class":3533},[5288],{"type":34,"value":5289},"current_metasplit ",{"type":24,"tag":2279,"props":5291,"children":5292},{"class":3527},[5293],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5295,"children":5296},{"class":3533},[5297],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5299,"children":5300},{"class":3557},[5301],{"type":34,"value":5302},"'metatrain'\n",{"type":24,"tag":2279,"props":5304,"children":5305},{"class":3522,"line":2808},[5306,5311,5315,5319,5323,5328,5332,5336,5340,5344,5348],{"type":24,"tag":2279,"props":5307,"children":5308},{"class":3533},[5309],{"type":34,"value":5310},"switch_metasplit_from ",{"type":24,"tag":2279,"props":5312,"children":5313},{"class":3527},[5314],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5316,"children":5317},{"class":3533},[5318],{"type":34,"value":4983},{"type":24,"tag":2279,"props":5320,"children":5321},{"class":3557},[5322],{"type":34,"value":4988},{"type":24,"tag":2279,"props":5324,"children":5325},{"class":3533},[5326],{"type":34,"value":5327},": ",{"type":24,"tag":2279,"props":5329,"children":5330},{"class":3557},[5331],{"type":34,"value":5016},{"type":24,"tag":2279,"props":5333,"children":5334},{"class":3533},[5335],{"type":34,"value":1340},{"type":24,"tag":2279,"props":5337,"children":5338},{"class":3557},[5339],{"type":34,"value":5016},{"type":24,"tag":2279,"props":5341,"children":5342},{"class":3533},[5343],{"type":34,"value":5327},{"type":24,"tag":2279,"props":5345,"children":5346},{"class":3557},[5347],{"type":34,"value":5041},{"type":24,"tag":2279,"props":5349,"children":5350},{"class":3533},[5351],{"type":34,"value":5352},"}\n",{"type":24,"tag":2279,"props":5354,"children":5355},{"class":3522,"line":2817},[5356],{"type":24,"tag":2279,"props":5357,"children":5358},{},[],{"type":24,"tag":2279,"props":5360,"children":5361},{"class":3522,"line":3577},[5362,5366,5371,5375],{"type":24,"tag":2279,"props":5363,"children":5364},{"class":3527},[5365],{"type":34,"value":4181},{"type":24,"tag":2279,"props":5367,"children":5368},{"class":3533},[5369],{"type":34,"value":5370}," alphabet ",{"type":24,"tag":2279,"props":5372,"children":5373},{"class":3527},[5374],{"type":34,"value":4191},{"type":24,"tag":2279,"props":5376,"children":5377},{"class":3533},[5378],{"type":34,"value":5379}," alphabets:\n",{"type":24,"tag":2279,"props":5381,"children":5382},{"class":3522,"line":3725},[5383,5387,5392,5396,5401,5406,5411],{"type":24,"tag":2279,"props":5384,"children":5385},{"class":3533},[5386],{"type":34,"value":4817},{"type":24,"tag":2279,"props":5388,"children":5389},{"class":3527},[5390],{"type":34,"value":5391},"if",{"type":24,"tag":2279,"props":5393,"children":5394},{"class":3533},[5395],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5397,"children":5398},{"class":3527},[5399],{"type":34,"value":5400},"not",{"type":24,"tag":2279,"props":5402,"children":5403},{"class":3533},[5404],{"type":34,"value":5405}," metasplits[current_metasplit].num_characters ",{"type":24,"tag":2279,"props":5407,"children":5408},{"class":3527},[5409],{"type":34,"value":5410},"\u003C",{"type":24,"tag":2279,"props":5412,"children":5413},{"class":3533},[5414],{"type":34,"value":5415}," metasplits[current_metasplit].min_num_characters:\n",{"type":24,"tag":2279,"props":5417,"children":5418},{"class":3522,"line":3747},[5419,5424,5428],{"type":24,"tag":2279,"props":5420,"children":5421},{"class":3533},[5422],{"type":34,"value":5423},"    current_metasplit ",{"type":24,"tag":2279,"props":5425,"children":5426},{"class":3527},[5427],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5429,"children":5430},{"class":3533},[5431],{"type":34,"value":5432}," switch_metasplit_from[current_metasplit]\n",{"type":24,"tag":2279,"props":5434,"children":5435},{"class":3522,"line":3769},[5436],{"type":24,"tag":2279,"props":5437,"children":5438},{"class":3533},[5439],{"type":34,"value":5440},"  metasplits[current_metasplit].alphabets.append(alphabet)\n",{"type":24,"tag":2279,"props":5442,"children":5443},{"class":3522,"line":3782},[5444,5449,5454],{"type":24,"tag":2279,"props":5445,"children":5446},{"class":3533},[5447],{"type":34,"value":5448},"  metasplits[current_metasplit].num_characters ",{"type":24,"tag":2279,"props":5450,"children":5451},{"class":3527},[5452],{"type":34,"value":5453},"+=",{"type":24,"tag":2279,"props":5455,"children":5456},{"class":3533},[5457],{"type":34,"value":5458}," chars_per_alphabet[alphabet]",{"type":24,"tag":46,"props":5460,"children":5461},{},[5462],{"type":34,"value":5463},"We still have to compute the number of problems of each Meta-set, which depends on its alphabets (and the number of characters in each of these alphabets).",{"type":24,"tag":46,"props":5465,"children":5466},{},[5467],{"type":34,"value":5468},"I developed a formula to compute this which goes as follows:",{"type":24,"tag":729,"props":5470,"children":5471},{},[5472,5489,5494,5499,5504],{"type":24,"tag":733,"props":5473,"children":5474},{},[5475,5477,5481,5483,5487],{"type":34,"value":5476},"As each problem's characters must be of the same alphabet, we can not group all characters in a single pool. Instead, we will compute it alphabet-wise and sum for all its alphabets. If we call $P$ the number of problems, $ P = \\sum_{\\alpha \\in MS}{P_{\\alpha}}$, where $P_{\\alpha}$ is the number of problems in the alphabet $\\alpha$ and $MS$ is the Meta-set (so the number of problems is the sum of the number of problems in each alphabet). This information is available right now (in the ",{"type":24,"tag":800,"props":5478,"children":5479},{},[5480],{"type":34,"value":4778},{"type":34,"value":5482}," objects and the ",{"type":24,"tag":800,"props":5484,"children":5485},{},[5486],{"type":34,"value":5241},{"type":34,"value":5488}," variable).",{"type":24,"tag":733,"props":5490,"children":5491},{},[5492],{"type":34,"value":5493},"The number of problems in an alphabet is the number of possible combinations of two characters among all belonging to the alphabet. From statistical theory, that is a Combination without repetition with combinations of 2, i.e. if $C_{\\alpha}$ is the number of characters in the alphabet $\\alpha$, ${C_{\\alpha} \\choose 2}$. We also know that ${m \\choose n}$ is computed as $\\frac{m!}{n! (m - n)!}$, so in our case ${C_{\\alpha} \\choose 2} = \\frac{C_{\\alpha}!}{2! (C_{\\alpha} - 2)!}$.",{"type":24,"tag":733,"props":5495,"children":5496},{},[5497],{"type":34,"value":5498},"We know that $2! = 2$. We also know that $\\frac{C_{\\alpha}!}{(C_{\\alpha} - 2)!} = \\frac{\\prod_{1}^{C_{\\alpha}}{i}}{\\prod_{1}^{C_{\\alpha} - 2}{j}} = \\frac{\\prod_{1}^{C_{\\alpha} - 2}{i} \\prod_{C_{\\alpha} - 1}^{C_{\\alpha}}{i}}{\\prod_{1}^{C_{\\alpha} - 2}{j}} = \\frac{\\prod_{1}^{C_{\\alpha} - 2}{i}}{\\prod_{1}^{C_{\\alpha} - 2}{j}} \\prod_{C_{\\alpha} - 1}^{C_{\\alpha}}{i} = 1 * \\prod_{C_{\\alpha} - 1}^{C_{\\alpha}}{i} = (C_{\\alpha}) * (C_{\\alpha} - 1) = C_{\\alpha}^2 - C_{\\alpha}$.",{"type":24,"tag":733,"props":5500,"children":5501},{},[5502],{"type":34,"value":5503},"So $P_{\\alpha} = {C_{\\alpha} \\choose 2} = \\frac{C_{\\alpha}!}{2! (C_{\\alpha} - 2)!} = \\frac{1}{2!} * \\frac{C_{\\alpha}!}{(C_{\\alpha} - 2)!} = \\frac{1}{2} * (C_{\\alpha}^2 - C_{\\alpha}) = \\frac{C_{\\alpha}^2 - C_{\\alpha}}{2}$.",{"type":24,"tag":733,"props":5505,"children":5506},{},[5507],{"type":34,"value":5508},"Thus, $P = \\sum_{\\alpha \\in MS}{P_{\\alpha}} = \\sum_{\\alpha \\in MS}{\\frac{C_{\\alpha}^2 - C_{\\alpha}}{2}} = \\frac{1}{2} \\sum_{\\alpha \\in MS}{C_{\\alpha}^2 - C_{\\alpha}}$.",{"type":24,"tag":46,"props":5510,"children":5511},{},[5512],{"type":34,"value":5513},"So finally:",{"type":24,"tag":46,"props":5515,"children":5516},{},[5517],{"type":34,"value":5518},"$P = \\frac{\\sum_{\\alpha \\in MS}{C_{\\alpha}^2 - C_{\\alpha}}}{2}$",{"type":24,"tag":3511,"props":5520,"children":5522},{"code":5521,"language":3514,"meta":10,"className":3515},"for metasplit in metasplits:\n  metasplits[metasplit].num_problems = 1/2 * sum([chars_per_alphabet[alph]**2 - chars_per_alphabet[alph] for alph in metasplits[metasplit].alphabets])\n",[5523],{"type":24,"tag":3495,"props":5524,"children":5525},{"__ignoreMap":10},[5526,5547],{"type":24,"tag":2279,"props":5527,"children":5528},{"class":3522,"line":3523},[5529,5533,5538,5542],{"type":24,"tag":2279,"props":5530,"children":5531},{"class":3527},[5532],{"type":34,"value":4181},{"type":24,"tag":2279,"props":5534,"children":5535},{"class":3533},[5536],{"type":34,"value":5537}," metasplit ",{"type":24,"tag":2279,"props":5539,"children":5540},{"class":3527},[5541],{"type":34,"value":4191},{"type":24,"tag":2279,"props":5543,"children":5544},{"class":3533},[5545],{"type":34,"value":5546}," metasplits:\n",{"type":24,"tag":2279,"props":5548,"children":5549},{"class":3522,"line":2808},[5550,5555,5559,5563,5567,5571,5575,5579,5583,5587,5592,5597,5602,5606,5610,5614,5619,5623,5627,5631],{"type":24,"tag":2279,"props":5551,"children":5552},{"class":3533},[5553],{"type":34,"value":5554},"  metasplits[metasplit].num_problems ",{"type":24,"tag":2279,"props":5556,"children":5557},{"class":3527},[5558],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5560,"children":5561},{"class":3533},[5562],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5564,"children":5565},{"class":3908},[5566],{"type":34,"value":2283},{"type":24,"tag":2279,"props":5568,"children":5569},{"class":3527},[5570],{"type":34,"value":3593},{"type":24,"tag":2279,"props":5572,"children":5573},{"class":3908},[5574],{"type":34,"value":2308},{"type":24,"tag":2279,"props":5576,"children":5577},{"class":3533},[5578],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5580,"children":5581},{"class":3527},[5582],{"type":34,"value":4248},{"type":24,"tag":2279,"props":5584,"children":5585},{"class":3533},[5586],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5588,"children":5589},{"class":3908},[5590],{"type":34,"value":5591},"sum",{"type":24,"tag":2279,"props":5593,"children":5594},{"class":3533},[5595],{"type":34,"value":5596},"([chars_per_alphabet[alph]",{"type":24,"tag":2279,"props":5598,"children":5599},{"class":3527},[5600],{"type":34,"value":5601},"**",{"type":24,"tag":2279,"props":5603,"children":5604},{"class":3908},[5605],{"type":34,"value":2308},{"type":24,"tag":2279,"props":5607,"children":5608},{"class":3533},[5609],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5611,"children":5612},{"class":3527},[5613],{"type":34,"value":3630},{"type":24,"tag":2279,"props":5615,"children":5616},{"class":3533},[5617],{"type":34,"value":5618}," chars_per_alphabet[alph] ",{"type":24,"tag":2279,"props":5620,"children":5621},{"class":3527},[5622],{"type":34,"value":4181},{"type":24,"tag":2279,"props":5624,"children":5625},{"class":3533},[5626],{"type":34,"value":5217},{"type":24,"tag":2279,"props":5628,"children":5629},{"class":3527},[5630],{"type":34,"value":4191},{"type":24,"tag":2279,"props":5632,"children":5633},{"class":3533},[5634],{"type":34,"value":5635}," metasplits[metasplit].alphabets])",{"type":24,"tag":46,"props":5637,"children":5638},{},[5639],{"type":34,"value":5640},"Also recall that problems act as samples at the Meta-level, so we may count the number of metabatches with thios information if we know the metabatch size.",{"type":24,"tag":3511,"props":5642,"children":5644},{"code":5643,"language":3514,"meta":10,"className":3515},"metabatch_size = 8\nnum_metabatches = int(metasplits['metatrain'].num_problems / metabatch_size)\n",[5645],{"type":24,"tag":3495,"props":5646,"children":5647},{"__ignoreMap":10},[5648,5669],{"type":24,"tag":2279,"props":5649,"children":5650},{"class":3522,"line":3523},[5651,5656,5660,5664],{"type":24,"tag":2279,"props":5652,"children":5653},{"class":3533},[5654],{"type":34,"value":5655},"metabatch_size ",{"type":24,"tag":2279,"props":5657,"children":5658},{"class":3527},[5659],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5661,"children":5662},{"class":3533},[5663],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5665,"children":5666},{"class":3908},[5667],{"type":34,"value":5668},"8\n",{"type":24,"tag":2279,"props":5670,"children":5671},{"class":3522,"line":2808},[5672,5677,5681,5685,5690,5695,5699,5704,5708],{"type":24,"tag":2279,"props":5673,"children":5674},{"class":3533},[5675],{"type":34,"value":5676},"num_metabatches ",{"type":24,"tag":2279,"props":5678,"children":5679},{"class":3527},[5680],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5682,"children":5683},{"class":3533},[5684],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5686,"children":5687},{"class":3908},[5688],{"type":34,"value":5689},"int",{"type":24,"tag":2279,"props":5691,"children":5692},{"class":3533},[5693],{"type":34,"value":5694},"(metasplits[",{"type":24,"tag":2279,"props":5696,"children":5697},{"class":3557},[5698],{"type":34,"value":4988},{"type":24,"tag":2279,"props":5700,"children":5701},{"class":3533},[5702],{"type":34,"value":5703},"].num_problems ",{"type":24,"tag":2279,"props":5705,"children":5706},{"class":3527},[5707],{"type":34,"value":3593},{"type":24,"tag":2279,"props":5709,"children":5710},{"class":3533},[5711],{"type":34,"value":5712}," metabatch_size)",{"type":24,"tag":3511,"props":5714,"children":5716},{"code":5715,"language":3514,"meta":10,"className":3515},"num_metabatches\n",[5717],{"type":24,"tag":3495,"props":5718,"children":5719},{"__ignoreMap":10},[5720],{"type":24,"tag":2279,"props":5721,"children":5722},{"class":3522,"line":3523},[5723],{"type":24,"tag":2279,"props":5724,"children":5725},{"class":3533},[5726],{"type":34,"value":5727},"num_metabatches",{"type":24,"tag":3511,"props":5729,"children":5731},{"code":5730},"1495\n",[5732],{"type":24,"tag":3495,"props":5733,"children":5734},{"__ignoreMap":10},[5735],{"type":34,"value":5730},{"type":24,"tag":1378,"props":5737,"children":5739},{"id":5738},"the-meta-level-dataloader",[5740],{"type":34,"value":5741},"The Meta-level DataLoader",{"type":24,"tag":46,"props":5743,"children":5744},{},[5745,5747,5752],{"type":34,"value":5746},"As we need to define DataLoaders when training a problem, which will generate the batches (samples + labels at each batch), at the Meta-level we will need an object that generates the meta-batches (problems at each meta-batch). We will call this the ",{"type":24,"tag":800,"props":5748,"children":5749},{},[5750],{"type":34,"value":5751},"MetaLoader",{"type":34,"value":170},{"type":24,"tag":46,"props":5754,"children":5755},{},[5756],{"type":34,"value":5757},"This Meta-Loader should give the tools to generate a DataLoader for each of its problems.",{"type":24,"tag":46,"props":5759,"children":5760},{},[5761],{"type":34,"value":5762},"So at this point let's explore the needs to create a problem DataLoader in our context. First, we need to define which will be the alphabet we will be working on. For simplicity, we will use the Latin alphabet as toy example. We will take all the characters of this alphabet from the list.",{"type":24,"tag":3511,"props":5764,"children":5766},{"code":5765,"language":3514,"meta":10,"className":3515},"toy_alphabet = 'Latin'\ntoy_characters = [char for char in characters if char.split('/')[0] == toy_alphabet]\n",[5767],{"type":24,"tag":3495,"props":5768,"children":5769},{"__ignoreMap":10},[5770,5791],{"type":24,"tag":2279,"props":5771,"children":5772},{"class":3522,"line":3523},[5773,5778,5782,5786],{"type":24,"tag":2279,"props":5774,"children":5775},{"class":3533},[5776],{"type":34,"value":5777},"toy_alphabet ",{"type":24,"tag":2279,"props":5779,"children":5780},{"class":3527},[5781],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5783,"children":5784},{"class":3533},[5785],{"type":34,"value":2285},{"type":24,"tag":2279,"props":5787,"children":5788},{"class":3557},[5789],{"type":34,"value":5790},"'Latin'\n",{"type":24,"tag":2279,"props":5792,"children":5793},{"class":3522,"line":2808},[5794,5799,5803,5808,5812,5816,5820,5825,5829,5834,5838,5842,5846,5850,5855],{"type":24,"tag":2279,"props":5795,"children":5796},{"class":3533},[5797],{"type":34,"value":5798},"toy_characters ",{"type":24,"tag":2279,"props":5800,"children":5801},{"class":3527},[5802],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5804,"children":5805},{"class":3533},[5806],{"type":34,"value":5807}," [char ",{"type":24,"tag":2279,"props":5809,"children":5810},{"class":3527},[5811],{"type":34,"value":4181},{"type":24,"tag":2279,"props":5813,"children":5814},{"class":3533},[5815],{"type":34,"value":5199},{"type":24,"tag":2279,"props":5817,"children":5818},{"class":3527},[5819],{"type":34,"value":4191},{"type":24,"tag":2279,"props":5821,"children":5822},{"class":3533},[5823],{"type":34,"value":5824}," characters ",{"type":24,"tag":2279,"props":5826,"children":5827},{"class":3527},[5828],{"type":34,"value":5391},{"type":24,"tag":2279,"props":5830,"children":5831},{"class":3533},[5832],{"type":34,"value":5833}," char.split(",{"type":24,"tag":2279,"props":5835,"children":5836},{"class":3557},[5837],{"type":34,"value":5177},{"type":24,"tag":2279,"props":5839,"children":5840},{"class":3533},[5841],{"type":34,"value":5182},{"type":24,"tag":2279,"props":5843,"children":5844},{"class":3908},[5845],{"type":34,"value":4023},{"type":24,"tag":2279,"props":5847,"children":5848},{"class":3533},[5849],{"type":34,"value":4176},{"type":24,"tag":2279,"props":5851,"children":5852},{"class":3527},[5853],{"type":34,"value":5854},"==",{"type":24,"tag":2279,"props":5856,"children":5857},{"class":3533},[5858],{"type":34,"value":5859}," toy_alphabet]",{"type":24,"tag":46,"props":5861,"children":5862},{},[5863],{"type":34,"value":5864},"Now let's randomly pick 2 characters within the list.",{"type":24,"tag":3511,"props":5866,"children":5868},{"code":5867,"language":3514,"meta":10,"className":3515},"toy_problem_characters = random.sample(toy_characters, 2)\n",[5869],{"type":24,"tag":3495,"props":5870,"children":5871},{"__ignoreMap":10},[5872],{"type":24,"tag":2279,"props":5873,"children":5874},{"class":3522,"line":3523},[5875,5880,5884,5889,5893],{"type":24,"tag":2279,"props":5876,"children":5877},{"class":3533},[5878],{"type":34,"value":5879},"toy_problem_characters ",{"type":24,"tag":2279,"props":5881,"children":5882},{"class":3527},[5883],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5885,"children":5886},{"class":3533},[5887],{"type":34,"value":5888}," random.sample(toy_characters, ",{"type":24,"tag":2279,"props":5890,"children":5891},{"class":3908},[5892],{"type":34,"value":2308},{"type":24,"tag":2279,"props":5894,"children":5895},{"class":3533},[5896],{"type":34,"value":3937},{"type":24,"tag":3511,"props":5898,"children":5900},{"code":5899,"language":3514,"meta":10,"className":3515},"toy_problem_characters\n",[5901],{"type":24,"tag":3495,"props":5902,"children":5903},{"__ignoreMap":10},[5904],{"type":24,"tag":2279,"props":5905,"children":5906},{"class":3522,"line":3523},[5907],{"type":24,"tag":2279,"props":5908,"children":5909},{"class":3533},[5910],{"type":34,"value":5911},"toy_problem_characters",{"type":24,"tag":3511,"props":5913,"children":5915},{"code":5914},"['Latin/character10', 'Latin/character11']\n",[5916],{"type":24,"tag":3495,"props":5917,"children":5918},{"__ignoreMap":10},[5919],{"type":34,"value":5914},{"type":24,"tag":46,"props":5921,"children":5922},{},[5923,5925,5930,5931,5936],{"type":34,"value":5924},"We picked both the 10th and the 11th characters from the Latin alphabet. These are ",{"type":24,"tag":800,"props":5926,"children":5927},{},[5928],{"type":34,"value":5929},"J",{"type":34,"value":422},{"type":24,"tag":800,"props":5932,"children":5933},{},[5934],{"type":34,"value":5935},"K",{"type":34,"value":5937}," (count it if you wish to). Let's continue to see if this matches.",{"type":24,"tag":46,"props":5939,"children":5940},{},[5941],{"type":34,"value":5942},"Now we want to get which samples in the dataset correspond to this character. Recall that in torchvision's Omniglot, samples are sequential with 20 samples per character, so we aim to get the position of the characters in the list of characters and therefore the position of its samples in the dataset. This last value corresponds to the range of values between the character position (in the whole list) multiplied by 20 and the character position +1 multiplied by 20 (the beginning of the following character range). We want a flattened list of these sample indices for both characters in the problem.",{"type":24,"tag":3511,"props":5944,"children":5946},{"code":5945,"language":3514,"meta":10,"className":3515},"toy_problem_char_idx = [characters.index(tchar) for tchar in toy_problem_characters]  #  position of the characters in the list of characters\ntoy_problem_samples_idx = [toy_sample_range for tcharidx in toy_problem_char_idx for toy_sample_range in range(tcharidx * 20, (tcharidx + 1) * 20)]\n",[5947],{"type":24,"tag":3495,"props":5948,"children":5949},{"__ignoreMap":10},[5950,5990],{"type":24,"tag":2279,"props":5951,"children":5952},{"class":3522,"line":3523},[5953,5958,5962,5967,5971,5976,5980,5985],{"type":24,"tag":2279,"props":5954,"children":5955},{"class":3533},[5956],{"type":34,"value":5957},"toy_problem_char_idx ",{"type":24,"tag":2279,"props":5959,"children":5960},{"class":3527},[5961],{"type":34,"value":3866},{"type":24,"tag":2279,"props":5963,"children":5964},{"class":3533},[5965],{"type":34,"value":5966}," [characters.index(tchar) ",{"type":24,"tag":2279,"props":5968,"children":5969},{"class":3527},[5970],{"type":34,"value":4181},{"type":24,"tag":2279,"props":5972,"children":5973},{"class":3533},[5974],{"type":34,"value":5975}," tchar ",{"type":24,"tag":2279,"props":5977,"children":5978},{"class":3527},[5979],{"type":34,"value":4191},{"type":24,"tag":2279,"props":5981,"children":5982},{"class":3533},[5983],{"type":34,"value":5984}," toy_problem_characters]  ",{"type":24,"tag":2279,"props":5986,"children":5987},{"class":3571},[5988],{"type":34,"value":5989},"#  position of the characters in the list of characters\n",{"type":24,"tag":2279,"props":5991,"children":5992},{"class":3522,"line":2808},[5993,5998,6002,6007,6011,6016,6020,6025,6029,6034,6038,6042,6046,6051,6055,6059,6063,6068,6073,6077,6081,6086,6090,6094,6098],{"type":24,"tag":2279,"props":5994,"children":5995},{"class":3533},[5996],{"type":34,"value":5997},"toy_problem_samples_idx ",{"type":24,"tag":2279,"props":5999,"children":6000},{"class":3527},[6001],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6003,"children":6004},{"class":3533},[6005],{"type":34,"value":6006}," [toy_sample_range ",{"type":24,"tag":2279,"props":6008,"children":6009},{"class":3527},[6010],{"type":34,"value":4181},{"type":24,"tag":2279,"props":6012,"children":6013},{"class":3533},[6014],{"type":34,"value":6015}," tcharidx ",{"type":24,"tag":2279,"props":6017,"children":6018},{"class":3527},[6019],{"type":34,"value":4191},{"type":24,"tag":2279,"props":6021,"children":6022},{"class":3533},[6023],{"type":34,"value":6024}," toy_problem_char_idx ",{"type":24,"tag":2279,"props":6026,"children":6027},{"class":3527},[6028],{"type":34,"value":4181},{"type":24,"tag":2279,"props":6030,"children":6031},{"class":3533},[6032],{"type":34,"value":6033}," toy_sample_range ",{"type":24,"tag":2279,"props":6035,"children":6036},{"class":3527},[6037],{"type":34,"value":4191},{"type":24,"tag":2279,"props":6039,"children":6040},{"class":3533},[6041],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6043,"children":6044},{"class":3908},[6045],{"type":34,"value":4200},{"type":24,"tag":2279,"props":6047,"children":6048},{"class":3533},[6049],{"type":34,"value":6050},"(tcharidx ",{"type":24,"tag":2279,"props":6052,"children":6053},{"class":3527},[6054],{"type":34,"value":4248},{"type":24,"tag":2279,"props":6056,"children":6057},{"class":3533},[6058],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6060,"children":6061},{"class":3908},[6062],{"type":34,"value":2725},{"type":24,"tag":2279,"props":6064,"children":6065},{"class":3533},[6066],{"type":34,"value":6067},", (tcharidx ",{"type":24,"tag":2279,"props":6069,"children":6070},{"class":3527},[6071],{"type":34,"value":6072},"+",{"type":24,"tag":2279,"props":6074,"children":6075},{"class":3533},[6076],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6078,"children":6079},{"class":3908},[6080],{"type":34,"value":2283},{"type":24,"tag":2279,"props":6082,"children":6083},{"class":3533},[6084],{"type":34,"value":6085},") ",{"type":24,"tag":2279,"props":6087,"children":6088},{"class":3527},[6089],{"type":34,"value":4248},{"type":24,"tag":2279,"props":6091,"children":6092},{"class":3533},[6093],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6095,"children":6096},{"class":3908},[6097],{"type":34,"value":2725},{"type":24,"tag":2279,"props":6099,"children":6100},{"class":3533},[6101],{"type":34,"value":4215},{"type":24,"tag":3511,"props":6103,"children":6105},{"code":6104,"language":3514,"meta":10,"className":3515},"toy_problem_samples_idx\n",[6106],{"type":24,"tag":3495,"props":6107,"children":6108},{"__ignoreMap":10},[6109],{"type":24,"tag":2279,"props":6110,"children":6111},{"class":3522,"line":3523},[6112],{"type":24,"tag":2279,"props":6113,"children":6114},{"class":3533},[6115],{"type":34,"value":6116},"toy_problem_samples_idx",{"type":24,"tag":3511,"props":6118,"children":6120},{"code":6119},"[13640,\n 13641,\n 13642,\n 13643,\n 13644,\n 13645,\n 13646,\n 13647,\n 13648,\n 13649,\n 13650,\n 13651,\n 13652,\n 13653,\n 13654,\n 13655,\n 13656,\n 13657,\n 13658,\n 13659,\n 13660,\n 13661,\n 13662,\n 13663,\n 13664,\n 13665,\n 13666,\n 13667,\n 13668,\n 13669,\n 13670,\n 13671,\n 13672,\n 13673,\n 13674,\n 13675,\n 13676,\n 13677,\n 13678,\n 13679]\n",[6121],{"type":24,"tag":3495,"props":6122,"children":6123},{"__ignoreMap":10},[6124],{"type":34,"value":6119},{"type":24,"tag":3511,"props":6126,"children":6128},{"code":6127,"language":3514,"meta":10,"className":3515},"len(toy_problem_samples_idx)\n",[6129],{"type":24,"tag":3495,"props":6130,"children":6131},{"__ignoreMap":10},[6132],{"type":24,"tag":2279,"props":6133,"children":6134},{"class":3522,"line":3523},[6135,6139],{"type":24,"tag":2279,"props":6136,"children":6137},{"class":3908},[6138],{"type":34,"value":4409},{"type":24,"tag":2279,"props":6140,"children":6141},{"class":3533},[6142],{"type":34,"value":6143},"(toy_problem_samples_idx)",{"type":24,"tag":3511,"props":6145,"children":6147},{"code":6146},"40\n",[6148],{"type":24,"tag":3495,"props":6149,"children":6150},{"__ignoreMap":10},[6151],{"type":34,"value":6146},{"type":24,"tag":46,"props":6153,"children":6154},{},[6155],{"type":34,"value":6156},"This length makes sense since we have 2 characters with 20 samples each.",{"type":24,"tag":46,"props":6158,"children":6159},{},[6160,6162,6169,6171,6178],{"type":34,"value":6161},"Now we need to explicitly tell the dataloader to take among these samples. The problem is that the Omniglot dataset from torchvision cannot be split as far as we know. Instead, we may make use of the torch's ",{"type":24,"tag":59,"props":6163,"children":6166},{"href":6164,"rel":6165},"https://pytorch.org/docs/stable/data.html#torch.utils.data.SubsetRandomSampler",[63],[6167],{"type":34,"value":6168},"SubsetRandomSampler object",{"type":34,"value":6170},", which explicitly tells which samples to randomly take. Furthermore, we want these samples to be taken by batches, so we will also wrap it into a ",{"type":24,"tag":59,"props":6172,"children":6175},{"href":6173,"rel":6174},"https://pytorch.org/docs/stable/data.html#torch.utils.data.BatchSampler",[63],[6176],{"type":34,"value":6177},"BatchSampler",{"type":34,"value":170},{"type":24,"tag":3511,"props":6180,"children":6182},{"code":6181,"language":3514,"meta":10,"className":3515},"indexer = BatchSampler(SubsetRandomSampler(toy_problem_samples_idx), batch_size=8, drop_last=True)\n",[6183],{"type":24,"tag":3495,"props":6184,"children":6185},{"__ignoreMap":10},[6186],{"type":24,"tag":2279,"props":6187,"children":6188},{"class":3522,"line":3523},[6189,6194,6198,6203,6207,6211,6215,6219,6224,6228,6232],{"type":24,"tag":2279,"props":6190,"children":6191},{"class":3533},[6192],{"type":34,"value":6193},"indexer ",{"type":24,"tag":2279,"props":6195,"children":6196},{"class":3527},[6197],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6199,"children":6200},{"class":3533},[6201],{"type":34,"value":6202}," BatchSampler(SubsetRandomSampler(toy_problem_samples_idx), ",{"type":24,"tag":2279,"props":6204,"children":6205},{"class":3882},[6206],{"type":34,"value":4496},{"type":24,"tag":2279,"props":6208,"children":6209},{"class":3527},[6210],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6212,"children":6213},{"class":3908},[6214],{"type":34,"value":2447},{"type":24,"tag":2279,"props":6216,"children":6217},{"class":3533},[6218],{"type":34,"value":1340},{"type":24,"tag":2279,"props":6220,"children":6221},{"class":3882},[6222],{"type":34,"value":6223},"drop_last",{"type":24,"tag":2279,"props":6225,"children":6226},{"class":3527},[6227],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6229,"children":6230},{"class":3908},[6231],{"type":34,"value":3911},{"type":24,"tag":2279,"props":6233,"children":6234},{"class":3533},[6235],{"type":34,"value":3937},{"type":24,"tag":46,"props":6237,"children":6238},{},[6239,6241,6246],{"type":34,"value":6240},"So now we may directly create a DataLoader with the raw Omniglot dataset using this sampler object that will directly serve us random batches of samples of the characters of our problems, as we want. We will use ",{"type":24,"tag":800,"props":6242,"children":6243},{},[6244],{"type":34,"value":6245},"shuffle=False",{"type":34,"value":6247}," since the sampler already shuffles the samples.",{"type":24,"tag":3511,"props":6249,"children":6251},{"code":6250,"language":3514,"meta":10,"className":3515},"problem_loader = DataLoader(dataset=omniglot_raw, shuffle=False, batch_sampler=indexer)\n",[6252],{"type":24,"tag":3495,"props":6253,"children":6254},{"__ignoreMap":10},[6255],{"type":24,"tag":2279,"props":6256,"children":6257},{"class":3522,"line":3523},[6258,6263,6267,6272,6276,6280,6285,6289,6293,6298,6302,6307,6311],{"type":24,"tag":2279,"props":6259,"children":6260},{"class":3533},[6261],{"type":34,"value":6262},"problem_loader ",{"type":24,"tag":2279,"props":6264,"children":6265},{"class":3527},[6266],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6268,"children":6269},{"class":3533},[6270],{"type":34,"value":6271}," DataLoader(",{"type":24,"tag":2279,"props":6273,"children":6274},{"class":3882},[6275],{"type":34,"value":3965},{"type":24,"tag":2279,"props":6277,"children":6278},{"class":3527},[6279],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6281,"children":6282},{"class":3533},[6283],{"type":34,"value":6284},"omniglot_raw, ",{"type":24,"tag":2279,"props":6286,"children":6287},{"class":3882},[6288],{"type":34,"value":4521},{"type":24,"tag":2279,"props":6290,"children":6291},{"class":3527},[6292],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6294,"children":6295},{"class":3908},[6296],{"type":34,"value":6297},"False",{"type":24,"tag":2279,"props":6299,"children":6300},{"class":3533},[6301],{"type":34,"value":1340},{"type":24,"tag":2279,"props":6303,"children":6304},{"class":3882},[6305],{"type":34,"value":6306},"batch_sampler",{"type":24,"tag":2279,"props":6308,"children":6309},{"class":3527},[6310],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6312,"children":6313},{"class":3533},[6314],{"type":34,"value":6315},"indexer)",{"type":24,"tag":46,"props":6317,"children":6318},{},[6319,6321,6326,6328,6332,6334,6338],{"type":34,"value":6320},"Now let's review both samples and labels from the Data Loader. We want to verify that samples are what we expect (shape of ",{"type":24,"tag":800,"props":6322,"children":6323},{},[6324],{"type":34,"value":6325},"batch_size x num_channels x width x height",{"type":34,"value":6327},", i.e. 8 x 1 x 105 x 105), that images correspond to ",{"type":24,"tag":800,"props":6329,"children":6330},{},[6331],{"type":34,"value":5929},{"type":34,"value":6333},"'s and ",{"type":24,"tag":800,"props":6335,"children":6336},{},[6337],{"type":34,"value":5935},{"type":34,"value":6339},"'s and that labels are randomly shuffled.",{"type":24,"tag":3511,"props":6341,"children":6343},{"code":6342,"language":3514,"meta":10,"className":3515},"for ibatch, batch in enumerate(problem_loader):\n  print('batch ' + str(ibatch))\n  print(len(batch))\n  print(batch[0].shape)\n  print(batch[1])\n",[6344],{"type":24,"tag":3495,"props":6345,"children":6346},{"__ignoreMap":10},[6347,6377,6419,6443,6468],{"type":24,"tag":2279,"props":6348,"children":6349},{"class":3522,"line":3523},[6350,6354,6359,6363,6367,6372],{"type":24,"tag":2279,"props":6351,"children":6352},{"class":3527},[6353],{"type":34,"value":4181},{"type":24,"tag":2279,"props":6355,"children":6356},{"class":3533},[6357],{"type":34,"value":6358}," ibatch, batch ",{"type":24,"tag":2279,"props":6360,"children":6361},{"class":3527},[6362],{"type":34,"value":4191},{"type":24,"tag":2279,"props":6364,"children":6365},{"class":3533},[6366],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6368,"children":6369},{"class":3908},[6370],{"type":34,"value":6371},"enumerate",{"type":24,"tag":2279,"props":6373,"children":6374},{"class":3533},[6375],{"type":34,"value":6376},"(problem_loader):\n",{"type":24,"tag":2279,"props":6378,"children":6379},{"class":3522,"line":2808},[6380,6384,6388,6392,6397,6401,6405,6409,6414],{"type":24,"tag":2279,"props":6381,"children":6382},{"class":3533},[6383],{"type":34,"value":4817},{"type":24,"tag":2279,"props":6385,"children":6386},{"class":3908},[6387],{"type":34,"value":5074},{"type":24,"tag":2279,"props":6389,"children":6390},{"class":3533},[6391],{"type":34,"value":4205},{"type":24,"tag":2279,"props":6393,"children":6394},{"class":3557},[6395],{"type":34,"value":6396},"'batch '",{"type":24,"tag":2279,"props":6398,"children":6399},{"class":3533},[6400],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6402,"children":6403},{"class":3527},[6404],{"type":34,"value":6072},{"type":24,"tag":2279,"props":6406,"children":6407},{"class":3533},[6408],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6410,"children":6411},{"class":3908},[6412],{"type":34,"value":6413},"str",{"type":24,"tag":2279,"props":6415,"children":6416},{"class":3533},[6417],{"type":34,"value":6418},"(ibatch))\n",{"type":24,"tag":2279,"props":6420,"children":6421},{"class":3522,"line":2817},[6422,6426,6430,6434,6438],{"type":24,"tag":2279,"props":6423,"children":6424},{"class":3533},[6425],{"type":34,"value":4817},{"type":24,"tag":2279,"props":6427,"children":6428},{"class":3908},[6429],{"type":34,"value":5074},{"type":24,"tag":2279,"props":6431,"children":6432},{"class":3533},[6433],{"type":34,"value":4205},{"type":24,"tag":2279,"props":6435,"children":6436},{"class":3908},[6437],{"type":34,"value":4409},{"type":24,"tag":2279,"props":6439,"children":6440},{"class":3533},[6441],{"type":34,"value":6442},"(batch))\n",{"type":24,"tag":2279,"props":6444,"children":6445},{"class":3522,"line":3577},[6446,6450,6454,6459,6463],{"type":24,"tag":2279,"props":6447,"children":6448},{"class":3533},[6449],{"type":34,"value":4817},{"type":24,"tag":2279,"props":6451,"children":6452},{"class":3908},[6453],{"type":34,"value":5074},{"type":24,"tag":2279,"props":6455,"children":6456},{"class":3533},[6457],{"type":34,"value":6458},"(batch[",{"type":24,"tag":2279,"props":6460,"children":6461},{"class":3908},[6462],{"type":34,"value":4023},{"type":24,"tag":2279,"props":6464,"children":6465},{"class":3533},[6466],{"type":34,"value":6467},"].shape)\n",{"type":24,"tag":2279,"props":6469,"children":6470},{"class":3522,"line":3725},[6471,6475,6479,6483,6487],{"type":24,"tag":2279,"props":6472,"children":6473},{"class":3533},[6474],{"type":34,"value":4817},{"type":24,"tag":2279,"props":6476,"children":6477},{"class":3908},[6478],{"type":34,"value":5074},{"type":24,"tag":2279,"props":6480,"children":6481},{"class":3533},[6482],{"type":34,"value":6458},{"type":24,"tag":2279,"props":6484,"children":6485},{"class":3908},[6486],{"type":34,"value":2283},{"type":24,"tag":2279,"props":6488,"children":6489},{"class":3533},[6490],{"type":34,"value":5088},{"type":24,"tag":3511,"props":6492,"children":6494},{"code":6493},"batch 0\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 683, 683, 682, 682, 683, 682, 682])\nbatch 1\n2\ntorch.Size([8, 1, 105, 105])\ntensor([683, 682, 683, 683, 682, 683, 683, 683])\nbatch 2\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 682, 683, 682, 682, 682, 683, 683])\nbatch 3\n2\ntorch.Size([8, 1, 105, 105])\ntensor([683, 683, 683, 682, 683, 683, 682, 682])\nbatch 4\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 683, 683, 682, 683, 682, 682, 682])\n",[6495],{"type":24,"tag":3495,"props":6496,"children":6497},{"__ignoreMap":10},[6498],{"type":34,"value":6493},{"type":24,"tag":3511,"props":6500,"children":6502},{"code":6501,"language":3514,"meta":10,"className":3515},"plt.figure(figsize=(15,15))\ncolumns = 8\nfor ibatch, batch in enumerate(problem_loader):\n  for isample, sample in enumerate(batch[0]):\n    plt.subplot(5, 8, (ibatch * 8) + isample + 1)\n    plt.imshow(sample[0].numpy())\n",[6503],{"type":24,"tag":3495,"props":6504,"children":6505},{"__ignoreMap":10},[6506,6545,6565,6592,6633,6700],{"type":24,"tag":2279,"props":6507,"children":6508},{"class":3522,"line":3523},[6509,6514,6519,6523,6527,6531,6536,6540],{"type":24,"tag":2279,"props":6510,"children":6511},{"class":3533},[6512],{"type":34,"value":6513},"plt.figure(",{"type":24,"tag":2279,"props":6515,"children":6516},{"class":3882},[6517],{"type":34,"value":6518},"figsize",{"type":24,"tag":2279,"props":6520,"children":6521},{"class":3527},[6522],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6524,"children":6525},{"class":3533},[6526],{"type":34,"value":4205},{"type":24,"tag":2279,"props":6528,"children":6529},{"class":3908},[6530],{"type":34,"value":2609},{"type":24,"tag":2279,"props":6532,"children":6533},{"class":3533},[6534],{"type":34,"value":6535},",",{"type":24,"tag":2279,"props":6537,"children":6538},{"class":3908},[6539],{"type":34,"value":2609},{"type":24,"tag":2279,"props":6541,"children":6542},{"class":3533},[6543],{"type":34,"value":6544},"))\n",{"type":24,"tag":2279,"props":6546,"children":6547},{"class":3522,"line":2808},[6548,6553,6557,6561],{"type":24,"tag":2279,"props":6549,"children":6550},{"class":3533},[6551],{"type":34,"value":6552},"columns ",{"type":24,"tag":2279,"props":6554,"children":6555},{"class":3527},[6556],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6558,"children":6559},{"class":3533},[6560],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6562,"children":6563},{"class":3908},[6564],{"type":34,"value":5668},{"type":24,"tag":2279,"props":6566,"children":6567},{"class":3522,"line":2817},[6568,6572,6576,6580,6584,6588],{"type":24,"tag":2279,"props":6569,"children":6570},{"class":3527},[6571],{"type":34,"value":4181},{"type":24,"tag":2279,"props":6573,"children":6574},{"class":3533},[6575],{"type":34,"value":6358},{"type":24,"tag":2279,"props":6577,"children":6578},{"class":3527},[6579],{"type":34,"value":4191},{"type":24,"tag":2279,"props":6581,"children":6582},{"class":3533},[6583],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6585,"children":6586},{"class":3908},[6587],{"type":34,"value":6371},{"type":24,"tag":2279,"props":6589,"children":6590},{"class":3533},[6591],{"type":34,"value":6376},{"type":24,"tag":2279,"props":6593,"children":6594},{"class":3522,"line":3577},[6595,6599,6603,6608,6612,6616,6620,6624,6628],{"type":24,"tag":2279,"props":6596,"children":6597},{"class":3533},[6598],{"type":34,"value":4817},{"type":24,"tag":2279,"props":6600,"children":6601},{"class":3527},[6602],{"type":34,"value":4181},{"type":24,"tag":2279,"props":6604,"children":6605},{"class":3533},[6606],{"type":34,"value":6607}," isample, sample ",{"type":24,"tag":2279,"props":6609,"children":6610},{"class":3527},[6611],{"type":34,"value":4191},{"type":24,"tag":2279,"props":6613,"children":6614},{"class":3533},[6615],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6617,"children":6618},{"class":3908},[6619],{"type":34,"value":6371},{"type":24,"tag":2279,"props":6621,"children":6622},{"class":3533},[6623],{"type":34,"value":6458},{"type":24,"tag":2279,"props":6625,"children":6626},{"class":3908},[6627],{"type":34,"value":4023},{"type":24,"tag":2279,"props":6629,"children":6630},{"class":3533},[6631],{"type":34,"value":6632},"]):\n",{"type":24,"tag":2279,"props":6634,"children":6635},{"class":3522,"line":3725},[6636,6641,6645,6649,6653,6658,6662,6666,6670,6674,6678,6683,6687,6691,6695],{"type":24,"tag":2279,"props":6637,"children":6638},{"class":3533},[6639],{"type":34,"value":6640},"    plt.subplot(",{"type":24,"tag":2279,"props":6642,"children":6643},{"class":3908},[6644],{"type":34,"value":2378},{"type":24,"tag":2279,"props":6646,"children":6647},{"class":3533},[6648],{"type":34,"value":1340},{"type":24,"tag":2279,"props":6650,"children":6651},{"class":3908},[6652],{"type":34,"value":2447},{"type":24,"tag":2279,"props":6654,"children":6655},{"class":3533},[6656],{"type":34,"value":6657},", (ibatch ",{"type":24,"tag":2279,"props":6659,"children":6660},{"class":3527},[6661],{"type":34,"value":4248},{"type":24,"tag":2279,"props":6663,"children":6664},{"class":3533},[6665],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6667,"children":6668},{"class":3908},[6669],{"type":34,"value":2447},{"type":24,"tag":2279,"props":6671,"children":6672},{"class":3533},[6673],{"type":34,"value":6085},{"type":24,"tag":2279,"props":6675,"children":6676},{"class":3527},[6677],{"type":34,"value":6072},{"type":24,"tag":2279,"props":6679,"children":6680},{"class":3533},[6681],{"type":34,"value":6682}," isample ",{"type":24,"tag":2279,"props":6684,"children":6685},{"class":3527},[6686],{"type":34,"value":6072},{"type":24,"tag":2279,"props":6688,"children":6689},{"class":3533},[6690],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6692,"children":6693},{"class":3908},[6694],{"type":34,"value":2283},{"type":24,"tag":2279,"props":6696,"children":6697},{"class":3533},[6698],{"type":34,"value":6699},")\n",{"type":24,"tag":2279,"props":6701,"children":6702},{"class":3522,"line":3747},[6703,6708,6712],{"type":24,"tag":2279,"props":6704,"children":6705},{"class":3533},[6706],{"type":34,"value":6707},"    plt.imshow(sample[",{"type":24,"tag":2279,"props":6709,"children":6710},{"class":3908},[6711],{"type":34,"value":4023},{"type":24,"tag":2279,"props":6713,"children":6714},{"class":3533},[6715],{"type":34,"value":4126},{"type":24,"tag":46,"props":6717,"children":6718},{},[6719],{"type":24,"tag":175,"props":6720,"children":6723},{"alt":6721,"src":6722},"problem","https://i.imgur.com/hTD81J1.png",[],{"type":24,"tag":46,"props":6725,"children":6726},{},[6727],{"type":34,"value":6728},"So as we see, everything matches our needs.",{"type":24,"tag":46,"props":6730,"children":6731},{},[6732],{"type":34,"value":6733},"Now that we defined a DataLoader for the problem, we are ready to create the Meta-Loaders.",{"type":24,"tag":46,"props":6735,"children":6736},{},[6737],{"type":34,"value":6738},"A Meta-Loader object should, at each step, be able to return a batch of problem DataLoaders. As we saw before, these DataLoaders should return at least the indices of the samples to use at each batch, and then at training/validation/test time the indices will point to the data to load from the Omniglot raw dataset. We could also work with DataLoaders that directly deliver the data, but since we would be creating lots of dataloaders with raw data, the memory cost could be too high. That is the main reason why we will work with indices instead.",{"type":24,"tag":46,"props":6740,"children":6741},{},[6742,6744,6749],{"type":34,"value":6743},"So, what should the MetaLoader class contain? To make it simple, we will just need its initialization and an ",{"type":24,"tag":30,"props":6745,"children":6746},{},[6747],{"type":34,"value":6748},"iter",{"type":34,"value":6750}," method that will be returning us the problem loaders at each meta-batch. The rest should be internal methods. And how should these mandatory methods work?",{"type":24,"tag":46,"props":6752,"children":6753},{},[6754,6756,6765],{"type":34,"value":6755},"Well, when initializing a MetaLoader it will load the necessary info at both Meta-level and Learning level, as well as it will initialize a sampler as we saw before at the DataLoader but now for the Meta-Level, which will be run at ",{"type":24,"tag":800,"props":6757,"children":6758},{},[6759,6760,6764],{"type":34,"value":3995},{"type":24,"tag":800,"props":6761,"children":6762},{},[6763],{"type":34,"value":6748},{"type":34,"value":3995},{"type":34,"value":6766},". This sampler will just sample from the problem indices (so one of the variables at the Meta-level must be the number of problems in the meta-set, that can be computed as explained before) for the same reason as before, memory optimization.",{"type":24,"tag":46,"props":6768,"children":6769},{},[6770,6772,6781,6783,6793,6795,6805,6807,6817],{"type":34,"value":6771},"Then at ",{"type":24,"tag":800,"props":6773,"children":6774},{},[6775,6776,6780],{"type":34,"value":3995},{"type":24,"tag":800,"props":6777,"children":6778},{},[6779],{"type":34,"value":6748},{"type":34,"value":3995},{"type":34,"value":6782}," time the sampler will return a batch of problem indices. From each of these indices we will make a method (",{"type":24,"tag":800,"props":6784,"children":6785},{},[6786,6787,6792],{"type":34,"value":3995},{"type":24,"tag":800,"props":6788,"children":6789},{},[6790],{"type":34,"value":6791},"get_problem_loader",{"type":34,"value":3995},{"type":34,"value":6794}," method) to get the corresponding problem loader, which will begin searching the alphabet and the characters in the alphabet for each problem index and then the samples index in this problem(",{"type":24,"tag":800,"props":6796,"children":6797},{},[6798,6799,6804],{"type":34,"value":3995},{"type":24,"tag":800,"props":6800,"children":6801},{},[6802],{"type":34,"value":6803},"problem_idx_to_samples_idx",{"type":34,"value":3995},{"type":34,"value":6806}," method), for further problem loader building (",{"type":24,"tag":800,"props":6808,"children":6809},{},[6810,6811,6816],{"type":34,"value":3995},{"type":24,"tag":800,"props":6812,"children":6813},{},[6814],{"type":34,"value":6815},"build_problem_loader_from_samples",{"type":34,"value":3995},{"type":34,"value":6818}," method, which will return the three loaders of the problem for train, validation and test).",{"type":24,"tag":46,"props":6820,"children":6821},{},[6822],{"type":34,"value":6823},"Thus, when iterating the MetaLoader object, we will at each meta-batch receive a list of (meta-batch size) dictionaries with keys train, validation and test where for each key the corresponding set DataLoader of the problem will be contained.",{"type":24,"tag":3511,"props":6825,"children":6827},{"code":6826,"language":3514,"meta":10,"className":3515},"class MetaLoader():\n    \"\"\"\n    \"\"\"\n    def __init__(self, base_dataset, metabatch_size, batch_sizes, \n                 chars_per_alphabet, problem_ratios):\n        self.base_dataset = base_dataset\n        self.metabatch_size = metabatch_size\n        self.batch_sizes = batch_sizes\n        self.chars_per_alph = chars_per_alphabet\n        self.problem_ratios = [0.75, 0.15, 0.1]\n        self.problems_per_alph = {}\n        self.num_problems = 0\n        self.__load_quantitative_info__()\n        self.metasampler = BatchSampler(RandomSampler(range(self.num_problems)), \n                                        batch_size=self.metabatch_size, \n                                        drop_last=True)\n    \n    def __load_quantitative_info__(self):\n        for alphb in self.chars_per_alph:\n            self.problems_per_alph[alphb] = int((self.chars_per_alph[alphb]**2 - \n                                                self.chars_per_alph[alphb]) / 2)\n            self.num_problems += self.problems_per_alph[alphb]\n    \n    def __has_reached__(self, idx, ctr, current):\n        return ctr + current > idx\n    \n    def __problem_idx_to_samples_idx__(self, problem_idx, alphb, \n                                       prbs_on_prev_alphabets, \n                                       chars_on_prev_alphabets):\n        pb_idx_in_alph = problem_idx - prbs_on_prev_alphabets\n        ichars_in_alphabet = (int(pb_idx_in_alph / self.chars_per_alph[alphb]), \n                                pb_idx_in_alph % self.chars_per_alph[alphb])\n        ichars = tuple([ich + chars_on_prev_alphabets \\\n                        for ich in ichars_in_alphabet])\n        return [sample_idx for charidx in ichars \n                for sample_idx in range(charidx * 20, (charidx + 1) * 20)]\n    \n    def __build_problem_loader_from_samples__(self, samples_idx):\n\n        random.shuffle(samples_idx)\n\n        train_val_frontier = int(len(samples_idx) * self.problem_ratios[0])\n        val_test_frontier = int(train_val_frontier + \n                                len(samples_idx) * self.problem_ratios[1])\n        \n        samples_idx_train = samples_idx[:train_val_frontier]\n        samples_idx_val = samples_idx[train_val_frontier:val_test_frontier]\n        samples_idx_test = samples_idx[val_test_frontier:]\n\n        train_sampler = BatchSampler(SubsetRandomSampler(samples_idx_train), \n                                     batch_size=self.batch_sizes['train'], \n                                     drop_last=True)\n        val_sampler = BatchSampler(SubsetRandomSampler(samples_idx_val), \n                                   batch_size=self.batch_sizes['val'], \n                                   drop_last=True)\n        test_sampler = BatchSampler(SubsetRandomSampler(samples_idx_test), \n                                    batch_size=self.batch_sizes['test'], \n                                    drop_last=True)\n        loaders = {'train': DataLoader(dataset=self.base_dataset, \n                                       batch_sampler=train_sampler),\n                   'val': DataLoader(dataset=self.base_dataset, \n                                       batch_sampler=val_sampler),\n                   'test': DataLoader(dataset=self.base_dataset, \n                                       batch_sampler=test_sampler)}\n        return loaders\n\n        \n    def __get_problem_loader__(self, problem_idx):\n        pbs_ctr = 0\n        chars_ctr = 0\n        for alphb in self.chars_per_alph:\n            if not self.__has_reached__(problem_idx, pbs_ctr, \n                                        self.problems_per_alph[alphb]):\n                pbs_ctr += self.problems_per_alph[alphb]\n                chars_ctr += self.chars_per_alph[alphb]\n            else:\n                problem_samples_idx = self.__problem_idx_to_samples_idx__(\n                    problem_idx, alphb, pbs_ctr, chars_ctr)\n                return self.__build_problem_loader_from_samples__(\n                    problem_samples_idx)\n\n    def  __iter__(self):\n        for imetabatch, metabatch in enumerate(self.metasampler):\n            problem_loaders = []\n            for problem_idx in metabatch:\n                problem_loaders.append(self.__get_problem_loader__(problem_idx))\n            yield problem_loaders\n",[6828],{"type":24,"tag":3495,"props":6829,"children":6830},{"__ignoreMap":10},[6831,6851,6863,6871,6895,6903,6929,6954,6979,7005,7058,7084,7112,7129,7172,7198,7222,7231,7257,7291,7356,7390,7423,7431,7457,7494,7502,7528,7537,7546,7573,7616,7642,7678,7705,7740,7825,7833,7859,7866,7875,7882,7942,7976,8017,8026,8044,8062,8080,8087,8105,8141,8165,8183,8217,8241,8259,8293,8317,8360,8382,8415,8436,8468,8489,8506,8513,8521,8547,8568,8589,8621,8654,8671,8696,8722,8739,8765,8774,8799,8808,8815,8840,8882,8899,8924,8942],{"type":24,"tag":2279,"props":6832,"children":6833},{"class":3522,"line":3523},[6834,6838,6842,6846],{"type":24,"tag":2279,"props":6835,"children":6836},{"class":3527},[6837],{"type":34,"value":4795},{"type":24,"tag":2279,"props":6839,"children":6840},{"class":3533},[6841],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6843,"children":6844},{"class":4802},[6845],{"type":34,"value":5751},{"type":24,"tag":2279,"props":6847,"children":6848},{"class":3533},[6849],{"type":34,"value":6850},"():\n",{"type":24,"tag":2279,"props":6852,"children":6853},{"class":3522,"line":2808},[6854,6858],{"type":24,"tag":2279,"props":6855,"children":6856},{"class":3533},[6857],{"type":34,"value":3879},{"type":24,"tag":2279,"props":6859,"children":6860},{"class":3557},[6861],{"type":34,"value":6862},"\"\"\"\n",{"type":24,"tag":2279,"props":6864,"children":6865},{"class":3522,"line":2817},[6866],{"type":24,"tag":2279,"props":6867,"children":6868},{"class":3557},[6869],{"type":34,"value":6870},"    \"\"\"\n",{"type":24,"tag":2279,"props":6872,"children":6873},{"class":3522,"line":3577},[6874,6878,6882,6886,6890],{"type":24,"tag":2279,"props":6875,"children":6876},{"class":3533},[6877],{"type":34,"value":3879},{"type":24,"tag":2279,"props":6879,"children":6880},{"class":3527},[6881],{"type":34,"value":4822},{"type":24,"tag":2279,"props":6883,"children":6884},{"class":3533},[6885],{"type":34,"value":2285},{"type":24,"tag":2279,"props":6887,"children":6888},{"class":3908},[6889],{"type":34,"value":4831},{"type":24,"tag":2279,"props":6891,"children":6892},{"class":3533},[6893],{"type":34,"value":6894},"(self, base_dataset, metabatch_size, batch_sizes, \n",{"type":24,"tag":2279,"props":6896,"children":6897},{"class":3522,"line":3725},[6898],{"type":24,"tag":2279,"props":6899,"children":6900},{"class":3533},[6901],{"type":34,"value":6902},"                 chars_per_alphabet, problem_ratios):\n",{"type":24,"tag":2279,"props":6904,"children":6905},{"class":3522,"line":3747},[6906,6911,6915,6920,6924],{"type":24,"tag":2279,"props":6907,"children":6908},{"class":3533},[6909],{"type":34,"value":6910},"        ",{"type":24,"tag":2279,"props":6912,"children":6913},{"class":3908},[6914],{"type":34,"value":4848},{"type":24,"tag":2279,"props":6916,"children":6917},{"class":3533},[6918],{"type":34,"value":6919},".base_dataset ",{"type":24,"tag":2279,"props":6921,"children":6922},{"class":3527},[6923],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6925,"children":6926},{"class":3533},[6927],{"type":34,"value":6928}," base_dataset\n",{"type":24,"tag":2279,"props":6930,"children":6931},{"class":3522,"line":3769},[6932,6936,6940,6945,6949],{"type":24,"tag":2279,"props":6933,"children":6934},{"class":3533},[6935],{"type":34,"value":6910},{"type":24,"tag":2279,"props":6937,"children":6938},{"class":3908},[6939],{"type":34,"value":4848},{"type":24,"tag":2279,"props":6941,"children":6942},{"class":3533},[6943],{"type":34,"value":6944},".metabatch_size ",{"type":24,"tag":2279,"props":6946,"children":6947},{"class":3527},[6948],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6950,"children":6951},{"class":3533},[6952],{"type":34,"value":6953}," metabatch_size\n",{"type":24,"tag":2279,"props":6955,"children":6956},{"class":3522,"line":3782},[6957,6961,6965,6970,6974],{"type":24,"tag":2279,"props":6958,"children":6959},{"class":3533},[6960],{"type":34,"value":6910},{"type":24,"tag":2279,"props":6962,"children":6963},{"class":3908},[6964],{"type":34,"value":4848},{"type":24,"tag":2279,"props":6966,"children":6967},{"class":3533},[6968],{"type":34,"value":6969},".batch_sizes ",{"type":24,"tag":2279,"props":6971,"children":6972},{"class":3527},[6973],{"type":34,"value":3866},{"type":24,"tag":2279,"props":6975,"children":6976},{"class":3533},[6977],{"type":34,"value":6978}," batch_sizes\n",{"type":24,"tag":2279,"props":6980,"children":6982},{"class":3522,"line":6981},9,[6983,6987,6991,6996,7000],{"type":24,"tag":2279,"props":6984,"children":6985},{"class":3533},[6986],{"type":34,"value":6910},{"type":24,"tag":2279,"props":6988,"children":6989},{"class":3908},[6990],{"type":34,"value":4848},{"type":24,"tag":2279,"props":6992,"children":6993},{"class":3533},[6994],{"type":34,"value":6995},".chars_per_alph ",{"type":24,"tag":2279,"props":6997,"children":6998},{"class":3527},[6999],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7001,"children":7002},{"class":3533},[7003],{"type":34,"value":7004}," chars_per_alphabet\n",{"type":24,"tag":2279,"props":7006,"children":7008},{"class":3522,"line":7007},10,[7009,7013,7017,7022,7026,7031,7036,7040,7044,7048,7053],{"type":24,"tag":2279,"props":7010,"children":7011},{"class":3533},[7012],{"type":34,"value":6910},{"type":24,"tag":2279,"props":7014,"children":7015},{"class":3908},[7016],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7018,"children":7019},{"class":3533},[7020],{"type":34,"value":7021},".problem_ratios ",{"type":24,"tag":2279,"props":7023,"children":7024},{"class":3527},[7025],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7027,"children":7028},{"class":3533},[7029],{"type":34,"value":7030}," [",{"type":24,"tag":2279,"props":7032,"children":7033},{"class":3908},[7034],{"type":34,"value":7035},"0.75",{"type":24,"tag":2279,"props":7037,"children":7038},{"class":3533},[7039],{"type":34,"value":1340},{"type":24,"tag":2279,"props":7041,"children":7042},{"class":3908},[7043],{"type":34,"value":5025},{"type":24,"tag":2279,"props":7045,"children":7046},{"class":3533},[7047],{"type":34,"value":1340},{"type":24,"tag":2279,"props":7049,"children":7050},{"class":3908},[7051],{"type":34,"value":7052},"0.1",{"type":24,"tag":2279,"props":7054,"children":7055},{"class":3533},[7056],{"type":34,"value":7057},"]\n",{"type":24,"tag":2279,"props":7059,"children":7061},{"class":3522,"line":7060},11,[7062,7066,7070,7075,7079],{"type":24,"tag":2279,"props":7063,"children":7064},{"class":3533},[7065],{"type":34,"value":6910},{"type":24,"tag":2279,"props":7067,"children":7068},{"class":3908},[7069],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7071,"children":7072},{"class":3533},[7073],{"type":34,"value":7074},".problems_per_alph ",{"type":24,"tag":2279,"props":7076,"children":7077},{"class":3527},[7078],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7080,"children":7081},{"class":3533},[7082],{"type":34,"value":7083}," {}\n",{"type":24,"tag":2279,"props":7085,"children":7087},{"class":3522,"line":7086},12,[7088,7092,7096,7100,7104,7108],{"type":24,"tag":2279,"props":7089,"children":7090},{"class":3533},[7091],{"type":34,"value":6910},{"type":24,"tag":2279,"props":7093,"children":7094},{"class":3908},[7095],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7097,"children":7098},{"class":3533},[7099],{"type":34,"value":4941},{"type":24,"tag":2279,"props":7101,"children":7102},{"class":3527},[7103],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7105,"children":7106},{"class":3533},[7107],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7109,"children":7110},{"class":3908},[7111],{"type":34,"value":4891},{"type":24,"tag":2279,"props":7113,"children":7115},{"class":3522,"line":7114},13,[7116,7120,7124],{"type":24,"tag":2279,"props":7117,"children":7118},{"class":3533},[7119],{"type":34,"value":6910},{"type":24,"tag":2279,"props":7121,"children":7122},{"class":3908},[7123],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7125,"children":7126},{"class":3533},[7127],{"type":34,"value":7128},".__load_quantitative_info__()\n",{"type":24,"tag":2279,"props":7130,"children":7132},{"class":3522,"line":7131},14,[7133,7137,7141,7146,7150,7155,7159,7163,7167],{"type":24,"tag":2279,"props":7134,"children":7135},{"class":3533},[7136],{"type":34,"value":6910},{"type":24,"tag":2279,"props":7138,"children":7139},{"class":3908},[7140],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7142,"children":7143},{"class":3533},[7144],{"type":34,"value":7145},".metasampler ",{"type":24,"tag":2279,"props":7147,"children":7148},{"class":3527},[7149],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7151,"children":7152},{"class":3533},[7153],{"type":34,"value":7154}," BatchSampler(RandomSampler(",{"type":24,"tag":2279,"props":7156,"children":7157},{"class":3908},[7158],{"type":34,"value":4200},{"type":24,"tag":2279,"props":7160,"children":7161},{"class":3533},[7162],{"type":34,"value":4205},{"type":24,"tag":2279,"props":7164,"children":7165},{"class":3908},[7166],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7168,"children":7169},{"class":3533},[7170],{"type":34,"value":7171},".num_problems)), \n",{"type":24,"tag":2279,"props":7173,"children":7175},{"class":3522,"line":7174},15,[7176,7181,7185,7189,7193],{"type":24,"tag":2279,"props":7177,"children":7178},{"class":3533},[7179],{"type":34,"value":7180},"                                        ",{"type":24,"tag":2279,"props":7182,"children":7183},{"class":3882},[7184],{"type":34,"value":4496},{"type":24,"tag":2279,"props":7186,"children":7187},{"class":3527},[7188],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7190,"children":7191},{"class":3908},[7192],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7194,"children":7195},{"class":3533},[7196],{"type":34,"value":7197},".metabatch_size, \n",{"type":24,"tag":2279,"props":7199,"children":7201},{"class":3522,"line":7200},16,[7202,7206,7210,7214,7218],{"type":24,"tag":2279,"props":7203,"children":7204},{"class":3533},[7205],{"type":34,"value":7180},{"type":24,"tag":2279,"props":7207,"children":7208},{"class":3882},[7209],{"type":34,"value":6223},{"type":24,"tag":2279,"props":7211,"children":7212},{"class":3527},[7213],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7215,"children":7216},{"class":3908},[7217],{"type":34,"value":3911},{"type":24,"tag":2279,"props":7219,"children":7220},{"class":3533},[7221],{"type":34,"value":6699},{"type":24,"tag":2279,"props":7223,"children":7225},{"class":3522,"line":7224},17,[7226],{"type":24,"tag":2279,"props":7227,"children":7228},{"class":3533},[7229],{"type":34,"value":7230},"    \n",{"type":24,"tag":2279,"props":7232,"children":7234},{"class":3522,"line":7233},18,[7235,7239,7243,7247,7252],{"type":24,"tag":2279,"props":7236,"children":7237},{"class":3533},[7238],{"type":34,"value":3879},{"type":24,"tag":2279,"props":7240,"children":7241},{"class":3527},[7242],{"type":34,"value":4822},{"type":24,"tag":2279,"props":7244,"children":7245},{"class":3533},[7246],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7248,"children":7249},{"class":4802},[7250],{"type":34,"value":7251},"__load_quantitative_info__",{"type":24,"tag":2279,"props":7253,"children":7254},{"class":3533},[7255],{"type":34,"value":7256},"(self):\n",{"type":24,"tag":2279,"props":7258,"children":7260},{"class":3522,"line":7259},19,[7261,7265,7269,7274,7278,7282,7286],{"type":24,"tag":2279,"props":7262,"children":7263},{"class":3533},[7264],{"type":34,"value":6910},{"type":24,"tag":2279,"props":7266,"children":7267},{"class":3527},[7268],{"type":34,"value":4181},{"type":24,"tag":2279,"props":7270,"children":7271},{"class":3533},[7272],{"type":34,"value":7273}," alphb ",{"type":24,"tag":2279,"props":7275,"children":7276},{"class":3527},[7277],{"type":34,"value":4191},{"type":24,"tag":2279,"props":7279,"children":7280},{"class":3533},[7281],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7283,"children":7284},{"class":3908},[7285],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7287,"children":7288},{"class":3533},[7289],{"type":34,"value":7290},".chars_per_alph:\n",{"type":24,"tag":2279,"props":7292,"children":7294},{"class":3522,"line":7293},20,[7295,7300,7304,7309,7313,7317,7321,7326,7330,7335,7339,7343,7347,7351],{"type":24,"tag":2279,"props":7296,"children":7297},{"class":3533},[7298],{"type":34,"value":7299},"            ",{"type":24,"tag":2279,"props":7301,"children":7302},{"class":3908},[7303],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7305,"children":7306},{"class":3533},[7307],{"type":34,"value":7308},".problems_per_alph[alphb] ",{"type":24,"tag":2279,"props":7310,"children":7311},{"class":3527},[7312],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7314,"children":7315},{"class":3533},[7316],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7318,"children":7319},{"class":3908},[7320],{"type":34,"value":5689},{"type":24,"tag":2279,"props":7322,"children":7323},{"class":3533},[7324],{"type":34,"value":7325},"((",{"type":24,"tag":2279,"props":7327,"children":7328},{"class":3908},[7329],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7331,"children":7332},{"class":3533},[7333],{"type":34,"value":7334},".chars_per_alph[alphb]",{"type":24,"tag":2279,"props":7336,"children":7337},{"class":3527},[7338],{"type":34,"value":5601},{"type":24,"tag":2279,"props":7340,"children":7341},{"class":3908},[7342],{"type":34,"value":2308},{"type":24,"tag":2279,"props":7344,"children":7345},{"class":3533},[7346],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7348,"children":7349},{"class":3527},[7350],{"type":34,"value":3630},{"type":24,"tag":2279,"props":7352,"children":7353},{"class":3533},[7354],{"type":34,"value":7355}," \n",{"type":24,"tag":2279,"props":7357,"children":7359},{"class":3522,"line":7358},21,[7360,7365,7369,7374,7378,7382,7386],{"type":24,"tag":2279,"props":7361,"children":7362},{"class":3533},[7363],{"type":34,"value":7364},"                                                ",{"type":24,"tag":2279,"props":7366,"children":7367},{"class":3908},[7368],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7370,"children":7371},{"class":3533},[7372],{"type":34,"value":7373},".chars_per_alph[alphb]) ",{"type":24,"tag":2279,"props":7375,"children":7376},{"class":3527},[7377],{"type":34,"value":3593},{"type":24,"tag":2279,"props":7379,"children":7380},{"class":3533},[7381],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7383,"children":7384},{"class":3908},[7385],{"type":34,"value":2308},{"type":24,"tag":2279,"props":7387,"children":7388},{"class":3533},[7389],{"type":34,"value":6699},{"type":24,"tag":2279,"props":7391,"children":7393},{"class":3522,"line":7392},22,[7394,7398,7402,7406,7410,7414,7418],{"type":24,"tag":2279,"props":7395,"children":7396},{"class":3533},[7397],{"type":34,"value":7299},{"type":24,"tag":2279,"props":7399,"children":7400},{"class":3908},[7401],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7403,"children":7404},{"class":3533},[7405],{"type":34,"value":4941},{"type":24,"tag":2279,"props":7407,"children":7408},{"class":3527},[7409],{"type":34,"value":5453},{"type":24,"tag":2279,"props":7411,"children":7412},{"class":3533},[7413],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7415,"children":7416},{"class":3908},[7417],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7419,"children":7420},{"class":3533},[7421],{"type":34,"value":7422},".problems_per_alph[alphb]\n",{"type":24,"tag":2279,"props":7424,"children":7426},{"class":3522,"line":7425},23,[7427],{"type":24,"tag":2279,"props":7428,"children":7429},{"class":3533},[7430],{"type":34,"value":7230},{"type":24,"tag":2279,"props":7432,"children":7434},{"class":3522,"line":7433},24,[7435,7439,7443,7447,7452],{"type":24,"tag":2279,"props":7436,"children":7437},{"class":3533},[7438],{"type":34,"value":3879},{"type":24,"tag":2279,"props":7440,"children":7441},{"class":3527},[7442],{"type":34,"value":4822},{"type":24,"tag":2279,"props":7444,"children":7445},{"class":3533},[7446],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7448,"children":7449},{"class":4802},[7450],{"type":34,"value":7451},"__has_reached__",{"type":24,"tag":2279,"props":7453,"children":7454},{"class":3533},[7455],{"type":34,"value":7456},"(self, idx, ctr, current):\n",{"type":24,"tag":2279,"props":7458,"children":7460},{"class":3522,"line":7459},25,[7461,7465,7470,7475,7479,7484,7489],{"type":24,"tag":2279,"props":7462,"children":7463},{"class":3533},[7464],{"type":34,"value":6910},{"type":24,"tag":2279,"props":7466,"children":7467},{"class":3527},[7468],{"type":34,"value":7469},"return",{"type":24,"tag":2279,"props":7471,"children":7472},{"class":3533},[7473],{"type":34,"value":7474}," ctr ",{"type":24,"tag":2279,"props":7476,"children":7477},{"class":3527},[7478],{"type":34,"value":6072},{"type":24,"tag":2279,"props":7480,"children":7481},{"class":3533},[7482],{"type":34,"value":7483}," current ",{"type":24,"tag":2279,"props":7485,"children":7486},{"class":3527},[7487],{"type":34,"value":7488},">",{"type":24,"tag":2279,"props":7490,"children":7491},{"class":3533},[7492],{"type":34,"value":7493}," idx\n",{"type":24,"tag":2279,"props":7495,"children":7497},{"class":3522,"line":7496},26,[7498],{"type":24,"tag":2279,"props":7499,"children":7500},{"class":3533},[7501],{"type":34,"value":7230},{"type":24,"tag":2279,"props":7503,"children":7505},{"class":3522,"line":7504},27,[7506,7510,7514,7518,7523],{"type":24,"tag":2279,"props":7507,"children":7508},{"class":3533},[7509],{"type":34,"value":3879},{"type":24,"tag":2279,"props":7511,"children":7512},{"class":3527},[7513],{"type":34,"value":4822},{"type":24,"tag":2279,"props":7515,"children":7516},{"class":3533},[7517],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7519,"children":7520},{"class":4802},[7521],{"type":34,"value":7522},"__problem_idx_to_samples_idx__",{"type":24,"tag":2279,"props":7524,"children":7525},{"class":3533},[7526],{"type":34,"value":7527},"(self, problem_idx, alphb, \n",{"type":24,"tag":2279,"props":7529,"children":7531},{"class":3522,"line":7530},28,[7532],{"type":24,"tag":2279,"props":7533,"children":7534},{"class":3533},[7535],{"type":34,"value":7536},"                                       prbs_on_prev_alphabets, \n",{"type":24,"tag":2279,"props":7538,"children":7540},{"class":3522,"line":7539},29,[7541],{"type":24,"tag":2279,"props":7542,"children":7543},{"class":3533},[7544],{"type":34,"value":7545},"                                       chars_on_prev_alphabets):\n",{"type":24,"tag":2279,"props":7547,"children":7549},{"class":3522,"line":7548},30,[7550,7555,7559,7564,7568],{"type":24,"tag":2279,"props":7551,"children":7552},{"class":3533},[7553],{"type":34,"value":7554},"        pb_idx_in_alph ",{"type":24,"tag":2279,"props":7556,"children":7557},{"class":3527},[7558],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7560,"children":7561},{"class":3533},[7562],{"type":34,"value":7563}," problem_idx ",{"type":24,"tag":2279,"props":7565,"children":7566},{"class":3527},[7567],{"type":34,"value":3630},{"type":24,"tag":2279,"props":7569,"children":7570},{"class":3533},[7571],{"type":34,"value":7572}," prbs_on_prev_alphabets\n",{"type":24,"tag":2279,"props":7574,"children":7576},{"class":3522,"line":7575},31,[7577,7582,7586,7590,7594,7599,7603,7607,7611],{"type":24,"tag":2279,"props":7578,"children":7579},{"class":3533},[7580],{"type":34,"value":7581},"        ichars_in_alphabet ",{"type":24,"tag":2279,"props":7583,"children":7584},{"class":3527},[7585],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7587,"children":7588},{"class":3533},[7589],{"type":34,"value":1868},{"type":24,"tag":2279,"props":7591,"children":7592},{"class":3908},[7593],{"type":34,"value":5689},{"type":24,"tag":2279,"props":7595,"children":7596},{"class":3533},[7597],{"type":34,"value":7598},"(pb_idx_in_alph ",{"type":24,"tag":2279,"props":7600,"children":7601},{"class":3527},[7602],{"type":34,"value":3593},{"type":24,"tag":2279,"props":7604,"children":7605},{"class":3533},[7606],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7608,"children":7609},{"class":3908},[7610],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7612,"children":7613},{"class":3533},[7614],{"type":34,"value":7615},".chars_per_alph[alphb]), \n",{"type":24,"tag":2279,"props":7617,"children":7619},{"class":3522,"line":7618},32,[7620,7625,7629,7633,7637],{"type":24,"tag":2279,"props":7621,"children":7622},{"class":3533},[7623],{"type":34,"value":7624},"                                pb_idx_in_alph ",{"type":24,"tag":2279,"props":7626,"children":7627},{"class":3527},[7628],{"type":34,"value":3583},{"type":24,"tag":2279,"props":7630,"children":7631},{"class":3533},[7632],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7634,"children":7635},{"class":3908},[7636],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7638,"children":7639},{"class":3533},[7640],{"type":34,"value":7641},".chars_per_alph[alphb])\n",{"type":24,"tag":2279,"props":7643,"children":7645},{"class":3522,"line":7644},33,[7646,7651,7655,7659,7664,7669,7673],{"type":24,"tag":2279,"props":7647,"children":7648},{"class":3533},[7649],{"type":34,"value":7650},"        ichars ",{"type":24,"tag":2279,"props":7652,"children":7653},{"class":3527},[7654],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7656,"children":7657},{"class":3533},[7658],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7660,"children":7661},{"class":3908},[7662],{"type":34,"value":7663},"tuple",{"type":24,"tag":2279,"props":7665,"children":7666},{"class":3533},[7667],{"type":34,"value":7668},"([ich ",{"type":24,"tag":2279,"props":7670,"children":7671},{"class":3527},[7672],{"type":34,"value":6072},{"type":24,"tag":2279,"props":7674,"children":7675},{"class":3533},[7676],{"type":34,"value":7677}," chars_on_prev_alphabets \\\n",{"type":24,"tag":2279,"props":7679,"children":7681},{"class":3522,"line":7680},34,[7682,7687,7691,7696,7700],{"type":24,"tag":2279,"props":7683,"children":7684},{"class":3533},[7685],{"type":34,"value":7686},"                        ",{"type":24,"tag":2279,"props":7688,"children":7689},{"class":3527},[7690],{"type":34,"value":4181},{"type":24,"tag":2279,"props":7692,"children":7693},{"class":3533},[7694],{"type":34,"value":7695}," ich ",{"type":24,"tag":2279,"props":7697,"children":7698},{"class":3527},[7699],{"type":34,"value":4191},{"type":24,"tag":2279,"props":7701,"children":7702},{"class":3533},[7703],{"type":34,"value":7704}," ichars_in_alphabet])\n",{"type":24,"tag":2279,"props":7706,"children":7708},{"class":3522,"line":7707},35,[7709,7713,7717,7722,7726,7731,7735],{"type":24,"tag":2279,"props":7710,"children":7711},{"class":3533},[7712],{"type":34,"value":6910},{"type":24,"tag":2279,"props":7714,"children":7715},{"class":3527},[7716],{"type":34,"value":7469},{"type":24,"tag":2279,"props":7718,"children":7719},{"class":3533},[7720],{"type":34,"value":7721}," [sample_idx ",{"type":24,"tag":2279,"props":7723,"children":7724},{"class":3527},[7725],{"type":34,"value":4181},{"type":24,"tag":2279,"props":7727,"children":7728},{"class":3533},[7729],{"type":34,"value":7730}," charidx ",{"type":24,"tag":2279,"props":7732,"children":7733},{"class":3527},[7734],{"type":34,"value":4191},{"type":24,"tag":2279,"props":7736,"children":7737},{"class":3533},[7738],{"type":34,"value":7739}," ichars \n",{"type":24,"tag":2279,"props":7741,"children":7743},{"class":3522,"line":7742},36,[7744,7749,7753,7758,7762,7766,7770,7775,7779,7783,7787,7792,7796,7800,7804,7808,7812,7816,7820],{"type":24,"tag":2279,"props":7745,"children":7746},{"class":3533},[7747],{"type":34,"value":7748},"                ",{"type":24,"tag":2279,"props":7750,"children":7751},{"class":3527},[7752],{"type":34,"value":4181},{"type":24,"tag":2279,"props":7754,"children":7755},{"class":3533},[7756],{"type":34,"value":7757}," sample_idx ",{"type":24,"tag":2279,"props":7759,"children":7760},{"class":3527},[7761],{"type":34,"value":4191},{"type":24,"tag":2279,"props":7763,"children":7764},{"class":3533},[7765],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7767,"children":7768},{"class":3908},[7769],{"type":34,"value":4200},{"type":24,"tag":2279,"props":7771,"children":7772},{"class":3533},[7773],{"type":34,"value":7774},"(charidx ",{"type":24,"tag":2279,"props":7776,"children":7777},{"class":3527},[7778],{"type":34,"value":4248},{"type":24,"tag":2279,"props":7780,"children":7781},{"class":3533},[7782],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7784,"children":7785},{"class":3908},[7786],{"type":34,"value":2725},{"type":24,"tag":2279,"props":7788,"children":7789},{"class":3533},[7790],{"type":34,"value":7791},", (charidx ",{"type":24,"tag":2279,"props":7793,"children":7794},{"class":3527},[7795],{"type":34,"value":6072},{"type":24,"tag":2279,"props":7797,"children":7798},{"class":3533},[7799],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7801,"children":7802},{"class":3908},[7803],{"type":34,"value":2283},{"type":24,"tag":2279,"props":7805,"children":7806},{"class":3533},[7807],{"type":34,"value":6085},{"type":24,"tag":2279,"props":7809,"children":7810},{"class":3527},[7811],{"type":34,"value":4248},{"type":24,"tag":2279,"props":7813,"children":7814},{"class":3533},[7815],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7817,"children":7818},{"class":3908},[7819],{"type":34,"value":2725},{"type":24,"tag":2279,"props":7821,"children":7822},{"class":3533},[7823],{"type":34,"value":7824},")]\n",{"type":24,"tag":2279,"props":7826,"children":7828},{"class":3522,"line":7827},37,[7829],{"type":24,"tag":2279,"props":7830,"children":7831},{"class":3533},[7832],{"type":34,"value":7230},{"type":24,"tag":2279,"props":7834,"children":7836},{"class":3522,"line":7835},38,[7837,7841,7845,7849,7854],{"type":24,"tag":2279,"props":7838,"children":7839},{"class":3533},[7840],{"type":34,"value":3879},{"type":24,"tag":2279,"props":7842,"children":7843},{"class":3527},[7844],{"type":34,"value":4822},{"type":24,"tag":2279,"props":7846,"children":7847},{"class":3533},[7848],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7850,"children":7851},{"class":4802},[7852],{"type":34,"value":7853},"__build_problem_loader_from_samples__",{"type":24,"tag":2279,"props":7855,"children":7856},{"class":3533},[7857],{"type":34,"value":7858},"(self, samples_idx):\n",{"type":24,"tag":2279,"props":7860,"children":7862},{"class":3522,"line":7861},39,[7863],{"type":24,"tag":2279,"props":7864,"children":7865},{},[],{"type":24,"tag":2279,"props":7867,"children":7869},{"class":3522,"line":7868},40,[7870],{"type":24,"tag":2279,"props":7871,"children":7872},{"class":3533},[7873],{"type":34,"value":7874},"        random.shuffle(samples_idx)\n",{"type":24,"tag":2279,"props":7876,"children":7878},{"class":3522,"line":7877},41,[7879],{"type":24,"tag":2279,"props":7880,"children":7881},{},[],{"type":24,"tag":2279,"props":7883,"children":7885},{"class":3522,"line":7884},42,[7886,7891,7895,7899,7903,7907,7911,7916,7920,7924,7928,7933,7937],{"type":24,"tag":2279,"props":7887,"children":7888},{"class":3533},[7889],{"type":34,"value":7890},"        train_val_frontier ",{"type":24,"tag":2279,"props":7892,"children":7893},{"class":3527},[7894],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7896,"children":7897},{"class":3533},[7898],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7900,"children":7901},{"class":3908},[7902],{"type":34,"value":5689},{"type":24,"tag":2279,"props":7904,"children":7905},{"class":3533},[7906],{"type":34,"value":4205},{"type":24,"tag":2279,"props":7908,"children":7909},{"class":3908},[7910],{"type":34,"value":4409},{"type":24,"tag":2279,"props":7912,"children":7913},{"class":3533},[7914],{"type":34,"value":7915},"(samples_idx) ",{"type":24,"tag":2279,"props":7917,"children":7918},{"class":3527},[7919],{"type":34,"value":4248},{"type":24,"tag":2279,"props":7921,"children":7922},{"class":3533},[7923],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7925,"children":7926},{"class":3908},[7927],{"type":34,"value":4848},{"type":24,"tag":2279,"props":7929,"children":7930},{"class":3533},[7931],{"type":34,"value":7932},".problem_ratios[",{"type":24,"tag":2279,"props":7934,"children":7935},{"class":3908},[7936],{"type":34,"value":4023},{"type":24,"tag":2279,"props":7938,"children":7939},{"class":3533},[7940],{"type":34,"value":7941},"])\n",{"type":24,"tag":2279,"props":7943,"children":7945},{"class":3522,"line":7944},43,[7946,7951,7955,7959,7963,7968,7972],{"type":24,"tag":2279,"props":7947,"children":7948},{"class":3533},[7949],{"type":34,"value":7950},"        val_test_frontier ",{"type":24,"tag":2279,"props":7952,"children":7953},{"class":3527},[7954],{"type":34,"value":3866},{"type":24,"tag":2279,"props":7956,"children":7957},{"class":3533},[7958],{"type":34,"value":2285},{"type":24,"tag":2279,"props":7960,"children":7961},{"class":3908},[7962],{"type":34,"value":5689},{"type":24,"tag":2279,"props":7964,"children":7965},{"class":3533},[7966],{"type":34,"value":7967},"(train_val_frontier ",{"type":24,"tag":2279,"props":7969,"children":7970},{"class":3527},[7971],{"type":34,"value":6072},{"type":24,"tag":2279,"props":7973,"children":7974},{"class":3533},[7975],{"type":34,"value":7355},{"type":24,"tag":2279,"props":7977,"children":7979},{"class":3522,"line":7978},44,[7980,7985,7989,7993,7997,8001,8005,8009,8013],{"type":24,"tag":2279,"props":7981,"children":7982},{"class":3533},[7983],{"type":34,"value":7984},"                                ",{"type":24,"tag":2279,"props":7986,"children":7987},{"class":3908},[7988],{"type":34,"value":4409},{"type":24,"tag":2279,"props":7990,"children":7991},{"class":3533},[7992],{"type":34,"value":7915},{"type":24,"tag":2279,"props":7994,"children":7995},{"class":3527},[7996],{"type":34,"value":4248},{"type":24,"tag":2279,"props":7998,"children":7999},{"class":3533},[8000],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8002,"children":8003},{"class":3908},[8004],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8006,"children":8007},{"class":3533},[8008],{"type":34,"value":7932},{"type":24,"tag":2279,"props":8010,"children":8011},{"class":3908},[8012],{"type":34,"value":2283},{"type":24,"tag":2279,"props":8014,"children":8015},{"class":3533},[8016],{"type":34,"value":7941},{"type":24,"tag":2279,"props":8018,"children":8020},{"class":3522,"line":8019},45,[8021],{"type":24,"tag":2279,"props":8022,"children":8023},{"class":3533},[8024],{"type":34,"value":8025},"        \n",{"type":24,"tag":2279,"props":8027,"children":8029},{"class":3522,"line":8028},46,[8030,8035,8039],{"type":24,"tag":2279,"props":8031,"children":8032},{"class":3533},[8033],{"type":34,"value":8034},"        samples_idx_train ",{"type":24,"tag":2279,"props":8036,"children":8037},{"class":3527},[8038],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8040,"children":8041},{"class":3533},[8042],{"type":34,"value":8043}," samples_idx[:train_val_frontier]\n",{"type":24,"tag":2279,"props":8045,"children":8047},{"class":3522,"line":8046},47,[8048,8053,8057],{"type":24,"tag":2279,"props":8049,"children":8050},{"class":3533},[8051],{"type":34,"value":8052},"        samples_idx_val ",{"type":24,"tag":2279,"props":8054,"children":8055},{"class":3527},[8056],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8058,"children":8059},{"class":3533},[8060],{"type":34,"value":8061}," samples_idx[train_val_frontier:val_test_frontier]\n",{"type":24,"tag":2279,"props":8063,"children":8065},{"class":3522,"line":8064},48,[8066,8071,8075],{"type":24,"tag":2279,"props":8067,"children":8068},{"class":3533},[8069],{"type":34,"value":8070},"        samples_idx_test ",{"type":24,"tag":2279,"props":8072,"children":8073},{"class":3527},[8074],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8076,"children":8077},{"class":3533},[8078],{"type":34,"value":8079}," samples_idx[val_test_frontier:]\n",{"type":24,"tag":2279,"props":8081,"children":8083},{"class":3522,"line":8082},49,[8084],{"type":24,"tag":2279,"props":8085,"children":8086},{},[],{"type":24,"tag":2279,"props":8088,"children":8090},{"class":3522,"line":8089},50,[8091,8096,8100],{"type":24,"tag":2279,"props":8092,"children":8093},{"class":3533},[8094],{"type":34,"value":8095},"        train_sampler ",{"type":24,"tag":2279,"props":8097,"children":8098},{"class":3527},[8099],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8101,"children":8102},{"class":3533},[8103],{"type":34,"value":8104}," BatchSampler(SubsetRandomSampler(samples_idx_train), \n",{"type":24,"tag":2279,"props":8106,"children":8108},{"class":3522,"line":8107},51,[8109,8114,8118,8122,8126,8131,8136],{"type":24,"tag":2279,"props":8110,"children":8111},{"class":3533},[8112],{"type":34,"value":8113},"                                     ",{"type":24,"tag":2279,"props":8115,"children":8116},{"class":3882},[8117],{"type":34,"value":4496},{"type":24,"tag":2279,"props":8119,"children":8120},{"class":3527},[8121],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8123,"children":8124},{"class":3908},[8125],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8127,"children":8128},{"class":3533},[8129],{"type":34,"value":8130},".batch_sizes[",{"type":24,"tag":2279,"props":8132,"children":8133},{"class":3557},[8134],{"type":34,"value":8135},"'train'",{"type":24,"tag":2279,"props":8137,"children":8138},{"class":3533},[8139],{"type":34,"value":8140},"], \n",{"type":24,"tag":2279,"props":8142,"children":8144},{"class":3522,"line":8143},52,[8145,8149,8153,8157,8161],{"type":24,"tag":2279,"props":8146,"children":8147},{"class":3533},[8148],{"type":34,"value":8113},{"type":24,"tag":2279,"props":8150,"children":8151},{"class":3882},[8152],{"type":34,"value":6223},{"type":24,"tag":2279,"props":8154,"children":8155},{"class":3527},[8156],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8158,"children":8159},{"class":3908},[8160],{"type":34,"value":3911},{"type":24,"tag":2279,"props":8162,"children":8163},{"class":3533},[8164],{"type":34,"value":6699},{"type":24,"tag":2279,"props":8166,"children":8168},{"class":3522,"line":8167},53,[8169,8174,8178],{"type":24,"tag":2279,"props":8170,"children":8171},{"class":3533},[8172],{"type":34,"value":8173},"        val_sampler ",{"type":24,"tag":2279,"props":8175,"children":8176},{"class":3527},[8177],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8179,"children":8180},{"class":3533},[8181],{"type":34,"value":8182}," BatchSampler(SubsetRandomSampler(samples_idx_val), \n",{"type":24,"tag":2279,"props":8184,"children":8186},{"class":3522,"line":8185},54,[8187,8192,8196,8200,8204,8208,8213],{"type":24,"tag":2279,"props":8188,"children":8189},{"class":3533},[8190],{"type":34,"value":8191},"                                   ",{"type":24,"tag":2279,"props":8193,"children":8194},{"class":3882},[8195],{"type":34,"value":4496},{"type":24,"tag":2279,"props":8197,"children":8198},{"class":3527},[8199],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8201,"children":8202},{"class":3908},[8203],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8205,"children":8206},{"class":3533},[8207],{"type":34,"value":8130},{"type":24,"tag":2279,"props":8209,"children":8210},{"class":3557},[8211],{"type":34,"value":8212},"'val'",{"type":24,"tag":2279,"props":8214,"children":8215},{"class":3533},[8216],{"type":34,"value":8140},{"type":24,"tag":2279,"props":8218,"children":8220},{"class":3522,"line":8219},55,[8221,8225,8229,8233,8237],{"type":24,"tag":2279,"props":8222,"children":8223},{"class":3533},[8224],{"type":34,"value":8191},{"type":24,"tag":2279,"props":8226,"children":8227},{"class":3882},[8228],{"type":34,"value":6223},{"type":24,"tag":2279,"props":8230,"children":8231},{"class":3527},[8232],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8234,"children":8235},{"class":3908},[8236],{"type":34,"value":3911},{"type":24,"tag":2279,"props":8238,"children":8239},{"class":3533},[8240],{"type":34,"value":6699},{"type":24,"tag":2279,"props":8242,"children":8244},{"class":3522,"line":8243},56,[8245,8250,8254],{"type":24,"tag":2279,"props":8246,"children":8247},{"class":3533},[8248],{"type":34,"value":8249},"        test_sampler ",{"type":24,"tag":2279,"props":8251,"children":8252},{"class":3527},[8253],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8255,"children":8256},{"class":3533},[8257],{"type":34,"value":8258}," BatchSampler(SubsetRandomSampler(samples_idx_test), \n",{"type":24,"tag":2279,"props":8260,"children":8262},{"class":3522,"line":8261},57,[8263,8268,8272,8276,8280,8284,8289],{"type":24,"tag":2279,"props":8264,"children":8265},{"class":3533},[8266],{"type":34,"value":8267},"                                    ",{"type":24,"tag":2279,"props":8269,"children":8270},{"class":3882},[8271],{"type":34,"value":4496},{"type":24,"tag":2279,"props":8273,"children":8274},{"class":3527},[8275],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8277,"children":8278},{"class":3908},[8279],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8281,"children":8282},{"class":3533},[8283],{"type":34,"value":8130},{"type":24,"tag":2279,"props":8285,"children":8286},{"class":3557},[8287],{"type":34,"value":8288},"'test'",{"type":24,"tag":2279,"props":8290,"children":8291},{"class":3533},[8292],{"type":34,"value":8140},{"type":24,"tag":2279,"props":8294,"children":8296},{"class":3522,"line":8295},58,[8297,8301,8305,8309,8313],{"type":24,"tag":2279,"props":8298,"children":8299},{"class":3533},[8300],{"type":34,"value":8267},{"type":24,"tag":2279,"props":8302,"children":8303},{"class":3882},[8304],{"type":34,"value":6223},{"type":24,"tag":2279,"props":8306,"children":8307},{"class":3527},[8308],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8310,"children":8311},{"class":3908},[8312],{"type":34,"value":3911},{"type":24,"tag":2279,"props":8314,"children":8315},{"class":3533},[8316],{"type":34,"value":6699},{"type":24,"tag":2279,"props":8318,"children":8320},{"class":3522,"line":8319},59,[8321,8326,8330,8334,8338,8343,8347,8351,8355],{"type":24,"tag":2279,"props":8322,"children":8323},{"class":3533},[8324],{"type":34,"value":8325},"        loaders ",{"type":24,"tag":2279,"props":8327,"children":8328},{"class":3527},[8329],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8331,"children":8332},{"class":3533},[8333],{"type":34,"value":4983},{"type":24,"tag":2279,"props":8335,"children":8336},{"class":3557},[8337],{"type":34,"value":8135},{"type":24,"tag":2279,"props":8339,"children":8340},{"class":3533},[8341],{"type":34,"value":8342},": DataLoader(",{"type":24,"tag":2279,"props":8344,"children":8345},{"class":3882},[8346],{"type":34,"value":3965},{"type":24,"tag":2279,"props":8348,"children":8349},{"class":3527},[8350],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8352,"children":8353},{"class":3908},[8354],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8356,"children":8357},{"class":3533},[8358],{"type":34,"value":8359},".base_dataset, \n",{"type":24,"tag":2279,"props":8361,"children":8363},{"class":3522,"line":8362},60,[8364,8369,8373,8377],{"type":24,"tag":2279,"props":8365,"children":8366},{"class":3533},[8367],{"type":34,"value":8368},"                                       ",{"type":24,"tag":2279,"props":8370,"children":8371},{"class":3882},[8372],{"type":34,"value":6306},{"type":24,"tag":2279,"props":8374,"children":8375},{"class":3527},[8376],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8378,"children":8379},{"class":3533},[8380],{"type":34,"value":8381},"train_sampler),\n",{"type":24,"tag":2279,"props":8383,"children":8385},{"class":3522,"line":8384},61,[8386,8391,8395,8399,8403,8407,8411],{"type":24,"tag":2279,"props":8387,"children":8388},{"class":3533},[8389],{"type":34,"value":8390},"                   ",{"type":24,"tag":2279,"props":8392,"children":8393},{"class":3557},[8394],{"type":34,"value":8212},{"type":24,"tag":2279,"props":8396,"children":8397},{"class":3533},[8398],{"type":34,"value":8342},{"type":24,"tag":2279,"props":8400,"children":8401},{"class":3882},[8402],{"type":34,"value":3965},{"type":24,"tag":2279,"props":8404,"children":8405},{"class":3527},[8406],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8408,"children":8409},{"class":3908},[8410],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8412,"children":8413},{"class":3533},[8414],{"type":34,"value":8359},{"type":24,"tag":2279,"props":8416,"children":8418},{"class":3522,"line":8417},62,[8419,8423,8427,8431],{"type":24,"tag":2279,"props":8420,"children":8421},{"class":3533},[8422],{"type":34,"value":8368},{"type":24,"tag":2279,"props":8424,"children":8425},{"class":3882},[8426],{"type":34,"value":6306},{"type":24,"tag":2279,"props":8428,"children":8429},{"class":3527},[8430],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8432,"children":8433},{"class":3533},[8434],{"type":34,"value":8435},"val_sampler),\n",{"type":24,"tag":2279,"props":8437,"children":8439},{"class":3522,"line":8438},63,[8440,8444,8448,8452,8456,8460,8464],{"type":24,"tag":2279,"props":8441,"children":8442},{"class":3533},[8443],{"type":34,"value":8390},{"type":24,"tag":2279,"props":8445,"children":8446},{"class":3557},[8447],{"type":34,"value":8288},{"type":24,"tag":2279,"props":8449,"children":8450},{"class":3533},[8451],{"type":34,"value":8342},{"type":24,"tag":2279,"props":8453,"children":8454},{"class":3882},[8455],{"type":34,"value":3965},{"type":24,"tag":2279,"props":8457,"children":8458},{"class":3527},[8459],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8461,"children":8462},{"class":3908},[8463],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8465,"children":8466},{"class":3533},[8467],{"type":34,"value":8359},{"type":24,"tag":2279,"props":8469,"children":8471},{"class":3522,"line":8470},64,[8472,8476,8480,8484],{"type":24,"tag":2279,"props":8473,"children":8474},{"class":3533},[8475],{"type":34,"value":8368},{"type":24,"tag":2279,"props":8477,"children":8478},{"class":3882},[8479],{"type":34,"value":6306},{"type":24,"tag":2279,"props":8481,"children":8482},{"class":3527},[8483],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8485,"children":8486},{"class":3533},[8487],{"type":34,"value":8488},"test_sampler)}\n",{"type":24,"tag":2279,"props":8490,"children":8492},{"class":3522,"line":8491},65,[8493,8497,8501],{"type":24,"tag":2279,"props":8494,"children":8495},{"class":3533},[8496],{"type":34,"value":6910},{"type":24,"tag":2279,"props":8498,"children":8499},{"class":3527},[8500],{"type":34,"value":7469},{"type":24,"tag":2279,"props":8502,"children":8503},{"class":3533},[8504],{"type":34,"value":8505}," loaders\n",{"type":24,"tag":2279,"props":8507,"children":8509},{"class":3522,"line":8508},66,[8510],{"type":24,"tag":2279,"props":8511,"children":8512},{},[],{"type":24,"tag":2279,"props":8514,"children":8516},{"class":3522,"line":8515},67,[8517],{"type":24,"tag":2279,"props":8518,"children":8519},{"class":3533},[8520],{"type":34,"value":8025},{"type":24,"tag":2279,"props":8522,"children":8524},{"class":3522,"line":8523},68,[8525,8529,8533,8537,8542],{"type":24,"tag":2279,"props":8526,"children":8527},{"class":3533},[8528],{"type":34,"value":3879},{"type":24,"tag":2279,"props":8530,"children":8531},{"class":3527},[8532],{"type":34,"value":4822},{"type":24,"tag":2279,"props":8534,"children":8535},{"class":3533},[8536],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8538,"children":8539},{"class":4802},[8540],{"type":34,"value":8541},"__get_problem_loader__",{"type":24,"tag":2279,"props":8543,"children":8544},{"class":3533},[8545],{"type":34,"value":8546},"(self, problem_idx):\n",{"type":24,"tag":2279,"props":8548,"children":8550},{"class":3522,"line":8549},69,[8551,8556,8560,8564],{"type":24,"tag":2279,"props":8552,"children":8553},{"class":3533},[8554],{"type":34,"value":8555},"        pbs_ctr ",{"type":24,"tag":2279,"props":8557,"children":8558},{"class":3527},[8559],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8561,"children":8562},{"class":3533},[8563],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8565,"children":8566},{"class":3908},[8567],{"type":34,"value":4891},{"type":24,"tag":2279,"props":8569,"children":8571},{"class":3522,"line":8570},70,[8572,8577,8581,8585],{"type":24,"tag":2279,"props":8573,"children":8574},{"class":3533},[8575],{"type":34,"value":8576},"        chars_ctr ",{"type":24,"tag":2279,"props":8578,"children":8579},{"class":3527},[8580],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8582,"children":8583},{"class":3533},[8584],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8586,"children":8587},{"class":3908},[8588],{"type":34,"value":4891},{"type":24,"tag":2279,"props":8590,"children":8592},{"class":3522,"line":8591},71,[8593,8597,8601,8605,8609,8613,8617],{"type":24,"tag":2279,"props":8594,"children":8595},{"class":3533},[8596],{"type":34,"value":6910},{"type":24,"tag":2279,"props":8598,"children":8599},{"class":3527},[8600],{"type":34,"value":4181},{"type":24,"tag":2279,"props":8602,"children":8603},{"class":3533},[8604],{"type":34,"value":7273},{"type":24,"tag":2279,"props":8606,"children":8607},{"class":3527},[8608],{"type":34,"value":4191},{"type":24,"tag":2279,"props":8610,"children":8611},{"class":3533},[8612],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8614,"children":8615},{"class":3908},[8616],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8618,"children":8619},{"class":3533},[8620],{"type":34,"value":7290},{"type":24,"tag":2279,"props":8622,"children":8624},{"class":3522,"line":8623},72,[8625,8629,8633,8637,8641,8645,8649],{"type":24,"tag":2279,"props":8626,"children":8627},{"class":3533},[8628],{"type":34,"value":7299},{"type":24,"tag":2279,"props":8630,"children":8631},{"class":3527},[8632],{"type":34,"value":5391},{"type":24,"tag":2279,"props":8634,"children":8635},{"class":3533},[8636],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8638,"children":8639},{"class":3527},[8640],{"type":34,"value":5400},{"type":24,"tag":2279,"props":8642,"children":8643},{"class":3533},[8644],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8646,"children":8647},{"class":3908},[8648],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8650,"children":8651},{"class":3533},[8652],{"type":34,"value":8653},".__has_reached__(problem_idx, pbs_ctr, \n",{"type":24,"tag":2279,"props":8655,"children":8657},{"class":3522,"line":8656},73,[8658,8662,8666],{"type":24,"tag":2279,"props":8659,"children":8660},{"class":3533},[8661],{"type":34,"value":7180},{"type":24,"tag":2279,"props":8663,"children":8664},{"class":3908},[8665],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8667,"children":8668},{"class":3533},[8669],{"type":34,"value":8670},".problems_per_alph[alphb]):\n",{"type":24,"tag":2279,"props":8672,"children":8674},{"class":3522,"line":8673},74,[8675,8680,8684,8688,8692],{"type":24,"tag":2279,"props":8676,"children":8677},{"class":3533},[8678],{"type":34,"value":8679},"                pbs_ctr ",{"type":24,"tag":2279,"props":8681,"children":8682},{"class":3527},[8683],{"type":34,"value":5453},{"type":24,"tag":2279,"props":8685,"children":8686},{"class":3533},[8687],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8689,"children":8690},{"class":3908},[8691],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8693,"children":8694},{"class":3533},[8695],{"type":34,"value":7422},{"type":24,"tag":2279,"props":8697,"children":8699},{"class":3522,"line":8698},75,[8700,8705,8709,8713,8717],{"type":24,"tag":2279,"props":8701,"children":8702},{"class":3533},[8703],{"type":34,"value":8704},"                chars_ctr ",{"type":24,"tag":2279,"props":8706,"children":8707},{"class":3527},[8708],{"type":34,"value":5453},{"type":24,"tag":2279,"props":8710,"children":8711},{"class":3533},[8712],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8714,"children":8715},{"class":3908},[8716],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8718,"children":8719},{"class":3533},[8720],{"type":34,"value":8721},".chars_per_alph[alphb]\n",{"type":24,"tag":2279,"props":8723,"children":8725},{"class":3522,"line":8724},76,[8726,8730,8735],{"type":24,"tag":2279,"props":8727,"children":8728},{"class":3533},[8729],{"type":34,"value":7299},{"type":24,"tag":2279,"props":8731,"children":8732},{"class":3527},[8733],{"type":34,"value":8734},"else",{"type":24,"tag":2279,"props":8736,"children":8737},{"class":3533},[8738],{"type":34,"value":4809},{"type":24,"tag":2279,"props":8740,"children":8742},{"class":3522,"line":8741},77,[8743,8748,8752,8756,8760],{"type":24,"tag":2279,"props":8744,"children":8745},{"class":3533},[8746],{"type":34,"value":8747},"                problem_samples_idx ",{"type":24,"tag":2279,"props":8749,"children":8750},{"class":3527},[8751],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8753,"children":8754},{"class":3533},[8755],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8757,"children":8758},{"class":3908},[8759],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8761,"children":8762},{"class":3533},[8763],{"type":34,"value":8764},".__problem_idx_to_samples_idx__(\n",{"type":24,"tag":2279,"props":8766,"children":8768},{"class":3522,"line":8767},78,[8769],{"type":24,"tag":2279,"props":8770,"children":8771},{"class":3533},[8772],{"type":34,"value":8773},"                    problem_idx, alphb, pbs_ctr, chars_ctr)\n",{"type":24,"tag":2279,"props":8775,"children":8777},{"class":3522,"line":8776},79,[8778,8782,8786,8790,8794],{"type":24,"tag":2279,"props":8779,"children":8780},{"class":3533},[8781],{"type":34,"value":7748},{"type":24,"tag":2279,"props":8783,"children":8784},{"class":3527},[8785],{"type":34,"value":7469},{"type":24,"tag":2279,"props":8787,"children":8788},{"class":3533},[8789],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8791,"children":8792},{"class":3908},[8793],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8795,"children":8796},{"class":3533},[8797],{"type":34,"value":8798},".__build_problem_loader_from_samples__(\n",{"type":24,"tag":2279,"props":8800,"children":8802},{"class":3522,"line":8801},80,[8803],{"type":24,"tag":2279,"props":8804,"children":8805},{"class":3533},[8806],{"type":34,"value":8807},"                    problem_samples_idx)\n",{"type":24,"tag":2279,"props":8809,"children":8811},{"class":3522,"line":8810},81,[8812],{"type":24,"tag":2279,"props":8813,"children":8814},{},[],{"type":24,"tag":2279,"props":8816,"children":8818},{"class":3522,"line":8817},82,[8819,8823,8827,8831,8836],{"type":24,"tag":2279,"props":8820,"children":8821},{"class":3533},[8822],{"type":34,"value":3879},{"type":24,"tag":2279,"props":8824,"children":8825},{"class":3527},[8826],{"type":34,"value":4822},{"type":24,"tag":2279,"props":8828,"children":8829},{"class":3533},[8830],{"type":34,"value":4817},{"type":24,"tag":2279,"props":8832,"children":8833},{"class":3908},[8834],{"type":34,"value":8835},"__iter__",{"type":24,"tag":2279,"props":8837,"children":8838},{"class":3533},[8839],{"type":34,"value":7256},{"type":24,"tag":2279,"props":8841,"children":8843},{"class":3522,"line":8842},83,[8844,8848,8852,8857,8861,8865,8869,8873,8877],{"type":24,"tag":2279,"props":8845,"children":8846},{"class":3533},[8847],{"type":34,"value":6910},{"type":24,"tag":2279,"props":8849,"children":8850},{"class":3527},[8851],{"type":34,"value":4181},{"type":24,"tag":2279,"props":8853,"children":8854},{"class":3533},[8855],{"type":34,"value":8856}," imetabatch, metabatch ",{"type":24,"tag":2279,"props":8858,"children":8859},{"class":3527},[8860],{"type":34,"value":4191},{"type":24,"tag":2279,"props":8862,"children":8863},{"class":3533},[8864],{"type":34,"value":2285},{"type":24,"tag":2279,"props":8866,"children":8867},{"class":3908},[8868],{"type":34,"value":6371},{"type":24,"tag":2279,"props":8870,"children":8871},{"class":3533},[8872],{"type":34,"value":4205},{"type":24,"tag":2279,"props":8874,"children":8875},{"class":3908},[8876],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8878,"children":8879},{"class":3533},[8880],{"type":34,"value":8881},".metasampler):\n",{"type":24,"tag":2279,"props":8883,"children":8885},{"class":3522,"line":8884},84,[8886,8891,8895],{"type":24,"tag":2279,"props":8887,"children":8888},{"class":3533},[8889],{"type":34,"value":8890},"            problem_loaders ",{"type":24,"tag":2279,"props":8892,"children":8893},{"class":3527},[8894],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8896,"children":8897},{"class":3533},[8898],{"type":34,"value":4862},{"type":24,"tag":2279,"props":8900,"children":8902},{"class":3522,"line":8901},85,[8903,8907,8911,8915,8919],{"type":24,"tag":2279,"props":8904,"children":8905},{"class":3533},[8906],{"type":34,"value":7299},{"type":24,"tag":2279,"props":8908,"children":8909},{"class":3527},[8910],{"type":34,"value":4181},{"type":24,"tag":2279,"props":8912,"children":8913},{"class":3533},[8914],{"type":34,"value":7563},{"type":24,"tag":2279,"props":8916,"children":8917},{"class":3527},[8918],{"type":34,"value":4191},{"type":24,"tag":2279,"props":8920,"children":8921},{"class":3533},[8922],{"type":34,"value":8923}," metabatch:\n",{"type":24,"tag":2279,"props":8925,"children":8927},{"class":3522,"line":8926},86,[8928,8933,8937],{"type":24,"tag":2279,"props":8929,"children":8930},{"class":3533},[8931],{"type":34,"value":8932},"                problem_loaders.append(",{"type":24,"tag":2279,"props":8934,"children":8935},{"class":3908},[8936],{"type":34,"value":4848},{"type":24,"tag":2279,"props":8938,"children":8939},{"class":3533},[8940],{"type":34,"value":8941},".__get_problem_loader__(problem_idx))\n",{"type":24,"tag":2279,"props":8943,"children":8945},{"class":3522,"line":8944},87,[8946,8950,8955],{"type":24,"tag":2279,"props":8947,"children":8948},{"class":3533},[8949],{"type":34,"value":7299},{"type":24,"tag":2279,"props":8951,"children":8952},{"class":3527},[8953],{"type":34,"value":8954},"yield",{"type":24,"tag":2279,"props":8956,"children":8957},{"class":3533},[8958],{"type":34,"value":8959}," problem_loaders",{"type":24,"tag":46,"props":8961,"children":8962},{},[8963,8965,8974],{"type":34,"value":8964},"We will reimplement the ",{"type":24,"tag":800,"props":8966,"children":8967},{},[8968,8969,8973],{"type":34,"value":3995},{"type":24,"tag":800,"props":8970,"children":8971},{},[8972],{"type":34,"value":5241},{"type":34,"value":3995},{"type":34,"value":8975}," variable by splitting it between the 3 Meta-sets.",{"type":24,"tag":3511,"props":8977,"children":8979},{"code":8978,"language":3514,"meta":10,"className":3515},"chars_per_alphabet = {split: {alph: [char.split('/')[0] for char in characters].count(alph) for alph in metasplits[split].alphabets} for split in metasplits}\n",[8980],{"type":24,"tag":3495,"props":8981,"children":8982},{"__ignoreMap":10},[8983],{"type":24,"tag":2279,"props":8984,"children":8985},{"class":3522,"line":3523},[8986,8990,8994,8999,9003,9007,9011,9015,9019,9023,9027,9031,9035,9039,9043,9048,9052,9057,9061],{"type":24,"tag":2279,"props":8987,"children":8988},{"class":3533},[8989],{"type":34,"value":5163},{"type":24,"tag":2279,"props":8991,"children":8992},{"class":3527},[8993],{"type":34,"value":3866},{"type":24,"tag":2279,"props":8995,"children":8996},{"class":3533},[8997],{"type":34,"value":8998}," {split: {alph: [char.split(",{"type":24,"tag":2279,"props":9000,"children":9001},{"class":3557},[9002],{"type":34,"value":5177},{"type":24,"tag":2279,"props":9004,"children":9005},{"class":3533},[9006],{"type":34,"value":5182},{"type":24,"tag":2279,"props":9008,"children":9009},{"class":3908},[9010],{"type":34,"value":4023},{"type":24,"tag":2279,"props":9012,"children":9013},{"class":3533},[9014],{"type":34,"value":4176},{"type":24,"tag":2279,"props":9016,"children":9017},{"class":3527},[9018],{"type":34,"value":4181},{"type":24,"tag":2279,"props":9020,"children":9021},{"class":3533},[9022],{"type":34,"value":5199},{"type":24,"tag":2279,"props":9024,"children":9025},{"class":3527},[9026],{"type":34,"value":4191},{"type":24,"tag":2279,"props":9028,"children":9029},{"class":3533},[9030],{"type":34,"value":5208},{"type":24,"tag":2279,"props":9032,"children":9033},{"class":3527},[9034],{"type":34,"value":4181},{"type":24,"tag":2279,"props":9036,"children":9037},{"class":3533},[9038],{"type":34,"value":5217},{"type":24,"tag":2279,"props":9040,"children":9041},{"class":3527},[9042],{"type":34,"value":4191},{"type":24,"tag":2279,"props":9044,"children":9045},{"class":3533},[9046],{"type":34,"value":9047}," metasplits[split].alphabets} ",{"type":24,"tag":2279,"props":9049,"children":9050},{"class":3527},[9051],{"type":34,"value":4181},{"type":24,"tag":2279,"props":9053,"children":9054},{"class":3533},[9055],{"type":34,"value":9056}," split ",{"type":24,"tag":2279,"props":9058,"children":9059},{"class":3527},[9060],{"type":34,"value":4191},{"type":24,"tag":2279,"props":9062,"children":9063},{"class":3533},[9064],{"type":34,"value":9065}," metasplits}",{"type":24,"tag":46,"props":9067,"children":9068},{},[9069],{"type":34,"value":9070},"And we will finally initialize a MetaLoader object. We will emulate a Metatrain loader.",{"type":24,"tag":3511,"props":9072,"children":9074},{"code":9073,"language":3514,"meta":10,"className":3515},"metaloader = MetaLoader(base_dataset=omniglot_raw, metabatch_size=metabatch_size, batch_sizes={'train': 8, 'val': 1, 'test': 1}, chars_per_alphabet=chars_per_alphabet['metatrain'], problem_ratios = [0.75, 0.15, 0.1])\n",[9075],{"type":24,"tag":3495,"props":9076,"children":9077},{"__ignoreMap":10},[9078],{"type":24,"tag":2279,"props":9079,"children":9080},{"class":3522,"line":3523},[9081,9086,9090,9095,9100,9104,9108,9113,9117,9122,9127,9131,9136,9140,9144,9148,9152,9156,9160,9164,9168,9172,9176,9180,9185,9189,9193,9198,9202,9207,9212,9216,9220,9224,9228,9232,9236,9240,9244],{"type":24,"tag":2279,"props":9082,"children":9083},{"class":3533},[9084],{"type":34,"value":9085},"metaloader ",{"type":24,"tag":2279,"props":9087,"children":9088},{"class":3527},[9089],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9091,"children":9092},{"class":3533},[9093],{"type":34,"value":9094}," MetaLoader(",{"type":24,"tag":2279,"props":9096,"children":9097},{"class":3882},[9098],{"type":34,"value":9099},"base_dataset",{"type":24,"tag":2279,"props":9101,"children":9102},{"class":3527},[9103],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9105,"children":9106},{"class":3533},[9107],{"type":34,"value":6284},{"type":24,"tag":2279,"props":9109,"children":9110},{"class":3882},[9111],{"type":34,"value":9112},"metabatch_size",{"type":24,"tag":2279,"props":9114,"children":9115},{"class":3527},[9116],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9118,"children":9119},{"class":3533},[9120],{"type":34,"value":9121},"metabatch_size, ",{"type":24,"tag":2279,"props":9123,"children":9124},{"class":3882},[9125],{"type":34,"value":9126},"batch_sizes",{"type":24,"tag":2279,"props":9128,"children":9129},{"class":3527},[9130],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9132,"children":9133},{"class":3533},[9134],{"type":34,"value":9135},"{",{"type":24,"tag":2279,"props":9137,"children":9138},{"class":3557},[9139],{"type":34,"value":8135},{"type":24,"tag":2279,"props":9141,"children":9142},{"class":3533},[9143],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9145,"children":9146},{"class":3908},[9147],{"type":34,"value":2447},{"type":24,"tag":2279,"props":9149,"children":9150},{"class":3533},[9151],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9153,"children":9154},{"class":3557},[9155],{"type":34,"value":8212},{"type":24,"tag":2279,"props":9157,"children":9158},{"class":3533},[9159],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9161,"children":9162},{"class":3908},[9163],{"type":34,"value":2283},{"type":24,"tag":2279,"props":9165,"children":9166},{"class":3533},[9167],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9169,"children":9170},{"class":3557},[9171],{"type":34,"value":8288},{"type":24,"tag":2279,"props":9173,"children":9174},{"class":3533},[9175],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9177,"children":9178},{"class":3908},[9179],{"type":34,"value":2283},{"type":24,"tag":2279,"props":9181,"children":9182},{"class":3533},[9183],{"type":34,"value":9184},"}, ",{"type":24,"tag":2279,"props":9186,"children":9187},{"class":3882},[9188],{"type":34,"value":5241},{"type":24,"tag":2279,"props":9190,"children":9191},{"class":3527},[9192],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9194,"children":9195},{"class":3533},[9196],{"type":34,"value":9197},"chars_per_alphabet[",{"type":24,"tag":2279,"props":9199,"children":9200},{"class":3557},[9201],{"type":34,"value":4988},{"type":24,"tag":2279,"props":9203,"children":9204},{"class":3533},[9205],{"type":34,"value":9206},"], ",{"type":24,"tag":2279,"props":9208,"children":9209},{"class":3882},[9210],{"type":34,"value":9211},"problem_ratios",{"type":24,"tag":2279,"props":9213,"children":9214},{"class":3533},[9215],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9217,"children":9218},{"class":3527},[9219],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9221,"children":9222},{"class":3533},[9223],{"type":34,"value":7030},{"type":24,"tag":2279,"props":9225,"children":9226},{"class":3908},[9227],{"type":34,"value":7035},{"type":24,"tag":2279,"props":9229,"children":9230},{"class":3533},[9231],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9233,"children":9234},{"class":3908},[9235],{"type":34,"value":5025},{"type":24,"tag":2279,"props":9237,"children":9238},{"class":3533},[9239],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9241,"children":9242},{"class":3908},[9243],{"type":34,"value":7052},{"type":24,"tag":2279,"props":9245,"children":9246},{"class":3533},[9247],{"type":34,"value":5088},{"type":24,"tag":46,"props":9249,"children":9250},{},[9251],{"type":34,"value":9252},"Now let's explore the content of a Meta-batch.",{"type":24,"tag":3511,"props":9254,"children":9256},{"code":9255,"language":3514,"meta":10,"className":3515},"metabatch = next(iter(metaloader))\n",[9257],{"type":24,"tag":3495,"props":9258,"children":9259},{"__ignoreMap":10},[9260],{"type":24,"tag":2279,"props":9261,"children":9262},{"class":3522,"line":3523},[9263,9268,9272,9276,9281,9285,9289],{"type":24,"tag":2279,"props":9264,"children":9265},{"class":3533},[9266],{"type":34,"value":9267},"metabatch ",{"type":24,"tag":2279,"props":9269,"children":9270},{"class":3527},[9271],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9273,"children":9274},{"class":3533},[9275],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9277,"children":9278},{"class":3908},[9279],{"type":34,"value":9280},"next",{"type":24,"tag":2279,"props":9282,"children":9283},{"class":3533},[9284],{"type":34,"value":4205},{"type":24,"tag":2279,"props":9286,"children":9287},{"class":3908},[9288],{"type":34,"value":6748},{"type":24,"tag":2279,"props":9290,"children":9291},{"class":3533},[9292],{"type":34,"value":9293},"(metaloader))",{"type":24,"tag":3511,"props":9295,"children":9297},{"code":9296,"language":3514,"meta":10,"className":3515},"metabatch[0]\n",[9298],{"type":24,"tag":3495,"props":9299,"children":9300},{"__ignoreMap":10},[9301],{"type":24,"tag":2279,"props":9302,"children":9303},{"class":3522,"line":3523},[9304,9309,9313],{"type":24,"tag":2279,"props":9305,"children":9306},{"class":3533},[9307],{"type":34,"value":9308},"metabatch[",{"type":24,"tag":2279,"props":9310,"children":9311},{"class":3908},[9312],{"type":34,"value":4023},{"type":24,"tag":2279,"props":9314,"children":9315},{"class":3533},[9316],{"type":34,"value":4028},{"type":24,"tag":3511,"props":9318,"children":9320},{"code":9319},"{'train': \u003Ctorch.utils.data.dataloader.DataLoader at 0x7f1fc92d3fa0>,\n 'val': \u003Ctorch.utils.data.dataloader.DataLoader at 0x7f1fc92d3850>,\n 'test': \u003Ctorch.utils.data.dataloader.DataLoader at 0x7f1fc92d3a90>}\n",[9321],{"type":24,"tag":3495,"props":9322,"children":9323},{"__ignoreMap":10},[9324],{"type":34,"value":9319},{"type":24,"tag":46,"props":9326,"children":9327},{},[9328],{"type":34,"value":9329},"As expected, we successfully got a series of dataloaders for each set at each problem. Now let's check the content of the samples in the problems of the metabatch. This means that we want to plot all the (shuffled) samples of each problem, so we should plot a collection of 8 grids where each grids contains a list of images among 2 samples.",{"type":24,"tag":3511,"props":9331,"children":9333},{"code":9332,"language":3514,"meta":10,"className":3515},"plt.figure(figsize=(15,100))\ncolumns = 8\nfor imb in range(8):\n    for ibatch, batch in enumerate(metabatch[imb]['train']):\n        for isample, sample in enumerate(batch[0]):\n            plt.subplot(40, 8, (imb * 40) + (ibatch * 8) + isample + 1)\n            plt.imshow(sample[0].numpy())\n",[9334],{"type":24,"tag":3495,"props":9335,"children":9336},{"__ignoreMap":10},[9337,9372,9391,9428,9468,9507,9598],{"type":24,"tag":2279,"props":9338,"children":9339},{"class":3522,"line":3523},[9340,9344,9348,9352,9356,9360,9364,9368],{"type":24,"tag":2279,"props":9341,"children":9342},{"class":3533},[9343],{"type":34,"value":6513},{"type":24,"tag":2279,"props":9345,"children":9346},{"class":3882},[9347],{"type":34,"value":6518},{"type":24,"tag":2279,"props":9349,"children":9350},{"class":3527},[9351],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9353,"children":9354},{"class":3533},[9355],{"type":34,"value":4205},{"type":24,"tag":2279,"props":9357,"children":9358},{"class":3908},[9359],{"type":34,"value":2609},{"type":24,"tag":2279,"props":9361,"children":9362},{"class":3533},[9363],{"type":34,"value":6535},{"type":24,"tag":2279,"props":9365,"children":9366},{"class":3908},[9367],{"type":34,"value":4210},{"type":24,"tag":2279,"props":9369,"children":9370},{"class":3533},[9371],{"type":34,"value":6544},{"type":24,"tag":2279,"props":9373,"children":9374},{"class":3522,"line":2808},[9375,9379,9383,9387],{"type":24,"tag":2279,"props":9376,"children":9377},{"class":3533},[9378],{"type":34,"value":6552},{"type":24,"tag":2279,"props":9380,"children":9381},{"class":3527},[9382],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9384,"children":9385},{"class":3533},[9386],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9388,"children":9389},{"class":3908},[9390],{"type":34,"value":5668},{"type":24,"tag":2279,"props":9392,"children":9393},{"class":3522,"line":2817},[9394,9398,9403,9407,9411,9415,9419,9423],{"type":24,"tag":2279,"props":9395,"children":9396},{"class":3527},[9397],{"type":34,"value":4181},{"type":24,"tag":2279,"props":9399,"children":9400},{"class":3533},[9401],{"type":34,"value":9402}," imb ",{"type":24,"tag":2279,"props":9404,"children":9405},{"class":3527},[9406],{"type":34,"value":4191},{"type":24,"tag":2279,"props":9408,"children":9409},{"class":3533},[9410],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9412,"children":9413},{"class":3908},[9414],{"type":34,"value":4200},{"type":24,"tag":2279,"props":9416,"children":9417},{"class":3533},[9418],{"type":34,"value":4205},{"type":24,"tag":2279,"props":9420,"children":9421},{"class":3908},[9422],{"type":34,"value":2447},{"type":24,"tag":2279,"props":9424,"children":9425},{"class":3533},[9426],{"type":34,"value":9427},"):\n",{"type":24,"tag":2279,"props":9429,"children":9430},{"class":3522,"line":3577},[9431,9435,9439,9443,9447,9451,9455,9460,9464],{"type":24,"tag":2279,"props":9432,"children":9433},{"class":3533},[9434],{"type":34,"value":3879},{"type":24,"tag":2279,"props":9436,"children":9437},{"class":3527},[9438],{"type":34,"value":4181},{"type":24,"tag":2279,"props":9440,"children":9441},{"class":3533},[9442],{"type":34,"value":6358},{"type":24,"tag":2279,"props":9444,"children":9445},{"class":3527},[9446],{"type":34,"value":4191},{"type":24,"tag":2279,"props":9448,"children":9449},{"class":3533},[9450],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9452,"children":9453},{"class":3908},[9454],{"type":34,"value":6371},{"type":24,"tag":2279,"props":9456,"children":9457},{"class":3533},[9458],{"type":34,"value":9459},"(metabatch[imb][",{"type":24,"tag":2279,"props":9461,"children":9462},{"class":3557},[9463],{"type":34,"value":8135},{"type":24,"tag":2279,"props":9465,"children":9466},{"class":3533},[9467],{"type":34,"value":6632},{"type":24,"tag":2279,"props":9469,"children":9470},{"class":3522,"line":3725},[9471,9475,9479,9483,9487,9491,9495,9499,9503],{"type":24,"tag":2279,"props":9472,"children":9473},{"class":3533},[9474],{"type":34,"value":6910},{"type":24,"tag":2279,"props":9476,"children":9477},{"class":3527},[9478],{"type":34,"value":4181},{"type":24,"tag":2279,"props":9480,"children":9481},{"class":3533},[9482],{"type":34,"value":6607},{"type":24,"tag":2279,"props":9484,"children":9485},{"class":3527},[9486],{"type":34,"value":4191},{"type":24,"tag":2279,"props":9488,"children":9489},{"class":3533},[9490],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9492,"children":9493},{"class":3908},[9494],{"type":34,"value":6371},{"type":24,"tag":2279,"props":9496,"children":9497},{"class":3533},[9498],{"type":34,"value":6458},{"type":24,"tag":2279,"props":9500,"children":9501},{"class":3908},[9502],{"type":34,"value":4023},{"type":24,"tag":2279,"props":9504,"children":9505},{"class":3533},[9506],{"type":34,"value":6632},{"type":24,"tag":2279,"props":9508,"children":9509},{"class":3522,"line":3747},[9510,9515,9520,9524,9528,9533,9537,9541,9545,9549,9553,9558,9562,9566,9570,9574,9578,9582,9586,9590,9594],{"type":24,"tag":2279,"props":9511,"children":9512},{"class":3533},[9513],{"type":34,"value":9514},"            plt.subplot(",{"type":24,"tag":2279,"props":9516,"children":9517},{"class":3908},[9518],{"type":34,"value":9519},"40",{"type":24,"tag":2279,"props":9521,"children":9522},{"class":3533},[9523],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9525,"children":9526},{"class":3908},[9527],{"type":34,"value":2447},{"type":24,"tag":2279,"props":9529,"children":9530},{"class":3533},[9531],{"type":34,"value":9532},", (imb ",{"type":24,"tag":2279,"props":9534,"children":9535},{"class":3527},[9536],{"type":34,"value":4248},{"type":24,"tag":2279,"props":9538,"children":9539},{"class":3533},[9540],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9542,"children":9543},{"class":3908},[9544],{"type":34,"value":9519},{"type":24,"tag":2279,"props":9546,"children":9547},{"class":3533},[9548],{"type":34,"value":6085},{"type":24,"tag":2279,"props":9550,"children":9551},{"class":3527},[9552],{"type":34,"value":6072},{"type":24,"tag":2279,"props":9554,"children":9555},{"class":3533},[9556],{"type":34,"value":9557}," (ibatch ",{"type":24,"tag":2279,"props":9559,"children":9560},{"class":3527},[9561],{"type":34,"value":4248},{"type":24,"tag":2279,"props":9563,"children":9564},{"class":3533},[9565],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9567,"children":9568},{"class":3908},[9569],{"type":34,"value":2447},{"type":24,"tag":2279,"props":9571,"children":9572},{"class":3533},[9573],{"type":34,"value":6085},{"type":24,"tag":2279,"props":9575,"children":9576},{"class":3527},[9577],{"type":34,"value":6072},{"type":24,"tag":2279,"props":9579,"children":9580},{"class":3533},[9581],{"type":34,"value":6682},{"type":24,"tag":2279,"props":9583,"children":9584},{"class":3527},[9585],{"type":34,"value":6072},{"type":24,"tag":2279,"props":9587,"children":9588},{"class":3533},[9589],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9591,"children":9592},{"class":3908},[9593],{"type":34,"value":2283},{"type":24,"tag":2279,"props":9595,"children":9596},{"class":3533},[9597],{"type":34,"value":6699},{"type":24,"tag":2279,"props":9599,"children":9600},{"class":3522,"line":3769},[9601,9606,9610],{"type":24,"tag":2279,"props":9602,"children":9603},{"class":3533},[9604],{"type":34,"value":9605},"            plt.imshow(sample[",{"type":24,"tag":2279,"props":9607,"children":9608},{"class":3908},[9609],{"type":34,"value":4023},{"type":24,"tag":2279,"props":9611,"children":9612},{"class":3533},[9613],{"type":34,"value":4126},{"type":24,"tag":46,"props":9615,"children":9616},{},[9617],{"type":24,"tag":175,"props":9618,"children":9621},{"alt":9619,"src":9620},"metabatch","https://i.imgur.com/p79tpSr.png",[],{"type":24,"tag":46,"props":9623,"children":9624},{},[9625],{"type":34,"value":9626},"So we again got what we expected. Thus, we will finally define our MetaLoaders.",{"type":24,"tag":3511,"props":9628,"children":9630},{"code":9629,"language":3514,"meta":10,"className":3515},"metatrain_loader = MetaLoader(base_dataset=omniglot_raw, metabatch_size=metabatch_size, batch_sizes={'train': 8, 'val': 1, 'test': 1}, chars_per_alphabet=chars_per_alphabet['metatrain'], problem_ratios = [0.75, 0.15, 0.1])\nmetaval_loader = MetaLoader(base_dataset=omniglot_raw, metabatch_size=metabatch_size, batch_sizes={'train': 8, 'val': 1, 'test': 1}, chars_per_alphabet=chars_per_alphabet['metaval'], problem_ratios = [0.75, 0.15, 0.1])\nmetatest_loader = MetaLoader(base_dataset=omniglot_raw, metabatch_size=1, batch_sizes={'train': 8, 'val': 1, 'test': 1}, chars_per_alphabet=chars_per_alphabet['metatest'], problem_ratios = [0.75, 0.15, 0.1])\n",[9631],{"type":24,"tag":3495,"props":9632,"children":9633},{"__ignoreMap":10},[9634,9794,9954],{"type":24,"tag":2279,"props":9635,"children":9636},{"class":3522,"line":3523},[9637,9642,9646,9650,9654,9658,9662,9666,9670,9674,9678,9682,9686,9690,9694,9698,9702,9706,9710,9714,9718,9722,9726,9730,9734,9738,9742,9746,9750,9754,9758,9762,9766,9770,9774,9778,9782,9786,9790],{"type":24,"tag":2279,"props":9638,"children":9639},{"class":3533},[9640],{"type":34,"value":9641},"metatrain_loader ",{"type":24,"tag":2279,"props":9643,"children":9644},{"class":3527},[9645],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9647,"children":9648},{"class":3533},[9649],{"type":34,"value":9094},{"type":24,"tag":2279,"props":9651,"children":9652},{"class":3882},[9653],{"type":34,"value":9099},{"type":24,"tag":2279,"props":9655,"children":9656},{"class":3527},[9657],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9659,"children":9660},{"class":3533},[9661],{"type":34,"value":6284},{"type":24,"tag":2279,"props":9663,"children":9664},{"class":3882},[9665],{"type":34,"value":9112},{"type":24,"tag":2279,"props":9667,"children":9668},{"class":3527},[9669],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9671,"children":9672},{"class":3533},[9673],{"type":34,"value":9121},{"type":24,"tag":2279,"props":9675,"children":9676},{"class":3882},[9677],{"type":34,"value":9126},{"type":24,"tag":2279,"props":9679,"children":9680},{"class":3527},[9681],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9683,"children":9684},{"class":3533},[9685],{"type":34,"value":9135},{"type":24,"tag":2279,"props":9687,"children":9688},{"class":3557},[9689],{"type":34,"value":8135},{"type":24,"tag":2279,"props":9691,"children":9692},{"class":3533},[9693],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9695,"children":9696},{"class":3908},[9697],{"type":34,"value":2447},{"type":24,"tag":2279,"props":9699,"children":9700},{"class":3533},[9701],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9703,"children":9704},{"class":3557},[9705],{"type":34,"value":8212},{"type":24,"tag":2279,"props":9707,"children":9708},{"class":3533},[9709],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9711,"children":9712},{"class":3908},[9713],{"type":34,"value":2283},{"type":24,"tag":2279,"props":9715,"children":9716},{"class":3533},[9717],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9719,"children":9720},{"class":3557},[9721],{"type":34,"value":8288},{"type":24,"tag":2279,"props":9723,"children":9724},{"class":3533},[9725],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9727,"children":9728},{"class":3908},[9729],{"type":34,"value":2283},{"type":24,"tag":2279,"props":9731,"children":9732},{"class":3533},[9733],{"type":34,"value":9184},{"type":24,"tag":2279,"props":9735,"children":9736},{"class":3882},[9737],{"type":34,"value":5241},{"type":24,"tag":2279,"props":9739,"children":9740},{"class":3527},[9741],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9743,"children":9744},{"class":3533},[9745],{"type":34,"value":9197},{"type":24,"tag":2279,"props":9747,"children":9748},{"class":3557},[9749],{"type":34,"value":4988},{"type":24,"tag":2279,"props":9751,"children":9752},{"class":3533},[9753],{"type":34,"value":9206},{"type":24,"tag":2279,"props":9755,"children":9756},{"class":3882},[9757],{"type":34,"value":9211},{"type":24,"tag":2279,"props":9759,"children":9760},{"class":3533},[9761],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9763,"children":9764},{"class":3527},[9765],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9767,"children":9768},{"class":3533},[9769],{"type":34,"value":7030},{"type":24,"tag":2279,"props":9771,"children":9772},{"class":3908},[9773],{"type":34,"value":7035},{"type":24,"tag":2279,"props":9775,"children":9776},{"class":3533},[9777],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9779,"children":9780},{"class":3908},[9781],{"type":34,"value":5025},{"type":24,"tag":2279,"props":9783,"children":9784},{"class":3533},[9785],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9787,"children":9788},{"class":3908},[9789],{"type":34,"value":7052},{"type":24,"tag":2279,"props":9791,"children":9792},{"class":3533},[9793],{"type":34,"value":7941},{"type":24,"tag":2279,"props":9795,"children":9796},{"class":3522,"line":2808},[9797,9802,9806,9810,9814,9818,9822,9826,9830,9834,9838,9842,9846,9850,9854,9858,9862,9866,9870,9874,9878,9882,9886,9890,9894,9898,9902,9906,9910,9914,9918,9922,9926,9930,9934,9938,9942,9946,9950],{"type":24,"tag":2279,"props":9798,"children":9799},{"class":3533},[9800],{"type":34,"value":9801},"metaval_loader ",{"type":24,"tag":2279,"props":9803,"children":9804},{"class":3527},[9805],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9807,"children":9808},{"class":3533},[9809],{"type":34,"value":9094},{"type":24,"tag":2279,"props":9811,"children":9812},{"class":3882},[9813],{"type":34,"value":9099},{"type":24,"tag":2279,"props":9815,"children":9816},{"class":3527},[9817],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9819,"children":9820},{"class":3533},[9821],{"type":34,"value":6284},{"type":24,"tag":2279,"props":9823,"children":9824},{"class":3882},[9825],{"type":34,"value":9112},{"type":24,"tag":2279,"props":9827,"children":9828},{"class":3527},[9829],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9831,"children":9832},{"class":3533},[9833],{"type":34,"value":9121},{"type":24,"tag":2279,"props":9835,"children":9836},{"class":3882},[9837],{"type":34,"value":9126},{"type":24,"tag":2279,"props":9839,"children":9840},{"class":3527},[9841],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9843,"children":9844},{"class":3533},[9845],{"type":34,"value":9135},{"type":24,"tag":2279,"props":9847,"children":9848},{"class":3557},[9849],{"type":34,"value":8135},{"type":24,"tag":2279,"props":9851,"children":9852},{"class":3533},[9853],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9855,"children":9856},{"class":3908},[9857],{"type":34,"value":2447},{"type":24,"tag":2279,"props":9859,"children":9860},{"class":3533},[9861],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9863,"children":9864},{"class":3557},[9865],{"type":34,"value":8212},{"type":24,"tag":2279,"props":9867,"children":9868},{"class":3533},[9869],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9871,"children":9872},{"class":3908},[9873],{"type":34,"value":2283},{"type":24,"tag":2279,"props":9875,"children":9876},{"class":3533},[9877],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9879,"children":9880},{"class":3557},[9881],{"type":34,"value":8288},{"type":24,"tag":2279,"props":9883,"children":9884},{"class":3533},[9885],{"type":34,"value":5327},{"type":24,"tag":2279,"props":9887,"children":9888},{"class":3908},[9889],{"type":34,"value":2283},{"type":24,"tag":2279,"props":9891,"children":9892},{"class":3533},[9893],{"type":34,"value":9184},{"type":24,"tag":2279,"props":9895,"children":9896},{"class":3882},[9897],{"type":34,"value":5241},{"type":24,"tag":2279,"props":9899,"children":9900},{"class":3527},[9901],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9903,"children":9904},{"class":3533},[9905],{"type":34,"value":9197},{"type":24,"tag":2279,"props":9907,"children":9908},{"class":3557},[9909],{"type":34,"value":5016},{"type":24,"tag":2279,"props":9911,"children":9912},{"class":3533},[9913],{"type":34,"value":9206},{"type":24,"tag":2279,"props":9915,"children":9916},{"class":3882},[9917],{"type":34,"value":9211},{"type":24,"tag":2279,"props":9919,"children":9920},{"class":3533},[9921],{"type":34,"value":2285},{"type":24,"tag":2279,"props":9923,"children":9924},{"class":3527},[9925],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9927,"children":9928},{"class":3533},[9929],{"type":34,"value":7030},{"type":24,"tag":2279,"props":9931,"children":9932},{"class":3908},[9933],{"type":34,"value":7035},{"type":24,"tag":2279,"props":9935,"children":9936},{"class":3533},[9937],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9939,"children":9940},{"class":3908},[9941],{"type":34,"value":5025},{"type":24,"tag":2279,"props":9943,"children":9944},{"class":3533},[9945],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9947,"children":9948},{"class":3908},[9949],{"type":34,"value":7052},{"type":24,"tag":2279,"props":9951,"children":9952},{"class":3533},[9953],{"type":34,"value":7941},{"type":24,"tag":2279,"props":9955,"children":9956},{"class":3522,"line":2817},[9957,9962,9966,9970,9974,9978,9982,9986,9990,9994,9998,10002,10006,10010,10014,10018,10022,10026,10030,10034,10038,10042,10046,10050,10054,10058,10062,10066,10070,10074,10078,10082,10086,10090,10094,10098,10102,10106,10110,10114],{"type":24,"tag":2279,"props":9958,"children":9959},{"class":3533},[9960],{"type":34,"value":9961},"metatest_loader ",{"type":24,"tag":2279,"props":9963,"children":9964},{"class":3527},[9965],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9967,"children":9968},{"class":3533},[9969],{"type":34,"value":9094},{"type":24,"tag":2279,"props":9971,"children":9972},{"class":3882},[9973],{"type":34,"value":9099},{"type":24,"tag":2279,"props":9975,"children":9976},{"class":3527},[9977],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9979,"children":9980},{"class":3533},[9981],{"type":34,"value":6284},{"type":24,"tag":2279,"props":9983,"children":9984},{"class":3882},[9985],{"type":34,"value":9112},{"type":24,"tag":2279,"props":9987,"children":9988},{"class":3527},[9989],{"type":34,"value":3866},{"type":24,"tag":2279,"props":9991,"children":9992},{"class":3908},[9993],{"type":34,"value":2283},{"type":24,"tag":2279,"props":9995,"children":9996},{"class":3533},[9997],{"type":34,"value":1340},{"type":24,"tag":2279,"props":9999,"children":10000},{"class":3882},[10001],{"type":34,"value":9126},{"type":24,"tag":2279,"props":10003,"children":10004},{"class":3527},[10005],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10007,"children":10008},{"class":3533},[10009],{"type":34,"value":9135},{"type":24,"tag":2279,"props":10011,"children":10012},{"class":3557},[10013],{"type":34,"value":8135},{"type":24,"tag":2279,"props":10015,"children":10016},{"class":3533},[10017],{"type":34,"value":5327},{"type":24,"tag":2279,"props":10019,"children":10020},{"class":3908},[10021],{"type":34,"value":2447},{"type":24,"tag":2279,"props":10023,"children":10024},{"class":3533},[10025],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10027,"children":10028},{"class":3557},[10029],{"type":34,"value":8212},{"type":24,"tag":2279,"props":10031,"children":10032},{"class":3533},[10033],{"type":34,"value":5327},{"type":24,"tag":2279,"props":10035,"children":10036},{"class":3908},[10037],{"type":34,"value":2283},{"type":24,"tag":2279,"props":10039,"children":10040},{"class":3533},[10041],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10043,"children":10044},{"class":3557},[10045],{"type":34,"value":8288},{"type":24,"tag":2279,"props":10047,"children":10048},{"class":3533},[10049],{"type":34,"value":5327},{"type":24,"tag":2279,"props":10051,"children":10052},{"class":3908},[10053],{"type":34,"value":2283},{"type":24,"tag":2279,"props":10055,"children":10056},{"class":3533},[10057],{"type":34,"value":9184},{"type":24,"tag":2279,"props":10059,"children":10060},{"class":3882},[10061],{"type":34,"value":5241},{"type":24,"tag":2279,"props":10063,"children":10064},{"class":3527},[10065],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10067,"children":10068},{"class":3533},[10069],{"type":34,"value":9197},{"type":24,"tag":2279,"props":10071,"children":10072},{"class":3557},[10073],{"type":34,"value":5041},{"type":24,"tag":2279,"props":10075,"children":10076},{"class":3533},[10077],{"type":34,"value":9206},{"type":24,"tag":2279,"props":10079,"children":10080},{"class":3882},[10081],{"type":34,"value":9211},{"type":24,"tag":2279,"props":10083,"children":10084},{"class":3533},[10085],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10087,"children":10088},{"class":3527},[10089],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10091,"children":10092},{"class":3533},[10093],{"type":34,"value":7030},{"type":24,"tag":2279,"props":10095,"children":10096},{"class":3908},[10097],{"type":34,"value":7035},{"type":24,"tag":2279,"props":10099,"children":10100},{"class":3533},[10101],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10103,"children":10104},{"class":3908},[10105],{"type":34,"value":5025},{"type":24,"tag":2279,"props":10107,"children":10108},{"class":3533},[10109],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10111,"children":10112},{"class":3908},[10113],{"type":34,"value":7052},{"type":24,"tag":2279,"props":10115,"children":10116},{"class":3533},[10117],{"type":34,"value":5088},{"type":24,"tag":1378,"props":10119,"children":10121},{"id":10120},"training-a-model-in-a-problem",[10122],{"type":34,"value":10123},"Training a model in a problem",{"type":24,"tag":46,"props":10125,"children":10126},{},[10127],{"type":34,"value":10128},"So at this point we are ready to use a single problem extracted from the train MetaLoader and train a model on it. First, we should get our DataLoaders",{"type":24,"tag":3511,"props":10130,"children":10132},{"code":10131,"language":3514,"meta":10,"className":3515},"toy_metabatch = next(iter(metatrain_loader))\n",[10133],{"type":24,"tag":3495,"props":10134,"children":10135},{"__ignoreMap":10},[10136],{"type":24,"tag":2279,"props":10137,"children":10138},{"class":3522,"line":3523},[10139,10144,10148,10152,10156,10160,10164],{"type":24,"tag":2279,"props":10140,"children":10141},{"class":3533},[10142],{"type":34,"value":10143},"toy_metabatch ",{"type":24,"tag":2279,"props":10145,"children":10146},{"class":3527},[10147],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10149,"children":10150},{"class":3533},[10151],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10153,"children":10154},{"class":3908},[10155],{"type":34,"value":9280},{"type":24,"tag":2279,"props":10157,"children":10158},{"class":3533},[10159],{"type":34,"value":4205},{"type":24,"tag":2279,"props":10161,"children":10162},{"class":3908},[10163],{"type":34,"value":6748},{"type":24,"tag":2279,"props":10165,"children":10166},{"class":3533},[10167],{"type":34,"value":10168},"(metatrain_loader))",{"type":24,"tag":3511,"props":10170,"children":10172},{"code":10171,"language":3514,"meta":10,"className":3515},"toy_problem_loader = toy_metabatch[0]['train']\ntoy_problem_loader_val = toy_metabatch[0]['val']\ntoy_problem_loader_test = toy_metabatch[0]['test']\n",[10173],{"type":24,"tag":3495,"props":10174,"children":10175},{"__ignoreMap":10},[10176,10209,10241],{"type":24,"tag":2279,"props":10177,"children":10178},{"class":3522,"line":3523},[10179,10184,10188,10193,10197,10201,10205],{"type":24,"tag":2279,"props":10180,"children":10181},{"class":3533},[10182],{"type":34,"value":10183},"toy_problem_loader ",{"type":24,"tag":2279,"props":10185,"children":10186},{"class":3527},[10187],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10189,"children":10190},{"class":3533},[10191],{"type":34,"value":10192}," toy_metabatch[",{"type":24,"tag":2279,"props":10194,"children":10195},{"class":3908},[10196],{"type":34,"value":4023},{"type":24,"tag":2279,"props":10198,"children":10199},{"class":3533},[10200],{"type":34,"value":4064},{"type":24,"tag":2279,"props":10202,"children":10203},{"class":3557},[10204],{"type":34,"value":8135},{"type":24,"tag":2279,"props":10206,"children":10207},{"class":3533},[10208],{"type":34,"value":7057},{"type":24,"tag":2279,"props":10210,"children":10211},{"class":3522,"line":2808},[10212,10217,10221,10225,10229,10233,10237],{"type":24,"tag":2279,"props":10213,"children":10214},{"class":3533},[10215],{"type":34,"value":10216},"toy_problem_loader_val ",{"type":24,"tag":2279,"props":10218,"children":10219},{"class":3527},[10220],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10222,"children":10223},{"class":3533},[10224],{"type":34,"value":10192},{"type":24,"tag":2279,"props":10226,"children":10227},{"class":3908},[10228],{"type":34,"value":4023},{"type":24,"tag":2279,"props":10230,"children":10231},{"class":3533},[10232],{"type":34,"value":4064},{"type":24,"tag":2279,"props":10234,"children":10235},{"class":3557},[10236],{"type":34,"value":8212},{"type":24,"tag":2279,"props":10238,"children":10239},{"class":3533},[10240],{"type":34,"value":7057},{"type":24,"tag":2279,"props":10242,"children":10243},{"class":3522,"line":2817},[10244,10249,10253,10257,10261,10265,10269],{"type":24,"tag":2279,"props":10245,"children":10246},{"class":3533},[10247],{"type":34,"value":10248},"toy_problem_loader_test ",{"type":24,"tag":2279,"props":10250,"children":10251},{"class":3527},[10252],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10254,"children":10255},{"class":3533},[10256],{"type":34,"value":10192},{"type":24,"tag":2279,"props":10258,"children":10259},{"class":3908},[10260],{"type":34,"value":4023},{"type":24,"tag":2279,"props":10262,"children":10263},{"class":3533},[10264],{"type":34,"value":4064},{"type":24,"tag":2279,"props":10266,"children":10267},{"class":3557},[10268],{"type":34,"value":8288},{"type":24,"tag":2279,"props":10270,"children":10271},{"class":3533},[10272],{"type":34,"value":4028},{"type":24,"tag":3511,"props":10274,"children":10276},{"code":10275,"language":3514,"meta":10,"className":3515},"for i, data in enumerate(toy_problem_loader, 0):\n    for isample, sample in enumerate(data[0]):\n        plt.subplot(3, 8, (i * 8) + isample + 1)\n        plt.imshow(sample[0].numpy())\n",[10277],{"type":24,"tag":3495,"props":10278,"children":10279},{"__ignoreMap":10},[10280,10317,10357,10422],{"type":24,"tag":2279,"props":10281,"children":10282},{"class":3522,"line":3523},[10283,10287,10292,10296,10300,10304,10309,10313],{"type":24,"tag":2279,"props":10284,"children":10285},{"class":3527},[10286],{"type":34,"value":4181},{"type":24,"tag":2279,"props":10288,"children":10289},{"class":3533},[10290],{"type":34,"value":10291}," i, data ",{"type":24,"tag":2279,"props":10293,"children":10294},{"class":3527},[10295],{"type":34,"value":4191},{"type":24,"tag":2279,"props":10297,"children":10298},{"class":3533},[10299],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10301,"children":10302},{"class":3908},[10303],{"type":34,"value":6371},{"type":24,"tag":2279,"props":10305,"children":10306},{"class":3533},[10307],{"type":34,"value":10308},"(toy_problem_loader, ",{"type":24,"tag":2279,"props":10310,"children":10311},{"class":3908},[10312],{"type":34,"value":4023},{"type":24,"tag":2279,"props":10314,"children":10315},{"class":3533},[10316],{"type":34,"value":9427},{"type":24,"tag":2279,"props":10318,"children":10319},{"class":3522,"line":2808},[10320,10324,10328,10332,10336,10340,10344,10349,10353],{"type":24,"tag":2279,"props":10321,"children":10322},{"class":3533},[10323],{"type":34,"value":3879},{"type":24,"tag":2279,"props":10325,"children":10326},{"class":3527},[10327],{"type":34,"value":4181},{"type":24,"tag":2279,"props":10329,"children":10330},{"class":3533},[10331],{"type":34,"value":6607},{"type":24,"tag":2279,"props":10333,"children":10334},{"class":3527},[10335],{"type":34,"value":4191},{"type":24,"tag":2279,"props":10337,"children":10338},{"class":3533},[10339],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10341,"children":10342},{"class":3908},[10343],{"type":34,"value":6371},{"type":24,"tag":2279,"props":10345,"children":10346},{"class":3533},[10347],{"type":34,"value":10348},"(data[",{"type":24,"tag":2279,"props":10350,"children":10351},{"class":3908},[10352],{"type":34,"value":4023},{"type":24,"tag":2279,"props":10354,"children":10355},{"class":3533},[10356],{"type":34,"value":6632},{"type":24,"tag":2279,"props":10358,"children":10359},{"class":3522,"line":2817},[10360,10365,10369,10373,10377,10382,10386,10390,10394,10398,10402,10406,10410,10414,10418],{"type":24,"tag":2279,"props":10361,"children":10362},{"class":3533},[10363],{"type":34,"value":10364},"        plt.subplot(",{"type":24,"tag":2279,"props":10366,"children":10367},{"class":3908},[10368],{"type":34,"value":2331},{"type":24,"tag":2279,"props":10370,"children":10371},{"class":3533},[10372],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10374,"children":10375},{"class":3908},[10376],{"type":34,"value":2447},{"type":24,"tag":2279,"props":10378,"children":10379},{"class":3533},[10380],{"type":34,"value":10381},", (i ",{"type":24,"tag":2279,"props":10383,"children":10384},{"class":3527},[10385],{"type":34,"value":4248},{"type":24,"tag":2279,"props":10387,"children":10388},{"class":3533},[10389],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10391,"children":10392},{"class":3908},[10393],{"type":34,"value":2447},{"type":24,"tag":2279,"props":10395,"children":10396},{"class":3533},[10397],{"type":34,"value":6085},{"type":24,"tag":2279,"props":10399,"children":10400},{"class":3527},[10401],{"type":34,"value":6072},{"type":24,"tag":2279,"props":10403,"children":10404},{"class":3533},[10405],{"type":34,"value":6682},{"type":24,"tag":2279,"props":10407,"children":10408},{"class":3527},[10409],{"type":34,"value":6072},{"type":24,"tag":2279,"props":10411,"children":10412},{"class":3533},[10413],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10415,"children":10416},{"class":3908},[10417],{"type":34,"value":2283},{"type":24,"tag":2279,"props":10419,"children":10420},{"class":3533},[10421],{"type":34,"value":6699},{"type":24,"tag":2279,"props":10423,"children":10424},{"class":3522,"line":3577},[10425,10430,10434],{"type":24,"tag":2279,"props":10426,"children":10427},{"class":3533},[10428],{"type":34,"value":10429},"        plt.imshow(sample[",{"type":24,"tag":2279,"props":10431,"children":10432},{"class":3908},[10433],{"type":34,"value":4023},{"type":24,"tag":2279,"props":10435,"children":10436},{"class":3533},[10437],{"type":34,"value":4126},{"type":24,"tag":46,"props":10439,"children":10440},{},[10441],{"type":24,"tag":175,"props":10442,"children":10445},{"alt":10443,"src":10444},"toyproblem","https://i.imgur.com/CkA6Zs9.png",[],{"type":24,"tag":46,"props":10447,"children":10448},{},[10449],{"type":34,"value":10450},"Now we will define a Simple Neural network (it should be enough for the simple 105x105 character classification problems).",{"type":24,"tag":3511,"props":10452,"children":10454},{"code":10453,"language":3514,"meta":10,"className":3515},"class SimpleNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 10, 5)\n        self.conv3 = nn.Conv2d(10, 12, 5)\n        self.conv4 = nn.Conv2d(12, 16, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(16 * 2 * 2, 10)\n        self.fc2 = nn.Linear(10, 1)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.sigmoid(self.fc2(x))\n        x = x.squeeze()\n        return x\n",[10455],{"type":24,"tag":3495,"props":10456,"children":10457},{"__ignoreMap":10},[10458,10496,10519,10545,10594,10642,10690,10738,10779,10852,10892,10898,10923,10957,10989,11021,11053,11077,11102,11127,11143],{"type":24,"tag":2279,"props":10459,"children":10460},{"class":3522,"line":3523},[10461,10465,10469,10474,10478,10483,10487,10492],{"type":24,"tag":2279,"props":10462,"children":10463},{"class":3527},[10464],{"type":34,"value":4795},{"type":24,"tag":2279,"props":10466,"children":10467},{"class":3533},[10468],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10470,"children":10471},{"class":4802},[10472],{"type":34,"value":10473},"SimpleNet",{"type":24,"tag":2279,"props":10475,"children":10476},{"class":3533},[10477],{"type":34,"value":4205},{"type":24,"tag":2279,"props":10479,"children":10480},{"class":4802},[10481],{"type":34,"value":10482},"nn",{"type":24,"tag":2279,"props":10484,"children":10485},{"class":3533},[10486],{"type":34,"value":170},{"type":24,"tag":2279,"props":10488,"children":10489},{"class":4802},[10490],{"type":34,"value":10491},"Module",{"type":24,"tag":2279,"props":10493,"children":10494},{"class":3533},[10495],{"type":34,"value":9427},{"type":24,"tag":2279,"props":10497,"children":10498},{"class":3522,"line":2808},[10499,10503,10507,10511,10515],{"type":24,"tag":2279,"props":10500,"children":10501},{"class":3533},[10502],{"type":34,"value":3879},{"type":24,"tag":2279,"props":10504,"children":10505},{"class":3527},[10506],{"type":34,"value":4822},{"type":24,"tag":2279,"props":10508,"children":10509},{"class":3533},[10510],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10512,"children":10513},{"class":3908},[10514],{"type":34,"value":4831},{"type":24,"tag":2279,"props":10516,"children":10517},{"class":3533},[10518],{"type":34,"value":7256},{"type":24,"tag":2279,"props":10520,"children":10521},{"class":3522,"line":2817},[10522,10526,10531,10536,10540],{"type":24,"tag":2279,"props":10523,"children":10524},{"class":3533},[10525],{"type":34,"value":6910},{"type":24,"tag":2279,"props":10527,"children":10528},{"class":3908},[10529],{"type":34,"value":10530},"super",{"type":24,"tag":2279,"props":10532,"children":10533},{"class":3533},[10534],{"type":34,"value":10535},"().",{"type":24,"tag":2279,"props":10537,"children":10538},{"class":3908},[10539],{"type":34,"value":4831},{"type":24,"tag":2279,"props":10541,"children":10542},{"class":3533},[10543],{"type":34,"value":10544},"()\n",{"type":24,"tag":2279,"props":10546,"children":10547},{"class":3522,"line":3577},[10548,10552,10556,10561,10565,10570,10574,10578,10582,10586,10590],{"type":24,"tag":2279,"props":10549,"children":10550},{"class":3533},[10551],{"type":34,"value":6910},{"type":24,"tag":2279,"props":10553,"children":10554},{"class":3908},[10555],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10557,"children":10558},{"class":3533},[10559],{"type":34,"value":10560},".conv1 ",{"type":24,"tag":2279,"props":10562,"children":10563},{"class":3527},[10564],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10566,"children":10567},{"class":3533},[10568],{"type":34,"value":10569}," nn.Conv2d(",{"type":24,"tag":2279,"props":10571,"children":10572},{"class":3908},[10573],{"type":34,"value":2283},{"type":24,"tag":2279,"props":10575,"children":10576},{"class":3533},[10577],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10579,"children":10580},{"class":3908},[10581],{"type":34,"value":2401},{"type":24,"tag":2279,"props":10583,"children":10584},{"class":3533},[10585],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10587,"children":10588},{"class":3908},[10589],{"type":34,"value":2378},{"type":24,"tag":2279,"props":10591,"children":10592},{"class":3533},[10593],{"type":34,"value":6699},{"type":24,"tag":2279,"props":10595,"children":10596},{"class":3522,"line":3725},[10597,10601,10605,10610,10614,10618,10622,10626,10630,10634,10638],{"type":24,"tag":2279,"props":10598,"children":10599},{"class":3533},[10600],{"type":34,"value":6910},{"type":24,"tag":2279,"props":10602,"children":10603},{"class":3908},[10604],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10606,"children":10607},{"class":3533},[10608],{"type":34,"value":10609},".conv2 ",{"type":24,"tag":2279,"props":10611,"children":10612},{"class":3527},[10613],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10615,"children":10616},{"class":3533},[10617],{"type":34,"value":10569},{"type":24,"tag":2279,"props":10619,"children":10620},{"class":3908},[10621],{"type":34,"value":2401},{"type":24,"tag":2279,"props":10623,"children":10624},{"class":3533},[10625],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10627,"children":10628},{"class":3908},[10629],{"type":34,"value":2493},{"type":24,"tag":2279,"props":10631,"children":10632},{"class":3533},[10633],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10635,"children":10636},{"class":3908},[10637],{"type":34,"value":2378},{"type":24,"tag":2279,"props":10639,"children":10640},{"class":3533},[10641],{"type":34,"value":6699},{"type":24,"tag":2279,"props":10643,"children":10644},{"class":3522,"line":3747},[10645,10649,10653,10658,10662,10666,10670,10674,10678,10682,10686],{"type":24,"tag":2279,"props":10646,"children":10647},{"class":3533},[10648],{"type":34,"value":6910},{"type":24,"tag":2279,"props":10650,"children":10651},{"class":3908},[10652],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10654,"children":10655},{"class":3533},[10656],{"type":34,"value":10657},".conv3 ",{"type":24,"tag":2279,"props":10659,"children":10660},{"class":3527},[10661],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10663,"children":10664},{"class":3533},[10665],{"type":34,"value":10569},{"type":24,"tag":2279,"props":10667,"children":10668},{"class":3908},[10669],{"type":34,"value":2493},{"type":24,"tag":2279,"props":10671,"children":10672},{"class":3533},[10673],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10675,"children":10676},{"class":3908},[10677],{"type":34,"value":2540},{"type":24,"tag":2279,"props":10679,"children":10680},{"class":3533},[10681],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10683,"children":10684},{"class":3908},[10685],{"type":34,"value":2378},{"type":24,"tag":2279,"props":10687,"children":10688},{"class":3533},[10689],{"type":34,"value":6699},{"type":24,"tag":2279,"props":10691,"children":10692},{"class":3522,"line":3769},[10693,10697,10701,10706,10710,10714,10718,10722,10726,10730,10734],{"type":24,"tag":2279,"props":10694,"children":10695},{"class":3533},[10696],{"type":34,"value":6910},{"type":24,"tag":2279,"props":10698,"children":10699},{"class":3908},[10700],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10702,"children":10703},{"class":3533},[10704],{"type":34,"value":10705},".conv4 ",{"type":24,"tag":2279,"props":10707,"children":10708},{"class":3527},[10709],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10711,"children":10712},{"class":3533},[10713],{"type":34,"value":10569},{"type":24,"tag":2279,"props":10715,"children":10716},{"class":3908},[10717],{"type":34,"value":2540},{"type":24,"tag":2279,"props":10719,"children":10720},{"class":3533},[10721],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10723,"children":10724},{"class":3908},[10725],{"type":34,"value":2632},{"type":24,"tag":2279,"props":10727,"children":10728},{"class":3533},[10729],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10731,"children":10732},{"class":3908},[10733],{"type":34,"value":2378},{"type":24,"tag":2279,"props":10735,"children":10736},{"class":3533},[10737],{"type":34,"value":6699},{"type":24,"tag":2279,"props":10739,"children":10740},{"class":3522,"line":3782},[10741,10745,10749,10754,10758,10763,10767,10771,10775],{"type":24,"tag":2279,"props":10742,"children":10743},{"class":3533},[10744],{"type":34,"value":6910},{"type":24,"tag":2279,"props":10746,"children":10747},{"class":3908},[10748],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10750,"children":10751},{"class":3533},[10752],{"type":34,"value":10753},".pool ",{"type":24,"tag":2279,"props":10755,"children":10756},{"class":3527},[10757],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10759,"children":10760},{"class":3533},[10761],{"type":34,"value":10762}," nn.MaxPool2d(",{"type":24,"tag":2279,"props":10764,"children":10765},{"class":3908},[10766],{"type":34,"value":2308},{"type":24,"tag":2279,"props":10768,"children":10769},{"class":3533},[10770],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10772,"children":10773},{"class":3908},[10774],{"type":34,"value":2308},{"type":24,"tag":2279,"props":10776,"children":10777},{"class":3533},[10778],{"type":34,"value":6699},{"type":24,"tag":2279,"props":10780,"children":10781},{"class":3522,"line":6981},[10782,10786,10790,10795,10799,10804,10808,10812,10816,10820,10824,10828,10832,10836,10840,10844,10848],{"type":24,"tag":2279,"props":10783,"children":10784},{"class":3533},[10785],{"type":34,"value":6910},{"type":24,"tag":2279,"props":10787,"children":10788},{"class":3908},[10789],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10791,"children":10792},{"class":3533},[10793],{"type":34,"value":10794},".fc1 ",{"type":24,"tag":2279,"props":10796,"children":10797},{"class":3527},[10798],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10800,"children":10801},{"class":3533},[10802],{"type":34,"value":10803}," nn.Linear(",{"type":24,"tag":2279,"props":10805,"children":10806},{"class":3908},[10807],{"type":34,"value":2632},{"type":24,"tag":2279,"props":10809,"children":10810},{"class":3533},[10811],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10813,"children":10814},{"class":3527},[10815],{"type":34,"value":4248},{"type":24,"tag":2279,"props":10817,"children":10818},{"class":3533},[10819],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10821,"children":10822},{"class":3908},[10823],{"type":34,"value":2308},{"type":24,"tag":2279,"props":10825,"children":10826},{"class":3533},[10827],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10829,"children":10830},{"class":3527},[10831],{"type":34,"value":4248},{"type":24,"tag":2279,"props":10833,"children":10834},{"class":3533},[10835],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10837,"children":10838},{"class":3908},[10839],{"type":34,"value":2308},{"type":24,"tag":2279,"props":10841,"children":10842},{"class":3533},[10843],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10845,"children":10846},{"class":3908},[10847],{"type":34,"value":2493},{"type":24,"tag":2279,"props":10849,"children":10850},{"class":3533},[10851],{"type":34,"value":6699},{"type":24,"tag":2279,"props":10853,"children":10854},{"class":3522,"line":7007},[10855,10859,10863,10868,10872,10876,10880,10884,10888],{"type":24,"tag":2279,"props":10856,"children":10857},{"class":3533},[10858],{"type":34,"value":6910},{"type":24,"tag":2279,"props":10860,"children":10861},{"class":3908},[10862],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10864,"children":10865},{"class":3533},[10866],{"type":34,"value":10867},".fc2 ",{"type":24,"tag":2279,"props":10869,"children":10870},{"class":3527},[10871],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10873,"children":10874},{"class":3533},[10875],{"type":34,"value":10803},{"type":24,"tag":2279,"props":10877,"children":10878},{"class":3908},[10879],{"type":34,"value":2493},{"type":24,"tag":2279,"props":10881,"children":10882},{"class":3533},[10883],{"type":34,"value":1340},{"type":24,"tag":2279,"props":10885,"children":10886},{"class":3908},[10887],{"type":34,"value":2283},{"type":24,"tag":2279,"props":10889,"children":10890},{"class":3533},[10891],{"type":34,"value":6699},{"type":24,"tag":2279,"props":10893,"children":10894},{"class":3522,"line":7060},[10895],{"type":24,"tag":2279,"props":10896,"children":10897},{},[],{"type":24,"tag":2279,"props":10899,"children":10900},{"class":3522,"line":7086},[10901,10905,10909,10913,10918],{"type":24,"tag":2279,"props":10902,"children":10903},{"class":3533},[10904],{"type":34,"value":3879},{"type":24,"tag":2279,"props":10906,"children":10907},{"class":3527},[10908],{"type":34,"value":4822},{"type":24,"tag":2279,"props":10910,"children":10911},{"class":3533},[10912],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10914,"children":10915},{"class":4802},[10916],{"type":34,"value":10917},"forward",{"type":24,"tag":2279,"props":10919,"children":10920},{"class":3533},[10921],{"type":34,"value":10922},"(self, x):\n",{"type":24,"tag":2279,"props":10924,"children":10925},{"class":3522,"line":7114},[10926,10931,10935,10939,10943,10948,10952],{"type":24,"tag":2279,"props":10927,"children":10928},{"class":3533},[10929],{"type":34,"value":10930},"        x ",{"type":24,"tag":2279,"props":10932,"children":10933},{"class":3527},[10934],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10936,"children":10937},{"class":3533},[10938],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10940,"children":10941},{"class":3908},[10942],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10944,"children":10945},{"class":3533},[10946],{"type":34,"value":10947},".pool(F.relu(",{"type":24,"tag":2279,"props":10949,"children":10950},{"class":3908},[10951],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10953,"children":10954},{"class":3533},[10955],{"type":34,"value":10956},".conv1(x)))\n",{"type":24,"tag":2279,"props":10958,"children":10959},{"class":3522,"line":7131},[10960,10964,10968,10972,10976,10980,10984],{"type":24,"tag":2279,"props":10961,"children":10962},{"class":3533},[10963],{"type":34,"value":10930},{"type":24,"tag":2279,"props":10965,"children":10966},{"class":3527},[10967],{"type":34,"value":3866},{"type":24,"tag":2279,"props":10969,"children":10970},{"class":3533},[10971],{"type":34,"value":2285},{"type":24,"tag":2279,"props":10973,"children":10974},{"class":3908},[10975],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10977,"children":10978},{"class":3533},[10979],{"type":34,"value":10947},{"type":24,"tag":2279,"props":10981,"children":10982},{"class":3908},[10983],{"type":34,"value":4848},{"type":24,"tag":2279,"props":10985,"children":10986},{"class":3533},[10987],{"type":34,"value":10988},".conv2(x)))\n",{"type":24,"tag":2279,"props":10990,"children":10991},{"class":3522,"line":7174},[10992,10996,11000,11004,11008,11012,11016],{"type":24,"tag":2279,"props":10993,"children":10994},{"class":3533},[10995],{"type":34,"value":10930},{"type":24,"tag":2279,"props":10997,"children":10998},{"class":3527},[10999],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11001,"children":11002},{"class":3533},[11003],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11005,"children":11006},{"class":3908},[11007],{"type":34,"value":4848},{"type":24,"tag":2279,"props":11009,"children":11010},{"class":3533},[11011],{"type":34,"value":10947},{"type":24,"tag":2279,"props":11013,"children":11014},{"class":3908},[11015],{"type":34,"value":4848},{"type":24,"tag":2279,"props":11017,"children":11018},{"class":3533},[11019],{"type":34,"value":11020},".conv3(x)))\n",{"type":24,"tag":2279,"props":11022,"children":11023},{"class":3522,"line":7200},[11024,11028,11032,11036,11040,11044,11048],{"type":24,"tag":2279,"props":11025,"children":11026},{"class":3533},[11027],{"type":34,"value":10930},{"type":24,"tag":2279,"props":11029,"children":11030},{"class":3527},[11031],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11033,"children":11034},{"class":3533},[11035],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11037,"children":11038},{"class":3908},[11039],{"type":34,"value":4848},{"type":24,"tag":2279,"props":11041,"children":11042},{"class":3533},[11043],{"type":34,"value":10947},{"type":24,"tag":2279,"props":11045,"children":11046},{"class":3908},[11047],{"type":34,"value":4848},{"type":24,"tag":2279,"props":11049,"children":11050},{"class":3533},[11051],{"type":34,"value":11052},".conv4(x)))\n",{"type":24,"tag":2279,"props":11054,"children":11055},{"class":3522,"line":7224},[11056,11060,11064,11069,11073],{"type":24,"tag":2279,"props":11057,"children":11058},{"class":3533},[11059],{"type":34,"value":10930},{"type":24,"tag":2279,"props":11061,"children":11062},{"class":3527},[11063],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11065,"children":11066},{"class":3533},[11067],{"type":34,"value":11068}," torch.flatten(x, ",{"type":24,"tag":2279,"props":11070,"children":11071},{"class":3908},[11072],{"type":34,"value":2283},{"type":24,"tag":2279,"props":11074,"children":11075},{"class":3533},[11076],{"type":34,"value":6699},{"type":24,"tag":2279,"props":11078,"children":11079},{"class":3522,"line":7233},[11080,11084,11088,11093,11097],{"type":24,"tag":2279,"props":11081,"children":11082},{"class":3533},[11083],{"type":34,"value":10930},{"type":24,"tag":2279,"props":11085,"children":11086},{"class":3527},[11087],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11089,"children":11090},{"class":3533},[11091],{"type":34,"value":11092}," F.relu(",{"type":24,"tag":2279,"props":11094,"children":11095},{"class":3908},[11096],{"type":34,"value":4848},{"type":24,"tag":2279,"props":11098,"children":11099},{"class":3533},[11100],{"type":34,"value":11101},".fc1(x))\n",{"type":24,"tag":2279,"props":11103,"children":11104},{"class":3522,"line":7259},[11105,11109,11113,11118,11122],{"type":24,"tag":2279,"props":11106,"children":11107},{"class":3533},[11108],{"type":34,"value":10930},{"type":24,"tag":2279,"props":11110,"children":11111},{"class":3527},[11112],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11114,"children":11115},{"class":3533},[11116],{"type":34,"value":11117}," F.sigmoid(",{"type":24,"tag":2279,"props":11119,"children":11120},{"class":3908},[11121],{"type":34,"value":4848},{"type":24,"tag":2279,"props":11123,"children":11124},{"class":3533},[11125],{"type":34,"value":11126},".fc2(x))\n",{"type":24,"tag":2279,"props":11128,"children":11129},{"class":3522,"line":7293},[11130,11134,11138],{"type":24,"tag":2279,"props":11131,"children":11132},{"class":3533},[11133],{"type":34,"value":10930},{"type":24,"tag":2279,"props":11135,"children":11136},{"class":3527},[11137],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11139,"children":11140},{"class":3533},[11141],{"type":34,"value":11142}," x.squeeze()\n",{"type":24,"tag":2279,"props":11144,"children":11145},{"class":3522,"line":7358},[11146,11150,11154],{"type":24,"tag":2279,"props":11147,"children":11148},{"class":3533},[11149],{"type":34,"value":6910},{"type":24,"tag":2279,"props":11151,"children":11152},{"class":3527},[11153],{"type":34,"value":7469},{"type":24,"tag":2279,"props":11155,"children":11156},{"class":3533},[11157],{"type":34,"value":11158}," x",{"type":24,"tag":46,"props":11160,"children":11161},{},[11162],{"type":34,"value":11163},"Now we will define also our Loss function as well as our optimizer (we will use SGD for simplicity). We will train 15 epochs in the problem and run a validation step at the end of an epoch.",{"type":24,"tag":3511,"props":11165,"children":11167},{"code":11166,"language":3514,"meta":10,"className":3515},"model = SimpleNet()\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",[11168],{"type":24,"tag":3495,"props":11169,"children":11170},{"__ignoreMap":10},[11171,11188,11205],{"type":24,"tag":2279,"props":11172,"children":11173},{"class":3522,"line":3523},[11174,11179,11183],{"type":24,"tag":2279,"props":11175,"children":11176},{"class":3533},[11177],{"type":34,"value":11178},"model ",{"type":24,"tag":2279,"props":11180,"children":11181},{"class":3527},[11182],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11184,"children":11185},{"class":3533},[11186],{"type":34,"value":11187}," SimpleNet()\n",{"type":24,"tag":2279,"props":11189,"children":11190},{"class":3522,"line":2808},[11191,11196,11200],{"type":24,"tag":2279,"props":11192,"children":11193},{"class":3533},[11194],{"type":34,"value":11195},"criterion ",{"type":24,"tag":2279,"props":11197,"children":11198},{"class":3527},[11199],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11201,"children":11202},{"class":3533},[11203],{"type":34,"value":11204}," nn.BCEWithLogitsLoss()\n",{"type":24,"tag":2279,"props":11206,"children":11207},{"class":3522,"line":2817},[11208,11213,11217,11222,11227,11231,11236,11240,11245,11249,11254],{"type":24,"tag":2279,"props":11209,"children":11210},{"class":3533},[11211],{"type":34,"value":11212},"optimizer ",{"type":24,"tag":2279,"props":11214,"children":11215},{"class":3527},[11216],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11218,"children":11219},{"class":3533},[11220],{"type":34,"value":11221}," optim.SGD(model.parameters(), ",{"type":24,"tag":2279,"props":11223,"children":11224},{"class":3882},[11225],{"type":34,"value":11226},"lr",{"type":24,"tag":2279,"props":11228,"children":11229},{"class":3527},[11230],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11232,"children":11233},{"class":3908},[11234],{"type":34,"value":11235},"0.01",{"type":24,"tag":2279,"props":11237,"children":11238},{"class":3533},[11239],{"type":34,"value":1340},{"type":24,"tag":2279,"props":11241,"children":11242},{"class":3882},[11243],{"type":34,"value":11244},"momentum",{"type":24,"tag":2279,"props":11246,"children":11247},{"class":3527},[11248],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11250,"children":11251},{"class":3908},[11252],{"type":34,"value":11253},"0.9",{"type":24,"tag":2279,"props":11255,"children":11256},{"class":3533},[11257],{"type":34,"value":3937},{"type":24,"tag":3511,"props":11259,"children":11261},{"code":11260,"language":3514,"meta":10,"className":3515},"n_epochs = 15\n",[11262],{"type":24,"tag":3495,"props":11263,"children":11264},{"__ignoreMap":10},[11265],{"type":24,"tag":2279,"props":11266,"children":11267},{"class":3522,"line":3523},[11268,11273,11277,11281],{"type":24,"tag":2279,"props":11269,"children":11270},{"class":3533},[11271],{"type":34,"value":11272},"n_epochs ",{"type":24,"tag":2279,"props":11274,"children":11275},{"class":3527},[11276],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11278,"children":11279},{"class":3533},[11280],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11282,"children":11283},{"class":3908},[11284],{"type":34,"value":2609},{"type":24,"tag":46,"props":11286,"children":11287},{},[11288],{"type":34,"value":11289},"We will need the following methods to process both labels and samples (for the labels we just one to convert both labels into 0 and 1 respectively).",{"type":24,"tag":3511,"props":11291,"children":11293},{"code":11292,"language":3514,"meta":10,"className":3515},"def process_labels(labels_raw, ref_label):\n  return (labels_raw == ref_label).float()\n\ndef preprocess_inputs(inputs):\n    return (1- inputs) * 255\n",[11294],{"type":24,"tag":3495,"props":11295,"children":11296},{"__ignoreMap":10},[11297,11318,11343,11349,11370],{"type":24,"tag":2279,"props":11298,"children":11299},{"class":3522,"line":3523},[11300,11304,11308,11313],{"type":24,"tag":2279,"props":11301,"children":11302},{"class":3527},[11303],{"type":34,"value":4822},{"type":24,"tag":2279,"props":11305,"children":11306},{"class":3533},[11307],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11309,"children":11310},{"class":4802},[11311],{"type":34,"value":11312},"process_labels",{"type":24,"tag":2279,"props":11314,"children":11315},{"class":3533},[11316],{"type":34,"value":11317},"(labels_raw, ref_label):\n",{"type":24,"tag":2279,"props":11319,"children":11320},{"class":3522,"line":2808},[11321,11325,11329,11334,11338],{"type":24,"tag":2279,"props":11322,"children":11323},{"class":3533},[11324],{"type":34,"value":4817},{"type":24,"tag":2279,"props":11326,"children":11327},{"class":3527},[11328],{"type":34,"value":7469},{"type":24,"tag":2279,"props":11330,"children":11331},{"class":3533},[11332],{"type":34,"value":11333}," (labels_raw ",{"type":24,"tag":2279,"props":11335,"children":11336},{"class":3527},[11337],{"type":34,"value":5854},{"type":24,"tag":2279,"props":11339,"children":11340},{"class":3533},[11341],{"type":34,"value":11342}," ref_label).float()\n",{"type":24,"tag":2279,"props":11344,"children":11345},{"class":3522,"line":2817},[11346],{"type":24,"tag":2279,"props":11347,"children":11348},{},[],{"type":24,"tag":2279,"props":11350,"children":11351},{"class":3522,"line":3577},[11352,11356,11360,11365],{"type":24,"tag":2279,"props":11353,"children":11354},{"class":3527},[11355],{"type":34,"value":4822},{"type":24,"tag":2279,"props":11357,"children":11358},{"class":3533},[11359],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11361,"children":11362},{"class":4802},[11363],{"type":34,"value":11364},"preprocess_inputs",{"type":24,"tag":2279,"props":11366,"children":11367},{"class":3533},[11368],{"type":34,"value":11369},"(inputs):\n",{"type":24,"tag":2279,"props":11371,"children":11372},{"class":3522,"line":3725},[11373,11377,11381,11385,11389,11393,11398,11402,11406],{"type":24,"tag":2279,"props":11374,"children":11375},{"class":3533},[11376],{"type":34,"value":3879},{"type":24,"tag":2279,"props":11378,"children":11379},{"class":3527},[11380],{"type":34,"value":7469},{"type":24,"tag":2279,"props":11382,"children":11383},{"class":3533},[11384],{"type":34,"value":1868},{"type":24,"tag":2279,"props":11386,"children":11387},{"class":3908},[11388],{"type":34,"value":2283},{"type":24,"tag":2279,"props":11390,"children":11391},{"class":3527},[11392],{"type":34,"value":3630},{"type":24,"tag":2279,"props":11394,"children":11395},{"class":3533},[11396],{"type":34,"value":11397}," inputs) ",{"type":24,"tag":2279,"props":11399,"children":11400},{"class":3527},[11401],{"type":34,"value":4248},{"type":24,"tag":2279,"props":11403,"children":11404},{"class":3533},[11405],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11407,"children":11408},{"class":3908},[11409],{"type":34,"value":11410},"255",{"type":24,"tag":46,"props":11412,"children":11413},{},[11414],{"type":34,"value":11415},"So we are ready to implement and run what we defined.",{"type":24,"tag":3511,"props":11417,"children":11419},{"code":11418,"language":3514,"meta":10,"className":3515},"ref_label = None\nfor epoch in range(n_epochs):\n    print(f'Epoch {epoch + 1}')\n    running_loss = 0.0\n    val_loss = 0.0\n    val_accuracy = 0.0\n    for i, data in enumerate(toy_problem_loader, 0):\n        inputs_raw, labels_raw = data\n        optimizer.zero_grad()\n        inputs = preprocess_inputs(inputs_raw)\n        outputs = model(inputs)\n        if ref_label is None:\n            ref_label = labels_raw[0]\n        labels = process_labels(labels_raw, ref_label)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        accuracy = (((1 - outputs) \u003C outputs).float() == labels).sum() / outputs.shape[0]\n        print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n    for iv, datav in enumerate(toy_problem_loader_val):\n        inputs_rawv, labels_rawv = datav\n        inputsv = preprocess_inputs(inputs_rawv)\n        outputsv = model(inputsv)\n        labelsv = process_labels(labels_rawv, ref_label)\n        lossv = criterion(outputsv, labelsv[0])\n        val_loss += lossv.item()\n        val_accuracy += (((1 - outputsv) \u003C outputsv).float() == labelsv).sum()\n    print(f'Epoch {epoch + 1}, VALIDATION], Loss: {val_loss / (iv + 1)}, Accuracy: {val_accuracy / (iv + 1)}')\n\nprint('Finished Training')\n",[11420],{"type":24,"tag":3495,"props":11421,"children":11422},{"__ignoreMap":10},[11423,11444,11473,11529,11550,11570,11590,11629,11646,11654,11671,11688,11721,11746,11763,11780,11788,11796,11813,11882,12005,12038,12055,12072,12089,12106,12131,12148,12199,12334,12340],{"type":24,"tag":2279,"props":11424,"children":11425},{"class":3522,"line":3523},[11426,11431,11435,11439],{"type":24,"tag":2279,"props":11427,"children":11428},{"class":3533},[11429],{"type":34,"value":11430},"ref_label ",{"type":24,"tag":2279,"props":11432,"children":11433},{"class":3527},[11434],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11436,"children":11437},{"class":3533},[11438],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11440,"children":11441},{"class":3908},[11442],{"type":34,"value":11443},"None\n",{"type":24,"tag":2279,"props":11445,"children":11446},{"class":3522,"line":2808},[11447,11451,11456,11460,11464,11468],{"type":24,"tag":2279,"props":11448,"children":11449},{"class":3527},[11450],{"type":34,"value":4181},{"type":24,"tag":2279,"props":11452,"children":11453},{"class":3533},[11454],{"type":34,"value":11455}," epoch ",{"type":24,"tag":2279,"props":11457,"children":11458},{"class":3527},[11459],{"type":34,"value":4191},{"type":24,"tag":2279,"props":11461,"children":11462},{"class":3533},[11463],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11465,"children":11466},{"class":3908},[11467],{"type":34,"value":4200},{"type":24,"tag":2279,"props":11469,"children":11470},{"class":3533},[11471],{"type":34,"value":11472},"(n_epochs):\n",{"type":24,"tag":2279,"props":11474,"children":11475},{"class":3522,"line":2817},[11476,11480,11484,11488,11493,11498,11502,11507,11511,11515,11520,11525],{"type":24,"tag":2279,"props":11477,"children":11478},{"class":3533},[11479],{"type":34,"value":3879},{"type":24,"tag":2279,"props":11481,"children":11482},{"class":3908},[11483],{"type":34,"value":5074},{"type":24,"tag":2279,"props":11485,"children":11486},{"class":3533},[11487],{"type":34,"value":4205},{"type":24,"tag":2279,"props":11489,"children":11490},{"class":3527},[11491],{"type":34,"value":11492},"f",{"type":24,"tag":2279,"props":11494,"children":11495},{"class":3557},[11496],{"type":34,"value":11497},"'Epoch ",{"type":24,"tag":2279,"props":11499,"children":11500},{"class":3908},[11501],{"type":34,"value":9135},{"type":24,"tag":2279,"props":11503,"children":11504},{"class":3533},[11505],{"type":34,"value":11506},"epoch ",{"type":24,"tag":2279,"props":11508,"children":11509},{"class":3527},[11510],{"type":34,"value":6072},{"type":24,"tag":2279,"props":11512,"children":11513},{"class":3533},[11514],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11516,"children":11517},{"class":3908},[11518],{"type":34,"value":11519},"1}",{"type":24,"tag":2279,"props":11521,"children":11522},{"class":3557},[11523],{"type":34,"value":11524},"'",{"type":24,"tag":2279,"props":11526,"children":11527},{"class":3533},[11528],{"type":34,"value":6699},{"type":24,"tag":2279,"props":11530,"children":11531},{"class":3522,"line":3577},[11532,11537,11541,11545],{"type":24,"tag":2279,"props":11533,"children":11534},{"class":3533},[11535],{"type":34,"value":11536},"    running_loss ",{"type":24,"tag":2279,"props":11538,"children":11539},{"class":3527},[11540],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11542,"children":11543},{"class":3533},[11544],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11546,"children":11547},{"class":3908},[11548],{"type":34,"value":11549},"0.0\n",{"type":24,"tag":2279,"props":11551,"children":11552},{"class":3522,"line":3725},[11553,11558,11562,11566],{"type":24,"tag":2279,"props":11554,"children":11555},{"class":3533},[11556],{"type":34,"value":11557},"    val_loss ",{"type":24,"tag":2279,"props":11559,"children":11560},{"class":3527},[11561],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11563,"children":11564},{"class":3533},[11565],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11567,"children":11568},{"class":3908},[11569],{"type":34,"value":11549},{"type":24,"tag":2279,"props":11571,"children":11572},{"class":3522,"line":3747},[11573,11578,11582,11586],{"type":24,"tag":2279,"props":11574,"children":11575},{"class":3533},[11576],{"type":34,"value":11577},"    val_accuracy ",{"type":24,"tag":2279,"props":11579,"children":11580},{"class":3527},[11581],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11583,"children":11584},{"class":3533},[11585],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11587,"children":11588},{"class":3908},[11589],{"type":34,"value":11549},{"type":24,"tag":2279,"props":11591,"children":11592},{"class":3522,"line":3769},[11593,11597,11601,11605,11609,11613,11617,11621,11625],{"type":24,"tag":2279,"props":11594,"children":11595},{"class":3533},[11596],{"type":34,"value":3879},{"type":24,"tag":2279,"props":11598,"children":11599},{"class":3527},[11600],{"type":34,"value":4181},{"type":24,"tag":2279,"props":11602,"children":11603},{"class":3533},[11604],{"type":34,"value":10291},{"type":24,"tag":2279,"props":11606,"children":11607},{"class":3527},[11608],{"type":34,"value":4191},{"type":24,"tag":2279,"props":11610,"children":11611},{"class":3533},[11612],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11614,"children":11615},{"class":3908},[11616],{"type":34,"value":6371},{"type":24,"tag":2279,"props":11618,"children":11619},{"class":3533},[11620],{"type":34,"value":10308},{"type":24,"tag":2279,"props":11622,"children":11623},{"class":3908},[11624],{"type":34,"value":4023},{"type":24,"tag":2279,"props":11626,"children":11627},{"class":3533},[11628],{"type":34,"value":9427},{"type":24,"tag":2279,"props":11630,"children":11631},{"class":3522,"line":3782},[11632,11637,11641],{"type":24,"tag":2279,"props":11633,"children":11634},{"class":3533},[11635],{"type":34,"value":11636},"        inputs_raw, labels_raw ",{"type":24,"tag":2279,"props":11638,"children":11639},{"class":3527},[11640],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11642,"children":11643},{"class":3533},[11644],{"type":34,"value":11645}," data\n",{"type":24,"tag":2279,"props":11647,"children":11648},{"class":3522,"line":6981},[11649],{"type":24,"tag":2279,"props":11650,"children":11651},{"class":3533},[11652],{"type":34,"value":11653},"        optimizer.zero_grad()\n",{"type":24,"tag":2279,"props":11655,"children":11656},{"class":3522,"line":7007},[11657,11662,11666],{"type":24,"tag":2279,"props":11658,"children":11659},{"class":3533},[11660],{"type":34,"value":11661},"        inputs ",{"type":24,"tag":2279,"props":11663,"children":11664},{"class":3527},[11665],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11667,"children":11668},{"class":3533},[11669],{"type":34,"value":11670}," preprocess_inputs(inputs_raw)\n",{"type":24,"tag":2279,"props":11672,"children":11673},{"class":3522,"line":7060},[11674,11679,11683],{"type":24,"tag":2279,"props":11675,"children":11676},{"class":3533},[11677],{"type":34,"value":11678},"        outputs ",{"type":24,"tag":2279,"props":11680,"children":11681},{"class":3527},[11682],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11684,"children":11685},{"class":3533},[11686],{"type":34,"value":11687}," model(inputs)\n",{"type":24,"tag":2279,"props":11689,"children":11690},{"class":3522,"line":7086},[11691,11695,11699,11704,11709,11713,11717],{"type":24,"tag":2279,"props":11692,"children":11693},{"class":3533},[11694],{"type":34,"value":6910},{"type":24,"tag":2279,"props":11696,"children":11697},{"class":3527},[11698],{"type":34,"value":5391},{"type":24,"tag":2279,"props":11700,"children":11701},{"class":3533},[11702],{"type":34,"value":11703}," ref_label ",{"type":24,"tag":2279,"props":11705,"children":11706},{"class":3527},[11707],{"type":34,"value":11708},"is",{"type":24,"tag":2279,"props":11710,"children":11711},{"class":3533},[11712],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11714,"children":11715},{"class":3908},[11716],{"type":34,"value":4954},{"type":24,"tag":2279,"props":11718,"children":11719},{"class":3533},[11720],{"type":34,"value":4809},{"type":24,"tag":2279,"props":11722,"children":11723},{"class":3522,"line":7114},[11724,11729,11733,11738,11742],{"type":24,"tag":2279,"props":11725,"children":11726},{"class":3533},[11727],{"type":34,"value":11728},"            ref_label ",{"type":24,"tag":2279,"props":11730,"children":11731},{"class":3527},[11732],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11734,"children":11735},{"class":3533},[11736],{"type":34,"value":11737}," labels_raw[",{"type":24,"tag":2279,"props":11739,"children":11740},{"class":3908},[11741],{"type":34,"value":4023},{"type":24,"tag":2279,"props":11743,"children":11744},{"class":3533},[11745],{"type":34,"value":7057},{"type":24,"tag":2279,"props":11747,"children":11748},{"class":3522,"line":7131},[11749,11754,11758],{"type":24,"tag":2279,"props":11750,"children":11751},{"class":3533},[11752],{"type":34,"value":11753},"        labels ",{"type":24,"tag":2279,"props":11755,"children":11756},{"class":3527},[11757],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11759,"children":11760},{"class":3533},[11761],{"type":34,"value":11762}," process_labels(labels_raw, ref_label)\n",{"type":24,"tag":2279,"props":11764,"children":11765},{"class":3522,"line":7174},[11766,11771,11775],{"type":24,"tag":2279,"props":11767,"children":11768},{"class":3533},[11769],{"type":34,"value":11770},"        loss ",{"type":24,"tag":2279,"props":11772,"children":11773},{"class":3527},[11774],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11776,"children":11777},{"class":3533},[11778],{"type":34,"value":11779}," criterion(outputs, labels)\n",{"type":24,"tag":2279,"props":11781,"children":11782},{"class":3522,"line":7200},[11783],{"type":24,"tag":2279,"props":11784,"children":11785},{"class":3533},[11786],{"type":34,"value":11787},"        loss.backward()\n",{"type":24,"tag":2279,"props":11789,"children":11790},{"class":3522,"line":7224},[11791],{"type":24,"tag":2279,"props":11792,"children":11793},{"class":3533},[11794],{"type":34,"value":11795},"        optimizer.step()\n",{"type":24,"tag":2279,"props":11797,"children":11798},{"class":3522,"line":7233},[11799,11804,11808],{"type":24,"tag":2279,"props":11800,"children":11801},{"class":3533},[11802],{"type":34,"value":11803},"        running_loss ",{"type":24,"tag":2279,"props":11805,"children":11806},{"class":3527},[11807],{"type":34,"value":5453},{"type":24,"tag":2279,"props":11809,"children":11810},{"class":3533},[11811],{"type":34,"value":11812}," loss.item()\n",{"type":24,"tag":2279,"props":11814,"children":11815},{"class":3522,"line":7259},[11816,11821,11825,11830,11834,11838,11842,11847,11851,11856,11860,11865,11869,11874,11878],{"type":24,"tag":2279,"props":11817,"children":11818},{"class":3533},[11819],{"type":34,"value":11820},"        accuracy ",{"type":24,"tag":2279,"props":11822,"children":11823},{"class":3527},[11824],{"type":34,"value":3866},{"type":24,"tag":2279,"props":11826,"children":11827},{"class":3533},[11828],{"type":34,"value":11829}," (((",{"type":24,"tag":2279,"props":11831,"children":11832},{"class":3908},[11833],{"type":34,"value":2283},{"type":24,"tag":2279,"props":11835,"children":11836},{"class":3533},[11837],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11839,"children":11840},{"class":3527},[11841],{"type":34,"value":3630},{"type":24,"tag":2279,"props":11843,"children":11844},{"class":3533},[11845],{"type":34,"value":11846}," outputs) ",{"type":24,"tag":2279,"props":11848,"children":11849},{"class":3527},[11850],{"type":34,"value":5410},{"type":24,"tag":2279,"props":11852,"children":11853},{"class":3533},[11854],{"type":34,"value":11855}," outputs).float() ",{"type":24,"tag":2279,"props":11857,"children":11858},{"class":3527},[11859],{"type":34,"value":5854},{"type":24,"tag":2279,"props":11861,"children":11862},{"class":3533},[11863],{"type":34,"value":11864}," labels).sum() ",{"type":24,"tag":2279,"props":11866,"children":11867},{"class":3527},[11868],{"type":34,"value":3593},{"type":24,"tag":2279,"props":11870,"children":11871},{"class":3533},[11872],{"type":34,"value":11873}," outputs.shape[",{"type":24,"tag":2279,"props":11875,"children":11876},{"class":3908},[11877],{"type":34,"value":4023},{"type":24,"tag":2279,"props":11879,"children":11880},{"class":3533},[11881],{"type":34,"value":7057},{"type":24,"tag":2279,"props":11883,"children":11884},{"class":3522,"line":7293},[11885,11889,11893,11897,11901,11905,11909,11913,11917,11921,11925,11930,11934,11939,11943,11947,11951,11956,11961,11966,11970,11975,11979,11984,11988,11993,11997,12001],{"type":24,"tag":2279,"props":11886,"children":11887},{"class":3533},[11888],{"type":34,"value":6910},{"type":24,"tag":2279,"props":11890,"children":11891},{"class":3908},[11892],{"type":34,"value":5074},{"type":24,"tag":2279,"props":11894,"children":11895},{"class":3533},[11896],{"type":34,"value":4205},{"type":24,"tag":2279,"props":11898,"children":11899},{"class":3527},[11900],{"type":34,"value":11492},{"type":24,"tag":2279,"props":11902,"children":11903},{"class":3557},[11904],{"type":34,"value":11497},{"type":24,"tag":2279,"props":11906,"children":11907},{"class":3908},[11908],{"type":34,"value":9135},{"type":24,"tag":2279,"props":11910,"children":11911},{"class":3533},[11912],{"type":34,"value":11506},{"type":24,"tag":2279,"props":11914,"children":11915},{"class":3527},[11916],{"type":34,"value":6072},{"type":24,"tag":2279,"props":11918,"children":11919},{"class":3533},[11920],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11922,"children":11923},{"class":3908},[11924],{"type":34,"value":11519},{"type":24,"tag":2279,"props":11926,"children":11927},{"class":3557},[11928],{"type":34,"value":11929},", step ",{"type":24,"tag":2279,"props":11931,"children":11932},{"class":3908},[11933],{"type":34,"value":9135},{"type":24,"tag":2279,"props":11935,"children":11936},{"class":3533},[11937],{"type":34,"value":11938},"i ",{"type":24,"tag":2279,"props":11940,"children":11941},{"class":3527},[11942],{"type":34,"value":6072},{"type":24,"tag":2279,"props":11944,"children":11945},{"class":3533},[11946],{"type":34,"value":2285},{"type":24,"tag":2279,"props":11948,"children":11949},{"class":3908},[11950],{"type":34,"value":2283},{"type":24,"tag":2279,"props":11952,"children":11953},{"class":3527},[11954],{"type":34,"value":11955},":5d",{"type":24,"tag":2279,"props":11957,"children":11958},{"class":3908},[11959],{"type":34,"value":11960},"}",{"type":24,"tag":2279,"props":11962,"children":11963},{"class":3557},[11964],{"type":34,"value":11965},"], Loss: ",{"type":24,"tag":2279,"props":11967,"children":11968},{"class":3908},[11969],{"type":34,"value":9135},{"type":24,"tag":2279,"props":11971,"children":11972},{"class":3533},[11973],{"type":34,"value":11974},"loss.item()",{"type":24,"tag":2279,"props":11976,"children":11977},{"class":3908},[11978],{"type":34,"value":11960},{"type":24,"tag":2279,"props":11980,"children":11981},{"class":3557},[11982],{"type":34,"value":11983},", Accuracy: ",{"type":24,"tag":2279,"props":11985,"children":11986},{"class":3908},[11987],{"type":34,"value":9135},{"type":24,"tag":2279,"props":11989,"children":11990},{"class":3533},[11991],{"type":34,"value":11992},"accuracy",{"type":24,"tag":2279,"props":11994,"children":11995},{"class":3908},[11996],{"type":34,"value":11960},{"type":24,"tag":2279,"props":11998,"children":11999},{"class":3557},[12000],{"type":34,"value":11524},{"type":24,"tag":2279,"props":12002,"children":12003},{"class":3533},[12004],{"type":34,"value":6699},{"type":24,"tag":2279,"props":12006,"children":12007},{"class":3522,"line":7358},[12008,12012,12016,12021,12025,12029,12033],{"type":24,"tag":2279,"props":12009,"children":12010},{"class":3533},[12011],{"type":34,"value":3879},{"type":24,"tag":2279,"props":12013,"children":12014},{"class":3527},[12015],{"type":34,"value":4181},{"type":24,"tag":2279,"props":12017,"children":12018},{"class":3533},[12019],{"type":34,"value":12020}," iv, datav ",{"type":24,"tag":2279,"props":12022,"children":12023},{"class":3527},[12024],{"type":34,"value":4191},{"type":24,"tag":2279,"props":12026,"children":12027},{"class":3533},[12028],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12030,"children":12031},{"class":3908},[12032],{"type":34,"value":6371},{"type":24,"tag":2279,"props":12034,"children":12035},{"class":3533},[12036],{"type":34,"value":12037},"(toy_problem_loader_val):\n",{"type":24,"tag":2279,"props":12039,"children":12040},{"class":3522,"line":7392},[12041,12046,12050],{"type":24,"tag":2279,"props":12042,"children":12043},{"class":3533},[12044],{"type":34,"value":12045},"        inputs_rawv, labels_rawv ",{"type":24,"tag":2279,"props":12047,"children":12048},{"class":3527},[12049],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12051,"children":12052},{"class":3533},[12053],{"type":34,"value":12054}," datav\n",{"type":24,"tag":2279,"props":12056,"children":12057},{"class":3522,"line":7425},[12058,12063,12067],{"type":24,"tag":2279,"props":12059,"children":12060},{"class":3533},[12061],{"type":34,"value":12062},"        inputsv ",{"type":24,"tag":2279,"props":12064,"children":12065},{"class":3527},[12066],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12068,"children":12069},{"class":3533},[12070],{"type":34,"value":12071}," preprocess_inputs(inputs_rawv)\n",{"type":24,"tag":2279,"props":12073,"children":12074},{"class":3522,"line":7433},[12075,12080,12084],{"type":24,"tag":2279,"props":12076,"children":12077},{"class":3533},[12078],{"type":34,"value":12079},"        outputsv ",{"type":24,"tag":2279,"props":12081,"children":12082},{"class":3527},[12083],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12085,"children":12086},{"class":3533},[12087],{"type":34,"value":12088}," model(inputsv)\n",{"type":24,"tag":2279,"props":12090,"children":12091},{"class":3522,"line":7459},[12092,12097,12101],{"type":24,"tag":2279,"props":12093,"children":12094},{"class":3533},[12095],{"type":34,"value":12096},"        labelsv ",{"type":24,"tag":2279,"props":12098,"children":12099},{"class":3527},[12100],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12102,"children":12103},{"class":3533},[12104],{"type":34,"value":12105}," process_labels(labels_rawv, ref_label)\n",{"type":24,"tag":2279,"props":12107,"children":12108},{"class":3522,"line":7496},[12109,12114,12118,12123,12127],{"type":24,"tag":2279,"props":12110,"children":12111},{"class":3533},[12112],{"type":34,"value":12113},"        lossv ",{"type":24,"tag":2279,"props":12115,"children":12116},{"class":3527},[12117],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12119,"children":12120},{"class":3533},[12121],{"type":34,"value":12122}," criterion(outputsv, labelsv[",{"type":24,"tag":2279,"props":12124,"children":12125},{"class":3908},[12126],{"type":34,"value":4023},{"type":24,"tag":2279,"props":12128,"children":12129},{"class":3533},[12130],{"type":34,"value":7941},{"type":24,"tag":2279,"props":12132,"children":12133},{"class":3522,"line":7504},[12134,12139,12143],{"type":24,"tag":2279,"props":12135,"children":12136},{"class":3533},[12137],{"type":34,"value":12138},"        val_loss ",{"type":24,"tag":2279,"props":12140,"children":12141},{"class":3527},[12142],{"type":34,"value":5453},{"type":24,"tag":2279,"props":12144,"children":12145},{"class":3533},[12146],{"type":34,"value":12147}," lossv.item()\n",{"type":24,"tag":2279,"props":12149,"children":12150},{"class":3522,"line":7530},[12151,12156,12160,12164,12168,12172,12176,12181,12185,12190,12194],{"type":24,"tag":2279,"props":12152,"children":12153},{"class":3533},[12154],{"type":34,"value":12155},"        val_accuracy ",{"type":24,"tag":2279,"props":12157,"children":12158},{"class":3527},[12159],{"type":34,"value":5453},{"type":24,"tag":2279,"props":12161,"children":12162},{"class":3533},[12163],{"type":34,"value":11829},{"type":24,"tag":2279,"props":12165,"children":12166},{"class":3908},[12167],{"type":34,"value":2283},{"type":24,"tag":2279,"props":12169,"children":12170},{"class":3533},[12171],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12173,"children":12174},{"class":3527},[12175],{"type":34,"value":3630},{"type":24,"tag":2279,"props":12177,"children":12178},{"class":3533},[12179],{"type":34,"value":12180}," outputsv) ",{"type":24,"tag":2279,"props":12182,"children":12183},{"class":3527},[12184],{"type":34,"value":5410},{"type":24,"tag":2279,"props":12186,"children":12187},{"class":3533},[12188],{"type":34,"value":12189}," outputsv).float() ",{"type":24,"tag":2279,"props":12191,"children":12192},{"class":3527},[12193],{"type":34,"value":5854},{"type":24,"tag":2279,"props":12195,"children":12196},{"class":3533},[12197],{"type":34,"value":12198}," labelsv).sum()\n",{"type":24,"tag":2279,"props":12200,"children":12201},{"class":3522,"line":7539},[12202,12206,12210,12214,12218,12222,12226,12230,12234,12238,12242,12247,12251,12256,12260,12265,12269,12273,12277,12281,12285,12289,12293,12298,12302,12306,12310,12314,12318,12322,12326,12330],{"type":24,"tag":2279,"props":12203,"children":12204},{"class":3533},[12205],{"type":34,"value":3879},{"type":24,"tag":2279,"props":12207,"children":12208},{"class":3908},[12209],{"type":34,"value":5074},{"type":24,"tag":2279,"props":12211,"children":12212},{"class":3533},[12213],{"type":34,"value":4205},{"type":24,"tag":2279,"props":12215,"children":12216},{"class":3527},[12217],{"type":34,"value":11492},{"type":24,"tag":2279,"props":12219,"children":12220},{"class":3557},[12221],{"type":34,"value":11497},{"type":24,"tag":2279,"props":12223,"children":12224},{"class":3908},[12225],{"type":34,"value":9135},{"type":24,"tag":2279,"props":12227,"children":12228},{"class":3533},[12229],{"type":34,"value":11506},{"type":24,"tag":2279,"props":12231,"children":12232},{"class":3527},[12233],{"type":34,"value":6072},{"type":24,"tag":2279,"props":12235,"children":12236},{"class":3533},[12237],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12239,"children":12240},{"class":3908},[12241],{"type":34,"value":11519},{"type":24,"tag":2279,"props":12243,"children":12244},{"class":3557},[12245],{"type":34,"value":12246},", VALIDATION], Loss: ",{"type":24,"tag":2279,"props":12248,"children":12249},{"class":3908},[12250],{"type":34,"value":9135},{"type":24,"tag":2279,"props":12252,"children":12253},{"class":3533},[12254],{"type":34,"value":12255},"val_loss ",{"type":24,"tag":2279,"props":12257,"children":12258},{"class":3527},[12259],{"type":34,"value":3593},{"type":24,"tag":2279,"props":12261,"children":12262},{"class":3533},[12263],{"type":34,"value":12264}," (iv ",{"type":24,"tag":2279,"props":12266,"children":12267},{"class":3527},[12268],{"type":34,"value":6072},{"type":24,"tag":2279,"props":12270,"children":12271},{"class":3533},[12272],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12274,"children":12275},{"class":3908},[12276],{"type":34,"value":2283},{"type":24,"tag":2279,"props":12278,"children":12279},{"class":3533},[12280],{"type":34,"value":3937},{"type":24,"tag":2279,"props":12282,"children":12283},{"class":3908},[12284],{"type":34,"value":11960},{"type":24,"tag":2279,"props":12286,"children":12287},{"class":3557},[12288],{"type":34,"value":11983},{"type":24,"tag":2279,"props":12290,"children":12291},{"class":3908},[12292],{"type":34,"value":9135},{"type":24,"tag":2279,"props":12294,"children":12295},{"class":3533},[12296],{"type":34,"value":12297},"val_accuracy ",{"type":24,"tag":2279,"props":12299,"children":12300},{"class":3527},[12301],{"type":34,"value":3593},{"type":24,"tag":2279,"props":12303,"children":12304},{"class":3533},[12305],{"type":34,"value":12264},{"type":24,"tag":2279,"props":12307,"children":12308},{"class":3527},[12309],{"type":34,"value":6072},{"type":24,"tag":2279,"props":12311,"children":12312},{"class":3533},[12313],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12315,"children":12316},{"class":3908},[12317],{"type":34,"value":2283},{"type":24,"tag":2279,"props":12319,"children":12320},{"class":3533},[12321],{"type":34,"value":3937},{"type":24,"tag":2279,"props":12323,"children":12324},{"class":3908},[12325],{"type":34,"value":11960},{"type":24,"tag":2279,"props":12327,"children":12328},{"class":3557},[12329],{"type":34,"value":11524},{"type":24,"tag":2279,"props":12331,"children":12332},{"class":3533},[12333],{"type":34,"value":6699},{"type":24,"tag":2279,"props":12335,"children":12336},{"class":3522,"line":7548},[12337],{"type":24,"tag":2279,"props":12338,"children":12339},{},[],{"type":24,"tag":2279,"props":12341,"children":12342},{"class":3522,"line":7575},[12343,12347,12351,12356],{"type":24,"tag":2279,"props":12344,"children":12345},{"class":3908},[12346],{"type":34,"value":5074},{"type":24,"tag":2279,"props":12348,"children":12349},{"class":3533},[12350],{"type":34,"value":4205},{"type":24,"tag":2279,"props":12352,"children":12353},{"class":3557},[12354],{"type":34,"value":12355},"'Finished Training'",{"type":24,"tag":2279,"props":12357,"children":12358},{"class":3533},[12359],{"type":34,"value":3937},{"type":24,"tag":3511,"props":12361,"children":12363},{"code":12362},"Epoch 1\n\n\n/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n\n\nEpoch 1, step     1], Loss: 0.6658390164375305, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6492561101913452, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.8146457672119141, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6260940631230673, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.60048508644104, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.5681989789009094, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6169461607933044, Accuracy: 0.875\nEpoch 2, VALIDATION], Loss: 0.5620179573694865, Accuracy: 1.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6216239333152771, Accuracy: 1.0\nEpoch 3, step     2], Loss: 0.5817804336547852, Accuracy: 1.0\nEpoch 3, step     3], Loss: 0.507636308670044, Accuracy: 1.0\nEpoch 3, VALIDATION], Loss: 0.5611441731452942, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.5516251921653748, Accuracy: 1.0\nEpoch 4, step     2], Loss: 0.5512588024139404, Accuracy: 1.0\nEpoch 4, step     3], Loss: 0.4609960913658142, Accuracy: 1.0\nEpoch 4, VALIDATION], Loss: 0.593102385600408, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.4159203767776489, Accuracy: 1.0\nEpoch 5, step     2], Loss: 0.6008561849594116, Accuracy: 1.0\nEpoch 5, step     3], Loss: 0.5070333480834961, Accuracy: 1.0\nEpoch 5, VALIDATION], Loss: 0.5653840551773707, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.5032209753990173, Accuracy: 1.0\nEpoch 6, step     2], Loss: 0.5032068490982056, Accuracy: 1.0\nEpoch 6, step     3], Loss: 0.4557313323020935, Accuracy: 1.0\nEpoch 6, VALIDATION], Loss: 0.6277975539366404, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.645679771900177, Accuracy: 1.0\nEpoch 7, step     2], Loss: 0.45026305317878723, Accuracy: 0.875\nEpoch 7, step     3], Loss: 0.5558935403823853, Accuracy: 0.875\nEpoch 7, VALIDATION], Loss: 0.6248213152090708, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.4557203948497772, Accuracy: 1.0\nEpoch 8, step     2], Loss: 0.5506904125213623, Accuracy: 1.0\nEpoch 8, step     3], Loss: 0.45581647753715515, Accuracy: 1.0\nEpoch 8, VALIDATION], Loss: 0.562673901518186, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.5032058358192444, Accuracy: 1.0\nEpoch 9, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 9, step     3], Loss: 0.5506901144981384, Accuracy: 1.0\nEpoch 9, VALIDATION], Loss: 0.5044418474038442, Accuracy: 1.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.4557187557220459, Accuracy: 1.0\nEpoch 10, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 10, step     3], Loss: 0.5981758236885071, Accuracy: 1.0\nEpoch 10, VALIDATION], Loss: 0.5032213479280472, Accuracy: 1.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.4557187557220459, Accuracy: 1.0\nEpoch 11, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 11, step     3], Loss: 0.5506902933120728, Accuracy: 1.0\nEpoch 11, VALIDATION], Loss: 0.5032058407862982, Accuracy: 1.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.5506907105445862, Accuracy: 1.0\nEpoch 12, step     2], Loss: 0.5032053589820862, Accuracy: 1.0\nEpoch 12, step     3], Loss: 0.5032044053077698, Accuracy: 1.0\nEpoch 12, VALIDATION], Loss: 0.5032146573066711, Accuracy: 1.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.5506961941719055, Accuracy: 1.0\nEpoch 13, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 13, step     3], Loss: 0.5507189035415649, Accuracy: 1.0\nEpoch 13, VALIDATION], Loss: 0.5032911549011866, Accuracy: 1.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.5508079528808594, Accuracy: 1.0\nEpoch 14, step     2], Loss: 0.5032503604888916, Accuracy: 1.0\nEpoch 14, step     3], Loss: 0.455719918012619, Accuracy: 1.0\nEpoch 14, VALIDATION], Loss: 0.5034261147181193, Accuracy: 1.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.5033642053604126, Accuracy: 1.0\nEpoch 15, step     2], Loss: 0.4083341956138611, Accuracy: 1.0\nEpoch 15, step     3], Loss: 0.550751805305481, Accuracy: 1.0\nEpoch 15, VALIDATION], Loss: 0.5033487677574158, Accuracy: 1.0\nFinished Training\n",[12364],{"type":24,"tag":3495,"props":12365,"children":12366},{"__ignoreMap":10},[12367],{"type":34,"value":12362},{"type":24,"tag":46,"props":12369,"children":12370},{},[12371],{"type":34,"value":12372},"As we can see, the model easily learns and in my case it reached an almost perfect accuracy. But things will get messy.",{"type":24,"tag":1378,"props":12374,"children":12376},{"id":12375},"train-with-manual-gd-algorithm",[12377],{"type":34,"value":12378},"Train with manual GD algorithm",{"type":24,"tag":46,"props":12380,"children":12381},{},[12382,12384,12390,12392,12402,12404,12410],{"type":34,"value":12383},"Before concluding I am a maniac by trying this for no reason, let's take a look at ",{"type":24,"tag":59,"props":12385,"children":12387},{"href":3461,"rel":12386},[63],[12388],{"type":34,"value":12389},"MAML official implementation on Github",{"type":34,"value":12391},". In the ",{"type":24,"tag":59,"props":12393,"children":12396},{"href":12394,"rel":12395},"https://github.com/cbfinn/maml/blob/master/maml.py#L79",[63],[12397],{"type":24,"tag":800,"props":12398,"children":12399},{},[12400],{"type":34,"value":12401},"maml.py",{"type":34,"value":12403}," module you can realize that at Learning level, authors also update manually the weights at each step. The same goes for ",{"type":24,"tag":59,"props":12405,"children":12407},{"href":3470,"rel":12406},[63],[12408],{"type":34,"value":12409},"unofficial Pytorch implementations",{"type":34,"value":12411},". Why is this? Well, if you think, in Meta-Learning, the model must learn at 2 levels. I.e. gradients, losses, optimizers, etc must work at 2 levels at the same time, which ML frameworks are not made for. Updating the weights manually in one of both levels is actually a workaround to this issue, so from Pytorch perspective there is no Learning level, and it just knows the updates at Meta-Learning level.",{"type":24,"tag":46,"props":12413,"children":12414},{},[12415],{"type":34,"value":12416},"So, before going for the Meta-Learning level we will manually train the same as before but now with manual updates. Note that updating model's parameters is done through the code chunk:",{"type":24,"tag":3511,"props":12418,"children":12420},{"code":12419},"for param, param_key in zip(new_weights, param_keys):\n            model._modules[param_key[0]]._parameters[param_key[1]] = param\n\n",[12421],{"type":24,"tag":3495,"props":12422,"children":12423},{"__ignoreMap":10},[12424],{"type":34,"value":12419},{"type":24,"tag":3511,"props":12426,"children":12428},{"code":12427,"language":3514,"meta":10,"className":3515},"model = SimpleNet()\ncriterion = nn.BCEWithLogitsLoss()\nupdate_lr = 0.01\n\nref_label = None\nparam_keys = [(mod, kname) for mod in model._modules for kname in model._modules[mod]._parameters]\nnew_weights = model.parameters()\nfor epoch in range(n_epochs):\n    print(f'Epoch {epoch + 1}')\n    running_loss = 0.0\n    val_loss = 0.0\n    val_accuracy = 0.0\n    for i, data in enumerate(toy_problem_loader, 0):\n        inputs_raw, labels_raw = data\n        inputs = preprocess_inputs(inputs_raw)\n        outputs = model(inputs)\n        if ref_label is None:\n            ref_label = labels_raw[0]\n        labels = process_labels(labels_raw, ref_label)\n        loss = criterion(outputs, labels)\n        grads = torch.autograd.grad(loss, model.parameters())\n        new_weights = list(map(lambda p: p[1] - update_lr * p[0], zip(grads, new_weights)))\n        running_loss += loss.item()\n        accuracy = (((1 - outputs) \u003C outputs).float() == labels).sum() / outputs.shape[0]\n        for param, param_key in zip(new_weights, param_keys):\n            model._modules[param_key[0]]._parameters[param_key[1]] = param\n        print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n    for iv, datav in enumerate(toy_problem_loader_val):\n        inputs_rawv, labels_rawv = datav\n        inputsv = preprocess_inputs(inputs_rawv)\n        outputsv = model(inputsv)\n        labelsv = process_labels(labels_rawv, ref_label)\n        lossv = criterion(outputsv, labelsv[0])\n        val_loss += lossv.item()\n        val_accuracy += (((1 - outputsv) \u003C outputsv).float() == labelsv).sum()\n    print(f'Epoch {epoch + 1}, VALIDATION], Loss: {val_loss / (iv + 1)}, Accuracy: {val_accuracy / (iv + 1)}')\n\nprint('Finished Training')\n",[12429],{"type":24,"tag":3495,"props":12430,"children":12431},{"__ignoreMap":10},[12432,12447,12462,12483,12489,12508,12561,12578,12605,12656,12675,12694,12713,12752,12767,12782,12797,12828,12851,12866,12881,12898,12986,13001,13064,13097,13132,13247,13278,13293,13308,13323,13338,13361,13376,13423,13554,13560],{"type":24,"tag":2279,"props":12433,"children":12434},{"class":3522,"line":3523},[12435,12439,12443],{"type":24,"tag":2279,"props":12436,"children":12437},{"class":3533},[12438],{"type":34,"value":11178},{"type":24,"tag":2279,"props":12440,"children":12441},{"class":3527},[12442],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12444,"children":12445},{"class":3533},[12446],{"type":34,"value":11187},{"type":24,"tag":2279,"props":12448,"children":12449},{"class":3522,"line":2808},[12450,12454,12458],{"type":24,"tag":2279,"props":12451,"children":12452},{"class":3533},[12453],{"type":34,"value":11195},{"type":24,"tag":2279,"props":12455,"children":12456},{"class":3527},[12457],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12459,"children":12460},{"class":3533},[12461],{"type":34,"value":11204},{"type":24,"tag":2279,"props":12463,"children":12464},{"class":3522,"line":2817},[12465,12470,12474,12478],{"type":24,"tag":2279,"props":12466,"children":12467},{"class":3533},[12468],{"type":34,"value":12469},"update_lr ",{"type":24,"tag":2279,"props":12471,"children":12472},{"class":3527},[12473],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12475,"children":12476},{"class":3533},[12477],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12479,"children":12480},{"class":3908},[12481],{"type":34,"value":12482},"0.01\n",{"type":24,"tag":2279,"props":12484,"children":12485},{"class":3522,"line":3577},[12486],{"type":24,"tag":2279,"props":12487,"children":12488},{},[],{"type":24,"tag":2279,"props":12490,"children":12491},{"class":3522,"line":3725},[12492,12496,12500,12504],{"type":24,"tag":2279,"props":12493,"children":12494},{"class":3533},[12495],{"type":34,"value":11430},{"type":24,"tag":2279,"props":12497,"children":12498},{"class":3527},[12499],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12501,"children":12502},{"class":3533},[12503],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12505,"children":12506},{"class":3908},[12507],{"type":34,"value":11443},{"type":24,"tag":2279,"props":12509,"children":12510},{"class":3522,"line":3747},[12511,12516,12520,12525,12529,12534,12538,12543,12547,12552,12556],{"type":24,"tag":2279,"props":12512,"children":12513},{"class":3533},[12514],{"type":34,"value":12515},"param_keys ",{"type":24,"tag":2279,"props":12517,"children":12518},{"class":3527},[12519],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12521,"children":12522},{"class":3533},[12523],{"type":34,"value":12524}," [(mod, kname) ",{"type":24,"tag":2279,"props":12526,"children":12527},{"class":3527},[12528],{"type":34,"value":4181},{"type":24,"tag":2279,"props":12530,"children":12531},{"class":3533},[12532],{"type":34,"value":12533}," mod ",{"type":24,"tag":2279,"props":12535,"children":12536},{"class":3527},[12537],{"type":34,"value":4191},{"type":24,"tag":2279,"props":12539,"children":12540},{"class":3533},[12541],{"type":34,"value":12542}," model._modules ",{"type":24,"tag":2279,"props":12544,"children":12545},{"class":3527},[12546],{"type":34,"value":4181},{"type":24,"tag":2279,"props":12548,"children":12549},{"class":3533},[12550],{"type":34,"value":12551}," kname ",{"type":24,"tag":2279,"props":12553,"children":12554},{"class":3527},[12555],{"type":34,"value":4191},{"type":24,"tag":2279,"props":12557,"children":12558},{"class":3533},[12559],{"type":34,"value":12560}," model._modules[mod]._parameters]\n",{"type":24,"tag":2279,"props":12562,"children":12563},{"class":3522,"line":3769},[12564,12569,12573],{"type":24,"tag":2279,"props":12565,"children":12566},{"class":3533},[12567],{"type":34,"value":12568},"new_weights ",{"type":24,"tag":2279,"props":12570,"children":12571},{"class":3527},[12572],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12574,"children":12575},{"class":3533},[12576],{"type":34,"value":12577}," model.parameters()\n",{"type":24,"tag":2279,"props":12579,"children":12580},{"class":3522,"line":3782},[12581,12585,12589,12593,12597,12601],{"type":24,"tag":2279,"props":12582,"children":12583},{"class":3527},[12584],{"type":34,"value":4181},{"type":24,"tag":2279,"props":12586,"children":12587},{"class":3533},[12588],{"type":34,"value":11455},{"type":24,"tag":2279,"props":12590,"children":12591},{"class":3527},[12592],{"type":34,"value":4191},{"type":24,"tag":2279,"props":12594,"children":12595},{"class":3533},[12596],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12598,"children":12599},{"class":3908},[12600],{"type":34,"value":4200},{"type":24,"tag":2279,"props":12602,"children":12603},{"class":3533},[12604],{"type":34,"value":11472},{"type":24,"tag":2279,"props":12606,"children":12607},{"class":3522,"line":6981},[12608,12612,12616,12620,12624,12628,12632,12636,12640,12644,12648,12652],{"type":24,"tag":2279,"props":12609,"children":12610},{"class":3533},[12611],{"type":34,"value":3879},{"type":24,"tag":2279,"props":12613,"children":12614},{"class":3908},[12615],{"type":34,"value":5074},{"type":24,"tag":2279,"props":12617,"children":12618},{"class":3533},[12619],{"type":34,"value":4205},{"type":24,"tag":2279,"props":12621,"children":12622},{"class":3527},[12623],{"type":34,"value":11492},{"type":24,"tag":2279,"props":12625,"children":12626},{"class":3557},[12627],{"type":34,"value":11497},{"type":24,"tag":2279,"props":12629,"children":12630},{"class":3908},[12631],{"type":34,"value":9135},{"type":24,"tag":2279,"props":12633,"children":12634},{"class":3533},[12635],{"type":34,"value":11506},{"type":24,"tag":2279,"props":12637,"children":12638},{"class":3527},[12639],{"type":34,"value":6072},{"type":24,"tag":2279,"props":12641,"children":12642},{"class":3533},[12643],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12645,"children":12646},{"class":3908},[12647],{"type":34,"value":11519},{"type":24,"tag":2279,"props":12649,"children":12650},{"class":3557},[12651],{"type":34,"value":11524},{"type":24,"tag":2279,"props":12653,"children":12654},{"class":3533},[12655],{"type":34,"value":6699},{"type":24,"tag":2279,"props":12657,"children":12658},{"class":3522,"line":7007},[12659,12663,12667,12671],{"type":24,"tag":2279,"props":12660,"children":12661},{"class":3533},[12662],{"type":34,"value":11536},{"type":24,"tag":2279,"props":12664,"children":12665},{"class":3527},[12666],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12668,"children":12669},{"class":3533},[12670],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12672,"children":12673},{"class":3908},[12674],{"type":34,"value":11549},{"type":24,"tag":2279,"props":12676,"children":12677},{"class":3522,"line":7060},[12678,12682,12686,12690],{"type":24,"tag":2279,"props":12679,"children":12680},{"class":3533},[12681],{"type":34,"value":11557},{"type":24,"tag":2279,"props":12683,"children":12684},{"class":3527},[12685],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12687,"children":12688},{"class":3533},[12689],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12691,"children":12692},{"class":3908},[12693],{"type":34,"value":11549},{"type":24,"tag":2279,"props":12695,"children":12696},{"class":3522,"line":7086},[12697,12701,12705,12709],{"type":24,"tag":2279,"props":12698,"children":12699},{"class":3533},[12700],{"type":34,"value":11577},{"type":24,"tag":2279,"props":12702,"children":12703},{"class":3527},[12704],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12706,"children":12707},{"class":3533},[12708],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12710,"children":12711},{"class":3908},[12712],{"type":34,"value":11549},{"type":24,"tag":2279,"props":12714,"children":12715},{"class":3522,"line":7114},[12716,12720,12724,12728,12732,12736,12740,12744,12748],{"type":24,"tag":2279,"props":12717,"children":12718},{"class":3533},[12719],{"type":34,"value":3879},{"type":24,"tag":2279,"props":12721,"children":12722},{"class":3527},[12723],{"type":34,"value":4181},{"type":24,"tag":2279,"props":12725,"children":12726},{"class":3533},[12727],{"type":34,"value":10291},{"type":24,"tag":2279,"props":12729,"children":12730},{"class":3527},[12731],{"type":34,"value":4191},{"type":24,"tag":2279,"props":12733,"children":12734},{"class":3533},[12735],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12737,"children":12738},{"class":3908},[12739],{"type":34,"value":6371},{"type":24,"tag":2279,"props":12741,"children":12742},{"class":3533},[12743],{"type":34,"value":10308},{"type":24,"tag":2279,"props":12745,"children":12746},{"class":3908},[12747],{"type":34,"value":4023},{"type":24,"tag":2279,"props":12749,"children":12750},{"class":3533},[12751],{"type":34,"value":9427},{"type":24,"tag":2279,"props":12753,"children":12754},{"class":3522,"line":7131},[12755,12759,12763],{"type":24,"tag":2279,"props":12756,"children":12757},{"class":3533},[12758],{"type":34,"value":11636},{"type":24,"tag":2279,"props":12760,"children":12761},{"class":3527},[12762],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12764,"children":12765},{"class":3533},[12766],{"type":34,"value":11645},{"type":24,"tag":2279,"props":12768,"children":12769},{"class":3522,"line":7174},[12770,12774,12778],{"type":24,"tag":2279,"props":12771,"children":12772},{"class":3533},[12773],{"type":34,"value":11661},{"type":24,"tag":2279,"props":12775,"children":12776},{"class":3527},[12777],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12779,"children":12780},{"class":3533},[12781],{"type":34,"value":11670},{"type":24,"tag":2279,"props":12783,"children":12784},{"class":3522,"line":7200},[12785,12789,12793],{"type":24,"tag":2279,"props":12786,"children":12787},{"class":3533},[12788],{"type":34,"value":11678},{"type":24,"tag":2279,"props":12790,"children":12791},{"class":3527},[12792],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12794,"children":12795},{"class":3533},[12796],{"type":34,"value":11687},{"type":24,"tag":2279,"props":12798,"children":12799},{"class":3522,"line":7224},[12800,12804,12808,12812,12816,12820,12824],{"type":24,"tag":2279,"props":12801,"children":12802},{"class":3533},[12803],{"type":34,"value":6910},{"type":24,"tag":2279,"props":12805,"children":12806},{"class":3527},[12807],{"type":34,"value":5391},{"type":24,"tag":2279,"props":12809,"children":12810},{"class":3533},[12811],{"type":34,"value":11703},{"type":24,"tag":2279,"props":12813,"children":12814},{"class":3527},[12815],{"type":34,"value":11708},{"type":24,"tag":2279,"props":12817,"children":12818},{"class":3533},[12819],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12821,"children":12822},{"class":3908},[12823],{"type":34,"value":4954},{"type":24,"tag":2279,"props":12825,"children":12826},{"class":3533},[12827],{"type":34,"value":4809},{"type":24,"tag":2279,"props":12829,"children":12830},{"class":3522,"line":7233},[12831,12835,12839,12843,12847],{"type":24,"tag":2279,"props":12832,"children":12833},{"class":3533},[12834],{"type":34,"value":11728},{"type":24,"tag":2279,"props":12836,"children":12837},{"class":3527},[12838],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12840,"children":12841},{"class":3533},[12842],{"type":34,"value":11737},{"type":24,"tag":2279,"props":12844,"children":12845},{"class":3908},[12846],{"type":34,"value":4023},{"type":24,"tag":2279,"props":12848,"children":12849},{"class":3533},[12850],{"type":34,"value":7057},{"type":24,"tag":2279,"props":12852,"children":12853},{"class":3522,"line":7259},[12854,12858,12862],{"type":24,"tag":2279,"props":12855,"children":12856},{"class":3533},[12857],{"type":34,"value":11753},{"type":24,"tag":2279,"props":12859,"children":12860},{"class":3527},[12861],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12863,"children":12864},{"class":3533},[12865],{"type":34,"value":11762},{"type":24,"tag":2279,"props":12867,"children":12868},{"class":3522,"line":7293},[12869,12873,12877],{"type":24,"tag":2279,"props":12870,"children":12871},{"class":3533},[12872],{"type":34,"value":11770},{"type":24,"tag":2279,"props":12874,"children":12875},{"class":3527},[12876],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12878,"children":12879},{"class":3533},[12880],{"type":34,"value":11779},{"type":24,"tag":2279,"props":12882,"children":12883},{"class":3522,"line":7358},[12884,12889,12893],{"type":24,"tag":2279,"props":12885,"children":12886},{"class":3533},[12887],{"type":34,"value":12888},"        grads ",{"type":24,"tag":2279,"props":12890,"children":12891},{"class":3527},[12892],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12894,"children":12895},{"class":3533},[12896],{"type":34,"value":12897}," torch.autograd.grad(loss, model.parameters())\n",{"type":24,"tag":2279,"props":12899,"children":12900},{"class":3522,"line":7392},[12901,12906,12910,12914,12919,12923,12928,12932,12937,12942,12946,12950,12954,12959,12963,12968,12972,12976,12981],{"type":24,"tag":2279,"props":12902,"children":12903},{"class":3533},[12904],{"type":34,"value":12905},"        new_weights ",{"type":24,"tag":2279,"props":12907,"children":12908},{"class":3527},[12909],{"type":34,"value":3866},{"type":24,"tag":2279,"props":12911,"children":12912},{"class":3533},[12913],{"type":34,"value":2285},{"type":24,"tag":2279,"props":12915,"children":12916},{"class":3908},[12917],{"type":34,"value":12918},"list",{"type":24,"tag":2279,"props":12920,"children":12921},{"class":3533},[12922],{"type":34,"value":4205},{"type":24,"tag":2279,"props":12924,"children":12925},{"class":3908},[12926],{"type":34,"value":12927},"map",{"type":24,"tag":2279,"props":12929,"children":12930},{"class":3533},[12931],{"type":34,"value":4205},{"type":24,"tag":2279,"props":12933,"children":12934},{"class":3527},[12935],{"type":34,"value":12936},"lambda",{"type":24,"tag":2279,"props":12938,"children":12939},{"class":3533},[12940],{"type":34,"value":12941}," p: p[",{"type":24,"tag":2279,"props":12943,"children":12944},{"class":3908},[12945],{"type":34,"value":2283},{"type":24,"tag":2279,"props":12947,"children":12948},{"class":3533},[12949],{"type":34,"value":4176},{"type":24,"tag":2279,"props":12951,"children":12952},{"class":3527},[12953],{"type":34,"value":3630},{"type":24,"tag":2279,"props":12955,"children":12956},{"class":3533},[12957],{"type":34,"value":12958}," update_lr ",{"type":24,"tag":2279,"props":12960,"children":12961},{"class":3527},[12962],{"type":34,"value":4248},{"type":24,"tag":2279,"props":12964,"children":12965},{"class":3533},[12966],{"type":34,"value":12967}," p[",{"type":24,"tag":2279,"props":12969,"children":12970},{"class":3908},[12971],{"type":34,"value":4023},{"type":24,"tag":2279,"props":12973,"children":12974},{"class":3533},[12975],{"type":34,"value":9206},{"type":24,"tag":2279,"props":12977,"children":12978},{"class":3908},[12979],{"type":34,"value":12980},"zip",{"type":24,"tag":2279,"props":12982,"children":12983},{"class":3533},[12984],{"type":34,"value":12985},"(grads, new_weights)))\n",{"type":24,"tag":2279,"props":12987,"children":12988},{"class":3522,"line":7425},[12989,12993,12997],{"type":24,"tag":2279,"props":12990,"children":12991},{"class":3533},[12992],{"type":34,"value":11803},{"type":24,"tag":2279,"props":12994,"children":12995},{"class":3527},[12996],{"type":34,"value":5453},{"type":24,"tag":2279,"props":12998,"children":12999},{"class":3533},[13000],{"type":34,"value":11812},{"type":24,"tag":2279,"props":13002,"children":13003},{"class":3522,"line":7433},[13004,13008,13012,13016,13020,13024,13028,13032,13036,13040,13044,13048,13052,13056,13060],{"type":24,"tag":2279,"props":13005,"children":13006},{"class":3533},[13007],{"type":34,"value":11820},{"type":24,"tag":2279,"props":13009,"children":13010},{"class":3527},[13011],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13013,"children":13014},{"class":3533},[13015],{"type":34,"value":11829},{"type":24,"tag":2279,"props":13017,"children":13018},{"class":3908},[13019],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13021,"children":13022},{"class":3533},[13023],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13025,"children":13026},{"class":3527},[13027],{"type":34,"value":3630},{"type":24,"tag":2279,"props":13029,"children":13030},{"class":3533},[13031],{"type":34,"value":11846},{"type":24,"tag":2279,"props":13033,"children":13034},{"class":3527},[13035],{"type":34,"value":5410},{"type":24,"tag":2279,"props":13037,"children":13038},{"class":3533},[13039],{"type":34,"value":11855},{"type":24,"tag":2279,"props":13041,"children":13042},{"class":3527},[13043],{"type":34,"value":5854},{"type":24,"tag":2279,"props":13045,"children":13046},{"class":3533},[13047],{"type":34,"value":11864},{"type":24,"tag":2279,"props":13049,"children":13050},{"class":3527},[13051],{"type":34,"value":3593},{"type":24,"tag":2279,"props":13053,"children":13054},{"class":3533},[13055],{"type":34,"value":11873},{"type":24,"tag":2279,"props":13057,"children":13058},{"class":3908},[13059],{"type":34,"value":4023},{"type":24,"tag":2279,"props":13061,"children":13062},{"class":3533},[13063],{"type":34,"value":7057},{"type":24,"tag":2279,"props":13065,"children":13066},{"class":3522,"line":7459},[13067,13071,13075,13080,13084,13088,13092],{"type":24,"tag":2279,"props":13068,"children":13069},{"class":3533},[13070],{"type":34,"value":6910},{"type":24,"tag":2279,"props":13072,"children":13073},{"class":3527},[13074],{"type":34,"value":4181},{"type":24,"tag":2279,"props":13076,"children":13077},{"class":3533},[13078],{"type":34,"value":13079}," param, param_key ",{"type":24,"tag":2279,"props":13081,"children":13082},{"class":3527},[13083],{"type":34,"value":4191},{"type":24,"tag":2279,"props":13085,"children":13086},{"class":3533},[13087],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13089,"children":13090},{"class":3908},[13091],{"type":34,"value":12980},{"type":24,"tag":2279,"props":13093,"children":13094},{"class":3533},[13095],{"type":34,"value":13096},"(new_weights, param_keys):\n",{"type":24,"tag":2279,"props":13098,"children":13099},{"class":3522,"line":7496},[13100,13105,13109,13114,13118,13123,13127],{"type":24,"tag":2279,"props":13101,"children":13102},{"class":3533},[13103],{"type":34,"value":13104},"            model._modules[param_key[",{"type":24,"tag":2279,"props":13106,"children":13107},{"class":3908},[13108],{"type":34,"value":4023},{"type":24,"tag":2279,"props":13110,"children":13111},{"class":3533},[13112],{"type":34,"value":13113},"]]._parameters[param_key[",{"type":24,"tag":2279,"props":13115,"children":13116},{"class":3908},[13117],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13119,"children":13120},{"class":3533},[13121],{"type":34,"value":13122},"]] ",{"type":24,"tag":2279,"props":13124,"children":13125},{"class":3527},[13126],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13128,"children":13129},{"class":3533},[13130],{"type":34,"value":13131}," param\n",{"type":24,"tag":2279,"props":13133,"children":13134},{"class":3522,"line":7504},[13135,13139,13143,13147,13151,13155,13159,13163,13167,13171,13175,13179,13183,13187,13191,13195,13199,13203,13207,13211,13215,13219,13223,13227,13231,13235,13239,13243],{"type":24,"tag":2279,"props":13136,"children":13137},{"class":3533},[13138],{"type":34,"value":6910},{"type":24,"tag":2279,"props":13140,"children":13141},{"class":3908},[13142],{"type":34,"value":5074},{"type":24,"tag":2279,"props":13144,"children":13145},{"class":3533},[13146],{"type":34,"value":4205},{"type":24,"tag":2279,"props":13148,"children":13149},{"class":3527},[13150],{"type":34,"value":11492},{"type":24,"tag":2279,"props":13152,"children":13153},{"class":3557},[13154],{"type":34,"value":11497},{"type":24,"tag":2279,"props":13156,"children":13157},{"class":3908},[13158],{"type":34,"value":9135},{"type":24,"tag":2279,"props":13160,"children":13161},{"class":3533},[13162],{"type":34,"value":11506},{"type":24,"tag":2279,"props":13164,"children":13165},{"class":3527},[13166],{"type":34,"value":6072},{"type":24,"tag":2279,"props":13168,"children":13169},{"class":3533},[13170],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13172,"children":13173},{"class":3908},[13174],{"type":34,"value":11519},{"type":24,"tag":2279,"props":13176,"children":13177},{"class":3557},[13178],{"type":34,"value":11929},{"type":24,"tag":2279,"props":13180,"children":13181},{"class":3908},[13182],{"type":34,"value":9135},{"type":24,"tag":2279,"props":13184,"children":13185},{"class":3533},[13186],{"type":34,"value":11938},{"type":24,"tag":2279,"props":13188,"children":13189},{"class":3527},[13190],{"type":34,"value":6072},{"type":24,"tag":2279,"props":13192,"children":13193},{"class":3533},[13194],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13196,"children":13197},{"class":3908},[13198],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13200,"children":13201},{"class":3527},[13202],{"type":34,"value":11955},{"type":24,"tag":2279,"props":13204,"children":13205},{"class":3908},[13206],{"type":34,"value":11960},{"type":24,"tag":2279,"props":13208,"children":13209},{"class":3557},[13210],{"type":34,"value":11965},{"type":24,"tag":2279,"props":13212,"children":13213},{"class":3908},[13214],{"type":34,"value":9135},{"type":24,"tag":2279,"props":13216,"children":13217},{"class":3533},[13218],{"type":34,"value":11974},{"type":24,"tag":2279,"props":13220,"children":13221},{"class":3908},[13222],{"type":34,"value":11960},{"type":24,"tag":2279,"props":13224,"children":13225},{"class":3557},[13226],{"type":34,"value":11983},{"type":24,"tag":2279,"props":13228,"children":13229},{"class":3908},[13230],{"type":34,"value":9135},{"type":24,"tag":2279,"props":13232,"children":13233},{"class":3533},[13234],{"type":34,"value":11992},{"type":24,"tag":2279,"props":13236,"children":13237},{"class":3908},[13238],{"type":34,"value":11960},{"type":24,"tag":2279,"props":13240,"children":13241},{"class":3557},[13242],{"type":34,"value":11524},{"type":24,"tag":2279,"props":13244,"children":13245},{"class":3533},[13246],{"type":34,"value":6699},{"type":24,"tag":2279,"props":13248,"children":13249},{"class":3522,"line":7530},[13250,13254,13258,13262,13266,13270,13274],{"type":24,"tag":2279,"props":13251,"children":13252},{"class":3533},[13253],{"type":34,"value":3879},{"type":24,"tag":2279,"props":13255,"children":13256},{"class":3527},[13257],{"type":34,"value":4181},{"type":24,"tag":2279,"props":13259,"children":13260},{"class":3533},[13261],{"type":34,"value":12020},{"type":24,"tag":2279,"props":13263,"children":13264},{"class":3527},[13265],{"type":34,"value":4191},{"type":24,"tag":2279,"props":13267,"children":13268},{"class":3533},[13269],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13271,"children":13272},{"class":3908},[13273],{"type":34,"value":6371},{"type":24,"tag":2279,"props":13275,"children":13276},{"class":3533},[13277],{"type":34,"value":12037},{"type":24,"tag":2279,"props":13279,"children":13280},{"class":3522,"line":7539},[13281,13285,13289],{"type":24,"tag":2279,"props":13282,"children":13283},{"class":3533},[13284],{"type":34,"value":12045},{"type":24,"tag":2279,"props":13286,"children":13287},{"class":3527},[13288],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13290,"children":13291},{"class":3533},[13292],{"type":34,"value":12054},{"type":24,"tag":2279,"props":13294,"children":13295},{"class":3522,"line":7548},[13296,13300,13304],{"type":24,"tag":2279,"props":13297,"children":13298},{"class":3533},[13299],{"type":34,"value":12062},{"type":24,"tag":2279,"props":13301,"children":13302},{"class":3527},[13303],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13305,"children":13306},{"class":3533},[13307],{"type":34,"value":12071},{"type":24,"tag":2279,"props":13309,"children":13310},{"class":3522,"line":7575},[13311,13315,13319],{"type":24,"tag":2279,"props":13312,"children":13313},{"class":3533},[13314],{"type":34,"value":12079},{"type":24,"tag":2279,"props":13316,"children":13317},{"class":3527},[13318],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13320,"children":13321},{"class":3533},[13322],{"type":34,"value":12088},{"type":24,"tag":2279,"props":13324,"children":13325},{"class":3522,"line":7618},[13326,13330,13334],{"type":24,"tag":2279,"props":13327,"children":13328},{"class":3533},[13329],{"type":34,"value":12096},{"type":24,"tag":2279,"props":13331,"children":13332},{"class":3527},[13333],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13335,"children":13336},{"class":3533},[13337],{"type":34,"value":12105},{"type":24,"tag":2279,"props":13339,"children":13340},{"class":3522,"line":7644},[13341,13345,13349,13353,13357],{"type":24,"tag":2279,"props":13342,"children":13343},{"class":3533},[13344],{"type":34,"value":12113},{"type":24,"tag":2279,"props":13346,"children":13347},{"class":3527},[13348],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13350,"children":13351},{"class":3533},[13352],{"type":34,"value":12122},{"type":24,"tag":2279,"props":13354,"children":13355},{"class":3908},[13356],{"type":34,"value":4023},{"type":24,"tag":2279,"props":13358,"children":13359},{"class":3533},[13360],{"type":34,"value":7941},{"type":24,"tag":2279,"props":13362,"children":13363},{"class":3522,"line":7680},[13364,13368,13372],{"type":24,"tag":2279,"props":13365,"children":13366},{"class":3533},[13367],{"type":34,"value":12138},{"type":24,"tag":2279,"props":13369,"children":13370},{"class":3527},[13371],{"type":34,"value":5453},{"type":24,"tag":2279,"props":13373,"children":13374},{"class":3533},[13375],{"type":34,"value":12147},{"type":24,"tag":2279,"props":13377,"children":13378},{"class":3522,"line":7707},[13379,13383,13387,13391,13395,13399,13403,13407,13411,13415,13419],{"type":24,"tag":2279,"props":13380,"children":13381},{"class":3533},[13382],{"type":34,"value":12155},{"type":24,"tag":2279,"props":13384,"children":13385},{"class":3527},[13386],{"type":34,"value":5453},{"type":24,"tag":2279,"props":13388,"children":13389},{"class":3533},[13390],{"type":34,"value":11829},{"type":24,"tag":2279,"props":13392,"children":13393},{"class":3908},[13394],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13396,"children":13397},{"class":3533},[13398],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13400,"children":13401},{"class":3527},[13402],{"type":34,"value":3630},{"type":24,"tag":2279,"props":13404,"children":13405},{"class":3533},[13406],{"type":34,"value":12180},{"type":24,"tag":2279,"props":13408,"children":13409},{"class":3527},[13410],{"type":34,"value":5410},{"type":24,"tag":2279,"props":13412,"children":13413},{"class":3533},[13414],{"type":34,"value":12189},{"type":24,"tag":2279,"props":13416,"children":13417},{"class":3527},[13418],{"type":34,"value":5854},{"type":24,"tag":2279,"props":13420,"children":13421},{"class":3533},[13422],{"type":34,"value":12198},{"type":24,"tag":2279,"props":13424,"children":13425},{"class":3522,"line":7742},[13426,13430,13434,13438,13442,13446,13450,13454,13458,13462,13466,13470,13474,13478,13482,13486,13490,13494,13498,13502,13506,13510,13514,13518,13522,13526,13530,13534,13538,13542,13546,13550],{"type":24,"tag":2279,"props":13427,"children":13428},{"class":3533},[13429],{"type":34,"value":3879},{"type":24,"tag":2279,"props":13431,"children":13432},{"class":3908},[13433],{"type":34,"value":5074},{"type":24,"tag":2279,"props":13435,"children":13436},{"class":3533},[13437],{"type":34,"value":4205},{"type":24,"tag":2279,"props":13439,"children":13440},{"class":3527},[13441],{"type":34,"value":11492},{"type":24,"tag":2279,"props":13443,"children":13444},{"class":3557},[13445],{"type":34,"value":11497},{"type":24,"tag":2279,"props":13447,"children":13448},{"class":3908},[13449],{"type":34,"value":9135},{"type":24,"tag":2279,"props":13451,"children":13452},{"class":3533},[13453],{"type":34,"value":11506},{"type":24,"tag":2279,"props":13455,"children":13456},{"class":3527},[13457],{"type":34,"value":6072},{"type":24,"tag":2279,"props":13459,"children":13460},{"class":3533},[13461],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13463,"children":13464},{"class":3908},[13465],{"type":34,"value":11519},{"type":24,"tag":2279,"props":13467,"children":13468},{"class":3557},[13469],{"type":34,"value":12246},{"type":24,"tag":2279,"props":13471,"children":13472},{"class":3908},[13473],{"type":34,"value":9135},{"type":24,"tag":2279,"props":13475,"children":13476},{"class":3533},[13477],{"type":34,"value":12255},{"type":24,"tag":2279,"props":13479,"children":13480},{"class":3527},[13481],{"type":34,"value":3593},{"type":24,"tag":2279,"props":13483,"children":13484},{"class":3533},[13485],{"type":34,"value":12264},{"type":24,"tag":2279,"props":13487,"children":13488},{"class":3527},[13489],{"type":34,"value":6072},{"type":24,"tag":2279,"props":13491,"children":13492},{"class":3533},[13493],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13495,"children":13496},{"class":3908},[13497],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13499,"children":13500},{"class":3533},[13501],{"type":34,"value":3937},{"type":24,"tag":2279,"props":13503,"children":13504},{"class":3908},[13505],{"type":34,"value":11960},{"type":24,"tag":2279,"props":13507,"children":13508},{"class":3557},[13509],{"type":34,"value":11983},{"type":24,"tag":2279,"props":13511,"children":13512},{"class":3908},[13513],{"type":34,"value":9135},{"type":24,"tag":2279,"props":13515,"children":13516},{"class":3533},[13517],{"type":34,"value":12297},{"type":24,"tag":2279,"props":13519,"children":13520},{"class":3527},[13521],{"type":34,"value":3593},{"type":24,"tag":2279,"props":13523,"children":13524},{"class":3533},[13525],{"type":34,"value":12264},{"type":24,"tag":2279,"props":13527,"children":13528},{"class":3527},[13529],{"type":34,"value":6072},{"type":24,"tag":2279,"props":13531,"children":13532},{"class":3533},[13533],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13535,"children":13536},{"class":3908},[13537],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13539,"children":13540},{"class":3533},[13541],{"type":34,"value":3937},{"type":24,"tag":2279,"props":13543,"children":13544},{"class":3908},[13545],{"type":34,"value":11960},{"type":24,"tag":2279,"props":13547,"children":13548},{"class":3557},[13549],{"type":34,"value":11524},{"type":24,"tag":2279,"props":13551,"children":13552},{"class":3533},[13553],{"type":34,"value":6699},{"type":24,"tag":2279,"props":13555,"children":13556},{"class":3522,"line":7827},[13557],{"type":24,"tag":2279,"props":13558,"children":13559},{},[],{"type":24,"tag":2279,"props":13561,"children":13562},{"class":3522,"line":7835},[13563,13567,13571,13575],{"type":24,"tag":2279,"props":13564,"children":13565},{"class":3908},[13566],{"type":34,"value":5074},{"type":24,"tag":2279,"props":13568,"children":13569},{"class":3533},[13570],{"type":34,"value":4205},{"type":24,"tag":2279,"props":13572,"children":13573},{"class":3557},[13574],{"type":34,"value":12355},{"type":24,"tag":2279,"props":13576,"children":13577},{"class":3533},[13578],{"type":34,"value":3937},{"type":24,"tag":46,"props":13580,"children":13581},{},[13582],{"type":34,"value":13583},"So training is also completed correctly this way.",{"type":24,"tag":1378,"props":13585,"children":13587},{"id":13586},"meta-learning-training",[13588],{"type":34,"value":13589},"Meta-Learning training",{"type":24,"tag":46,"props":13591,"children":13592},{},[13593],{"type":34,"value":13594},"At this point we will directly define the Meta-Learning pipeline as follows:",{"type":24,"tag":729,"props":13596,"children":13597},{},[13598,13603,13608,13613,13618,13623,13628,13633,13638],{"type":24,"tag":733,"props":13599,"children":13600},{},[13601],{"type":34,"value":13602},"At each Meta-epoch, the Meta-train MetaLoader is called at each Meta-train meta-step.",{"type":24,"tag":733,"props":13604,"children":13605},{},[13606],{"type":34,"value":13607},"At each Meta-train meta-step, at each problem is the meta-batch is asked for its DataLoaders",{"type":24,"tag":733,"props":13609,"children":13610},{},[13611],{"type":34,"value":13612},"For the train DataLoader, at each epoch each step is called and the batch is predicted.",{"type":24,"tag":733,"props":13614,"children":13615},{},[13616],{"type":34,"value":13617},"Manually, at this step the model weights are updated",{"type":24,"tag":733,"props":13619,"children":13620},{},[13621],{"type":34,"value":13622},"At the end of the epoch, a validation is run",{"type":24,"tag":733,"props":13624,"children":13625},{},[13626],{"type":34,"value":13627},"In the last epoch, the validation loss is computed normally but the model is returned to its original (at the beginning of the problem) state.",{"type":24,"tag":733,"props":13629,"children":13630},{},[13631],{"type":34,"value":13632},"The same is repeated over all the problems in the meta-batch and all final validation losses are averaged.",{"type":24,"tag":733,"props":13634,"children":13635},{},[13636],{"type":34,"value":13637},"A pyorch update is performed at the end of the meta-batch",{"type":24,"tag":733,"props":13639,"children":13640},{},[13641],{"type":34,"value":13642},"Every 1000 meta-steps a Meta-Validation meta-step is performed. The process is the same as in Meta-train but the loss won't update the model (only computed for Meta-training guidance matters).",{"type":24,"tag":3511,"props":13644,"children":13646},{"code":13645,"language":3514,"meta":10,"className":3515},"def make_step(model, outputs, labels, update_lr, in_weights):\n    loss = criterion(outputs, labels)\n    grads = torch.autograd.grad(loss, model.parameters())\n    out_weights = list(map(lambda p: p[1] - update_lr * p[0], zip(grads, in_weights)))\n    accuracy = (((1 - outputs) \u003C outputs).float() == labels).sum() / outputs.shape[0]\n    return out_weights, loss, accuracy\n",[13647],{"type":24,"tag":3495,"props":13648,"children":13649},{"__ignoreMap":10},[13650,13671,13687,13703,13784,13848],{"type":24,"tag":2279,"props":13651,"children":13652},{"class":3522,"line":3523},[13653,13657,13661,13666],{"type":24,"tag":2279,"props":13654,"children":13655},{"class":3527},[13656],{"type":34,"value":4822},{"type":24,"tag":2279,"props":13658,"children":13659},{"class":3533},[13660],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13662,"children":13663},{"class":4802},[13664],{"type":34,"value":13665},"make_step",{"type":24,"tag":2279,"props":13667,"children":13668},{"class":3533},[13669],{"type":34,"value":13670},"(model, outputs, labels, update_lr, in_weights):\n",{"type":24,"tag":2279,"props":13672,"children":13673},{"class":3522,"line":2808},[13674,13679,13683],{"type":24,"tag":2279,"props":13675,"children":13676},{"class":3533},[13677],{"type":34,"value":13678},"    loss ",{"type":24,"tag":2279,"props":13680,"children":13681},{"class":3527},[13682],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13684,"children":13685},{"class":3533},[13686],{"type":34,"value":11779},{"type":24,"tag":2279,"props":13688,"children":13689},{"class":3522,"line":2817},[13690,13695,13699],{"type":24,"tag":2279,"props":13691,"children":13692},{"class":3533},[13693],{"type":34,"value":13694},"    grads ",{"type":24,"tag":2279,"props":13696,"children":13697},{"class":3527},[13698],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13700,"children":13701},{"class":3533},[13702],{"type":34,"value":12897},{"type":24,"tag":2279,"props":13704,"children":13705},{"class":3522,"line":3577},[13706,13711,13715,13719,13723,13727,13731,13735,13739,13743,13747,13751,13755,13759,13763,13767,13771,13775,13779],{"type":24,"tag":2279,"props":13707,"children":13708},{"class":3533},[13709],{"type":34,"value":13710},"    out_weights ",{"type":24,"tag":2279,"props":13712,"children":13713},{"class":3527},[13714],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13716,"children":13717},{"class":3533},[13718],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13720,"children":13721},{"class":3908},[13722],{"type":34,"value":12918},{"type":24,"tag":2279,"props":13724,"children":13725},{"class":3533},[13726],{"type":34,"value":4205},{"type":24,"tag":2279,"props":13728,"children":13729},{"class":3908},[13730],{"type":34,"value":12927},{"type":24,"tag":2279,"props":13732,"children":13733},{"class":3533},[13734],{"type":34,"value":4205},{"type":24,"tag":2279,"props":13736,"children":13737},{"class":3527},[13738],{"type":34,"value":12936},{"type":24,"tag":2279,"props":13740,"children":13741},{"class":3533},[13742],{"type":34,"value":12941},{"type":24,"tag":2279,"props":13744,"children":13745},{"class":3908},[13746],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13748,"children":13749},{"class":3533},[13750],{"type":34,"value":4176},{"type":24,"tag":2279,"props":13752,"children":13753},{"class":3527},[13754],{"type":34,"value":3630},{"type":24,"tag":2279,"props":13756,"children":13757},{"class":3533},[13758],{"type":34,"value":12958},{"type":24,"tag":2279,"props":13760,"children":13761},{"class":3527},[13762],{"type":34,"value":4248},{"type":24,"tag":2279,"props":13764,"children":13765},{"class":3533},[13766],{"type":34,"value":12967},{"type":24,"tag":2279,"props":13768,"children":13769},{"class":3908},[13770],{"type":34,"value":4023},{"type":24,"tag":2279,"props":13772,"children":13773},{"class":3533},[13774],{"type":34,"value":9206},{"type":24,"tag":2279,"props":13776,"children":13777},{"class":3908},[13778],{"type":34,"value":12980},{"type":24,"tag":2279,"props":13780,"children":13781},{"class":3533},[13782],{"type":34,"value":13783},"(grads, in_weights)))\n",{"type":24,"tag":2279,"props":13785,"children":13786},{"class":3522,"line":3725},[13787,13792,13796,13800,13804,13808,13812,13816,13820,13824,13828,13832,13836,13840,13844],{"type":24,"tag":2279,"props":13788,"children":13789},{"class":3533},[13790],{"type":34,"value":13791},"    accuracy ",{"type":24,"tag":2279,"props":13793,"children":13794},{"class":3527},[13795],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13797,"children":13798},{"class":3533},[13799],{"type":34,"value":11829},{"type":24,"tag":2279,"props":13801,"children":13802},{"class":3908},[13803],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13805,"children":13806},{"class":3533},[13807],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13809,"children":13810},{"class":3527},[13811],{"type":34,"value":3630},{"type":24,"tag":2279,"props":13813,"children":13814},{"class":3533},[13815],{"type":34,"value":11846},{"type":24,"tag":2279,"props":13817,"children":13818},{"class":3527},[13819],{"type":34,"value":5410},{"type":24,"tag":2279,"props":13821,"children":13822},{"class":3533},[13823],{"type":34,"value":11855},{"type":24,"tag":2279,"props":13825,"children":13826},{"class":3527},[13827],{"type":34,"value":5854},{"type":24,"tag":2279,"props":13829,"children":13830},{"class":3533},[13831],{"type":34,"value":11864},{"type":24,"tag":2279,"props":13833,"children":13834},{"class":3527},[13835],{"type":34,"value":3593},{"type":24,"tag":2279,"props":13837,"children":13838},{"class":3533},[13839],{"type":34,"value":11873},{"type":24,"tag":2279,"props":13841,"children":13842},{"class":3908},[13843],{"type":34,"value":4023},{"type":24,"tag":2279,"props":13845,"children":13846},{"class":3533},[13847],{"type":34,"value":7057},{"type":24,"tag":2279,"props":13849,"children":13850},{"class":3522,"line":3747},[13851,13855,13859],{"type":24,"tag":2279,"props":13852,"children":13853},{"class":3533},[13854],{"type":34,"value":3879},{"type":24,"tag":2279,"props":13856,"children":13857},{"class":3527},[13858],{"type":34,"value":7469},{"type":24,"tag":2279,"props":13860,"children":13861},{"class":3533},[13862],{"type":34,"value":13863}," out_weights, loss, accuracy",{"type":24,"tag":3511,"props":13865,"children":13867},{"code":13866,"language":3514,"meta":10,"className":3515},"def update_model(model, new_weights, param_keys):\n    for param, param_key in zip(new_weights, param_keys):\n        model._modules[param_key[0]]._parameters[param_key[1]] = param\n",[13868],{"type":24,"tag":3495,"props":13869,"children":13870},{"__ignoreMap":10},[13871,13892,13923],{"type":24,"tag":2279,"props":13872,"children":13873},{"class":3522,"line":3523},[13874,13878,13882,13887],{"type":24,"tag":2279,"props":13875,"children":13876},{"class":3527},[13877],{"type":34,"value":4822},{"type":24,"tag":2279,"props":13879,"children":13880},{"class":3533},[13881],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13883,"children":13884},{"class":4802},[13885],{"type":34,"value":13886},"update_model",{"type":24,"tag":2279,"props":13888,"children":13889},{"class":3533},[13890],{"type":34,"value":13891},"(model, new_weights, param_keys):\n",{"type":24,"tag":2279,"props":13893,"children":13894},{"class":3522,"line":2808},[13895,13899,13903,13907,13911,13915,13919],{"type":24,"tag":2279,"props":13896,"children":13897},{"class":3533},[13898],{"type":34,"value":3879},{"type":24,"tag":2279,"props":13900,"children":13901},{"class":3527},[13902],{"type":34,"value":4181},{"type":24,"tag":2279,"props":13904,"children":13905},{"class":3533},[13906],{"type":34,"value":13079},{"type":24,"tag":2279,"props":13908,"children":13909},{"class":3527},[13910],{"type":34,"value":4191},{"type":24,"tag":2279,"props":13912,"children":13913},{"class":3533},[13914],{"type":34,"value":2285},{"type":24,"tag":2279,"props":13916,"children":13917},{"class":3908},[13918],{"type":34,"value":12980},{"type":24,"tag":2279,"props":13920,"children":13921},{"class":3533},[13922],{"type":34,"value":13096},{"type":24,"tag":2279,"props":13924,"children":13925},{"class":3522,"line":2817},[13926,13931,13935,13939,13943,13947,13951],{"type":24,"tag":2279,"props":13927,"children":13928},{"class":3533},[13929],{"type":34,"value":13930},"        model._modules[param_key[",{"type":24,"tag":2279,"props":13932,"children":13933},{"class":3908},[13934],{"type":34,"value":4023},{"type":24,"tag":2279,"props":13936,"children":13937},{"class":3533},[13938],{"type":34,"value":13113},{"type":24,"tag":2279,"props":13940,"children":13941},{"class":3908},[13942],{"type":34,"value":2283},{"type":24,"tag":2279,"props":13944,"children":13945},{"class":3533},[13946],{"type":34,"value":13122},{"type":24,"tag":2279,"props":13948,"children":13949},{"class":3527},[13950],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13952,"children":13953},{"class":3533},[13954],{"type":34,"value":13955}," param",{"type":24,"tag":3511,"props":13957,"children":13959},{"code":13958,"language":3514,"meta":10,"className":3515},"model = SimpleNet()\ncriterion = nn.BCEWithLogitsLoss()\nupdate_lr = 0.01\nmeta_lr = 0.001\nn_epochs = 15\nn_metaepochs = 2\n\nmetaoptimizer = optim.SGD(model.parameters(), lr=meta_lr, momentum=0.9)\nparam_keys = [(mod, kname) for mod in model._modules for kname in model._modules[mod]._parameters]\n\nfor metaepoch in range(n_metaepochs):\n\n    print('===============================')\n    print(f'//           Meta-Epoch {metaepoch + 1}       //')    \n    print('===============================')\n\n    for mi, metabatch in enumerate(metatrain_loader, 0):  #  Meta-step\n        print(f'{mi} updates at Meta-Level')\n\n        running_loss = 0.0  #  At each meta-step, the loss is reset\n\n        initial_weights = model.parameters()\n\n        for pi, problem_loaders in enumerate(metabatch, 0):  #  Problem in the meta-batch\n\n            print(f'- Problem {pi + 1} -')\n\n            problem_loader = problem_loaders['train']\n            problem_loader_val = problem_loaders['val']\n            ref_label = None\n\n            new_weights = initial_weights\n\n            for epoch in range(n_epochs):  #  Epoch in the problem training\n\n                print(f'Epoch {epoch + 1}')\n\n                val_loss = 0.0\n                val_accuracy = 0.0\n\n                for i, data in enumerate(problem_loader, 0):  #  Step in the problem\n\n                    inputs_raw, labels_raw = data\n                    inputs = preprocess_inputs(inputs_raw)\n                    outputs = model(inputs)\n                    if ref_label is None:\n                        ref_label = labels_raw[0]   #  On a new problem (1st step) adjust label mapping\n                    labels = process_labels(labels_raw, ref_label)\n\n                    new_weights, loss, accuracy = make_step(model, outputs, labels, update_lr, new_weights)\n                    update_model(model, new_weights, param_keys)  #  At each step in the problem manually update the model\n\n                    print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n\n                for iv, datav in enumerate(problem_loader_val):  #  At the end of the training process in an epoch of a problem we compute a whole validation\n\n                    inputs_rawv, labels_rawv = datav\n                    inputsv = preprocess_inputs(inputs_rawv)\n                    outputsv = model(inputsv)\n                    labelsv = process_labels(labels_rawv, ref_label)\n\n                    lossv = criterion(outputsv, labelsv[0])  #  Loss in a validation batch\n                    val_loss += lossv.item()\n                    val_accuracy += (((1 - outputsv) \u003C outputsv).float() == labelsv).sum()\n\n                print(f'Epoch {epoch + 1}, VALIDATION], Loss: {val_loss / (iv + 1)}, Accuracy: {val_accuracy / (iv + 1)}')  #  Loss and accuracy averaged for all validation batches in the problem, displayed after whole validation\n\n            running_loss += lossv  #  After all epochs (all training process) in a single problem the validation loss is added\n\n            update_model(model, initial_weights, param_keys)  # After the whole train + validation of a problem and the final loss is added, return the model to its original stage in the meta-step \n        \n        metastep_loss = running_loss / metabatch_size  #  The added validation losses of all problems in the metabatch are averaged\n\n        metaoptimizer.zero_grad()  #  We perform gradient descent at the Meta-Level over the averaged validation loss\n        metastep_loss.backward()\n        metaoptimizer.step()\n\n        if (mi + 1) % 1000 == 0:  #  Meta-validation performed every 1000 meta-steps\n\n            print('META-VALIDATION STEP:')\n\n            for mbvi, metabatch_val in enumerate(metaval_loader):  #  Meta-validation meta-step\n\n                if (mbvi + 1) % 10 == 0:\n\n                    print(f'Validation step {mbvi + 1}')\n                    \n                initial_weights = model.parameters()\n\n                for problem_loaders in metabatch_val:  #  Problem in the meta-validation meta-batch\n\n                    problem_loader = problem_loaders['train']\n                    problem_loader_val = problem_loaders['val']\n                    ref_label = None\n                    new_weights = initial_weights\n\n                    for epoch in range(n_epochs):  #  Epoch in the problem training\n\n                        val_loss = 0.0\n                        val_accuracy = 0.0\n\n                        for i, data in enumerate(problem_loader, 0):  #  Step in the problem\n                            \n                            inputs_raw, labels_raw = data\n                            inputs = preprocess_inputs(inputs_raw)\n                            outputs = model(inputs)\n                            if ref_label is None:\n                                ref_label = labels_raw[0]\n                            labels = process_labels(labels_raw, ref_label)\n\n                            new_weights, loss, accuracy = make_step(model, outputs, labels, update_lr, new_weights)\n                            update_model(model, new_weights, param_keys)  #  Note that we still need to update although being in (Meta-)validation. That is because we are in meta-validation but at the Learning level we are in training stage\n\n                        #    print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n\n                        for iv, datav in enumerate(problem_loader_val):  #  At the end of the training process in an epoch of a problem we compute a whole validation, as in Meta-Train\n\n                            inputs_rawv, labels_rawv = datav\n                            inputsv = preprocess_inputs(inputs_rawv)\n                            outputsv = model(inputsv)\n                            labelsv = process_labels(labels_rawv, ref_label)\n                            \n                            lossv = criterion(outputsv, labelsv[0])\n                            val_loss += lossv.item()\n                            val_accuracy += (((1 - outputsv) \u003C outputsv).float() == labelsv).sum()\n\n                    \n                    if (mbvi + 1) % 10 == 0:\n\n                        print(f'Last epoch, VALIDATION], Loss: {val_loss / (iv + 1)}, Accuracy: {val_accuracy / (iv + 1)}')  # The Meta-Validation only runs for informative matters, so our goal is to have this at the end of each problem (every 10 steps)\n\n                    update_model(model, initial_weights, param_keys)\n\n            print('END OF META-VALIDATION STEP')\n\n\n\n\n\n",[13960],{"type":24,"tag":3495,"props":13961,"children":13962},{"__ignoreMap":10},[13963,13978,13993,14012,14033,14053,14074,14080,14125,14172,14178,14207,14213,14237,14292,14315,14321,14368,14413,14419,14448,14454,14470,14476,14522,14528,14582,14588,14613,14637,14656,14662,14679,14685,14722,14728,14779,14785,14805,14825,14831,14876,14882,14898,14914,14930,14962,14992,15008,15014,15031,15044,15050,15165,15171,15208,15214,15230,15246,15262,15278,15284,15314,15330,15378,15384,15521,15527,15549,15555,15568,15575,15606,15612,15625,15633,15641,15647,15718,15724,15748,15754,15792,15798,15862,15868,15921,15929,15946,15953,15984,15991,16016,16041,16062,16079,16086,16122,16129,16150,16171,16178,16222,16231,16248,16265,16282,16315,16340,16357,16364,16381,16395,16402,16415,16422,16459,16466,16483,16500,16517,16534,16542,16567,16584,16633,16640,16648,16712,16719,16833,16840,16849,16856],{"type":24,"tag":2279,"props":13964,"children":13965},{"class":3522,"line":3523},[13966,13970,13974],{"type":24,"tag":2279,"props":13967,"children":13968},{"class":3533},[13969],{"type":34,"value":11178},{"type":24,"tag":2279,"props":13971,"children":13972},{"class":3527},[13973],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13975,"children":13976},{"class":3533},[13977],{"type":34,"value":11187},{"type":24,"tag":2279,"props":13979,"children":13980},{"class":3522,"line":2808},[13981,13985,13989],{"type":24,"tag":2279,"props":13982,"children":13983},{"class":3533},[13984],{"type":34,"value":11195},{"type":24,"tag":2279,"props":13986,"children":13987},{"class":3527},[13988],{"type":34,"value":3866},{"type":24,"tag":2279,"props":13990,"children":13991},{"class":3533},[13992],{"type":34,"value":11204},{"type":24,"tag":2279,"props":13994,"children":13995},{"class":3522,"line":2817},[13996,14000,14004,14008],{"type":24,"tag":2279,"props":13997,"children":13998},{"class":3533},[13999],{"type":34,"value":12469},{"type":24,"tag":2279,"props":14001,"children":14002},{"class":3527},[14003],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14005,"children":14006},{"class":3533},[14007],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14009,"children":14010},{"class":3908},[14011],{"type":34,"value":12482},{"type":24,"tag":2279,"props":14013,"children":14014},{"class":3522,"line":3577},[14015,14020,14024,14028],{"type":24,"tag":2279,"props":14016,"children":14017},{"class":3533},[14018],{"type":34,"value":14019},"meta_lr ",{"type":24,"tag":2279,"props":14021,"children":14022},{"class":3527},[14023],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14025,"children":14026},{"class":3533},[14027],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14029,"children":14030},{"class":3908},[14031],{"type":34,"value":14032},"0.001\n",{"type":24,"tag":2279,"props":14034,"children":14035},{"class":3522,"line":3725},[14036,14040,14044,14048],{"type":24,"tag":2279,"props":14037,"children":14038},{"class":3533},[14039],{"type":34,"value":11272},{"type":24,"tag":2279,"props":14041,"children":14042},{"class":3527},[14043],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14045,"children":14046},{"class":3533},[14047],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14049,"children":14050},{"class":3908},[14051],{"type":34,"value":14052},"15\n",{"type":24,"tag":2279,"props":14054,"children":14055},{"class":3522,"line":3747},[14056,14061,14065,14069],{"type":24,"tag":2279,"props":14057,"children":14058},{"class":3533},[14059],{"type":34,"value":14060},"n_metaepochs ",{"type":24,"tag":2279,"props":14062,"children":14063},{"class":3527},[14064],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14066,"children":14067},{"class":3533},[14068],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14070,"children":14071},{"class":3908},[14072],{"type":34,"value":14073},"2\n",{"type":24,"tag":2279,"props":14075,"children":14076},{"class":3522,"line":3769},[14077],{"type":24,"tag":2279,"props":14078,"children":14079},{},[],{"type":24,"tag":2279,"props":14081,"children":14082},{"class":3522,"line":3782},[14083,14088,14092,14096,14100,14104,14109,14113,14117,14121],{"type":24,"tag":2279,"props":14084,"children":14085},{"class":3533},[14086],{"type":34,"value":14087},"metaoptimizer ",{"type":24,"tag":2279,"props":14089,"children":14090},{"class":3527},[14091],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14093,"children":14094},{"class":3533},[14095],{"type":34,"value":11221},{"type":24,"tag":2279,"props":14097,"children":14098},{"class":3882},[14099],{"type":34,"value":11226},{"type":24,"tag":2279,"props":14101,"children":14102},{"class":3527},[14103],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14105,"children":14106},{"class":3533},[14107],{"type":34,"value":14108},"meta_lr, ",{"type":24,"tag":2279,"props":14110,"children":14111},{"class":3882},[14112],{"type":34,"value":11244},{"type":24,"tag":2279,"props":14114,"children":14115},{"class":3527},[14116],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14118,"children":14119},{"class":3908},[14120],{"type":34,"value":11253},{"type":24,"tag":2279,"props":14122,"children":14123},{"class":3533},[14124],{"type":34,"value":6699},{"type":24,"tag":2279,"props":14126,"children":14127},{"class":3522,"line":6981},[14128,14132,14136,14140,14144,14148,14152,14156,14160,14164,14168],{"type":24,"tag":2279,"props":14129,"children":14130},{"class":3533},[14131],{"type":34,"value":12515},{"type":24,"tag":2279,"props":14133,"children":14134},{"class":3527},[14135],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14137,"children":14138},{"class":3533},[14139],{"type":34,"value":12524},{"type":24,"tag":2279,"props":14141,"children":14142},{"class":3527},[14143],{"type":34,"value":4181},{"type":24,"tag":2279,"props":14145,"children":14146},{"class":3533},[14147],{"type":34,"value":12533},{"type":24,"tag":2279,"props":14149,"children":14150},{"class":3527},[14151],{"type":34,"value":4191},{"type":24,"tag":2279,"props":14153,"children":14154},{"class":3533},[14155],{"type":34,"value":12542},{"type":24,"tag":2279,"props":14157,"children":14158},{"class":3527},[14159],{"type":34,"value":4181},{"type":24,"tag":2279,"props":14161,"children":14162},{"class":3533},[14163],{"type":34,"value":12551},{"type":24,"tag":2279,"props":14165,"children":14166},{"class":3527},[14167],{"type":34,"value":4191},{"type":24,"tag":2279,"props":14169,"children":14170},{"class":3533},[14171],{"type":34,"value":12560},{"type":24,"tag":2279,"props":14173,"children":14174},{"class":3522,"line":7007},[14175],{"type":24,"tag":2279,"props":14176,"children":14177},{},[],{"type":24,"tag":2279,"props":14179,"children":14180},{"class":3522,"line":7060},[14181,14185,14190,14194,14198,14202],{"type":24,"tag":2279,"props":14182,"children":14183},{"class":3527},[14184],{"type":34,"value":4181},{"type":24,"tag":2279,"props":14186,"children":14187},{"class":3533},[14188],{"type":34,"value":14189}," metaepoch ",{"type":24,"tag":2279,"props":14191,"children":14192},{"class":3527},[14193],{"type":34,"value":4191},{"type":24,"tag":2279,"props":14195,"children":14196},{"class":3533},[14197],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14199,"children":14200},{"class":3908},[14201],{"type":34,"value":4200},{"type":24,"tag":2279,"props":14203,"children":14204},{"class":3533},[14205],{"type":34,"value":14206},"(n_metaepochs):\n",{"type":24,"tag":2279,"props":14208,"children":14209},{"class":3522,"line":7086},[14210],{"type":24,"tag":2279,"props":14211,"children":14212},{},[],{"type":24,"tag":2279,"props":14214,"children":14215},{"class":3522,"line":7114},[14216,14220,14224,14228,14233],{"type":24,"tag":2279,"props":14217,"children":14218},{"class":3533},[14219],{"type":34,"value":3879},{"type":24,"tag":2279,"props":14221,"children":14222},{"class":3908},[14223],{"type":34,"value":5074},{"type":24,"tag":2279,"props":14225,"children":14226},{"class":3533},[14227],{"type":34,"value":4205},{"type":24,"tag":2279,"props":14229,"children":14230},{"class":3557},[14231],{"type":34,"value":14232},"'==============================='",{"type":24,"tag":2279,"props":14234,"children":14235},{"class":3533},[14236],{"type":34,"value":6699},{"type":24,"tag":2279,"props":14238,"children":14239},{"class":3522,"line":7131},[14240,14244,14248,14252,14256,14261,14265,14270,14274,14278,14282,14287],{"type":24,"tag":2279,"props":14241,"children":14242},{"class":3533},[14243],{"type":34,"value":3879},{"type":24,"tag":2279,"props":14245,"children":14246},{"class":3908},[14247],{"type":34,"value":5074},{"type":24,"tag":2279,"props":14249,"children":14250},{"class":3533},[14251],{"type":34,"value":4205},{"type":24,"tag":2279,"props":14253,"children":14254},{"class":3527},[14255],{"type":34,"value":11492},{"type":24,"tag":2279,"props":14257,"children":14258},{"class":3557},[14259],{"type":34,"value":14260},"'//           Meta-Epoch ",{"type":24,"tag":2279,"props":14262,"children":14263},{"class":3908},[14264],{"type":34,"value":9135},{"type":24,"tag":2279,"props":14266,"children":14267},{"class":3533},[14268],{"type":34,"value":14269},"metaepoch ",{"type":24,"tag":2279,"props":14271,"children":14272},{"class":3527},[14273],{"type":34,"value":6072},{"type":24,"tag":2279,"props":14275,"children":14276},{"class":3533},[14277],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14279,"children":14280},{"class":3908},[14281],{"type":34,"value":11519},{"type":24,"tag":2279,"props":14283,"children":14284},{"class":3557},[14285],{"type":34,"value":14286},"       //'",{"type":24,"tag":2279,"props":14288,"children":14289},{"class":3533},[14290],{"type":34,"value":14291},")    \n",{"type":24,"tag":2279,"props":14293,"children":14294},{"class":3522,"line":7174},[14295,14299,14303,14307,14311],{"type":24,"tag":2279,"props":14296,"children":14297},{"class":3533},[14298],{"type":34,"value":3879},{"type":24,"tag":2279,"props":14300,"children":14301},{"class":3908},[14302],{"type":34,"value":5074},{"type":24,"tag":2279,"props":14304,"children":14305},{"class":3533},[14306],{"type":34,"value":4205},{"type":24,"tag":2279,"props":14308,"children":14309},{"class":3557},[14310],{"type":34,"value":14232},{"type":24,"tag":2279,"props":14312,"children":14313},{"class":3533},[14314],{"type":34,"value":6699},{"type":24,"tag":2279,"props":14316,"children":14317},{"class":3522,"line":7200},[14318],{"type":24,"tag":2279,"props":14319,"children":14320},{},[],{"type":24,"tag":2279,"props":14322,"children":14323},{"class":3522,"line":7224},[14324,14328,14332,14337,14341,14345,14349,14354,14358,14363],{"type":24,"tag":2279,"props":14325,"children":14326},{"class":3533},[14327],{"type":34,"value":3879},{"type":24,"tag":2279,"props":14329,"children":14330},{"class":3527},[14331],{"type":34,"value":4181},{"type":24,"tag":2279,"props":14333,"children":14334},{"class":3533},[14335],{"type":34,"value":14336}," mi, metabatch ",{"type":24,"tag":2279,"props":14338,"children":14339},{"class":3527},[14340],{"type":34,"value":4191},{"type":24,"tag":2279,"props":14342,"children":14343},{"class":3533},[14344],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14346,"children":14347},{"class":3908},[14348],{"type":34,"value":6371},{"type":24,"tag":2279,"props":14350,"children":14351},{"class":3533},[14352],{"type":34,"value":14353},"(metatrain_loader, ",{"type":24,"tag":2279,"props":14355,"children":14356},{"class":3908},[14357],{"type":34,"value":4023},{"type":24,"tag":2279,"props":14359,"children":14360},{"class":3533},[14361],{"type":34,"value":14362},"):  ",{"type":24,"tag":2279,"props":14364,"children":14365},{"class":3571},[14366],{"type":34,"value":14367},"#  Meta-step\n",{"type":24,"tag":2279,"props":14369,"children":14370},{"class":3522,"line":7233},[14371,14375,14379,14383,14387,14391,14395,14400,14404,14409],{"type":24,"tag":2279,"props":14372,"children":14373},{"class":3533},[14374],{"type":34,"value":6910},{"type":24,"tag":2279,"props":14376,"children":14377},{"class":3908},[14378],{"type":34,"value":5074},{"type":24,"tag":2279,"props":14380,"children":14381},{"class":3533},[14382],{"type":34,"value":4205},{"type":24,"tag":2279,"props":14384,"children":14385},{"class":3527},[14386],{"type":34,"value":11492},{"type":24,"tag":2279,"props":14388,"children":14389},{"class":3557},[14390],{"type":34,"value":11524},{"type":24,"tag":2279,"props":14392,"children":14393},{"class":3908},[14394],{"type":34,"value":9135},{"type":24,"tag":2279,"props":14396,"children":14397},{"class":3533},[14398],{"type":34,"value":14399},"mi",{"type":24,"tag":2279,"props":14401,"children":14402},{"class":3908},[14403],{"type":34,"value":11960},{"type":24,"tag":2279,"props":14405,"children":14406},{"class":3557},[14407],{"type":34,"value":14408}," updates at Meta-Level'",{"type":24,"tag":2279,"props":14410,"children":14411},{"class":3533},[14412],{"type":34,"value":6699},{"type":24,"tag":2279,"props":14414,"children":14415},{"class":3522,"line":7259},[14416],{"type":24,"tag":2279,"props":14417,"children":14418},{},[],{"type":24,"tag":2279,"props":14420,"children":14421},{"class":3522,"line":7293},[14422,14426,14430,14434,14439,14443],{"type":24,"tag":2279,"props":14423,"children":14424},{"class":3533},[14425],{"type":34,"value":11803},{"type":24,"tag":2279,"props":14427,"children":14428},{"class":3527},[14429],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14431,"children":14432},{"class":3533},[14433],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14435,"children":14436},{"class":3908},[14437],{"type":34,"value":14438},"0.0",{"type":24,"tag":2279,"props":14440,"children":14441},{"class":3533},[14442],{"type":34,"value":4817},{"type":24,"tag":2279,"props":14444,"children":14445},{"class":3571},[14446],{"type":34,"value":14447},"#  At each meta-step, the loss is reset\n",{"type":24,"tag":2279,"props":14449,"children":14450},{"class":3522,"line":7358},[14451],{"type":24,"tag":2279,"props":14452,"children":14453},{},[],{"type":24,"tag":2279,"props":14455,"children":14456},{"class":3522,"line":7392},[14457,14462,14466],{"type":24,"tag":2279,"props":14458,"children":14459},{"class":3533},[14460],{"type":34,"value":14461},"        initial_weights ",{"type":24,"tag":2279,"props":14463,"children":14464},{"class":3527},[14465],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14467,"children":14468},{"class":3533},[14469],{"type":34,"value":12577},{"type":24,"tag":2279,"props":14471,"children":14472},{"class":3522,"line":7425},[14473],{"type":24,"tag":2279,"props":14474,"children":14475},{},[],{"type":24,"tag":2279,"props":14477,"children":14478},{"class":3522,"line":7433},[14479,14483,14487,14492,14496,14500,14504,14509,14513,14517],{"type":24,"tag":2279,"props":14480,"children":14481},{"class":3533},[14482],{"type":34,"value":6910},{"type":24,"tag":2279,"props":14484,"children":14485},{"class":3527},[14486],{"type":34,"value":4181},{"type":24,"tag":2279,"props":14488,"children":14489},{"class":3533},[14490],{"type":34,"value":14491}," pi, problem_loaders ",{"type":24,"tag":2279,"props":14493,"children":14494},{"class":3527},[14495],{"type":34,"value":4191},{"type":24,"tag":2279,"props":14497,"children":14498},{"class":3533},[14499],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14501,"children":14502},{"class":3908},[14503],{"type":34,"value":6371},{"type":24,"tag":2279,"props":14505,"children":14506},{"class":3533},[14507],{"type":34,"value":14508},"(metabatch, ",{"type":24,"tag":2279,"props":14510,"children":14511},{"class":3908},[14512],{"type":34,"value":4023},{"type":24,"tag":2279,"props":14514,"children":14515},{"class":3533},[14516],{"type":34,"value":14362},{"type":24,"tag":2279,"props":14518,"children":14519},{"class":3571},[14520],{"type":34,"value":14521},"#  Problem in the meta-batch\n",{"type":24,"tag":2279,"props":14523,"children":14524},{"class":3522,"line":7459},[14525],{"type":24,"tag":2279,"props":14526,"children":14527},{},[],{"type":24,"tag":2279,"props":14529,"children":14530},{"class":3522,"line":7496},[14531,14535,14539,14543,14547,14552,14556,14561,14565,14569,14573,14578],{"type":24,"tag":2279,"props":14532,"children":14533},{"class":3533},[14534],{"type":34,"value":7299},{"type":24,"tag":2279,"props":14536,"children":14537},{"class":3908},[14538],{"type":34,"value":5074},{"type":24,"tag":2279,"props":14540,"children":14541},{"class":3533},[14542],{"type":34,"value":4205},{"type":24,"tag":2279,"props":14544,"children":14545},{"class":3527},[14546],{"type":34,"value":11492},{"type":24,"tag":2279,"props":14548,"children":14549},{"class":3557},[14550],{"type":34,"value":14551},"'- Problem ",{"type":24,"tag":2279,"props":14553,"children":14554},{"class":3908},[14555],{"type":34,"value":9135},{"type":24,"tag":2279,"props":14557,"children":14558},{"class":3533},[14559],{"type":34,"value":14560},"pi ",{"type":24,"tag":2279,"props":14562,"children":14563},{"class":3527},[14564],{"type":34,"value":6072},{"type":24,"tag":2279,"props":14566,"children":14567},{"class":3533},[14568],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14570,"children":14571},{"class":3908},[14572],{"type":34,"value":11519},{"type":24,"tag":2279,"props":14574,"children":14575},{"class":3557},[14576],{"type":34,"value":14577}," -'",{"type":24,"tag":2279,"props":14579,"children":14580},{"class":3533},[14581],{"type":34,"value":6699},{"type":24,"tag":2279,"props":14583,"children":14584},{"class":3522,"line":7504},[14585],{"type":24,"tag":2279,"props":14586,"children":14587},{},[],{"type":24,"tag":2279,"props":14589,"children":14590},{"class":3522,"line":7530},[14591,14596,14600,14605,14609],{"type":24,"tag":2279,"props":14592,"children":14593},{"class":3533},[14594],{"type":34,"value":14595},"            problem_loader ",{"type":24,"tag":2279,"props":14597,"children":14598},{"class":3527},[14599],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14601,"children":14602},{"class":3533},[14603],{"type":34,"value":14604}," problem_loaders[",{"type":24,"tag":2279,"props":14606,"children":14607},{"class":3557},[14608],{"type":34,"value":8135},{"type":24,"tag":2279,"props":14610,"children":14611},{"class":3533},[14612],{"type":34,"value":7057},{"type":24,"tag":2279,"props":14614,"children":14615},{"class":3522,"line":7539},[14616,14621,14625,14629,14633],{"type":24,"tag":2279,"props":14617,"children":14618},{"class":3533},[14619],{"type":34,"value":14620},"            problem_loader_val ",{"type":24,"tag":2279,"props":14622,"children":14623},{"class":3527},[14624],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14626,"children":14627},{"class":3533},[14628],{"type":34,"value":14604},{"type":24,"tag":2279,"props":14630,"children":14631},{"class":3557},[14632],{"type":34,"value":8212},{"type":24,"tag":2279,"props":14634,"children":14635},{"class":3533},[14636],{"type":34,"value":7057},{"type":24,"tag":2279,"props":14638,"children":14639},{"class":3522,"line":7548},[14640,14644,14648,14652],{"type":24,"tag":2279,"props":14641,"children":14642},{"class":3533},[14643],{"type":34,"value":11728},{"type":24,"tag":2279,"props":14645,"children":14646},{"class":3527},[14647],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14649,"children":14650},{"class":3533},[14651],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14653,"children":14654},{"class":3908},[14655],{"type":34,"value":11443},{"type":24,"tag":2279,"props":14657,"children":14658},{"class":3522,"line":7575},[14659],{"type":24,"tag":2279,"props":14660,"children":14661},{},[],{"type":24,"tag":2279,"props":14663,"children":14664},{"class":3522,"line":7618},[14665,14670,14674],{"type":24,"tag":2279,"props":14666,"children":14667},{"class":3533},[14668],{"type":34,"value":14669},"            new_weights ",{"type":24,"tag":2279,"props":14671,"children":14672},{"class":3527},[14673],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14675,"children":14676},{"class":3533},[14677],{"type":34,"value":14678}," initial_weights\n",{"type":24,"tag":2279,"props":14680,"children":14681},{"class":3522,"line":7644},[14682],{"type":24,"tag":2279,"props":14683,"children":14684},{},[],{"type":24,"tag":2279,"props":14686,"children":14687},{"class":3522,"line":7680},[14688,14692,14696,14700,14704,14708,14712,14717],{"type":24,"tag":2279,"props":14689,"children":14690},{"class":3533},[14691],{"type":34,"value":7299},{"type":24,"tag":2279,"props":14693,"children":14694},{"class":3527},[14695],{"type":34,"value":4181},{"type":24,"tag":2279,"props":14697,"children":14698},{"class":3533},[14699],{"type":34,"value":11455},{"type":24,"tag":2279,"props":14701,"children":14702},{"class":3527},[14703],{"type":34,"value":4191},{"type":24,"tag":2279,"props":14705,"children":14706},{"class":3533},[14707],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14709,"children":14710},{"class":3908},[14711],{"type":34,"value":4200},{"type":24,"tag":2279,"props":14713,"children":14714},{"class":3533},[14715],{"type":34,"value":14716},"(n_epochs):  ",{"type":24,"tag":2279,"props":14718,"children":14719},{"class":3571},[14720],{"type":34,"value":14721},"#  Epoch in the problem training\n",{"type":24,"tag":2279,"props":14723,"children":14724},{"class":3522,"line":7707},[14725],{"type":24,"tag":2279,"props":14726,"children":14727},{},[],{"type":24,"tag":2279,"props":14729,"children":14730},{"class":3522,"line":7742},[14731,14735,14739,14743,14747,14751,14755,14759,14763,14767,14771,14775],{"type":24,"tag":2279,"props":14732,"children":14733},{"class":3533},[14734],{"type":34,"value":7748},{"type":24,"tag":2279,"props":14736,"children":14737},{"class":3908},[14738],{"type":34,"value":5074},{"type":24,"tag":2279,"props":14740,"children":14741},{"class":3533},[14742],{"type":34,"value":4205},{"type":24,"tag":2279,"props":14744,"children":14745},{"class":3527},[14746],{"type":34,"value":11492},{"type":24,"tag":2279,"props":14748,"children":14749},{"class":3557},[14750],{"type":34,"value":11497},{"type":24,"tag":2279,"props":14752,"children":14753},{"class":3908},[14754],{"type":34,"value":9135},{"type":24,"tag":2279,"props":14756,"children":14757},{"class":3533},[14758],{"type":34,"value":11506},{"type":24,"tag":2279,"props":14760,"children":14761},{"class":3527},[14762],{"type":34,"value":6072},{"type":24,"tag":2279,"props":14764,"children":14765},{"class":3533},[14766],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14768,"children":14769},{"class":3908},[14770],{"type":34,"value":11519},{"type":24,"tag":2279,"props":14772,"children":14773},{"class":3557},[14774],{"type":34,"value":11524},{"type":24,"tag":2279,"props":14776,"children":14777},{"class":3533},[14778],{"type":34,"value":6699},{"type":24,"tag":2279,"props":14780,"children":14781},{"class":3522,"line":7827},[14782],{"type":24,"tag":2279,"props":14783,"children":14784},{},[],{"type":24,"tag":2279,"props":14786,"children":14787},{"class":3522,"line":7835},[14788,14793,14797,14801],{"type":24,"tag":2279,"props":14789,"children":14790},{"class":3533},[14791],{"type":34,"value":14792},"                val_loss ",{"type":24,"tag":2279,"props":14794,"children":14795},{"class":3527},[14796],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14798,"children":14799},{"class":3533},[14800],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14802,"children":14803},{"class":3908},[14804],{"type":34,"value":11549},{"type":24,"tag":2279,"props":14806,"children":14807},{"class":3522,"line":7861},[14808,14813,14817,14821],{"type":24,"tag":2279,"props":14809,"children":14810},{"class":3533},[14811],{"type":34,"value":14812},"                val_accuracy ",{"type":24,"tag":2279,"props":14814,"children":14815},{"class":3527},[14816],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14818,"children":14819},{"class":3533},[14820],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14822,"children":14823},{"class":3908},[14824],{"type":34,"value":11549},{"type":24,"tag":2279,"props":14826,"children":14827},{"class":3522,"line":7868},[14828],{"type":24,"tag":2279,"props":14829,"children":14830},{},[],{"type":24,"tag":2279,"props":14832,"children":14833},{"class":3522,"line":7877},[14834,14838,14842,14846,14850,14854,14858,14863,14867,14871],{"type":24,"tag":2279,"props":14835,"children":14836},{"class":3533},[14837],{"type":34,"value":7748},{"type":24,"tag":2279,"props":14839,"children":14840},{"class":3527},[14841],{"type":34,"value":4181},{"type":24,"tag":2279,"props":14843,"children":14844},{"class":3533},[14845],{"type":34,"value":10291},{"type":24,"tag":2279,"props":14847,"children":14848},{"class":3527},[14849],{"type":34,"value":4191},{"type":24,"tag":2279,"props":14851,"children":14852},{"class":3533},[14853],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14855,"children":14856},{"class":3908},[14857],{"type":34,"value":6371},{"type":24,"tag":2279,"props":14859,"children":14860},{"class":3533},[14861],{"type":34,"value":14862},"(problem_loader, ",{"type":24,"tag":2279,"props":14864,"children":14865},{"class":3908},[14866],{"type":34,"value":4023},{"type":24,"tag":2279,"props":14868,"children":14869},{"class":3533},[14870],{"type":34,"value":14362},{"type":24,"tag":2279,"props":14872,"children":14873},{"class":3571},[14874],{"type":34,"value":14875},"#  Step in the problem\n",{"type":24,"tag":2279,"props":14877,"children":14878},{"class":3522,"line":7884},[14879],{"type":24,"tag":2279,"props":14880,"children":14881},{},[],{"type":24,"tag":2279,"props":14883,"children":14884},{"class":3522,"line":7944},[14885,14890,14894],{"type":24,"tag":2279,"props":14886,"children":14887},{"class":3533},[14888],{"type":34,"value":14889},"                    inputs_raw, labels_raw ",{"type":24,"tag":2279,"props":14891,"children":14892},{"class":3527},[14893],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14895,"children":14896},{"class":3533},[14897],{"type":34,"value":11645},{"type":24,"tag":2279,"props":14899,"children":14900},{"class":3522,"line":7978},[14901,14906,14910],{"type":24,"tag":2279,"props":14902,"children":14903},{"class":3533},[14904],{"type":34,"value":14905},"                    inputs ",{"type":24,"tag":2279,"props":14907,"children":14908},{"class":3527},[14909],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14911,"children":14912},{"class":3533},[14913],{"type":34,"value":11670},{"type":24,"tag":2279,"props":14915,"children":14916},{"class":3522,"line":8019},[14917,14922,14926],{"type":24,"tag":2279,"props":14918,"children":14919},{"class":3533},[14920],{"type":34,"value":14921},"                    outputs ",{"type":24,"tag":2279,"props":14923,"children":14924},{"class":3527},[14925],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14927,"children":14928},{"class":3533},[14929],{"type":34,"value":11687},{"type":24,"tag":2279,"props":14931,"children":14932},{"class":3522,"line":8028},[14933,14938,14942,14946,14950,14954,14958],{"type":24,"tag":2279,"props":14934,"children":14935},{"class":3533},[14936],{"type":34,"value":14937},"                    ",{"type":24,"tag":2279,"props":14939,"children":14940},{"class":3527},[14941],{"type":34,"value":5391},{"type":24,"tag":2279,"props":14943,"children":14944},{"class":3533},[14945],{"type":34,"value":11703},{"type":24,"tag":2279,"props":14947,"children":14948},{"class":3527},[14949],{"type":34,"value":11708},{"type":24,"tag":2279,"props":14951,"children":14952},{"class":3533},[14953],{"type":34,"value":2285},{"type":24,"tag":2279,"props":14955,"children":14956},{"class":3908},[14957],{"type":34,"value":4954},{"type":24,"tag":2279,"props":14959,"children":14960},{"class":3533},[14961],{"type":34,"value":4809},{"type":24,"tag":2279,"props":14963,"children":14964},{"class":3522,"line":8046},[14965,14970,14974,14978,14982,14987],{"type":24,"tag":2279,"props":14966,"children":14967},{"class":3533},[14968],{"type":34,"value":14969},"                        ref_label ",{"type":24,"tag":2279,"props":14971,"children":14972},{"class":3527},[14973],{"type":34,"value":3866},{"type":24,"tag":2279,"props":14975,"children":14976},{"class":3533},[14977],{"type":34,"value":11737},{"type":24,"tag":2279,"props":14979,"children":14980},{"class":3908},[14981],{"type":34,"value":4023},{"type":24,"tag":2279,"props":14983,"children":14984},{"class":3533},[14985],{"type":34,"value":14986},"]   ",{"type":24,"tag":2279,"props":14988,"children":14989},{"class":3571},[14990],{"type":34,"value":14991},"#  On a new problem (1st step) adjust label mapping\n",{"type":24,"tag":2279,"props":14993,"children":14994},{"class":3522,"line":8064},[14995,15000,15004],{"type":24,"tag":2279,"props":14996,"children":14997},{"class":3533},[14998],{"type":34,"value":14999},"                    labels ",{"type":24,"tag":2279,"props":15001,"children":15002},{"class":3527},[15003],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15005,"children":15006},{"class":3533},[15007],{"type":34,"value":11762},{"type":24,"tag":2279,"props":15009,"children":15010},{"class":3522,"line":8082},[15011],{"type":24,"tag":2279,"props":15012,"children":15013},{},[],{"type":24,"tag":2279,"props":15015,"children":15016},{"class":3522,"line":8089},[15017,15022,15026],{"type":24,"tag":2279,"props":15018,"children":15019},{"class":3533},[15020],{"type":34,"value":15021},"                    new_weights, loss, accuracy ",{"type":24,"tag":2279,"props":15023,"children":15024},{"class":3527},[15025],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15027,"children":15028},{"class":3533},[15029],{"type":34,"value":15030}," make_step(model, outputs, labels, update_lr, new_weights)\n",{"type":24,"tag":2279,"props":15032,"children":15033},{"class":3522,"line":8107},[15034,15039],{"type":24,"tag":2279,"props":15035,"children":15036},{"class":3533},[15037],{"type":34,"value":15038},"                    update_model(model, new_weights, param_keys)  ",{"type":24,"tag":2279,"props":15040,"children":15041},{"class":3571},[15042],{"type":34,"value":15043},"#  At each step in the problem manually update the model\n",{"type":24,"tag":2279,"props":15045,"children":15046},{"class":3522,"line":8143},[15047],{"type":24,"tag":2279,"props":15048,"children":15049},{},[],{"type":24,"tag":2279,"props":15051,"children":15052},{"class":3522,"line":8167},[15053,15057,15061,15065,15069,15073,15077,15081,15085,15089,15093,15097,15101,15105,15109,15113,15117,15121,15125,15129,15133,15137,15141,15145,15149,15153,15157,15161],{"type":24,"tag":2279,"props":15054,"children":15055},{"class":3533},[15056],{"type":34,"value":14937},{"type":24,"tag":2279,"props":15058,"children":15059},{"class":3908},[15060],{"type":34,"value":5074},{"type":24,"tag":2279,"props":15062,"children":15063},{"class":3533},[15064],{"type":34,"value":4205},{"type":24,"tag":2279,"props":15066,"children":15067},{"class":3527},[15068],{"type":34,"value":11492},{"type":24,"tag":2279,"props":15070,"children":15071},{"class":3557},[15072],{"type":34,"value":11497},{"type":24,"tag":2279,"props":15074,"children":15075},{"class":3908},[15076],{"type":34,"value":9135},{"type":24,"tag":2279,"props":15078,"children":15079},{"class":3533},[15080],{"type":34,"value":11506},{"type":24,"tag":2279,"props":15082,"children":15083},{"class":3527},[15084],{"type":34,"value":6072},{"type":24,"tag":2279,"props":15086,"children":15087},{"class":3533},[15088],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15090,"children":15091},{"class":3908},[15092],{"type":34,"value":11519},{"type":24,"tag":2279,"props":15094,"children":15095},{"class":3557},[15096],{"type":34,"value":11929},{"type":24,"tag":2279,"props":15098,"children":15099},{"class":3908},[15100],{"type":34,"value":9135},{"type":24,"tag":2279,"props":15102,"children":15103},{"class":3533},[15104],{"type":34,"value":11938},{"type":24,"tag":2279,"props":15106,"children":15107},{"class":3527},[15108],{"type":34,"value":6072},{"type":24,"tag":2279,"props":15110,"children":15111},{"class":3533},[15112],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15114,"children":15115},{"class":3908},[15116],{"type":34,"value":2283},{"type":24,"tag":2279,"props":15118,"children":15119},{"class":3527},[15120],{"type":34,"value":11955},{"type":24,"tag":2279,"props":15122,"children":15123},{"class":3908},[15124],{"type":34,"value":11960},{"type":24,"tag":2279,"props":15126,"children":15127},{"class":3557},[15128],{"type":34,"value":11965},{"type":24,"tag":2279,"props":15130,"children":15131},{"class":3908},[15132],{"type":34,"value":9135},{"type":24,"tag":2279,"props":15134,"children":15135},{"class":3533},[15136],{"type":34,"value":11974},{"type":24,"tag":2279,"props":15138,"children":15139},{"class":3908},[15140],{"type":34,"value":11960},{"type":24,"tag":2279,"props":15142,"children":15143},{"class":3557},[15144],{"type":34,"value":11983},{"type":24,"tag":2279,"props":15146,"children":15147},{"class":3908},[15148],{"type":34,"value":9135},{"type":24,"tag":2279,"props":15150,"children":15151},{"class":3533},[15152],{"type":34,"value":11992},{"type":24,"tag":2279,"props":15154,"children":15155},{"class":3908},[15156],{"type":34,"value":11960},{"type":24,"tag":2279,"props":15158,"children":15159},{"class":3557},[15160],{"type":34,"value":11524},{"type":24,"tag":2279,"props":15162,"children":15163},{"class":3533},[15164],{"type":34,"value":6699},{"type":24,"tag":2279,"props":15166,"children":15167},{"class":3522,"line":8185},[15168],{"type":24,"tag":2279,"props":15169,"children":15170},{},[],{"type":24,"tag":2279,"props":15172,"children":15173},{"class":3522,"line":8219},[15174,15178,15182,15186,15190,15194,15198,15203],{"type":24,"tag":2279,"props":15175,"children":15176},{"class":3533},[15177],{"type":34,"value":7748},{"type":24,"tag":2279,"props":15179,"children":15180},{"class":3527},[15181],{"type":34,"value":4181},{"type":24,"tag":2279,"props":15183,"children":15184},{"class":3533},[15185],{"type":34,"value":12020},{"type":24,"tag":2279,"props":15187,"children":15188},{"class":3527},[15189],{"type":34,"value":4191},{"type":24,"tag":2279,"props":15191,"children":15192},{"class":3533},[15193],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15195,"children":15196},{"class":3908},[15197],{"type":34,"value":6371},{"type":24,"tag":2279,"props":15199,"children":15200},{"class":3533},[15201],{"type":34,"value":15202},"(problem_loader_val):  ",{"type":24,"tag":2279,"props":15204,"children":15205},{"class":3571},[15206],{"type":34,"value":15207},"#  At the end of the training process in an epoch of a problem we compute a whole validation\n",{"type":24,"tag":2279,"props":15209,"children":15210},{"class":3522,"line":8243},[15211],{"type":24,"tag":2279,"props":15212,"children":15213},{},[],{"type":24,"tag":2279,"props":15215,"children":15216},{"class":3522,"line":8261},[15217,15222,15226],{"type":24,"tag":2279,"props":15218,"children":15219},{"class":3533},[15220],{"type":34,"value":15221},"                    inputs_rawv, labels_rawv ",{"type":24,"tag":2279,"props":15223,"children":15224},{"class":3527},[15225],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15227,"children":15228},{"class":3533},[15229],{"type":34,"value":12054},{"type":24,"tag":2279,"props":15231,"children":15232},{"class":3522,"line":8295},[15233,15238,15242],{"type":24,"tag":2279,"props":15234,"children":15235},{"class":3533},[15236],{"type":34,"value":15237},"                    inputsv ",{"type":24,"tag":2279,"props":15239,"children":15240},{"class":3527},[15241],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15243,"children":15244},{"class":3533},[15245],{"type":34,"value":12071},{"type":24,"tag":2279,"props":15247,"children":15248},{"class":3522,"line":8319},[15249,15254,15258],{"type":24,"tag":2279,"props":15250,"children":15251},{"class":3533},[15252],{"type":34,"value":15253},"                    outputsv ",{"type":24,"tag":2279,"props":15255,"children":15256},{"class":3527},[15257],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15259,"children":15260},{"class":3533},[15261],{"type":34,"value":12088},{"type":24,"tag":2279,"props":15263,"children":15264},{"class":3522,"line":8362},[15265,15270,15274],{"type":24,"tag":2279,"props":15266,"children":15267},{"class":3533},[15268],{"type":34,"value":15269},"                    labelsv ",{"type":24,"tag":2279,"props":15271,"children":15272},{"class":3527},[15273],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15275,"children":15276},{"class":3533},[15277],{"type":34,"value":12105},{"type":24,"tag":2279,"props":15279,"children":15280},{"class":3522,"line":8384},[15281],{"type":24,"tag":2279,"props":15282,"children":15283},{},[],{"type":24,"tag":2279,"props":15285,"children":15286},{"class":3522,"line":8417},[15287,15292,15296,15300,15304,15309],{"type":24,"tag":2279,"props":15288,"children":15289},{"class":3533},[15290],{"type":34,"value":15291},"                    lossv ",{"type":24,"tag":2279,"props":15293,"children":15294},{"class":3527},[15295],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15297,"children":15298},{"class":3533},[15299],{"type":34,"value":12122},{"type":24,"tag":2279,"props":15301,"children":15302},{"class":3908},[15303],{"type":34,"value":4023},{"type":24,"tag":2279,"props":15305,"children":15306},{"class":3533},[15307],{"type":34,"value":15308},"])  ",{"type":24,"tag":2279,"props":15310,"children":15311},{"class":3571},[15312],{"type":34,"value":15313},"#  Loss in a validation batch\n",{"type":24,"tag":2279,"props":15315,"children":15316},{"class":3522,"line":8438},[15317,15322,15326],{"type":24,"tag":2279,"props":15318,"children":15319},{"class":3533},[15320],{"type":34,"value":15321},"                    val_loss ",{"type":24,"tag":2279,"props":15323,"children":15324},{"class":3527},[15325],{"type":34,"value":5453},{"type":24,"tag":2279,"props":15327,"children":15328},{"class":3533},[15329],{"type":34,"value":12147},{"type":24,"tag":2279,"props":15331,"children":15332},{"class":3522,"line":8470},[15333,15338,15342,15346,15350,15354,15358,15362,15366,15370,15374],{"type":24,"tag":2279,"props":15334,"children":15335},{"class":3533},[15336],{"type":34,"value":15337},"                    val_accuracy ",{"type":24,"tag":2279,"props":15339,"children":15340},{"class":3527},[15341],{"type":34,"value":5453},{"type":24,"tag":2279,"props":15343,"children":15344},{"class":3533},[15345],{"type":34,"value":11829},{"type":24,"tag":2279,"props":15347,"children":15348},{"class":3908},[15349],{"type":34,"value":2283},{"type":24,"tag":2279,"props":15351,"children":15352},{"class":3533},[15353],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15355,"children":15356},{"class":3527},[15357],{"type":34,"value":3630},{"type":24,"tag":2279,"props":15359,"children":15360},{"class":3533},[15361],{"type":34,"value":12180},{"type":24,"tag":2279,"props":15363,"children":15364},{"class":3527},[15365],{"type":34,"value":5410},{"type":24,"tag":2279,"props":15367,"children":15368},{"class":3533},[15369],{"type":34,"value":12189},{"type":24,"tag":2279,"props":15371,"children":15372},{"class":3527},[15373],{"type":34,"value":5854},{"type":24,"tag":2279,"props":15375,"children":15376},{"class":3533},[15377],{"type":34,"value":12198},{"type":24,"tag":2279,"props":15379,"children":15380},{"class":3522,"line":8491},[15381],{"type":24,"tag":2279,"props":15382,"children":15383},{},[],{"type":24,"tag":2279,"props":15385,"children":15386},{"class":3522,"line":8508},[15387,15391,15395,15399,15403,15407,15411,15415,15419,15423,15427,15431,15435,15439,15443,15447,15451,15455,15459,15463,15467,15471,15475,15479,15483,15487,15491,15495,15499,15503,15507,15511,15516],{"type":24,"tag":2279,"props":15388,"children":15389},{"class":3533},[15390],{"type":34,"value":7748},{"type":24,"tag":2279,"props":15392,"children":15393},{"class":3908},[15394],{"type":34,"value":5074},{"type":24,"tag":2279,"props":15396,"children":15397},{"class":3533},[15398],{"type":34,"value":4205},{"type":24,"tag":2279,"props":15400,"children":15401},{"class":3527},[15402],{"type":34,"value":11492},{"type":24,"tag":2279,"props":15404,"children":15405},{"class":3557},[15406],{"type":34,"value":11497},{"type":24,"tag":2279,"props":15408,"children":15409},{"class":3908},[15410],{"type":34,"value":9135},{"type":24,"tag":2279,"props":15412,"children":15413},{"class":3533},[15414],{"type":34,"value":11506},{"type":24,"tag":2279,"props":15416,"children":15417},{"class":3527},[15418],{"type":34,"value":6072},{"type":24,"tag":2279,"props":15420,"children":15421},{"class":3533},[15422],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15424,"children":15425},{"class":3908},[15426],{"type":34,"value":11519},{"type":24,"tag":2279,"props":15428,"children":15429},{"class":3557},[15430],{"type":34,"value":12246},{"type":24,"tag":2279,"props":15432,"children":15433},{"class":3908},[15434],{"type":34,"value":9135},{"type":24,"tag":2279,"props":15436,"children":15437},{"class":3533},[15438],{"type":34,"value":12255},{"type":24,"tag":2279,"props":15440,"children":15441},{"class":3527},[15442],{"type":34,"value":3593},{"type":24,"tag":2279,"props":15444,"children":15445},{"class":3533},[15446],{"type":34,"value":12264},{"type":24,"tag":2279,"props":15448,"children":15449},{"class":3527},[15450],{"type":34,"value":6072},{"type":24,"tag":2279,"props":15452,"children":15453},{"class":3533},[15454],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15456,"children":15457},{"class":3908},[15458],{"type":34,"value":2283},{"type":24,"tag":2279,"props":15460,"children":15461},{"class":3533},[15462],{"type":34,"value":3937},{"type":24,"tag":2279,"props":15464,"children":15465},{"class":3908},[15466],{"type":34,"value":11960},{"type":24,"tag":2279,"props":15468,"children":15469},{"class":3557},[15470],{"type":34,"value":11983},{"type":24,"tag":2279,"props":15472,"children":15473},{"class":3908},[15474],{"type":34,"value":9135},{"type":24,"tag":2279,"props":15476,"children":15477},{"class":3533},[15478],{"type":34,"value":12297},{"type":24,"tag":2279,"props":15480,"children":15481},{"class":3527},[15482],{"type":34,"value":3593},{"type":24,"tag":2279,"props":15484,"children":15485},{"class":3533},[15486],{"type":34,"value":12264},{"type":24,"tag":2279,"props":15488,"children":15489},{"class":3527},[15490],{"type":34,"value":6072},{"type":24,"tag":2279,"props":15492,"children":15493},{"class":3533},[15494],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15496,"children":15497},{"class":3908},[15498],{"type":34,"value":2283},{"type":24,"tag":2279,"props":15500,"children":15501},{"class":3533},[15502],{"type":34,"value":3937},{"type":24,"tag":2279,"props":15504,"children":15505},{"class":3908},[15506],{"type":34,"value":11960},{"type":24,"tag":2279,"props":15508,"children":15509},{"class":3557},[15510],{"type":34,"value":11524},{"type":24,"tag":2279,"props":15512,"children":15513},{"class":3533},[15514],{"type":34,"value":15515},")  ",{"type":24,"tag":2279,"props":15517,"children":15518},{"class":3571},[15519],{"type":34,"value":15520},"#  Loss and accuracy averaged for all validation batches in the problem, displayed after whole validation\n",{"type":24,"tag":2279,"props":15522,"children":15523},{"class":3522,"line":8515},[15524],{"type":24,"tag":2279,"props":15525,"children":15526},{},[],{"type":24,"tag":2279,"props":15528,"children":15529},{"class":3522,"line":8523},[15530,15535,15539,15544],{"type":24,"tag":2279,"props":15531,"children":15532},{"class":3533},[15533],{"type":34,"value":15534},"            running_loss ",{"type":24,"tag":2279,"props":15536,"children":15537},{"class":3527},[15538],{"type":34,"value":5453},{"type":24,"tag":2279,"props":15540,"children":15541},{"class":3533},[15542],{"type":34,"value":15543}," lossv  ",{"type":24,"tag":2279,"props":15545,"children":15546},{"class":3571},[15547],{"type":34,"value":15548},"#  After all epochs (all training process) in a single problem the validation loss is added\n",{"type":24,"tag":2279,"props":15550,"children":15551},{"class":3522,"line":8549},[15552],{"type":24,"tag":2279,"props":15553,"children":15554},{},[],{"type":24,"tag":2279,"props":15556,"children":15557},{"class":3522,"line":8570},[15558,15563],{"type":24,"tag":2279,"props":15559,"children":15560},{"class":3533},[15561],{"type":34,"value":15562},"            update_model(model, initial_weights, param_keys)  ",{"type":24,"tag":2279,"props":15564,"children":15565},{"class":3571},[15566],{"type":34,"value":15567},"# After the whole train + validation of a problem and the final loss is added, return the model to its original stage in the meta-step \n",{"type":24,"tag":2279,"props":15569,"children":15570},{"class":3522,"line":8591},[15571],{"type":24,"tag":2279,"props":15572,"children":15573},{"class":3533},[15574],{"type":34,"value":8025},{"type":24,"tag":2279,"props":15576,"children":15577},{"class":3522,"line":8623},[15578,15583,15587,15592,15596,15601],{"type":24,"tag":2279,"props":15579,"children":15580},{"class":3533},[15581],{"type":34,"value":15582},"        metastep_loss ",{"type":24,"tag":2279,"props":15584,"children":15585},{"class":3527},[15586],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15588,"children":15589},{"class":3533},[15590],{"type":34,"value":15591}," running_loss ",{"type":24,"tag":2279,"props":15593,"children":15594},{"class":3527},[15595],{"type":34,"value":3593},{"type":24,"tag":2279,"props":15597,"children":15598},{"class":3533},[15599],{"type":34,"value":15600}," metabatch_size  ",{"type":24,"tag":2279,"props":15602,"children":15603},{"class":3571},[15604],{"type":34,"value":15605},"#  The added validation losses of all problems in the metabatch are averaged\n",{"type":24,"tag":2279,"props":15607,"children":15608},{"class":3522,"line":8656},[15609],{"type":24,"tag":2279,"props":15610,"children":15611},{},[],{"type":24,"tag":2279,"props":15613,"children":15614},{"class":3522,"line":8673},[15615,15620],{"type":24,"tag":2279,"props":15616,"children":15617},{"class":3533},[15618],{"type":34,"value":15619},"        metaoptimizer.zero_grad()  ",{"type":24,"tag":2279,"props":15621,"children":15622},{"class":3571},[15623],{"type":34,"value":15624},"#  We perform gradient descent at the Meta-Level over the averaged validation loss\n",{"type":24,"tag":2279,"props":15626,"children":15627},{"class":3522,"line":8698},[15628],{"type":24,"tag":2279,"props":15629,"children":15630},{"class":3533},[15631],{"type":34,"value":15632},"        metastep_loss.backward()\n",{"type":24,"tag":2279,"props":15634,"children":15635},{"class":3522,"line":8724},[15636],{"type":24,"tag":2279,"props":15637,"children":15638},{"class":3533},[15639],{"type":34,"value":15640},"        metaoptimizer.step()\n",{"type":24,"tag":2279,"props":15642,"children":15643},{"class":3522,"line":8741},[15644],{"type":24,"tag":2279,"props":15645,"children":15646},{},[],{"type":24,"tag":2279,"props":15648,"children":15649},{"class":3522,"line":8767},[15650,15654,15658,15663,15667,15671,15675,15679,15683,15687,15692,15696,15700,15704,15708,15713],{"type":24,"tag":2279,"props":15651,"children":15652},{"class":3533},[15653],{"type":34,"value":6910},{"type":24,"tag":2279,"props":15655,"children":15656},{"class":3527},[15657],{"type":34,"value":5391},{"type":24,"tag":2279,"props":15659,"children":15660},{"class":3533},[15661],{"type":34,"value":15662}," (mi ",{"type":24,"tag":2279,"props":15664,"children":15665},{"class":3527},[15666],{"type":34,"value":6072},{"type":24,"tag":2279,"props":15668,"children":15669},{"class":3533},[15670],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15672,"children":15673},{"class":3908},[15674],{"type":34,"value":2283},{"type":24,"tag":2279,"props":15676,"children":15677},{"class":3533},[15678],{"type":34,"value":6085},{"type":24,"tag":2279,"props":15680,"children":15681},{"class":3527},[15682],{"type":34,"value":3583},{"type":24,"tag":2279,"props":15684,"children":15685},{"class":3533},[15686],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15688,"children":15689},{"class":3908},[15690],{"type":34,"value":15691},"1000",{"type":24,"tag":2279,"props":15693,"children":15694},{"class":3533},[15695],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15697,"children":15698},{"class":3527},[15699],{"type":34,"value":5854},{"type":24,"tag":2279,"props":15701,"children":15702},{"class":3533},[15703],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15705,"children":15706},{"class":3908},[15707],{"type":34,"value":4023},{"type":24,"tag":2279,"props":15709,"children":15710},{"class":3533},[15711],{"type":34,"value":15712},":  ",{"type":24,"tag":2279,"props":15714,"children":15715},{"class":3571},[15716],{"type":34,"value":15717},"#  Meta-validation performed every 1000 meta-steps\n",{"type":24,"tag":2279,"props":15719,"children":15720},{"class":3522,"line":8776},[15721],{"type":24,"tag":2279,"props":15722,"children":15723},{},[],{"type":24,"tag":2279,"props":15725,"children":15726},{"class":3522,"line":8801},[15727,15731,15735,15739,15744],{"type":24,"tag":2279,"props":15728,"children":15729},{"class":3533},[15730],{"type":34,"value":7299},{"type":24,"tag":2279,"props":15732,"children":15733},{"class":3908},[15734],{"type":34,"value":5074},{"type":24,"tag":2279,"props":15736,"children":15737},{"class":3533},[15738],{"type":34,"value":4205},{"type":24,"tag":2279,"props":15740,"children":15741},{"class":3557},[15742],{"type":34,"value":15743},"'META-VALIDATION STEP:'",{"type":24,"tag":2279,"props":15745,"children":15746},{"class":3533},[15747],{"type":34,"value":6699},{"type":24,"tag":2279,"props":15749,"children":15750},{"class":3522,"line":8810},[15751],{"type":24,"tag":2279,"props":15752,"children":15753},{},[],{"type":24,"tag":2279,"props":15755,"children":15756},{"class":3522,"line":8817},[15757,15761,15765,15770,15774,15778,15782,15787],{"type":24,"tag":2279,"props":15758,"children":15759},{"class":3533},[15760],{"type":34,"value":7299},{"type":24,"tag":2279,"props":15762,"children":15763},{"class":3527},[15764],{"type":34,"value":4181},{"type":24,"tag":2279,"props":15766,"children":15767},{"class":3533},[15768],{"type":34,"value":15769}," mbvi, metabatch_val ",{"type":24,"tag":2279,"props":15771,"children":15772},{"class":3527},[15773],{"type":34,"value":4191},{"type":24,"tag":2279,"props":15775,"children":15776},{"class":3533},[15777],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15779,"children":15780},{"class":3908},[15781],{"type":34,"value":6371},{"type":24,"tag":2279,"props":15783,"children":15784},{"class":3533},[15785],{"type":34,"value":15786},"(metaval_loader):  ",{"type":24,"tag":2279,"props":15788,"children":15789},{"class":3571},[15790],{"type":34,"value":15791},"#  Meta-validation meta-step\n",{"type":24,"tag":2279,"props":15793,"children":15794},{"class":3522,"line":8842},[15795],{"type":24,"tag":2279,"props":15796,"children":15797},{},[],{"type":24,"tag":2279,"props":15799,"children":15800},{"class":3522,"line":8884},[15801,15805,15809,15814,15818,15822,15826,15830,15834,15838,15842,15846,15850,15854,15858],{"type":24,"tag":2279,"props":15802,"children":15803},{"class":3533},[15804],{"type":34,"value":7748},{"type":24,"tag":2279,"props":15806,"children":15807},{"class":3527},[15808],{"type":34,"value":5391},{"type":24,"tag":2279,"props":15810,"children":15811},{"class":3533},[15812],{"type":34,"value":15813}," (mbvi ",{"type":24,"tag":2279,"props":15815,"children":15816},{"class":3527},[15817],{"type":34,"value":6072},{"type":24,"tag":2279,"props":15819,"children":15820},{"class":3533},[15821],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15823,"children":15824},{"class":3908},[15825],{"type":34,"value":2283},{"type":24,"tag":2279,"props":15827,"children":15828},{"class":3533},[15829],{"type":34,"value":6085},{"type":24,"tag":2279,"props":15831,"children":15832},{"class":3527},[15833],{"type":34,"value":3583},{"type":24,"tag":2279,"props":15835,"children":15836},{"class":3533},[15837],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15839,"children":15840},{"class":3908},[15841],{"type":34,"value":2493},{"type":24,"tag":2279,"props":15843,"children":15844},{"class":3533},[15845],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15847,"children":15848},{"class":3527},[15849],{"type":34,"value":5854},{"type":24,"tag":2279,"props":15851,"children":15852},{"class":3533},[15853],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15855,"children":15856},{"class":3908},[15857],{"type":34,"value":4023},{"type":24,"tag":2279,"props":15859,"children":15860},{"class":3533},[15861],{"type":34,"value":4809},{"type":24,"tag":2279,"props":15863,"children":15864},{"class":3522,"line":8901},[15865],{"type":24,"tag":2279,"props":15866,"children":15867},{},[],{"type":24,"tag":2279,"props":15869,"children":15870},{"class":3522,"line":8926},[15871,15875,15879,15883,15887,15892,15896,15901,15905,15909,15913,15917],{"type":24,"tag":2279,"props":15872,"children":15873},{"class":3533},[15874],{"type":34,"value":14937},{"type":24,"tag":2279,"props":15876,"children":15877},{"class":3908},[15878],{"type":34,"value":5074},{"type":24,"tag":2279,"props":15880,"children":15881},{"class":3533},[15882],{"type":34,"value":4205},{"type":24,"tag":2279,"props":15884,"children":15885},{"class":3527},[15886],{"type":34,"value":11492},{"type":24,"tag":2279,"props":15888,"children":15889},{"class":3557},[15890],{"type":34,"value":15891},"'Validation step ",{"type":24,"tag":2279,"props":15893,"children":15894},{"class":3908},[15895],{"type":34,"value":9135},{"type":24,"tag":2279,"props":15897,"children":15898},{"class":3533},[15899],{"type":34,"value":15900},"mbvi ",{"type":24,"tag":2279,"props":15902,"children":15903},{"class":3527},[15904],{"type":34,"value":6072},{"type":24,"tag":2279,"props":15906,"children":15907},{"class":3533},[15908],{"type":34,"value":2285},{"type":24,"tag":2279,"props":15910,"children":15911},{"class":3908},[15912],{"type":34,"value":11519},{"type":24,"tag":2279,"props":15914,"children":15915},{"class":3557},[15916],{"type":34,"value":11524},{"type":24,"tag":2279,"props":15918,"children":15919},{"class":3533},[15920],{"type":34,"value":6699},{"type":24,"tag":2279,"props":15922,"children":15923},{"class":3522,"line":8944},[15924],{"type":24,"tag":2279,"props":15925,"children":15926},{"class":3533},[15927],{"type":34,"value":15928},"                    \n",{"type":24,"tag":2279,"props":15930,"children":15932},{"class":3522,"line":15931},88,[15933,15938,15942],{"type":24,"tag":2279,"props":15934,"children":15935},{"class":3533},[15936],{"type":34,"value":15937},"                initial_weights ",{"type":24,"tag":2279,"props":15939,"children":15940},{"class":3527},[15941],{"type":34,"value":3866},{"type":24,"tag":2279,"props":15943,"children":15944},{"class":3533},[15945],{"type":34,"value":12577},{"type":24,"tag":2279,"props":15947,"children":15949},{"class":3522,"line":15948},89,[15950],{"type":24,"tag":2279,"props":15951,"children":15952},{},[],{"type":24,"tag":2279,"props":15954,"children":15956},{"class":3522,"line":15955},90,[15957,15961,15965,15970,15974,15979],{"type":24,"tag":2279,"props":15958,"children":15959},{"class":3533},[15960],{"type":34,"value":7748},{"type":24,"tag":2279,"props":15962,"children":15963},{"class":3527},[15964],{"type":34,"value":4181},{"type":24,"tag":2279,"props":15966,"children":15967},{"class":3533},[15968],{"type":34,"value":15969}," problem_loaders ",{"type":24,"tag":2279,"props":15971,"children":15972},{"class":3527},[15973],{"type":34,"value":4191},{"type":24,"tag":2279,"props":15975,"children":15976},{"class":3533},[15977],{"type":34,"value":15978}," metabatch_val:  ",{"type":24,"tag":2279,"props":15980,"children":15981},{"class":3571},[15982],{"type":34,"value":15983},"#  Problem in the meta-validation meta-batch\n",{"type":24,"tag":2279,"props":15985,"children":15987},{"class":3522,"line":15986},91,[15988],{"type":24,"tag":2279,"props":15989,"children":15990},{},[],{"type":24,"tag":2279,"props":15992,"children":15994},{"class":3522,"line":15993},92,[15995,16000,16004,16008,16012],{"type":24,"tag":2279,"props":15996,"children":15997},{"class":3533},[15998],{"type":34,"value":15999},"                    problem_loader ",{"type":24,"tag":2279,"props":16001,"children":16002},{"class":3527},[16003],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16005,"children":16006},{"class":3533},[16007],{"type":34,"value":14604},{"type":24,"tag":2279,"props":16009,"children":16010},{"class":3557},[16011],{"type":34,"value":8135},{"type":24,"tag":2279,"props":16013,"children":16014},{"class":3533},[16015],{"type":34,"value":7057},{"type":24,"tag":2279,"props":16017,"children":16019},{"class":3522,"line":16018},93,[16020,16025,16029,16033,16037],{"type":24,"tag":2279,"props":16021,"children":16022},{"class":3533},[16023],{"type":34,"value":16024},"                    problem_loader_val ",{"type":24,"tag":2279,"props":16026,"children":16027},{"class":3527},[16028],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16030,"children":16031},{"class":3533},[16032],{"type":34,"value":14604},{"type":24,"tag":2279,"props":16034,"children":16035},{"class":3557},[16036],{"type":34,"value":8212},{"type":24,"tag":2279,"props":16038,"children":16039},{"class":3533},[16040],{"type":34,"value":7057},{"type":24,"tag":2279,"props":16042,"children":16044},{"class":3522,"line":16043},94,[16045,16050,16054,16058],{"type":24,"tag":2279,"props":16046,"children":16047},{"class":3533},[16048],{"type":34,"value":16049},"                    ref_label ",{"type":24,"tag":2279,"props":16051,"children":16052},{"class":3527},[16053],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16055,"children":16056},{"class":3533},[16057],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16059,"children":16060},{"class":3908},[16061],{"type":34,"value":11443},{"type":24,"tag":2279,"props":16063,"children":16065},{"class":3522,"line":16064},95,[16066,16071,16075],{"type":24,"tag":2279,"props":16067,"children":16068},{"class":3533},[16069],{"type":34,"value":16070},"                    new_weights ",{"type":24,"tag":2279,"props":16072,"children":16073},{"class":3527},[16074],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16076,"children":16077},{"class":3533},[16078],{"type":34,"value":14678},{"type":24,"tag":2279,"props":16080,"children":16082},{"class":3522,"line":16081},96,[16083],{"type":24,"tag":2279,"props":16084,"children":16085},{},[],{"type":24,"tag":2279,"props":16087,"children":16089},{"class":3522,"line":16088},97,[16090,16094,16098,16102,16106,16110,16114,16118],{"type":24,"tag":2279,"props":16091,"children":16092},{"class":3533},[16093],{"type":34,"value":14937},{"type":24,"tag":2279,"props":16095,"children":16096},{"class":3527},[16097],{"type":34,"value":4181},{"type":24,"tag":2279,"props":16099,"children":16100},{"class":3533},[16101],{"type":34,"value":11455},{"type":24,"tag":2279,"props":16103,"children":16104},{"class":3527},[16105],{"type":34,"value":4191},{"type":24,"tag":2279,"props":16107,"children":16108},{"class":3533},[16109],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16111,"children":16112},{"class":3908},[16113],{"type":34,"value":4200},{"type":24,"tag":2279,"props":16115,"children":16116},{"class":3533},[16117],{"type":34,"value":14716},{"type":24,"tag":2279,"props":16119,"children":16120},{"class":3571},[16121],{"type":34,"value":14721},{"type":24,"tag":2279,"props":16123,"children":16125},{"class":3522,"line":16124},98,[16126],{"type":24,"tag":2279,"props":16127,"children":16128},{},[],{"type":24,"tag":2279,"props":16130,"children":16132},{"class":3522,"line":16131},99,[16133,16138,16142,16146],{"type":24,"tag":2279,"props":16134,"children":16135},{"class":3533},[16136],{"type":34,"value":16137},"                        val_loss ",{"type":24,"tag":2279,"props":16139,"children":16140},{"class":3527},[16141],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16143,"children":16144},{"class":3533},[16145],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16147,"children":16148},{"class":3908},[16149],{"type":34,"value":11549},{"type":24,"tag":2279,"props":16151,"children":16153},{"class":3522,"line":16152},100,[16154,16159,16163,16167],{"type":24,"tag":2279,"props":16155,"children":16156},{"class":3533},[16157],{"type":34,"value":16158},"                        val_accuracy ",{"type":24,"tag":2279,"props":16160,"children":16161},{"class":3527},[16162],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16164,"children":16165},{"class":3533},[16166],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16168,"children":16169},{"class":3908},[16170],{"type":34,"value":11549},{"type":24,"tag":2279,"props":16172,"children":16174},{"class":3522,"line":16173},101,[16175],{"type":24,"tag":2279,"props":16176,"children":16177},{},[],{"type":24,"tag":2279,"props":16179,"children":16181},{"class":3522,"line":16180},102,[16182,16186,16190,16194,16198,16202,16206,16210,16214,16218],{"type":24,"tag":2279,"props":16183,"children":16184},{"class":3533},[16185],{"type":34,"value":7686},{"type":24,"tag":2279,"props":16187,"children":16188},{"class":3527},[16189],{"type":34,"value":4181},{"type":24,"tag":2279,"props":16191,"children":16192},{"class":3533},[16193],{"type":34,"value":10291},{"type":24,"tag":2279,"props":16195,"children":16196},{"class":3527},[16197],{"type":34,"value":4191},{"type":24,"tag":2279,"props":16199,"children":16200},{"class":3533},[16201],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16203,"children":16204},{"class":3908},[16205],{"type":34,"value":6371},{"type":24,"tag":2279,"props":16207,"children":16208},{"class":3533},[16209],{"type":34,"value":14862},{"type":24,"tag":2279,"props":16211,"children":16212},{"class":3908},[16213],{"type":34,"value":4023},{"type":24,"tag":2279,"props":16215,"children":16216},{"class":3533},[16217],{"type":34,"value":14362},{"type":24,"tag":2279,"props":16219,"children":16220},{"class":3571},[16221],{"type":34,"value":14875},{"type":24,"tag":2279,"props":16223,"children":16225},{"class":3522,"line":16224},103,[16226],{"type":24,"tag":2279,"props":16227,"children":16228},{"class":3533},[16229],{"type":34,"value":16230},"                            \n",{"type":24,"tag":2279,"props":16232,"children":16234},{"class":3522,"line":16233},104,[16235,16240,16244],{"type":24,"tag":2279,"props":16236,"children":16237},{"class":3533},[16238],{"type":34,"value":16239},"                            inputs_raw, labels_raw ",{"type":24,"tag":2279,"props":16241,"children":16242},{"class":3527},[16243],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16245,"children":16246},{"class":3533},[16247],{"type":34,"value":11645},{"type":24,"tag":2279,"props":16249,"children":16251},{"class":3522,"line":16250},105,[16252,16257,16261],{"type":24,"tag":2279,"props":16253,"children":16254},{"class":3533},[16255],{"type":34,"value":16256},"                            inputs ",{"type":24,"tag":2279,"props":16258,"children":16259},{"class":3527},[16260],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16262,"children":16263},{"class":3533},[16264],{"type":34,"value":11670},{"type":24,"tag":2279,"props":16266,"children":16268},{"class":3522,"line":16267},106,[16269,16274,16278],{"type":24,"tag":2279,"props":16270,"children":16271},{"class":3533},[16272],{"type":34,"value":16273},"                            outputs ",{"type":24,"tag":2279,"props":16275,"children":16276},{"class":3527},[16277],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16279,"children":16280},{"class":3533},[16281],{"type":34,"value":11687},{"type":24,"tag":2279,"props":16283,"children":16285},{"class":3522,"line":16284},107,[16286,16291,16295,16299,16303,16307,16311],{"type":24,"tag":2279,"props":16287,"children":16288},{"class":3533},[16289],{"type":34,"value":16290},"                            ",{"type":24,"tag":2279,"props":16292,"children":16293},{"class":3527},[16294],{"type":34,"value":5391},{"type":24,"tag":2279,"props":16296,"children":16297},{"class":3533},[16298],{"type":34,"value":11703},{"type":24,"tag":2279,"props":16300,"children":16301},{"class":3527},[16302],{"type":34,"value":11708},{"type":24,"tag":2279,"props":16304,"children":16305},{"class":3533},[16306],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16308,"children":16309},{"class":3908},[16310],{"type":34,"value":4954},{"type":24,"tag":2279,"props":16312,"children":16313},{"class":3533},[16314],{"type":34,"value":4809},{"type":24,"tag":2279,"props":16316,"children":16318},{"class":3522,"line":16317},108,[16319,16324,16328,16332,16336],{"type":24,"tag":2279,"props":16320,"children":16321},{"class":3533},[16322],{"type":34,"value":16323},"                                ref_label ",{"type":24,"tag":2279,"props":16325,"children":16326},{"class":3527},[16327],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16329,"children":16330},{"class":3533},[16331],{"type":34,"value":11737},{"type":24,"tag":2279,"props":16333,"children":16334},{"class":3908},[16335],{"type":34,"value":4023},{"type":24,"tag":2279,"props":16337,"children":16338},{"class":3533},[16339],{"type":34,"value":7057},{"type":24,"tag":2279,"props":16341,"children":16343},{"class":3522,"line":16342},109,[16344,16349,16353],{"type":24,"tag":2279,"props":16345,"children":16346},{"class":3533},[16347],{"type":34,"value":16348},"                            labels ",{"type":24,"tag":2279,"props":16350,"children":16351},{"class":3527},[16352],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16354,"children":16355},{"class":3533},[16356],{"type":34,"value":11762},{"type":24,"tag":2279,"props":16358,"children":16360},{"class":3522,"line":16359},110,[16361],{"type":24,"tag":2279,"props":16362,"children":16363},{},[],{"type":24,"tag":2279,"props":16365,"children":16367},{"class":3522,"line":16366},111,[16368,16373,16377],{"type":24,"tag":2279,"props":16369,"children":16370},{"class":3533},[16371],{"type":34,"value":16372},"                            new_weights, loss, accuracy ",{"type":24,"tag":2279,"props":16374,"children":16375},{"class":3527},[16376],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16378,"children":16379},{"class":3533},[16380],{"type":34,"value":15030},{"type":24,"tag":2279,"props":16382,"children":16384},{"class":3522,"line":16383},112,[16385,16390],{"type":24,"tag":2279,"props":16386,"children":16387},{"class":3533},[16388],{"type":34,"value":16389},"                            update_model(model, new_weights, param_keys)  ",{"type":24,"tag":2279,"props":16391,"children":16392},{"class":3571},[16393],{"type":34,"value":16394},"#  Note that we still need to update although being in (Meta-)validation. That is because we are in meta-validation but at the Learning level we are in training stage\n",{"type":24,"tag":2279,"props":16396,"children":16398},{"class":3522,"line":16397},113,[16399],{"type":24,"tag":2279,"props":16400,"children":16401},{},[],{"type":24,"tag":2279,"props":16403,"children":16405},{"class":3522,"line":16404},114,[16406,16410],{"type":24,"tag":2279,"props":16407,"children":16408},{"class":3533},[16409],{"type":34,"value":7686},{"type":24,"tag":2279,"props":16411,"children":16412},{"class":3571},[16413],{"type":34,"value":16414},"#    print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n",{"type":24,"tag":2279,"props":16416,"children":16418},{"class":3522,"line":16417},115,[16419],{"type":24,"tag":2279,"props":16420,"children":16421},{},[],{"type":24,"tag":2279,"props":16423,"children":16425},{"class":3522,"line":16424},116,[16426,16430,16434,16438,16442,16446,16450,16454],{"type":24,"tag":2279,"props":16427,"children":16428},{"class":3533},[16429],{"type":34,"value":7686},{"type":24,"tag":2279,"props":16431,"children":16432},{"class":3527},[16433],{"type":34,"value":4181},{"type":24,"tag":2279,"props":16435,"children":16436},{"class":3533},[16437],{"type":34,"value":12020},{"type":24,"tag":2279,"props":16439,"children":16440},{"class":3527},[16441],{"type":34,"value":4191},{"type":24,"tag":2279,"props":16443,"children":16444},{"class":3533},[16445],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16447,"children":16448},{"class":3908},[16449],{"type":34,"value":6371},{"type":24,"tag":2279,"props":16451,"children":16452},{"class":3533},[16453],{"type":34,"value":15202},{"type":24,"tag":2279,"props":16455,"children":16456},{"class":3571},[16457],{"type":34,"value":16458},"#  At the end of the training process in an epoch of a problem we compute a whole validation, as in Meta-Train\n",{"type":24,"tag":2279,"props":16460,"children":16462},{"class":3522,"line":16461},117,[16463],{"type":24,"tag":2279,"props":16464,"children":16465},{},[],{"type":24,"tag":2279,"props":16467,"children":16469},{"class":3522,"line":16468},118,[16470,16475,16479],{"type":24,"tag":2279,"props":16471,"children":16472},{"class":3533},[16473],{"type":34,"value":16474},"                            inputs_rawv, labels_rawv ",{"type":24,"tag":2279,"props":16476,"children":16477},{"class":3527},[16478],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16480,"children":16481},{"class":3533},[16482],{"type":34,"value":12054},{"type":24,"tag":2279,"props":16484,"children":16486},{"class":3522,"line":16485},119,[16487,16492,16496],{"type":24,"tag":2279,"props":16488,"children":16489},{"class":3533},[16490],{"type":34,"value":16491},"                            inputsv ",{"type":24,"tag":2279,"props":16493,"children":16494},{"class":3527},[16495],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16497,"children":16498},{"class":3533},[16499],{"type":34,"value":12071},{"type":24,"tag":2279,"props":16501,"children":16503},{"class":3522,"line":16502},120,[16504,16509,16513],{"type":24,"tag":2279,"props":16505,"children":16506},{"class":3533},[16507],{"type":34,"value":16508},"                            outputsv ",{"type":24,"tag":2279,"props":16510,"children":16511},{"class":3527},[16512],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16514,"children":16515},{"class":3533},[16516],{"type":34,"value":12088},{"type":24,"tag":2279,"props":16518,"children":16520},{"class":3522,"line":16519},121,[16521,16526,16530],{"type":24,"tag":2279,"props":16522,"children":16523},{"class":3533},[16524],{"type":34,"value":16525},"                            labelsv ",{"type":24,"tag":2279,"props":16527,"children":16528},{"class":3527},[16529],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16531,"children":16532},{"class":3533},[16533],{"type":34,"value":12105},{"type":24,"tag":2279,"props":16535,"children":16537},{"class":3522,"line":16536},122,[16538],{"type":24,"tag":2279,"props":16539,"children":16540},{"class":3533},[16541],{"type":34,"value":16230},{"type":24,"tag":2279,"props":16543,"children":16545},{"class":3522,"line":16544},123,[16546,16551,16555,16559,16563],{"type":24,"tag":2279,"props":16547,"children":16548},{"class":3533},[16549],{"type":34,"value":16550},"                            lossv ",{"type":24,"tag":2279,"props":16552,"children":16553},{"class":3527},[16554],{"type":34,"value":3866},{"type":24,"tag":2279,"props":16556,"children":16557},{"class":3533},[16558],{"type":34,"value":12122},{"type":24,"tag":2279,"props":16560,"children":16561},{"class":3908},[16562],{"type":34,"value":4023},{"type":24,"tag":2279,"props":16564,"children":16565},{"class":3533},[16566],{"type":34,"value":7941},{"type":24,"tag":2279,"props":16568,"children":16570},{"class":3522,"line":16569},124,[16571,16576,16580],{"type":24,"tag":2279,"props":16572,"children":16573},{"class":3533},[16574],{"type":34,"value":16575},"                            val_loss ",{"type":24,"tag":2279,"props":16577,"children":16578},{"class":3527},[16579],{"type":34,"value":5453},{"type":24,"tag":2279,"props":16581,"children":16582},{"class":3533},[16583],{"type":34,"value":12147},{"type":24,"tag":2279,"props":16585,"children":16587},{"class":3522,"line":16586},125,[16588,16593,16597,16601,16605,16609,16613,16617,16621,16625,16629],{"type":24,"tag":2279,"props":16589,"children":16590},{"class":3533},[16591],{"type":34,"value":16592},"                            val_accuracy ",{"type":24,"tag":2279,"props":16594,"children":16595},{"class":3527},[16596],{"type":34,"value":5453},{"type":24,"tag":2279,"props":16598,"children":16599},{"class":3533},[16600],{"type":34,"value":11829},{"type":24,"tag":2279,"props":16602,"children":16603},{"class":3908},[16604],{"type":34,"value":2283},{"type":24,"tag":2279,"props":16606,"children":16607},{"class":3533},[16608],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16610,"children":16611},{"class":3527},[16612],{"type":34,"value":3630},{"type":24,"tag":2279,"props":16614,"children":16615},{"class":3533},[16616],{"type":34,"value":12180},{"type":24,"tag":2279,"props":16618,"children":16619},{"class":3527},[16620],{"type":34,"value":5410},{"type":24,"tag":2279,"props":16622,"children":16623},{"class":3533},[16624],{"type":34,"value":12189},{"type":24,"tag":2279,"props":16626,"children":16627},{"class":3527},[16628],{"type":34,"value":5854},{"type":24,"tag":2279,"props":16630,"children":16631},{"class":3533},[16632],{"type":34,"value":12198},{"type":24,"tag":2279,"props":16634,"children":16636},{"class":3522,"line":16635},126,[16637],{"type":24,"tag":2279,"props":16638,"children":16639},{},[],{"type":24,"tag":2279,"props":16641,"children":16643},{"class":3522,"line":16642},127,[16644],{"type":24,"tag":2279,"props":16645,"children":16646},{"class":3533},[16647],{"type":34,"value":15928},{"type":24,"tag":2279,"props":16649,"children":16651},{"class":3522,"line":16650},128,[16652,16656,16660,16664,16668,16672,16676,16680,16684,16688,16692,16696,16700,16704,16708],{"type":24,"tag":2279,"props":16653,"children":16654},{"class":3533},[16655],{"type":34,"value":14937},{"type":24,"tag":2279,"props":16657,"children":16658},{"class":3527},[16659],{"type":34,"value":5391},{"type":24,"tag":2279,"props":16661,"children":16662},{"class":3533},[16663],{"type":34,"value":15813},{"type":24,"tag":2279,"props":16665,"children":16666},{"class":3527},[16667],{"type":34,"value":6072},{"type":24,"tag":2279,"props":16669,"children":16670},{"class":3533},[16671],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16673,"children":16674},{"class":3908},[16675],{"type":34,"value":2283},{"type":24,"tag":2279,"props":16677,"children":16678},{"class":3533},[16679],{"type":34,"value":6085},{"type":24,"tag":2279,"props":16681,"children":16682},{"class":3527},[16683],{"type":34,"value":3583},{"type":24,"tag":2279,"props":16685,"children":16686},{"class":3533},[16687],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16689,"children":16690},{"class":3908},[16691],{"type":34,"value":2493},{"type":24,"tag":2279,"props":16693,"children":16694},{"class":3533},[16695],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16697,"children":16698},{"class":3527},[16699],{"type":34,"value":5854},{"type":24,"tag":2279,"props":16701,"children":16702},{"class":3533},[16703],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16705,"children":16706},{"class":3908},[16707],{"type":34,"value":4023},{"type":24,"tag":2279,"props":16709,"children":16710},{"class":3533},[16711],{"type":34,"value":4809},{"type":24,"tag":2279,"props":16713,"children":16715},{"class":3522,"line":16714},129,[16716],{"type":24,"tag":2279,"props":16717,"children":16718},{},[],{"type":24,"tag":2279,"props":16720,"children":16722},{"class":3522,"line":16721},130,[16723,16727,16731,16735,16739,16744,16748,16752,16756,16760,16764,16768,16772,16776,16780,16784,16788,16792,16796,16800,16804,16808,16812,16816,16820,16824,16828],{"type":24,"tag":2279,"props":16724,"children":16725},{"class":3533},[16726],{"type":34,"value":7686},{"type":24,"tag":2279,"props":16728,"children":16729},{"class":3908},[16730],{"type":34,"value":5074},{"type":24,"tag":2279,"props":16732,"children":16733},{"class":3533},[16734],{"type":34,"value":4205},{"type":24,"tag":2279,"props":16736,"children":16737},{"class":3527},[16738],{"type":34,"value":11492},{"type":24,"tag":2279,"props":16740,"children":16741},{"class":3557},[16742],{"type":34,"value":16743},"'Last epoch, VALIDATION], Loss: ",{"type":24,"tag":2279,"props":16745,"children":16746},{"class":3908},[16747],{"type":34,"value":9135},{"type":24,"tag":2279,"props":16749,"children":16750},{"class":3533},[16751],{"type":34,"value":12255},{"type":24,"tag":2279,"props":16753,"children":16754},{"class":3527},[16755],{"type":34,"value":3593},{"type":24,"tag":2279,"props":16757,"children":16758},{"class":3533},[16759],{"type":34,"value":12264},{"type":24,"tag":2279,"props":16761,"children":16762},{"class":3527},[16763],{"type":34,"value":6072},{"type":24,"tag":2279,"props":16765,"children":16766},{"class":3533},[16767],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16769,"children":16770},{"class":3908},[16771],{"type":34,"value":2283},{"type":24,"tag":2279,"props":16773,"children":16774},{"class":3533},[16775],{"type":34,"value":3937},{"type":24,"tag":2279,"props":16777,"children":16778},{"class":3908},[16779],{"type":34,"value":11960},{"type":24,"tag":2279,"props":16781,"children":16782},{"class":3557},[16783],{"type":34,"value":11983},{"type":24,"tag":2279,"props":16785,"children":16786},{"class":3908},[16787],{"type":34,"value":9135},{"type":24,"tag":2279,"props":16789,"children":16790},{"class":3533},[16791],{"type":34,"value":12297},{"type":24,"tag":2279,"props":16793,"children":16794},{"class":3527},[16795],{"type":34,"value":3593},{"type":24,"tag":2279,"props":16797,"children":16798},{"class":3533},[16799],{"type":34,"value":12264},{"type":24,"tag":2279,"props":16801,"children":16802},{"class":3527},[16803],{"type":34,"value":6072},{"type":24,"tag":2279,"props":16805,"children":16806},{"class":3533},[16807],{"type":34,"value":2285},{"type":24,"tag":2279,"props":16809,"children":16810},{"class":3908},[16811],{"type":34,"value":2283},{"type":24,"tag":2279,"props":16813,"children":16814},{"class":3533},[16815],{"type":34,"value":3937},{"type":24,"tag":2279,"props":16817,"children":16818},{"class":3908},[16819],{"type":34,"value":11960},{"type":24,"tag":2279,"props":16821,"children":16822},{"class":3557},[16823],{"type":34,"value":11524},{"type":24,"tag":2279,"props":16825,"children":16826},{"class":3533},[16827],{"type":34,"value":15515},{"type":24,"tag":2279,"props":16829,"children":16830},{"class":3571},[16831],{"type":34,"value":16832},"# The Meta-Validation only runs for informative matters, so our goal is to have this at the end of each problem (every 10 steps)\n",{"type":24,"tag":2279,"props":16834,"children":16836},{"class":3522,"line":16835},131,[16837],{"type":24,"tag":2279,"props":16838,"children":16839},{},[],{"type":24,"tag":2279,"props":16841,"children":16843},{"class":3522,"line":16842},132,[16844],{"type":24,"tag":2279,"props":16845,"children":16846},{"class":3533},[16847],{"type":34,"value":16848},"                    update_model(model, initial_weights, param_keys)\n",{"type":24,"tag":2279,"props":16850,"children":16852},{"class":3522,"line":16851},133,[16853],{"type":24,"tag":2279,"props":16854,"children":16855},{},[],{"type":24,"tag":2279,"props":16857,"children":16859},{"class":3522,"line":16858},134,[16860,16864,16868,16872,16877],{"type":24,"tag":2279,"props":16861,"children":16862},{"class":3533},[16863],{"type":34,"value":7299},{"type":24,"tag":2279,"props":16865,"children":16866},{"class":3908},[16867],{"type":34,"value":5074},{"type":24,"tag":2279,"props":16869,"children":16870},{"class":3533},[16871],{"type":34,"value":4205},{"type":24,"tag":2279,"props":16873,"children":16874},{"class":3557},[16875],{"type":34,"value":16876},"'END OF META-VALIDATION STEP'",{"type":24,"tag":2279,"props":16878,"children":16879},{"class":3533},[16880],{"type":34,"value":3937},{"type":24,"tag":3511,"props":16882,"children":16884},{"code":16883},"===============================\n//           Meta-Epoch 1       //\n===============================\n0 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.7687771320343018, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6925913095474243, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6927804350852966, Accuracy: 0.5\n\n\n/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n\n\n\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n1036 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\n1037 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6932497620582581, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 4\nEpoch 4, step     1], Loss: 0.6932467222213745, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6932439208030701, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6932413578033447, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6932388544082642, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931473016738892, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6932364702224731, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 9\nEpoch 9, step     1], Loss: 0.6932342648506165, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6932321190834045, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6932300925254822, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6932281851768494, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.6932263374328613, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6932245492935181, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.693159818649292, Accuracy: 0.875\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.693159818649292, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.693159818649292, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.693159818649292, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.693159818649292, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931470036506653, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471228599548, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931470036506653, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471228599548, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     3], Loss: 0.6931470036506653, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931469440460205, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931470036506653, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471228599548, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471228599548, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931470036506653, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931470036506653, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931472420692444, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931472420692444, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n1038 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1039 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931465268135071, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471228599548, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6929552555084229, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.693013608455658, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931463479995728, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6929985284805298, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6930403709411621, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931462287902832, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6930311918258667, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6929515600204468, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931459903717041, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6929175853729248, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6929798126220703, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6928402781486511, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931451559066772, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931452751159668, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6929152011871338, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931449174880981, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.692875862121582, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6928192377090454, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6924663782119751, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6925125122070312, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931395530700684, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6914534568786621, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471228599548, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     2], Loss: 0.6931257247924805, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6903964877128601, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6930469870567322, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6734169125556946, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6456539630889893, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6456685662269592, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931453347206116, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6456435322761536, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931467950344086, Accuracy: 0.3333333432674408\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931618452072144, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.7013384103775024, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.7013236880302429, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931618452072144, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.7013236880302429, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931618452072144, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.7013384103775024, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931618452072144, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.7013236880302429, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931618452072144, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.7013236880302429, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931618452072144, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.7013236880302429, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.7013383507728577, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931618452072144, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.7013384103775024, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1040 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931450963020325, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931450963020325, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n1041 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931325197219849, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.685472846031189, Accuracy: 0.125\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.685472846031189, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931325197219849, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931324601173401, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931325197219849, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.685472846031189, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6854581832885742, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6854581832885742, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931325197219849, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.685472846031189, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931325197219849, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.685472846031189, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.685472846031189, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6854581832885742, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.685472846031189, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1042 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931456327438354, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.5982619524002075, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931469440460205, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6456738114356995, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931468844413757, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6457263231277466, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931469440460205, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.693146824836731, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6457088589668274, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931469241778055, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6457077860832214, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6456754803657532, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931454539299011, Accuracy: 0.75\nEpoch 4, VALIDATION], Loss: 0.6931469142436981, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931309103965759, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.5982460975646973, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931453943252563, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931469043095907, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931443214416504, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6456587910652161, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6457151770591736, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931468844413757, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6456596255302429, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931452751159668, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6457098126411438, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931468745072683, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.645708441734314, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6456731557846069, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.693132221698761, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931468645731608, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931296586990356, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.5982348322868347, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931437253952026, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6456550359725952, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.645706832408905, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6456537246704102, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931468347708384, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6457046270370483, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6456717252731323, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931255459785461, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.693146824836731, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931438446044922, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931449770927429, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6457033753395081, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.693146804968516, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6456713080406189, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931432485580444, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.693146804968516, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6456672549247742, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931449174880981, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6457016468048096, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931467950344086, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6485647559165955, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6485647559165955, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6485647559165955, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6485647559165955, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6485647559165955, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6485647559165955, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n1043 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 3, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 5, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 5, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 6, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 6, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 7, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 7, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 8, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 9, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 9, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 11, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 12, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 12, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 13, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 13, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 14, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 14, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 15, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 15, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\n",[16885],{"type":24,"tag":3495,"props":16886,"children":16887},{"__ignoreMap":10},[16888],{"type":34,"value":16883},{"type":24,"tag":46,"props":16890,"children":16891},{},[16892],{"type":34,"value":16893},"As said before, we don't want to check the performance of the approach since we will need deep review and debug of the behaviour (with proper hyperparameter search, etc) and this is out of the scope of this post. However, I am glad to see that I have a running and working Meta-Learning pipeline.",{"type":24,"tag":46,"props":16895,"children":16896},{},[16897],{"type":34,"value":16898},"In the next post, my intention is to see make a performance analysis of this and compare it to other approaches.",{"type":24,"tag":36,"props":16900,"children":16902},{"id":16901},"thank-you-again-reader",[16903],{"type":34,"value":16904},"Thank you again, reader",{"type":24,"tag":46,"props":16906,"children":16907},{},[16908],{"type":34,"value":16909},"This is my second blog post and the first in which I presented code. I had an enjoyable experience with it and I will repeat this format for sure! Actually, in the next post I pretend to expose one more episode about this Meta-Learning topic, in which I may perform some analysis of the apporach results, comparisons, etc. Again, thank you for your attention and we'll meet in the next post!",{"type":24,"tag":16911,"props":16912,"children":16913},"style",{},[16914],{"type":34,"value":16915},".github-light_github-dark{color:#24292e;background:#fff;}.dark .github-light_github-dark{color:#e1e4e8;background:#24292e;}.ct-149352{color:#D73A49;}.dark .ct-149352{color:#F97583;}.ct-553616{color:#24292E;}.dark .ct-553616{color:#E1E4E8;}.ct-952708{color:#032F62;}.dark .ct-952708{color:#9ECBFF;}.ct-086898{color:#6A737D;}.ct-157101{color:#E36209;}.dark .ct-157101{color:#FFAB70;}.ct-617022{color:#005CC5;}.dark .ct-617022{color:#79B8FF;}.ct-762058{color:#6F42C1;}.dark .ct-762058{color:#B392F0;}",{"title":10,"searchDepth":2808,"depth":2808,"links":16917},[16918,16922,16923,16924,16934],{"id":3112,"depth":2808,"text":3115,"children":16919},[16920,16921],{"id":3123,"depth":2817,"text":3126},{"id":3201,"depth":2817,"text":3204},{"id":3379,"depth":2808,"text":3382},{"id":3479,"depth":2808,"text":3482},{"id":3495,"depth":2808,"text":3498,"children":16925},[16926,16927,16928,16929,16930,16931,16932,16933],{"id":3501,"depth":2817,"text":3504},{"id":3804,"depth":2817,"text":3807},{"id":4568,"depth":2817,"text":4571},{"id":4750,"depth":2817,"text":4753},{"id":5738,"depth":2817,"text":5741},{"id":10120,"depth":2817,"text":10123},{"id":12375,"depth":2817,"text":12378},{"id":13586,"depth":2817,"text":13589},{"id":16901,"depth":2808,"text":16904},"content:articles:2022-12-20-meta-learning-implementation.md","articles/2022-12-20-meta-learning-implementation.md",["ShallowRef",16938],{},{"preference":340,"value":340,"unknown":16940,"forced":9},true,[16942,16945,16965],{"title":16943,"_path":3593,"layout":16944},"About","default",{"title":16946,"_path":16947,"children":16948,"layout":16964},"Articles","/articles",[16949,16950,16951,16952,16955,16958,16961],{"title":2839,"_path":2838,"layout":19},{"title":11,"_path":7,"layout":19},{"title":3034,"_path":3033,"layout":19},{"title":16953,"_path":16954,"layout":19},"Meta-Learning: MAML evaluation and discussion by Metabloggism","/articles/2023-02-07-meta-learning-analysis",{"title":16956,"_path":16957,"layout":19},"Introduction of SHORTS","/articles/2023-02-08-shorts",{"title":16959,"_path":16960,"layout":19},"Short: ONNX","/articles/2023-02-09-short-onnx",{"title":16962,"_path":16963,"layout":19},"Short: Shap values","/articles/2023-04-14-short-shap","page",{"title":16966,"_path":16967,"layout":16944},"Contact","/contact",{"uil:github":16969,"uil:linkedin":16972,"material-symbols:arrow-upward":16974,"ph:arrow-left":16976},{"left":16970,"top":16970,"width":7433,"height":7433,"rotate":16970,"vFlip":9,"hFlip":9,"body":16971},0,"\u003Cpath fill=\"currentColor\" d=\"M12 2.247a10 10 0 0 0-3.162 19.487c.5.088.687-.212.687-.475c0-.237-.012-1.025-.012-1.862c-2.513.462-3.163-.613-3.363-1.175a3.636 3.636 0 0 0-1.025-1.413c-.35-.187-.85-.65-.013-.662a2.001 2.001 0 0 1 1.538 1.025a2.137 2.137 0 0 0 2.912.825a2.104 2.104 0 0 1 .638-1.338c-2.225-.25-4.55-1.112-4.55-4.937a3.892 3.892 0 0 1 1.025-2.688a3.594 3.594 0 0 1 .1-2.65s.837-.262 2.75 1.025a9.427 9.427 0 0 1 5 0c1.912-1.3 2.75-1.025 2.75-1.025a3.593 3.593 0 0 1 .1 2.65a3.869 3.869 0 0 1 1.025 2.688c0 3.837-2.338 4.687-4.563 4.937a2.368 2.368 0 0 1 .675 1.85c0 1.338-.012 2.413-.012 2.75c0 .263.187.575.687.475A10.005 10.005 0 0 0 12 2.247Z\"/>",{"left":16970,"top":16970,"width":7433,"height":7433,"rotate":16970,"vFlip":9,"hFlip":9,"body":16973},"\u003Cpath fill=\"currentColor\" d=\"M20.47 2H3.53a1.45 1.45 0 0 0-1.47 1.43v17.14A1.45 1.45 0 0 0 3.53 22h16.94a1.45 1.45 0 0 0 1.47-1.43V3.43A1.45 1.45 0 0 0 20.47 2ZM8.09 18.74h-3v-9h3ZM6.59 8.48a1.56 1.56 0 1 1 0-3.12a1.57 1.57 0 1 1 0 3.12Zm12.32 10.26h-3v-4.83c0-1.21-.43-2-1.52-2A1.65 1.65 0 0 0 12.85 13a2 2 0 0 0-.1.73v5h-3v-9h3V11a3 3 0 0 1 2.71-1.5c2 0 3.45 1.29 3.45 4.06Z\"/>",{"left":16970,"top":16970,"width":7433,"height":7433,"rotate":16970,"vFlip":9,"hFlip":9,"body":16975},"\u003Cpath fill=\"currentColor\" d=\"M11 20V7.825l-5.6 5.6L4 12l8-8l8 8l-1.4 1.425l-5.6-5.6V20h-2Z\"/>",{"left":16970,"top":16970,"width":16977,"height":16977,"rotate":16970,"vFlip":9,"hFlip":9,"body":16978},256,"\u003Cpath fill=\"currentColor\" d=\"M224 128a8 8 0 0 1-8 8H59.31l58.35 58.34a8 8 0 0 1-11.32 11.32l-72-72a8 8 0 0 1 0-11.32l72-72a8 8 0 0 1 11.32 11.32L59.31 120H216a8 8 0 0 1 8 8Z\"/>",["Reactive",16980],{}]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{FORMSPREE_URL:"",plausible:{hashMode:false,trackLocalhost:false,domain:"",apiHost:"https://plausible.io",autoPageviews:true,autoOutboundTracking:false},studio:{apiURL:"https://api.nuxt.studio"},mdc:{components:{prose:true,map:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"}},headings:{anchorLinks:{h1:false,h2:true,h3:true,h4:true,h5:false,h6:false}}},content:{locales:[],defaultLocale:"",integrity:1693576793614,experimental:{stripQueryParameters:false,advanceQuery:false,clientDB:false},respectPathCase:false,api:{baseURL:"/api/_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:{default:"github-light",dark:"github-dark"},preload:["json","js","ts","html","css","vue","diff","shell","markdown","yaml","bash","ini","c","cpp"]},wsUrl:"",documentDriven:{page:true,navigation:true,surround:true,globals:{},layoutFallbacks:["theme"],injectPage:true},host:"",trailingSlash:false,contentHead:true,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:"/",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body>
</html>
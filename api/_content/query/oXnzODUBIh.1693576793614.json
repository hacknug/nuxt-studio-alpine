[{"_path":"/articles/2022-11-15-welcome-post","_dir":"articles","_draft":false,"_partial":false,"_locale":"","title":"Welcome Post","description":"Learn how to configure Alpine with the app.config.ts file.","layout":"article","date":"2022-11-15T00:00:00.000Z","cover":"/articles/get-started.webp","author":{"name":"Ignasi Mas aka Mr. Leylo","avatarUrl":"https://pbs.twimg.com/profile_images/1042510623962275840/1Iw_Mvud_400x400.jpg","link":"https://twitter.com/atinux"},"body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"welcome-post"},"children":[{"type":"text","value":"Welcome Post"}]},{"type":"element","tag":"h2","props":{"id":"welcome"},"children":[{"type":"text","value":"Welcome"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"My name is Ignasi Mas, I am a Machine Learning/AI Engineer with a broad interest in solving data issues. My background is built in Computer Vision, although my interest focus (which obviously includes Computer Vision) is wider."}]},{"type":"element","tag":"hr","props":{"id":""},"children":[]},{"type":"element","tag":"h3","props":{"id":"about-me"},"children":[{"type":"text","value":"About me"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I studied Telecommunication Engineering at "},{"type":"element","tag":"a","props":{"href":"https://telecos.upc.edu/acl_users/credentials_cookie_auth/require_login?came_from=https%3A//telecos.upc.edu/es","rel":["nofollow"]},"children":[{"type":"text","value":"ETSETB, UPC"}]},{"type":"text","value":". Some day we may talk deeply about my experience studying this career, but for now let's just say that the content in it is acquiring the knowledge to understand each point in the signal lifecycle."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"What's the particularity about this? Well, our knowledge about signal has increased so much during the last decades, that more and more issues and solutions have flourished, thus becoming Telecommunication Engineering a vastly wide career. That is of course something good but is also more sensible to unrelated limitations. In the end, time is limited, and if you want to cover everything you lose granularity."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"During my progress in my career, I felt more and more attracted to the development of intelligent systems. In that context, I demanded more knowledge than what I was getting, but the loss of granularity mentioned above made that impossible. Once I graduated I felt incomplete about that. I missed something. And that something was Machine Learning. Based "},{"type":"element","tag":"a","props":{"href":"https://www.andrewng.org/","rel":["nofollow"]},"children":[{"type":"text","value":"Andrew NG"}]},{"type":"text","value":" opened my eyes through "},{"type":"element","tag":"a","props":{"href":"https://www.coursera.org/learn/machine-learning","rel":["nofollow"]},"children":[{"type":"text","value":"its course"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I found the following piece in my career's puzzle as the "},{"type":"element","tag":"a","props":{"href":"https://www.uab.cat/web/estudiar/official-master-s-degrees/general-information/computer-vision-1096480962610.html?param1=1345648392514","rel":["nofollow"]},"children":[{"type":"text","value":"Master in Computer Vision"}]},{"type":"text","value":" from "},{"type":"element","tag":"a","props":{"href":"http://www.cvc.uab.es/","rel":["nofollow"]},"children":[{"type":"text","value":"Computer Vision Center"}]},{"type":"text","value":". There perhaps I may be able to merge two of my main academic interests, Machine Learning and Computer Vision. Two years later, I didn't regret that decision. This Master fed me with the seeds to gain further knowledge, and begin learning everything in the wild."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"But my adventure still had to deliver another incredible chapter. That was the development of my Master's thesis. I wanted to focus on something of my special interest, so I researched open and hot topics in Machine Learning. I had many interests so it was hard to choose, but I found in Few-Shot Learning one of my main focuses. There, I learned about Meta-Learning and found one of the potentially needed from Meta-Learning problems in ML: Active Learning."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In this blog, we will have time to talk about Meta-Learning and Active Learning further, but just know that I developed my Master's thesis about Meta-Active Learning. I.e. using Meta-Learning to solve Active Learning problems. I focused on one concrete Active Learning scenario (again, we will study these scenarios someday in this space). I sweated blood just to replicate the State of the Art approaches. I remember the days trying to handle memory in my PyTorch tensors… (in Meta-Learning, memory management works differently since you keep different gradients for different levels… but no more spoilers). And I almost jumped out of joy the day I had some reasonable results in my proposed solutions."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This chapter did not finish presenting my dissertation for the Master (which I obviously did and finally got), but I presented it to the MDALC Workshop at "},{"type":"element","tag":"a","props":{"href":"https://iccv2019.thecvf.com/","rel":["nofollow"]},"children":[{"type":"text","value":"ICCV 2019"}]},{"type":"text","value":", and they accepted it! We published "},{"type":"element","tag":"a","props":{"href":"https://ieeexplore.ieee.org/document/9022361","rel":["nofollow"]},"children":[{"type":"text","value":"the paper"}]},{"type":"text","value":" and it is accessible to anyone since then."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Is my academic history finished yet? Of course not! I am actively thinking about a possible PhD that I may do someday. I actually had a couple of opportunities that in the end were not materialized at all, but for sure there will be more. It is not something time sensitive right now, but it would be another way to acquire and deliver more knowledge. Actually, this will not necessarily be my only path, I may find other ways to do so. So new adventures await!"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"Oh, but Ignasi, you didn't tell us about your professional trajectory"}]},{"type":"text","value":". Yes, indeed. I have plenty of experiences and cool projects along with incredible people that I participated in. But that is probably a story for another space. Or maybe another day…"}]},{"type":"element","tag":"h3","props":{"id":"about-this-blog"},"children":[{"type":"text","value":"About this blog"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In the current episode, I realized that I spend time browsing the State of the Art in some matters and playing with code, but it is something I have always done by myself. However, wait.... Why not share it with everyone? It is a good trade. You get my knowledge and I get your feedback. So, how can I share it with everyone? Oh, a blog! It is an easy tool where I may focus on the content, instead of the shape. If this grows, I may redefine it later. But at my beginnings, that is the idea."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"At the time I am writing this, I still have to do "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"everything"}]},{"type":"text","value":" in the blog. My idea here is to post in a more or less formal way (I want to make it easy to read for you) posts about different theory ML topics of my interest as well as maybe some practical exercises where I'll share my reasoning live."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I can't tell you the frequency at which I will be posting. My idea first is to try to post every two weeks (time enough for researching some problem and preparing the post while I am working because I need to eat, you know?), but I can't promise anything yet."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In the first weeks, I will post topics I already know about and focus on how to present them to you. This way, I will train myself for the future, in which I will deliver to you new topics."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So just one more thing: let's have fun together!"}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"welcome","depth":2,"text":"Welcome","children":[{"id":"about-me","depth":3,"text":"About me"},{"id":"about-this-blog","depth":3,"text":"About this blog"}]}]}},"_type":"markdown","_id":"content:articles:2022-11-15-welcome-post.md","_source":"content","_file":"articles/2022-11-15-welcome-post.md","_extension":"md"},{"_path":"/articles/2022-12-20-meta-learning-implementation","_dir":"articles","_draft":false,"_partial":false,"_locale":"","title":"Meta-Learning implementation","description":"Writing Markdown articles in Alpine is straightforward.","cover":"/articles/write-articles.webp","date":"2022-12-20T00:00:00.000Z","layout":"article","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"meta-learning-implementation"},"children":[{"type":"text","value":"Meta-Learning implementation"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"IMPORTANT NOTE:"}]},{"type":"text","value":" This post consists of a Python Notebook. I inserted the content in Markdown into the blog, so you'll find explanations, code and results. A copy of the Notebook itself "},{"type":"element","tag":"a","props":{"href":"https://colab.research.google.com/drive/1MmAdSuQbB4kfUtEntL0PmQmtvbaR3QtU?usp=sharing","rel":["nofollow"]},"children":[{"type":"text","value":"is also shared"}]},{"type":"text","value":"."}]},{"type":"element","tag":"h1","props":{"id":"meta-learning-experiment-maml-implementation-by-metabloggism"},"children":[{"type":"text","value":"Meta-Learning: Experiment & MAML implementation by Metabloggism"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Welcome to this first Notebook by Metabloggism! This episode follows directly the post "},{"type":"element","tag":"a","props":{"href":"https://metabloggism.github.io/2022/11/21/meta-learning.html","rel":["nofollow"]},"children":[{"type":"text","value":"Meta-Learning explained"}]},{"type":"text","value":". As a recap from it, we reviewed the meaning of Meta-Learning, how it did appear and evolve and how is it approached nowadays. We concluded that today, we use Meta-Learning mostly as a tool against scenarios with few data in a specific problem we want to solve but where we are able to find data from related problems, thus building a domain of problems at a higher level from Learning called "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"Meta-Learning"}]},{"type":"text","value":". At this level you may learn how to learn efficiently in each problem, and that may be done in different ways. One of the most praised approaches in the last years, and the one which probably is more commonly used in these settings is "},{"type":"element","tag":"a","props":{"href":"https://arxiv.org/pdf/1703.03400.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"MAML"}]},{"type":"text","value":", which at the Meta-Learning level learns a proper general (in the problems domain) initialization of any (learnable by gradient descent) model at the Learning level. If you still have doubts, I would recommend reading the mentioned post again before reading this Notebook."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The scope of this post is to materialize what we described in the previous one. First, we will take a tour of the experiment setting, defining what we want to solve in the end and building the scenario in which we will work on. Second, we will implement a MAML approach and train at Meta-Learning."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This is a simple walkthrough of this process. We do not aim to engage in a performance analysis since we will let this be for a future post, with other variables deeply explored, a fair comparison with other approaches, with a proper hyperparameter exploration, etc."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So that said, let's engage into work!"}]},{"type":"element","tag":"h2","props":{"id":"preliminaries-meta-learning-datasets"},"children":[{"type":"text","value":"Preliminaries: Meta-Learning datasets"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I need to introduce something I forgot in the previous post. We did not talk about Meta-Learning datasets!"}]},{"type":"element","tag":"h3","props":{"id":"requirements-of-a-good-meta-learning-dataset"},"children":[{"type":"text","value":"Requirements of a good Meta-Learning dataset"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"With all the previous theory, our definition of Meta-Learning could be something like "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"Learning tools that will allow to Learn to solve problems from a certain domain"}]},{"type":"text","value":" and we do so by repeatedly learning to solve these problems. Thus, any dataset which allows us to do so can be considered a Meta-Learning dataset."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Meta-Learning datasets may be used to directly solve target problems, but since they don't always allow this, they are commonly used for making experiments with approaches for analysis."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In general, any usual dataset can be used as a Meta-Learning dataset. Just think about "},{"type":"element","tag":"a","props":{"href":"https://www.image-net.org/","rel":["nofollow"]},"children":[{"type":"text","value":"Imagenet"}]},{"type":"text","value":", for example (let's think about the classification task). There you have a series of samples and labels belonging to a group of classes. There you can take the whole domain of classes and build a domain of problems consisting in binary classification problems, where you may have as many problems as combinations of 2 classes, and therefore Learn to Learn (Meta-Learn) to solve any binary classification problem there. Even more extreme, think of a simple dataset that a little Startup company which makes supervised face identification handles, consisting of faces of both people in the group to identify and out from it (labeled). One could make artificial groups of other people and build several problems of the same nature."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"However, you may have noted that these domains are forced and do not have a strong semantical relation, making the information extraction weak among problems, and almost not improving the performance in the target Learning one. There are some aspects that determine if a dataset is proper for Meta-Learning, which enable to exploit their relation to skip some steps in any target problem from the domain. Thus, in general any dataset can act as a Meta-Learning dataset, but not all of them will be able to become the desired Meta-learning tool. So, which ingredients must it contain?"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"The ingredients of any Learning problem, e.g. for Supervised Classification problems, samples and labels."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Labels should preferably be variated, to allow us to build a properly extensive schedule at the Meta-Learning level. Note that many classes can be converted to many problems. At least, should allow having more than one problem."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"A rich hierarchy/meta-information which should allow us to relate the instances and build meaningful domains"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Moreover, commonly the Meta-Learning datasets have some common traits:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"As they aim to pose some challenge to you, they mostly have a limited number of samples per class to emulate a Few-Shot Learning scenario. In case they don't you can always enforce this limitation."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Since they need lots of classes (and therefore lots of samples), they tend to work in light data (e.g. in Computer Vision in low-resolution)."}]}]},{"type":"element","tag":"h3","props":{"id":"datasets"},"children":[{"type":"text","value":"Datasets"}]},{"type":"element","tag":"h4","props":{"id":"omniglot"},"children":[{"type":"element","tag":"a","props":{"href":"https://omniglot.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Omniglot"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"One of the most common datasets. "},{"type":"element","tag":"a","props":{"href":"https://cims.nyu.edu/~brenden/papers/LakeEtAl2011CogSci.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"Presented by Lake et al. in 2015"}]},{"type":"text","value":" as a challenge to solve a Few-Shot Learning problem (although they didn't mention the term "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"Few-Shot"}]},{"type":"text","value":"), it was the dataset chosen by Koch et al. to describe a One-Shot Learning problem (remind "},{"type":"element","tag":"a","props":{"href":"https://metabloggism.github.io/2022/11/21/meta-learning.html","rel":["nofollow"]},"children":[{"type":"text","value":"the section "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"The comeback of Meta-Learning and its relation to Few-Shot Learning"}]},{"type":"text","value":" in the previous post"}]},{"type":"text","value":") and since then a benchmark in Meta-Learning. It has been used in most of the main Meta-Learning approaches, such as "},{"type":"element","tag":"a","props":{"href":""},"children":[{"type":"text","value":"MANN"}]},{"type":"text","value":", "},{"type":"element","tag":"a","props":{"href":"https://arxiv.org/pdf/1606.04080.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"MatchingNets"}]},{"type":"text","value":", "},{"type":"element","tag":"a","props":{"href":"https://arxiv.org/pdf/1703.05175.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"Prototypical Networks"}]},{"type":"text","value":", "},{"type":"element","tag":"a","props":{"href":"https://arxiv.org/pdf/1703.03400.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"MAML"}]},{"type":"text","value":" or "},{"type":"element","tag":"a","props":{"href":"https://arxiv.org/pdf/1909.05557.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"Modular Meta-Learning"}]},{"type":"text","value":". An API for the dataset is also included in some top ML frameworks like Pytorch (in the torchvision package)."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"It consists in a series of alphabets where in each alphabet there is a series of characters and for each character a limited group of samples (20 samples). A sample consists in a 105x105 (single-channel) image representing the character. The label of the sample is the character itself (related to an alphabet). This allows building semantically meaningful domains of problems, depending on the alphabet which the characters belong to."}]},{"type":"element","tag":"h4","props":{"id":"mini-imagenet"},"children":[{"type":"text","value":"Mini-Imagenet"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Introduced in the paper of "},{"type":"element","tag":"a","props":{"href":"https://arxiv.org/pdf/1606.04080v2.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"MatchingNets"}]},{"type":"text","value":". "},{"type":"element","tag":"a","props":{"href":"https://www.kaggle.com/datasets/arjunashok33/miniimagenet","rel":["nofollow"]},"children":[{"type":"text","value":"It"}]},{"type":"text","value":" is probably the second benchmark for Meta-Learning. A modified version of the "},{"type":"element","tag":"a","props":{"href":"https://www.image-net.org/","rel":["nofollow"]},"children":[{"type":"text","value":"ImageNet"}]},{"type":"text","value":" Computer Vision dataset where a semantic selection has been performed. It is also used in some of the main approaches of Meta-Learning (aside from MatchingNets)."}]},{"type":"element","tag":"h4","props":{"id":"imagenet-and-other-common-general-datasets-used-in-meta-learning"},"children":[{"type":"text","value":"Imagenet and other common general datasets used in Meta-Learning"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Most times, the Meta-Learning approaches are used in general datasets with enforced conditions. An example is found in "},{"type":"element","tag":"a","props":{"href":"https://arxiv.org/pdf/1606.04474.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"Learning to learn by gradient descent by gradient descent"}]},{"type":"text","value":", where authors used common datasets like "},{"type":"element","tag":"a","props":{"href":"https://yann.lecun.com/exdb/mnist/","rel":["nofollow"]},"children":[{"type":"text","value":"MNIST"}]},{"type":"text","value":" or "},{"type":"element","tag":"a","props":{"href":"https://www.cs.toronto.edu/~kriz/cifar.html","rel":["nofollow"]},"children":[{"type":"text","value":"CIFAR-10"}]},{"type":"text","value":"."}]},{"type":"element","tag":"h4","props":{"id":"non-cv-datasets"},"children":[{"type":"text","value":"Non-CV datasets"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Note that we only considered CV datasets until now. I come from the CV field, but I do not pretend to focus in CV in this episode. However, these datasets are actually the ones mostly used when testing the main Meta-Learning approaches. Alternatively, some regression tasks are also tested like in "},{"type":"element","tag":"a","props":{"href":"https://arxiv.org/pdf/1703.03400.pdf","rel":["nofollow"]},"children":[{"type":"text","value":"MAML"}]},{"type":"text","value":"."}]},{"type":"element","tag":"h2","props":{"id":"experiment-definition"},"children":[{"type":"text","value":"Experiment definition"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"There are two main components we may want to implement in the notebook: the challenge and the solution."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We will work in the Omniglot dataset since it is the most standard benchmark as well as it provides a hierarchy we will use to build the domain."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The challenge I propose to solve is "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"Learning to be able to solve, given a random alphabet, a character (within the alphabet) binary classification task with few samples"}]},{"type":"text","value":". Thus, our setting will go as follows:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Build all the possible problems of this type in Omniglot:"},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Pick each combination of 2 characters within all alphabets"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"For each combination, get all the samples and make common ML splits: train, validation and test"}]}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Make splits of alphabets at Meta-Learning level: Meta-train, Meta-validation and Meta-test:"},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"For each Meta-split (Meta-sets from now on) take all possible problems for all its alphabets"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We aim to be able to take any of the Meta-test problems and after a proper training of that problem, be able to solve its test set."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We rely on the fact that the Meta-sets will be enough varied (they will be randomly sorted) to represent the whole domain each."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"As for the solution, we will use the MAML approach. Remember that this approach works by, at each meta-step, taking a meta-batch of problems and for each problem computing an individual training (over its training samples) and evaluating the loss in its test set, averaging it over all the problems in the meta-batch and thus resulting in the meta-step loss."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I found in Github "},{"type":"element","tag":"a","props":{"href":"https://github.com/cbfinn/maml","rel":["nofollow"]},"children":[{"type":"text","value":"the official implementation"}]},{"type":"text","value":" of MAML by Chelsea Finn, in Tensorflow, as well as other unofficial implementations in Pytorch, like "},{"type":"element","tag":"a","props":{"href":"https://github.com/dragen1860/MAML-Pytorch","rel":["nofollow"]},"children":[{"type":"text","value":"this one"}]},{"type":"text","value":". However, we want to take control of the implementations to bring it to our own experiment, so we will develop it from scratch (but following the ideas there)."}]},{"type":"element","tag":"h2","props":{"id":"tools"},"children":[{"type":"text","value":"Tools"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For this Proof of Concept we will use Python and Pytorch as our ML framework."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I developed it in a Google Collab so I may be able to use GPU's."}]},{"type":"element","tag":"h2","props":{"id":"code"},"children":[{"type":"text","value":"Code"}]},{"type":"element","tag":"h3","props":{"id":"imports-and-setting"},"children":[{"type":"text","value":"Imports and setting"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The following cell can be skipped since it is just necessary for running the Google Collab Notebook in my Drive environment."}]},{"type":"element","tag":"pre","props":{"code":"from google.colab import drive\ndrive.mount('/content/drive')   \n# WRITE PATH WHERE YOU WERE\n%cd drive/MyDrive/collab_space/metabloggism/meta-learning\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"from"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" google.colab "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" drive\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"drive.mount("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'/content/drive'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")   \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"# WRITE PATH WHERE YOU WERE\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"%"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"cd drive"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"MyDrive"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"collab_space"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metabloggism"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"meta"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"learning"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"Mounted at /content/drive\n/content/drive/MyDrive/collab_space/metabloggism/meta-learning\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"Mounted at /content/drive\n/content/drive/MyDrive/collab_space/metabloggism/meta-learning\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Imports, we'll skip explanations, I just came back here to import any module that we needed."}]},{"type":"element","tag":"pre","props":{"code":"import random\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler, BatchSampler\nimport torchvision\nimport matplotlib.pyplot as plt\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" random\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch.nn "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"as"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch.nn.functional "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"as"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" F\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch.optim "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"as"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" optim\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"from"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch.utils.data "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" DataLoader, RandomSampler, SubsetRandomSampler, BatchSampler\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torchvision\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":8},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"import"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" matplotlib.pyplot "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"as"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" plt"}]}]}]}]},{"type":"element","tag":"h3","props":{"id":"exploring-torchvisions-omniglot-dataset"},"children":[{"type":"text","value":"Exploring torchvision's Omniglot dataset"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"As mentioned before, torchvision offers an API for handling Omniglot. We'll dissect its composition now."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"First, we must initialize it following torchvision's Omniglot "},{"type":"element","tag":"a","props":{"href":"https://pytorch.org/vision/stable/generated/torchvision.datasets.Omniglot.html","rel":["nofollow"]},"children":[{"type":"text","value":"documentation"}]},{"type":"text","value":". We'll download the whole ZIP of images("},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"download=True"}]},{"type":"text","value":" and specifying a "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"root"}]},{"type":"text","value":" directory, if you don't want it just set "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"download"}]},{"type":"text","value":" to *False) and the only transform we want is having it as tensors for our future NN."}]},{"type":"element","tag":"pre","props":{"code":"dataset = torchvision.datasets.Omniglot(\n    root=\"./dataset/omniglot\", download=True, transform=torchvision.transforms.ToTensor()\n)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"dataset "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torchvision.datasets.Omniglot(\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"root"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"\"./dataset/omniglot\""}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"download"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"True"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"transform"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"torchvision.transforms.ToTensor()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"Files already downloaded and verified\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"Files already downloaded and verified\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Ok, with that loaded, let's check the object's appearance."}]},{"type":"element","tag":"pre","props":{"code":"dataset\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"dataset"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"Dataset Omniglot\n    Number of datapoints: 19280\n    Root location: ./dataset/omniglot/omniglot-py\n    StandardTransform\nTransform: ToTensor()\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"Dataset Omniglot\n    Number of datapoints: 19280\n    Root location: ./dataset/omniglot/omniglot-py\n    StandardTransform\nTransform: ToTensor()\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Everything seems just as we asked, with a dataset of ~19k data points."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Exploraing a bit the documentation, we'll see that the only way to use the dataset is "},{"type":"element","tag":"a","props":{"href":"https://pytorch.org/vision/stable/generated/torchvision.datasets.Omniglot.html#torchvision.datasets.Omniglot.__getitem__","rel":["nofollow"]},"children":[{"type":"text","value":"through its "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_"},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"getitem"}]},{"type":"text","value":"_"}]}]},{"type":"text","value":", i.e. you can only get any of its elements (from its ~19k), so let's get for example the first one and review it."}]},{"type":"element","tag":"pre","props":{"code":"dataset[0]\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"dataset["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          ...,\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.]]]), 0)\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          ...,\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.],\n          [1., 1., 1.,  ..., 1., 1., 1.]]]), 0)\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Ok, it seems to be a tuple as the documentation says. According to it, the first element is the image itself (a torch tensor) while the second one is the target label). Let's review both"}]},{"type":"element","tag":"pre","props":{"code":"dataset[0][0].shape\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"dataset["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"].shape"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"torch.Size([1, 105, 105])\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"torch.Size([1, 105, 105])\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"As expected, the image is a single channel one of 105x105. Let's plot its only channel."}]},{"type":"element","tag":"pre","props":{"code":"plt.imshow(dataset[0][0][0].numpy())\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"plt.imshow(dataset["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"].numpy())"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"<matplotlib.image.AxesImage at 0x7f1fca5129d0>\n\n\n\n\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"<matplotlib.image.AxesImage at 0x7f1fca5129d0>\n\n\n\n\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"sample","src":"https://i.imgur.com/zimxwVw.png"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So this is the appearance of an Omniglot symbol. Everything seems fine with the samples then, and we know how to get them. Let's go for the labels."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We may review the first 100 labels."}]},{"type":"element","tag":"pre","props":{"code":"[dataset[ismp][1] for ismp in range(100)]\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"[dataset[ismp]["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ismp "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"100"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")]"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"[0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4]\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"[0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4,\n 4]\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Do you realize the pattern? Labels are sequential and each label repeats for 20 samples. Which is the number of samples per character (class). To verify that, if we get a label every 2k samples, each label should add 100 to the previous."}]},{"type":"element","tag":"pre","props":{"code":"[dataset[ismp * 2000][1] for ismp in range(8)]\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"[dataset[ismp "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2000"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ismp "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")]"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"[0, 100, 200, 300, 400, 500, 600, 700]\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"[0, 100, 200, 300, 400, 500, 600, 700]\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Which happens."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Ok, one last thing that will be useful for us. Going deeper, apart from the documentation we can also get to the "},{"type":"element","tag":"a","props":{"href":"https://pytorch.org/vision/stable/_modules/torchvision/datasets/omniglot.html#Omniglot","rel":["nofollow"]},"children":[{"type":"text","value":"source code"}]},{"type":"text","value":" and realize 2 useful attributes of the dataset object called "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_alphabets"}]},{"type":"text","value":" and "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_characters"}]},{"type":"text","value":", which is the ordered list of each of them. This way, we'll have semantical information on each of the labels and therefore we may be able to build our scenario."}]},{"type":"element","tag":"pre","props":{"code":"alphabets = dataset._alphabets\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"alphabets "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" dataset._alphabets"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"characters = dataset._characters\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" dataset._characters"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Let's check how many alphabets and characters are there."}]},{"type":"element","tag":"pre","props":{"code":"len(alphabets)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"len"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(alphabets)"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"30\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"30\n"}]}]},{"type":"element","tag":"pre","props":{"code":"len(characters)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"len"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(characters)"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"964\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"964\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Which makes sense."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The last thing, let's verify we can embed the dataset into a torch DataLoader."}]},{"type":"element","tag":"pre","props":{"code":"data_loader = torch.utils.data.DataLoader(dataset,\n                                          batch_size=4,\n                                          shuffle=True,\n                                          num_workers=8)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"data_loader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch.utils.data.DataLoader(dataset,\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                          "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"4"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                          "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"shuffle"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"True"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":",\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                          "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"num_workers"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n"}]}]},{"type":"element","tag":"h3","props":{"id":"load-raw-dataset"},"children":[{"type":"text","value":"Load raw dataset"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So with averything that we learned, let's load our dataset and its related info."}]},{"type":"element","tag":"pre","props":{"code":"omniglot_raw = torchvision.datasets.Omniglot(root=\"./dataset/omniglot\", download=True, transform=torchvision.transforms.ToTensor())\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"omniglot_raw "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torchvision.datasets.Omniglot("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"root"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"\"./dataset/omniglot\""}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"download"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"True"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"transform"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"torchvision.transforms.ToTensor())"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"Files already downloaded and verified\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"Files already downloaded and verified\n"}]}]},{"type":"element","tag":"pre","props":{"code":"alphabets = omniglot_raw._alphabets\ncharacters = omniglot_raw._characters\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"alphabets "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" omniglot_raw._alphabets\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" omniglot_raw._characters"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"num_alphabets = len(alphabets)\nnum_characters = len(characters)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"num_alphabets "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"len"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(alphabets)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"num_characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"len"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(characters)"}]}]}]}]},{"type":"element","tag":"h3","props":{"id":"building-the-meta-splits"},"children":[{"type":"text","value":"Building the Meta-Splits"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Ok, at this point we want to build each Meta-Split (or Meta-set). The material needs of a Meta-set are the alphabets it will contain. Remember that each Meta-set will determine its problems, but that is interpretablñe from its alphabets, since the problems will be all the possible problems of binary classification between characters of a same alphabet within the Meta-set."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We want to balance the Meta-set at character level, in a way in which each Meta-set will contain an approximation to a fixed ratio of characters, while respecting the constraint in which each whole alphabet must belong to a single Meta-set."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The simplest way to do so is to take each empty Meta-set and add alphabets until the fixed ratio is reached, then the last Meta-set will get the remaining alphabets. This last Meta-set will be Meta-test, since losing a bit of its content doesn't seem a disaster aside from its statistical significance."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So first we will define a "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"MetaSplit"}]},{"type":"text","value":" class that will contain this information. It will also contain some informative attributes such as the minimum number of characters, which will be computed at initialization depending on the Meta-set ratio and the total number of characters (these variables will be passed), the current number of characters (which will be updated out from the class when alphabets are added) and the number of problems, which will also be added from out of the class."}]},{"type":"element","tag":"pre","props":{"code":"class MetaSplit:\n  def __init__(self, ratio, total_num_characters):\n    self.alphabets = []\n    self.num_characters = 0\n    self.min_num_characters = total_num_characters * ratio\n    self.num_problems = None\n\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"class"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"MetaSplit"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"__init__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self, ratio, total_num_characters):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".alphabets "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" []\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".num_characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".min_num_characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" total_num_characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ratio\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".num_problems "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"And let's initialize the Meta-splits (after this step they will still be empty)"}]},{"type":"element","tag":"pre","props":{"code":"metasplits = {'metatrain': MetaSplit(0.7, num_characters),\n              'metaval': MetaSplit(0.15, num_characters),\n              'metatest': MetaSplit(0.15, num_characters)}\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metasplits "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" {"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatrain'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": MetaSplit("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.7"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", num_characters),\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"              "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metaval'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": MetaSplit("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", num_characters),\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"              "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatest'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": MetaSplit("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", num_characters)}"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The following step is counting the number of characters in each alphabet. To do so, we need to parse the strings of the alphabets and the characters, which go as the following."}]},{"type":"element","tag":"pre","props":{"code":"print(alphabets[0])\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(alphabets["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"Alphabet_of_the_Magi\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"Alphabet_of_the_Magi\n"}]}]},{"type":"element","tag":"pre","props":{"code":"print(characters[0])\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(characters["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"Alphabet_of_the_Magi/character01\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"Alphabet_of_the_Magi/character01\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Ok, so easily we can see that a character goes as "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"alphabet/character_in_alphabet"}]},{"type":"text","value":". So, we will for each alphabet count in how many characters does it match the substring before the "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"/"}]},{"type":"text","value":"."}]},{"type":"element","tag":"pre","props":{"code":"chars_per_alphabet = {alph: [char.split('/')[0] for char in characters].count(alph) for alph in alphabets}\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"chars_per_alphabet "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" {alph: [char.split("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'/'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" char "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" characters].count(alph) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" alph "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" alphabets}"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"chars_per_alphabet\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"chars_per_alphabet"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"{'Alphabet_of_the_Magi': 20,\n 'Anglo-Saxon_Futhorc': 29,\n 'Arcadian': 26,\n 'Armenian': 41,\n 'Asomtavruli_(Georgian)': 40,\n 'Balinese': 24,\n 'Bengali': 46,\n 'Blackfoot_(Canadian_Aboriginal_Syllabics)': 14,\n 'Braille': 26,\n 'Burmese_(Myanmar)': 34,\n 'Cyrillic': 33,\n 'Early_Aramaic': 22,\n 'Futurama': 26,\n 'Grantha': 43,\n 'Greek': 24,\n 'Gujarati': 48,\n 'Hebrew': 22,\n 'Inuktitut_(Canadian_Aboriginal_Syllabics)': 16,\n 'Japanese_(hiragana)': 52,\n 'Japanese_(katakana)': 47,\n 'Korean': 40,\n 'Latin': 26,\n 'Malay_(Jawi_-_Arabic)': 40,\n 'Mkhedruli_(Georgian)': 41,\n 'N_Ko': 33,\n 'Ojibwe_(Canadian_Aboriginal_Syllabics)': 14,\n 'Sanskrit': 42,\n 'Syriac_(Estrangelo)': 23,\n 'Tagalog': 17,\n 'Tifinagh': 55}\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"{'Alphabet_of_the_Magi': 20,\n 'Anglo-Saxon_Futhorc': 29,\n 'Arcadian': 26,\n 'Armenian': 41,\n 'Asomtavruli_(Georgian)': 40,\n 'Balinese': 24,\n 'Bengali': 46,\n 'Blackfoot_(Canadian_Aboriginal_Syllabics)': 14,\n 'Braille': 26,\n 'Burmese_(Myanmar)': 34,\n 'Cyrillic': 33,\n 'Early_Aramaic': 22,\n 'Futurama': 26,\n 'Grantha': 43,\n 'Greek': 24,\n 'Gujarati': 48,\n 'Hebrew': 22,\n 'Inuktitut_(Canadian_Aboriginal_Syllabics)': 16,\n 'Japanese_(hiragana)': 52,\n 'Japanese_(katakana)': 47,\n 'Korean': 40,\n 'Latin': 26,\n 'Malay_(Jawi_-_Arabic)': 40,\n 'Mkhedruli_(Georgian)': 41,\n 'N_Ko': 33,\n 'Ojibwe_(Canadian_Aboriginal_Syllabics)': 14,\n 'Sanskrit': 42,\n 'Syriac_(Estrangelo)': 23,\n 'Tagalog': 17,\n 'Tifinagh': 55}\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"And finally let's shuffle the alphabets and split among the Meta-sets!"}]},{"type":"element","tag":"pre","props":{"code":"random.shuffle(alphabets)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"random.shuffle(alphabets)"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"As said, we will take each alphabet and add it to its corresponding Meta-set. To do so, we will begin with a given Meta-set (in our case the order is Meta-train, Meta-validation and Meta-test) and check if its internal number of characters has reached its minimum value so in case it does we will switch to the next Meta-set. In any case we will add the current alphabet to the current Meta-set and update the number of characters."}]},{"type":"element","tag":"pre","props":{"code":"current_metasplit = 'metatrain'\nswitch_metasplit_from = {'metatrain': 'metaval', 'metaval': 'metatest'}\n\nfor alphabet in alphabets:\n  if not metasplits[current_metasplit].num_characters < metasplits[current_metasplit].min_num_characters:\n    current_metasplit = switch_metasplit_from[current_metasplit]\n  metasplits[current_metasplit].alphabets.append(alphabet)\n  metasplits[current_metasplit].num_characters += chars_per_alphabet[alphabet]\n\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"current_metasplit "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatrain'\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"switch_metasplit_from "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" {"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatrain'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metaval'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metaval'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatest'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"}\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" alphabet "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" alphabets:\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"not"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metasplits[current_metasplit].num_characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metasplits[current_metasplit].min_num_characters:\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    current_metasplit "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" switch_metasplit_from[current_metasplit]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  metasplits[current_metasplit].alphabets.append(alphabet)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":8},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  metasplits[current_metasplit].num_characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" chars_per_alphabet[alphabet]"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We still have to compute the number of problems of each Meta-set, which depends on its alphabets (and the number of characters in each of these alphabets)."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I developed a formula to compute this which goes as follows:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"As each problem's characters must be of the same alphabet, we can not group all characters in a single pool. Instead, we will compute it alphabet-wise and sum for all its alphabets. If we call $P$ the number of problems, $ P = \\sum_{\\alpha \\in MS}{P_{\\alpha}}$, where $P_{\\alpha}$ is the number of problems in the alphabet $\\alpha$ and $MS$ is the Meta-set (so the number of problems is the sum of the number of problems in each alphabet). This information is available right now (in the "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"MetaSplit"}]},{"type":"text","value":" objects and the "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"chars_per_alphabet"}]},{"type":"text","value":" variable)."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"The number of problems in an alphabet is the number of possible combinations of two characters among all belonging to the alphabet. From statistical theory, that is a Combination without repetition with combinations of 2, i.e. if $C_{\\alpha}$ is the number of characters in the alphabet $\\alpha$, ${C_{\\alpha} \\choose 2}$. We also know that ${m \\choose n}$ is computed as $\\frac{m!}{n! (m - n)!}$, so in our case ${C_{\\alpha} \\choose 2} = \\frac{C_{\\alpha}!}{2! (C_{\\alpha} - 2)!}$."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"We know that $2! = 2$. We also know that $\\frac{C_{\\alpha}!}{(C_{\\alpha} - 2)!} = \\frac{\\prod_{1}^{C_{\\alpha}}{i}}{\\prod_{1}^{C_{\\alpha} - 2}{j}} = \\frac{\\prod_{1}^{C_{\\alpha} - 2}{i} \\prod_{C_{\\alpha} - 1}^{C_{\\alpha}}{i}}{\\prod_{1}^{C_{\\alpha} - 2}{j}} = \\frac{\\prod_{1}^{C_{\\alpha} - 2}{i}}{\\prod_{1}^{C_{\\alpha} - 2}{j}} \\prod_{C_{\\alpha} - 1}^{C_{\\alpha}}{i} = 1 * \\prod_{C_{\\alpha} - 1}^{C_{\\alpha}}{i} = (C_{\\alpha}) * (C_{\\alpha} - 1) = C_{\\alpha}^2 - C_{\\alpha}$."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"So $P_{\\alpha} = {C_{\\alpha} \\choose 2} = \\frac{C_{\\alpha}!}{2! (C_{\\alpha} - 2)!} = \\frac{1}{2!} * \\frac{C_{\\alpha}!}{(C_{\\alpha} - 2)!} = \\frac{1}{2} * (C_{\\alpha}^2 - C_{\\alpha}) = \\frac{C_{\\alpha}^2 - C_{\\alpha}}{2}$."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Thus, $P = \\sum_{\\alpha \\in MS}{P_{\\alpha}} = \\sum_{\\alpha \\in MS}{\\frac{C_{\\alpha}^2 - C_{\\alpha}}{2}} = \\frac{1}{2} \\sum_{\\alpha \\in MS}{C_{\\alpha}^2 - C_{\\alpha}}$."}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So finally:"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"$P = \\frac{\\sum_{\\alpha \\in MS}{C_{\\alpha}^2 - C_{\\alpha}}}{2}$"}]},{"type":"element","tag":"pre","props":{"code":"for metasplit in metasplits:\n  metasplits[metasplit].num_problems = 1/2 * sum([chars_per_alphabet[alph]**2 - chars_per_alphabet[alph] for alph in metasplits[metasplit].alphabets])\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metasplit "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metasplits:\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  metasplits[metasplit].num_problems "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"sum"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"([chars_per_alphabet[alph]"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"**"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" chars_per_alphabet[alph] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" alph "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metasplits[metasplit].alphabets])"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Also recall that problems act as samples at the Meta-level, so we may count the number of metabatches with thios information if we know the metabatch size."}]},{"type":"element","tag":"pre","props":{"code":"metabatch_size = 8\nnum_metabatches = int(metasplits['metatrain'].num_problems / metabatch_size)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metabatch_size "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"num_metabatches "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"int"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(metasplits["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatrain'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"].num_problems "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metabatch_size)"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"num_metabatches\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"num_metabatches"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"1495\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"1495\n"}]}]},{"type":"element","tag":"h3","props":{"id":"the-meta-level-dataloader"},"children":[{"type":"text","value":"The Meta-level DataLoader"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"As we need to define DataLoaders when training a problem, which will generate the batches (samples + labels at each batch), at the Meta-level we will need an object that generates the meta-batches (problems at each meta-batch). We will call this the "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"MetaLoader"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This Meta-Loader should give the tools to generate a DataLoader for each of its problems."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So at this point let's explore the needs to create a problem DataLoader in our context. First, we need to define which will be the alphabet we will be working on. For simplicity, we will use the Latin alphabet as toy example. We will take all the characters of this alphabet from the list."}]},{"type":"element","tag":"pre","props":{"code":"toy_alphabet = 'Latin'\ntoy_characters = [char for char in characters if char.split('/')[0] == toy_alphabet]\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_alphabet "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Latin'\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" [char "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" char "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" char.split("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'/'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" toy_alphabet]"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Now let's randomly pick 2 characters within the list."}]},{"type":"element","tag":"pre","props":{"code":"toy_problem_characters = random.sample(toy_characters, 2)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_problem_characters "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" random.sample(toy_characters, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"toy_problem_characters\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_problem_characters"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"['Latin/character10', 'Latin/character11']\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"['Latin/character10', 'Latin/character11']\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We picked both the 10th and the 11th characters from the Latin alphabet. These are "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"J"}]},{"type":"text","value":" and "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"K"}]},{"type":"text","value":" (count it if you wish to). Let's continue to see if this matches."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Now we want to get which samples in the dataset correspond to this character. Recall that in torchvision's Omniglot, samples are sequential with 20 samples per character, so we aim to get the position of the characters in the list of characters and therefore the position of its samples in the dataset. This last value corresponds to the range of values between the character position (in the whole list) multiplied by 20 and the character position +1 multiplied by 20 (the beginning of the following character range). We want a flattened list of these sample indices for both characters in the problem."}]},{"type":"element","tag":"pre","props":{"code":"toy_problem_char_idx = [characters.index(tchar) for tchar in toy_problem_characters]  #  position of the characters in the list of characters\ntoy_problem_samples_idx = [toy_sample_range for tcharidx in toy_problem_char_idx for toy_sample_range in range(tcharidx * 20, (tcharidx + 1) * 20)]\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_problem_char_idx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" [characters.index(tchar) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" tchar "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" toy_problem_characters]  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  position of the characters in the list of characters\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_problem_samples_idx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" [toy_sample_range "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" tcharidx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" toy_problem_char_idx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" toy_sample_range "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(tcharidx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"20"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", (tcharidx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"20"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")]"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"toy_problem_samples_idx\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_problem_samples_idx"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"[13640,\n 13641,\n 13642,\n 13643,\n 13644,\n 13645,\n 13646,\n 13647,\n 13648,\n 13649,\n 13650,\n 13651,\n 13652,\n 13653,\n 13654,\n 13655,\n 13656,\n 13657,\n 13658,\n 13659,\n 13660,\n 13661,\n 13662,\n 13663,\n 13664,\n 13665,\n 13666,\n 13667,\n 13668,\n 13669,\n 13670,\n 13671,\n 13672,\n 13673,\n 13674,\n 13675,\n 13676,\n 13677,\n 13678,\n 13679]\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"[13640,\n 13641,\n 13642,\n 13643,\n 13644,\n 13645,\n 13646,\n 13647,\n 13648,\n 13649,\n 13650,\n 13651,\n 13652,\n 13653,\n 13654,\n 13655,\n 13656,\n 13657,\n 13658,\n 13659,\n 13660,\n 13661,\n 13662,\n 13663,\n 13664,\n 13665,\n 13666,\n 13667,\n 13668,\n 13669,\n 13670,\n 13671,\n 13672,\n 13673,\n 13674,\n 13675,\n 13676,\n 13677,\n 13678,\n 13679]\n"}]}]},{"type":"element","tag":"pre","props":{"code":"len(toy_problem_samples_idx)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"len"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(toy_problem_samples_idx)"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"40\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"40\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This length makes sense since we have 2 characters with 20 samples each."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Now we need to explicitly tell the dataloader to take among these samples. The problem is that the Omniglot dataset from torchvision cannot be split as far as we know. Instead, we may make use of the torch's "},{"type":"element","tag":"a","props":{"href":"https://pytorch.org/docs/stable/data.html#torch.utils.data.SubsetRandomSampler","rel":["nofollow"]},"children":[{"type":"text","value":"SubsetRandomSampler object"}]},{"type":"text","value":", which explicitly tells which samples to randomly take. Furthermore, we want these samples to be taken by batches, so we will also wrap it into a "},{"type":"element","tag":"a","props":{"href":"https://pytorch.org/docs/stable/data.html#torch.utils.data.BatchSampler","rel":["nofollow"]},"children":[{"type":"text","value":"BatchSampler"}]},{"type":"text","value":"."}]},{"type":"element","tag":"pre","props":{"code":"indexer = BatchSampler(SubsetRandomSampler(toy_problem_samples_idx), batch_size=8, drop_last=True)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"indexer "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" BatchSampler(SubsetRandomSampler(toy_problem_samples_idx), "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"drop_last"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"True"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So now we may directly create a DataLoader with the raw Omniglot dataset using this sampler object that will directly serve us random batches of samples of the characters of our problems, as we want. We will use "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"shuffle=False"}]},{"type":"text","value":" since the sampler already shuffles the samples."}]},{"type":"element","tag":"pre","props":{"code":"problem_loader = DataLoader(dataset=omniglot_raw, shuffle=False, batch_sampler=indexer)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"problem_loader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" DataLoader("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"dataset"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"omniglot_raw, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"shuffle"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"False"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_sampler"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"indexer)"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Now let's review both samples and labels from the Data Loader. We want to verify that samples are what we expect (shape of "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"batch_size x num_channels x width x height"}]},{"type":"text","value":", i.e. 8 x 1 x 105 x 105), that images correspond to "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"J"}]},{"type":"text","value":"'s and "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"K"}]},{"type":"text","value":"'s and that labels are randomly shuffled."}]},{"type":"element","tag":"pre","props":{"code":"for ibatch, batch in enumerate(problem_loader):\n  print('batch ' + str(ibatch))\n  print(len(batch))\n  print(batch[0].shape)\n  print(batch[1])\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ibatch, batch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(problem_loader):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'batch '"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"str"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(ibatch))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"len"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(batch))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(batch["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"].shape)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(batch["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"batch 0\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 683, 683, 682, 682, 683, 682, 682])\nbatch 1\n2\ntorch.Size([8, 1, 105, 105])\ntensor([683, 682, 683, 683, 682, 683, 683, 683])\nbatch 2\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 682, 683, 682, 682, 682, 683, 683])\nbatch 3\n2\ntorch.Size([8, 1, 105, 105])\ntensor([683, 683, 683, 682, 683, 683, 682, 682])\nbatch 4\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 683, 683, 682, 683, 682, 682, 682])\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"batch 0\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 683, 683, 682, 682, 683, 682, 682])\nbatch 1\n2\ntorch.Size([8, 1, 105, 105])\ntensor([683, 682, 683, 683, 682, 683, 683, 683])\nbatch 2\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 682, 683, 682, 682, 682, 683, 683])\nbatch 3\n2\ntorch.Size([8, 1, 105, 105])\ntensor([683, 683, 683, 682, 683, 683, 682, 682])\nbatch 4\n2\ntorch.Size([8, 1, 105, 105])\ntensor([682, 683, 683, 682, 683, 682, 682, 682])\n"}]}]},{"type":"element","tag":"pre","props":{"code":"plt.figure(figsize=(15,15))\ncolumns = 8\nfor ibatch, batch in enumerate(problem_loader):\n  for isample, sample in enumerate(batch[0]):\n    plt.subplot(5, 8, (ibatch * 8) + isample + 1)\n    plt.imshow(sample[0].numpy())\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"plt.figure("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"figsize"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":","}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"columns "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ibatch, batch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(problem_loader):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" isample, sample "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(batch["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    plt.subplot("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"5"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", (ibatch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" isample "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    plt.imshow(sample["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"].numpy())"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"problem","src":"https://i.imgur.com/hTD81J1.png"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So as we see, everything matches our needs."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Now that we defined a DataLoader for the problem, we are ready to create the Meta-Loaders."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"A Meta-Loader object should, at each step, be able to return a batch of problem DataLoaders. As we saw before, these DataLoaders should return at least the indices of the samples to use at each batch, and then at training/validation/test time the indices will point to the data to load from the Omniglot raw dataset. We could also work with DataLoaders that directly deliver the data, but since we would be creating lots of dataloaders with raw data, the memory cost could be too high. That is the main reason why we will work with indices instead."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So, what should the MetaLoader class contain? To make it simple, we will just need its initialization and an "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"iter"}]},{"type":"text","value":" method that will be returning us the problem loaders at each meta-batch. The rest should be internal methods. And how should these mandatory methods work?"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Well, when initializing a MetaLoader it will load the necessary info at both Meta-level and Learning level, as well as it will initialize a sampler as we saw before at the DataLoader but now for the Meta-Level, which will be run at "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_"},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"iter"}]},{"type":"text","value":"_"}]},{"type":"text","value":". This sampler will just sample from the problem indices (so one of the variables at the Meta-level must be the number of problems in the meta-set, that can be computed as explained before) for the same reason as before, memory optimization."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Then at "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_"},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"iter"}]},{"type":"text","value":"_"}]},{"type":"text","value":" time the sampler will return a batch of problem indices. From each of these indices we will make a method ("},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_"},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"get_problem_loader"}]},{"type":"text","value":"_"}]},{"type":"text","value":" method) to get the corresponding problem loader, which will begin searching the alphabet and the characters in the alphabet for each problem index and then the samples index in this problem("},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_"},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"problem_idx_to_samples_idx"}]},{"type":"text","value":"_"}]},{"type":"text","value":" method), for further problem loader building ("},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_"},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"build_problem_loader_from_samples"}]},{"type":"text","value":"_"}]},{"type":"text","value":" method, which will return the three loaders of the problem for train, validation and test)."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Thus, when iterating the MetaLoader object, we will at each meta-batch receive a list of (meta-batch size) dictionaries with keys train, validation and test where for each key the corresponding set DataLoader of the problem will be contained."}]},{"type":"element","tag":"pre","props":{"code":"class MetaLoader():\n    \"\"\"\n    \"\"\"\n    def __init__(self, base_dataset, metabatch_size, batch_sizes, \n                 chars_per_alphabet, problem_ratios):\n        self.base_dataset = base_dataset\n        self.metabatch_size = metabatch_size\n        self.batch_sizes = batch_sizes\n        self.chars_per_alph = chars_per_alphabet\n        self.problem_ratios = [0.75, 0.15, 0.1]\n        self.problems_per_alph = {}\n        self.num_problems = 0\n        self.__load_quantitative_info__()\n        self.metasampler = BatchSampler(RandomSampler(range(self.num_problems)), \n                                        batch_size=self.metabatch_size, \n                                        drop_last=True)\n    \n    def __load_quantitative_info__(self):\n        for alphb in self.chars_per_alph:\n            self.problems_per_alph[alphb] = int((self.chars_per_alph[alphb]**2 - \n                                                self.chars_per_alph[alphb]) / 2)\n            self.num_problems += self.problems_per_alph[alphb]\n    \n    def __has_reached__(self, idx, ctr, current):\n        return ctr + current > idx\n    \n    def __problem_idx_to_samples_idx__(self, problem_idx, alphb, \n                                       prbs_on_prev_alphabets, \n                                       chars_on_prev_alphabets):\n        pb_idx_in_alph = problem_idx - prbs_on_prev_alphabets\n        ichars_in_alphabet = (int(pb_idx_in_alph / self.chars_per_alph[alphb]), \n                                pb_idx_in_alph % self.chars_per_alph[alphb])\n        ichars = tuple([ich + chars_on_prev_alphabets \\\n                        for ich in ichars_in_alphabet])\n        return [sample_idx for charidx in ichars \n                for sample_idx in range(charidx * 20, (charidx + 1) * 20)]\n    \n    def __build_problem_loader_from_samples__(self, samples_idx):\n\n        random.shuffle(samples_idx)\n\n        train_val_frontier = int(len(samples_idx) * self.problem_ratios[0])\n        val_test_frontier = int(train_val_frontier + \n                                len(samples_idx) * self.problem_ratios[1])\n        \n        samples_idx_train = samples_idx[:train_val_frontier]\n        samples_idx_val = samples_idx[train_val_frontier:val_test_frontier]\n        samples_idx_test = samples_idx[val_test_frontier:]\n\n        train_sampler = BatchSampler(SubsetRandomSampler(samples_idx_train), \n                                     batch_size=self.batch_sizes['train'], \n                                     drop_last=True)\n        val_sampler = BatchSampler(SubsetRandomSampler(samples_idx_val), \n                                   batch_size=self.batch_sizes['val'], \n                                   drop_last=True)\n        test_sampler = BatchSampler(SubsetRandomSampler(samples_idx_test), \n                                    batch_size=self.batch_sizes['test'], \n                                    drop_last=True)\n        loaders = {'train': DataLoader(dataset=self.base_dataset, \n                                       batch_sampler=train_sampler),\n                   'val': DataLoader(dataset=self.base_dataset, \n                                       batch_sampler=val_sampler),\n                   'test': DataLoader(dataset=self.base_dataset, \n                                       batch_sampler=test_sampler)}\n        return loaders\n\n        \n    def __get_problem_loader__(self, problem_idx):\n        pbs_ctr = 0\n        chars_ctr = 0\n        for alphb in self.chars_per_alph:\n            if not self.__has_reached__(problem_idx, pbs_ctr, \n                                        self.problems_per_alph[alphb]):\n                pbs_ctr += self.problems_per_alph[alphb]\n                chars_ctr += self.chars_per_alph[alphb]\n            else:\n                problem_samples_idx = self.__problem_idx_to_samples_idx__(\n                    problem_idx, alphb, pbs_ctr, chars_ctr)\n                return self.__build_problem_loader_from_samples__(\n                    problem_samples_idx)\n\n    def  __iter__(self):\n        for imetabatch, metabatch in enumerate(self.metasampler):\n            problem_loaders = []\n            for problem_idx in metabatch:\n                problem_loaders.append(self.__get_problem_loader__(problem_idx))\n            yield problem_loaders\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"class"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"MetaLoader"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"():\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"\"\"\"\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"    \"\"\"\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"__init__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self, base_dataset, metabatch_size, batch_sizes, \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                 chars_per_alphabet, problem_ratios):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".base_dataset "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" base_dataset\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".metabatch_size "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metabatch_size\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":8},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".batch_sizes "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" batch_sizes\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":9},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".chars_per_alph "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" chars_per_alphabet\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":10},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".problem_ratios "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.75"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":11},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".problems_per_alph "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" {}\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":12},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".num_problems "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":13},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".__load_quantitative_info__()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":14},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".metasampler "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" BatchSampler(RandomSampler("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".num_problems)), \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":15},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                        "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".metabatch_size, \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":16},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                        "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"drop_last"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"True"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":17},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":18},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"__load_quantitative_info__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":19},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" alphb "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".chars_per_alph:\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":20},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".problems_per_alph[alphb] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"int"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".chars_per_alph[alphb]"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"**"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":21},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                                "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".chars_per_alph[alphb]) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":22},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".num_problems "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".problems_per_alph[alphb]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":23},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":24},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"__has_reached__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self, idx, ctr, current):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":25},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"return"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ctr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" current "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":">"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" idx\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":26},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":27},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"__problem_idx_to_samples_idx__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self, problem_idx, alphb, \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":28},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                       prbs_on_prev_alphabets, \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":29},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                       chars_on_prev_alphabets):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":30},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        pb_idx_in_alph "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" problem_idx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" prbs_on_prev_alphabets\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":31},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        ichars_in_alphabet "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"int"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(pb_idx_in_alph "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".chars_per_alph[alphb]), \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":32},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                pb_idx_in_alph "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"%"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".chars_per_alph[alphb])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":33},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        ichars "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"tuple"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"([ich "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" chars_on_prev_alphabets \\\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":34},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ich "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ichars_in_alphabet])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":35},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"return"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" [sample_idx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" charidx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ichars \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":36},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" sample_idx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(charidx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"20"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", (charidx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"20"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":37},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":38},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"__build_problem_loader_from_samples__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self, samples_idx):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":39},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":40},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        random.shuffle(samples_idx)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":41},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":42},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        train_val_frontier "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"int"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"len"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(samples_idx) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".problem_ratios["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":43},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        val_test_frontier "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"int"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(train_val_frontier "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":44},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"len"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(samples_idx) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".problem_ratios["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":45},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":46},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        samples_idx_train "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" samples_idx[:train_val_frontier]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":47},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        samples_idx_val "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" samples_idx[train_val_frontier:val_test_frontier]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":48},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        samples_idx_test "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" samples_idx[val_test_frontier:]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":49},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":50},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        train_sampler "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" BatchSampler(SubsetRandomSampler(samples_idx_train), \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":51},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                     "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".batch_sizes["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":52},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                     "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"drop_last"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"True"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":53},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        val_sampler "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" BatchSampler(SubsetRandomSampler(samples_idx_val), \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":54},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                   "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".batch_sizes["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":55},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                   "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"drop_last"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"True"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":56},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        test_sampler "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" BatchSampler(SubsetRandomSampler(samples_idx_test), \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":57},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                    "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".batch_sizes["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'test'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":58},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                    "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"drop_last"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"True"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":59},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        loaders "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" {"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": DataLoader("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"dataset"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".base_dataset, \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":60},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                       "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_sampler"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"train_sampler),\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":61},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                   "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": DataLoader("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"dataset"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".base_dataset, \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":62},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                       "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_sampler"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_sampler),\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":63},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                   "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'test'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": DataLoader("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"dataset"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".base_dataset, \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":64},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                       "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_sampler"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"test_sampler)}\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":65},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"return"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" loaders\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":66},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":67},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":68},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"__get_problem_loader__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self, problem_idx):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":69},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        pbs_ctr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":70},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        chars_ctr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":71},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" alphb "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".chars_per_alph:\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":72},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"not"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".__has_reached__(problem_idx, pbs_ctr, \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":73},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".problems_per_alph[alphb]):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":74},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                pbs_ctr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".problems_per_alph[alphb]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":75},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                chars_ctr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".chars_per_alph[alphb]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":76},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"else"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":77},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                problem_samples_idx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".__problem_idx_to_samples_idx__(\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":78},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    problem_idx, alphb, pbs_ctr, chars_ctr)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":79},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"return"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".__build_problem_loader_from_samples__(\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":80},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    problem_samples_idx)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":81},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":82},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"__iter__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":83},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" imetabatch, metabatch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".metasampler):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":84},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            problem_loaders "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" []\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":85},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" problem_idx "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metabatch:\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":86},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                problem_loaders.append("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".__get_problem_loader__(problem_idx))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":87},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"yield"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" problem_loaders"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We will reimplement the "},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"_"},{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"chars_per_alphabet"}]},{"type":"text","value":"_"}]},{"type":"text","value":" variable by splitting it between the 3 Meta-sets."}]},{"type":"element","tag":"pre","props":{"code":"chars_per_alphabet = {split: {alph: [char.split('/')[0] for char in characters].count(alph) for alph in metasplits[split].alphabets} for split in metasplits}\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"chars_per_alphabet "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" {split: {alph: [char.split("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'/'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" char "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" characters].count(alph) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" alph "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metasplits[split].alphabets} "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" split "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metasplits}"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"And we will finally initialize a MetaLoader object. We will emulate a Metatrain loader."}]},{"type":"element","tag":"pre","props":{"code":"metaloader = MetaLoader(base_dataset=omniglot_raw, metabatch_size=metabatch_size, batch_sizes={'train': 8, 'val': 1, 'test': 1}, chars_per_alphabet=chars_per_alphabet['metatrain'], problem_ratios = [0.75, 0.15, 0.1])\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metaloader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" MetaLoader("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"base_dataset"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"omniglot_raw, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"metabatch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metabatch_size, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_sizes"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'test'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"}, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"chars_per_alphabet"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"chars_per_alphabet["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatrain'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"problem_ratios"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.75"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Now let's explore the content of a Meta-batch."}]},{"type":"element","tag":"pre","props":{"code":"metabatch = next(iter(metaloader))\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metabatch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"next"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"iter"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(metaloader))"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"metabatch[0]\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metabatch["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"{'train': <torch.utils.data.dataloader.DataLoader at 0x7f1fc92d3fa0>,\n 'val': <torch.utils.data.dataloader.DataLoader at 0x7f1fc92d3850>,\n 'test': <torch.utils.data.dataloader.DataLoader at 0x7f1fc92d3a90>}\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"{'train': <torch.utils.data.dataloader.DataLoader at 0x7f1fc92d3fa0>,\n 'val': <torch.utils.data.dataloader.DataLoader at 0x7f1fc92d3850>,\n 'test': <torch.utils.data.dataloader.DataLoader at 0x7f1fc92d3a90>}\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"As expected, we successfully got a series of dataloaders for each set at each problem. Now let's check the content of the samples in the problems of the metabatch. This means that we want to plot all the (shuffled) samples of each problem, so we should plot a collection of 8 grids where each grids contains a list of images among 2 samples."}]},{"type":"element","tag":"pre","props":{"code":"plt.figure(figsize=(15,100))\ncolumns = 8\nfor imb in range(8):\n    for ibatch, batch in enumerate(metabatch[imb]['train']):\n        for isample, sample in enumerate(batch[0]):\n            plt.subplot(40, 8, (imb * 40) + (ibatch * 8) + isample + 1)\n            plt.imshow(sample[0].numpy())\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"plt.figure("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"figsize"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":","}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"100"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"columns "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" imb "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ibatch, batch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(metabatch[imb]["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" isample, sample "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(batch["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            plt.subplot("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"40"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", (imb "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"40"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (ibatch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" isample "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            plt.imshow(sample["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"].numpy())"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"metabatch","src":"https://i.imgur.com/p79tpSr.png"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So we again got what we expected. Thus, we will finally define our MetaLoaders."}]},{"type":"element","tag":"pre","props":{"code":"metatrain_loader = MetaLoader(base_dataset=omniglot_raw, metabatch_size=metabatch_size, batch_sizes={'train': 8, 'val': 1, 'test': 1}, chars_per_alphabet=chars_per_alphabet['metatrain'], problem_ratios = [0.75, 0.15, 0.1])\nmetaval_loader = MetaLoader(base_dataset=omniglot_raw, metabatch_size=metabatch_size, batch_sizes={'train': 8, 'val': 1, 'test': 1}, chars_per_alphabet=chars_per_alphabet['metaval'], problem_ratios = [0.75, 0.15, 0.1])\nmetatest_loader = MetaLoader(base_dataset=omniglot_raw, metabatch_size=1, batch_sizes={'train': 8, 'val': 1, 'test': 1}, chars_per_alphabet=chars_per_alphabet['metatest'], problem_ratios = [0.75, 0.15, 0.1])\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metatrain_loader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" MetaLoader("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"base_dataset"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"omniglot_raw, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"metabatch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metabatch_size, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_sizes"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'test'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"}, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"chars_per_alphabet"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"chars_per_alphabet["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatrain'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"problem_ratios"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.75"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metaval_loader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" MetaLoader("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"base_dataset"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"omniglot_raw, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"metabatch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metabatch_size, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_sizes"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'test'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"}, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"chars_per_alphabet"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"chars_per_alphabet["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metaval'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"problem_ratios"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.75"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metatest_loader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" MetaLoader("}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"base_dataset"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"omniglot_raw, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"metabatch_size"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"batch_sizes"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'test'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":": "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"}, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"chars_per_alphabet"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"chars_per_alphabet["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'metatest'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"problem_ratios"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.75"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.15"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])"}]}]}]}]},{"type":"element","tag":"h3","props":{"id":"training-a-model-in-a-problem"},"children":[{"type":"text","value":"Training a model in a problem"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So at this point we are ready to use a single problem extracted from the train MetaLoader and train a model on it. First, we should get our DataLoaders"}]},{"type":"element","tag":"pre","props":{"code":"toy_metabatch = next(iter(metatrain_loader))\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_metabatch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"next"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"iter"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(metatrain_loader))"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"toy_problem_loader = toy_metabatch[0]['train']\ntoy_problem_loader_val = toy_metabatch[0]['val']\ntoy_problem_loader_test = toy_metabatch[0]['test']\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_problem_loader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" toy_metabatch["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_problem_loader_val "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" toy_metabatch["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"toy_problem_loader_test "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" toy_metabatch["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'test'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"for i, data in enumerate(toy_problem_loader, 0):\n    for isample, sample in enumerate(data[0]):\n        plt.subplot(3, 8, (i * 8) + isample + 1)\n        plt.imshow(sample[0].numpy())\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" i, data "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(toy_problem_loader, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" isample, sample "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(data["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        plt.subplot("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"3"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", (i "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"8"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" isample "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        plt.imshow(sample["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"].numpy())"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"toyproblem","src":"https://i.imgur.com/CkA6Zs9.png"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Now we will define a Simple Neural network (it should be enough for the simple 105x105 character classification problems)."}]},{"type":"element","tag":"pre","props":{"code":"class SimpleNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 10, 5)\n        self.conv3 = nn.Conv2d(10, 12, 5)\n        self.conv4 = nn.Conv2d(12, 16, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(16 * 2 * 2, 10)\n        self.fc2 = nn.Linear(10, 1)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.sigmoid(self.fc2(x))\n        x = x.squeeze()\n        return x\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"class"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"SimpleNet"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"nn"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"."}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"Module"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"__init__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"super"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"()."}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"__init__"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".conv1 "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.Conv2d("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"6"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"5"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".conv2 "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.Conv2d("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"6"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"10"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"5"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".conv3 "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.Conv2d("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"10"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"12"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"5"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".conv4 "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.Conv2d("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"12"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"16"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"5"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":8},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".pool "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.MaxPool2d("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":9},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".fc1 "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.Linear("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"16"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"10"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":10},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".fc2 "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.Linear("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"10"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":11},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":12},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"forward"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(self, x):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":13},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        x "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".pool(F.relu("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".conv1(x)))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":14},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        x "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".pool(F.relu("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".conv2(x)))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":15},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        x "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".pool(F.relu("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".conv3(x)))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":16},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        x "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".pool(F.relu("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".conv4(x)))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":17},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        x "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch.flatten(x, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":18},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        x "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" F.relu("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".fc1(x))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":19},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        x "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" F.sigmoid("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"self"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":".fc2(x))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":20},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        x "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" x.squeeze()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":21},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"return"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" x"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Now we will define also our Loss function as well as our optimizer (we will use SGD for simplicity). We will train 15 epochs in the problem and run a validation step at the end of an epoch."}]},{"type":"element","tag":"pre","props":{"code":"model = SimpleNet()\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"model "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" SimpleNet()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"criterion "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.BCEWithLogitsLoss()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"optimizer "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" optim.SGD(model.parameters(), "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"lr"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.01"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"momentum"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.9"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"n_epochs = 15\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"n_epochs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"15"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We will need the following methods to process both labels and samples (for the labels we just one to convert both labels into 0 and 1 respectively)."}]},{"type":"element","tag":"pre","props":{"code":"def process_labels(labels_raw, ref_label):\n  return (labels_raw == ref_label).float()\n\ndef preprocess_inputs(inputs):\n    return (1- inputs) * 255\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"process_labels"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(labels_raw, ref_label):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"return"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (labels_raw "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ref_label).float()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"preprocess_inputs"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(inputs):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"return"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" inputs) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"255"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So we are ready to implement and run what we defined."}]},{"type":"element","tag":"pre","props":{"code":"ref_label = None\nfor epoch in range(n_epochs):\n    print(f'Epoch {epoch + 1}')\n    running_loss = 0.0\n    val_loss = 0.0\n    val_accuracy = 0.0\n    for i, data in enumerate(toy_problem_loader, 0):\n        inputs_raw, labels_raw = data\n        optimizer.zero_grad()\n        inputs = preprocess_inputs(inputs_raw)\n        outputs = model(inputs)\n        if ref_label is None:\n            ref_label = labels_raw[0]\n        labels = process_labels(labels_raw, ref_label)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        accuracy = (((1 - outputs) < outputs).float() == labels).sum() / outputs.shape[0]\n        print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n    for iv, datav in enumerate(toy_problem_loader_val):\n        inputs_rawv, labels_rawv = datav\n        inputsv = preprocess_inputs(inputs_rawv)\n        outputsv = model(inputsv)\n        labelsv = process_labels(labels_rawv, ref_label)\n        lossv = criterion(outputsv, labelsv[0])\n        val_loss += lossv.item()\n        val_accuracy += (((1 - outputsv) < outputsv).float() == labelsv).sum()\n    print(f'Epoch {epoch + 1}, VALIDATION], Loss: {val_loss / (iv + 1)}, Accuracy: {val_accuracy / (iv + 1)}')\n\nprint('Finished Training')\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(n_epochs):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    running_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" i, data "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(toy_problem_loader, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":8},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        inputs_raw, labels_raw "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" data\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":9},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        optimizer.zero_grad()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":10},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        inputs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" preprocess_inputs(inputs_raw)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":11},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        outputs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model(inputs)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":12},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"is"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":13},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labels_raw["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":14},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        labels "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" process_labels(labels_raw, ref_label)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":15},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" criterion(outputs, labels)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":16},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        loss.backward()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":17},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        optimizer.step()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":18},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        running_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" loss.item()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":19},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ((("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs).float() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labels).sum() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs.shape["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":20},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", step "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"i "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":":5d"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"], Loss: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"loss.item()"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", Accuracy: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"accuracy"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":21},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" iv, datav "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(toy_problem_loader_val):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":22},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        inputs_rawv, labels_rawv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" datav\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":23},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        inputsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" preprocess_inputs(inputs_rawv)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":24},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        outputsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model(inputsv)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":25},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        labelsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" process_labels(labels_rawv, ref_label)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":26},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        lossv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" criterion(outputsv, labelsv["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":27},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" lossv.item()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":28},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ((("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputsv) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputsv).float() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labelsv).sum()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":29},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", VALIDATION], Loss: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (iv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", Accuracy: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (iv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":30},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":31},"children":[{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Finished Training'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"Epoch 1\n\n\n/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n\n\nEpoch 1, step     1], Loss: 0.6658390164375305, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6492561101913452, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.8146457672119141, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6260940631230673, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.60048508644104, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.5681989789009094, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6169461607933044, Accuracy: 0.875\nEpoch 2, VALIDATION], Loss: 0.5620179573694865, Accuracy: 1.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6216239333152771, Accuracy: 1.0\nEpoch 3, step     2], Loss: 0.5817804336547852, Accuracy: 1.0\nEpoch 3, step     3], Loss: 0.507636308670044, Accuracy: 1.0\nEpoch 3, VALIDATION], Loss: 0.5611441731452942, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.5516251921653748, Accuracy: 1.0\nEpoch 4, step     2], Loss: 0.5512588024139404, Accuracy: 1.0\nEpoch 4, step     3], Loss: 0.4609960913658142, Accuracy: 1.0\nEpoch 4, VALIDATION], Loss: 0.593102385600408, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.4159203767776489, Accuracy: 1.0\nEpoch 5, step     2], Loss: 0.6008561849594116, Accuracy: 1.0\nEpoch 5, step     3], Loss: 0.5070333480834961, Accuracy: 1.0\nEpoch 5, VALIDATION], Loss: 0.5653840551773707, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.5032209753990173, Accuracy: 1.0\nEpoch 6, step     2], Loss: 0.5032068490982056, Accuracy: 1.0\nEpoch 6, step     3], Loss: 0.4557313323020935, Accuracy: 1.0\nEpoch 6, VALIDATION], Loss: 0.6277975539366404, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.645679771900177, Accuracy: 1.0\nEpoch 7, step     2], Loss: 0.45026305317878723, Accuracy: 0.875\nEpoch 7, step     3], Loss: 0.5558935403823853, Accuracy: 0.875\nEpoch 7, VALIDATION], Loss: 0.6248213152090708, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.4557203948497772, Accuracy: 1.0\nEpoch 8, step     2], Loss: 0.5506904125213623, Accuracy: 1.0\nEpoch 8, step     3], Loss: 0.45581647753715515, Accuracy: 1.0\nEpoch 8, VALIDATION], Loss: 0.562673901518186, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.5032058358192444, Accuracy: 1.0\nEpoch 9, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 9, step     3], Loss: 0.5506901144981384, Accuracy: 1.0\nEpoch 9, VALIDATION], Loss: 0.5044418474038442, Accuracy: 1.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.4557187557220459, Accuracy: 1.0\nEpoch 10, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 10, step     3], Loss: 0.5981758236885071, Accuracy: 1.0\nEpoch 10, VALIDATION], Loss: 0.5032213479280472, Accuracy: 1.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.4557187557220459, Accuracy: 1.0\nEpoch 11, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 11, step     3], Loss: 0.5506902933120728, Accuracy: 1.0\nEpoch 11, VALIDATION], Loss: 0.5032058407862982, Accuracy: 1.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.5506907105445862, Accuracy: 1.0\nEpoch 12, step     2], Loss: 0.5032053589820862, Accuracy: 1.0\nEpoch 12, step     3], Loss: 0.5032044053077698, Accuracy: 1.0\nEpoch 12, VALIDATION], Loss: 0.5032146573066711, Accuracy: 1.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.5506961941719055, Accuracy: 1.0\nEpoch 13, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 13, step     3], Loss: 0.5507189035415649, Accuracy: 1.0\nEpoch 13, VALIDATION], Loss: 0.5032911549011866, Accuracy: 1.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.5508079528808594, Accuracy: 1.0\nEpoch 14, step     2], Loss: 0.5032503604888916, Accuracy: 1.0\nEpoch 14, step     3], Loss: 0.455719918012619, Accuracy: 1.0\nEpoch 14, VALIDATION], Loss: 0.5034261147181193, Accuracy: 1.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.5033642053604126, Accuracy: 1.0\nEpoch 15, step     2], Loss: 0.4083341956138611, Accuracy: 1.0\nEpoch 15, step     3], Loss: 0.550751805305481, Accuracy: 1.0\nEpoch 15, VALIDATION], Loss: 0.5033487677574158, Accuracy: 1.0\nFinished Training\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"Epoch 1\n\n\n/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n\n\nEpoch 1, step     1], Loss: 0.6658390164375305, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6492561101913452, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.8146457672119141, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6260940631230673, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.60048508644104, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.5681989789009094, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6169461607933044, Accuracy: 0.875\nEpoch 2, VALIDATION], Loss: 0.5620179573694865, Accuracy: 1.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6216239333152771, Accuracy: 1.0\nEpoch 3, step     2], Loss: 0.5817804336547852, Accuracy: 1.0\nEpoch 3, step     3], Loss: 0.507636308670044, Accuracy: 1.0\nEpoch 3, VALIDATION], Loss: 0.5611441731452942, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.5516251921653748, Accuracy: 1.0\nEpoch 4, step     2], Loss: 0.5512588024139404, Accuracy: 1.0\nEpoch 4, step     3], Loss: 0.4609960913658142, Accuracy: 1.0\nEpoch 4, VALIDATION], Loss: 0.593102385600408, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.4159203767776489, Accuracy: 1.0\nEpoch 5, step     2], Loss: 0.6008561849594116, Accuracy: 1.0\nEpoch 5, step     3], Loss: 0.5070333480834961, Accuracy: 1.0\nEpoch 5, VALIDATION], Loss: 0.5653840551773707, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.5032209753990173, Accuracy: 1.0\nEpoch 6, step     2], Loss: 0.5032068490982056, Accuracy: 1.0\nEpoch 6, step     3], Loss: 0.4557313323020935, Accuracy: 1.0\nEpoch 6, VALIDATION], Loss: 0.6277975539366404, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.645679771900177, Accuracy: 1.0\nEpoch 7, step     2], Loss: 0.45026305317878723, Accuracy: 0.875\nEpoch 7, step     3], Loss: 0.5558935403823853, Accuracy: 0.875\nEpoch 7, VALIDATION], Loss: 0.6248213152090708, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.4557203948497772, Accuracy: 1.0\nEpoch 8, step     2], Loss: 0.5506904125213623, Accuracy: 1.0\nEpoch 8, step     3], Loss: 0.45581647753715515, Accuracy: 1.0\nEpoch 8, VALIDATION], Loss: 0.562673901518186, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.5032058358192444, Accuracy: 1.0\nEpoch 9, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 9, step     3], Loss: 0.5506901144981384, Accuracy: 1.0\nEpoch 9, VALIDATION], Loss: 0.5044418474038442, Accuracy: 1.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.4557187557220459, Accuracy: 1.0\nEpoch 10, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 10, step     3], Loss: 0.5981758236885071, Accuracy: 1.0\nEpoch 10, VALIDATION], Loss: 0.5032213479280472, Accuracy: 1.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.4557187557220459, Accuracy: 1.0\nEpoch 11, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 11, step     3], Loss: 0.5506902933120728, Accuracy: 1.0\nEpoch 11, VALIDATION], Loss: 0.5032058407862982, Accuracy: 1.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.5506907105445862, Accuracy: 1.0\nEpoch 12, step     2], Loss: 0.5032053589820862, Accuracy: 1.0\nEpoch 12, step     3], Loss: 0.5032044053077698, Accuracy: 1.0\nEpoch 12, VALIDATION], Loss: 0.5032146573066711, Accuracy: 1.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.5506961941719055, Accuracy: 1.0\nEpoch 13, step     2], Loss: 0.5032044649124146, Accuracy: 1.0\nEpoch 13, step     3], Loss: 0.5507189035415649, Accuracy: 1.0\nEpoch 13, VALIDATION], Loss: 0.5032911549011866, Accuracy: 1.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.5508079528808594, Accuracy: 1.0\nEpoch 14, step     2], Loss: 0.5032503604888916, Accuracy: 1.0\nEpoch 14, step     3], Loss: 0.455719918012619, Accuracy: 1.0\nEpoch 14, VALIDATION], Loss: 0.5034261147181193, Accuracy: 1.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.5033642053604126, Accuracy: 1.0\nEpoch 15, step     2], Loss: 0.4083341956138611, Accuracy: 1.0\nEpoch 15, step     3], Loss: 0.550751805305481, Accuracy: 1.0\nEpoch 15, VALIDATION], Loss: 0.5033487677574158, Accuracy: 1.0\nFinished Training\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"As we can see, the model easily learns and in my case it reached an almost perfect accuracy. But things will get messy."}]},{"type":"element","tag":"h3","props":{"id":"train-with-manual-gd-algorithm"},"children":[{"type":"text","value":"Train with manual GD algorithm"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Before concluding I am a maniac by trying this for no reason, let's take a look at "},{"type":"element","tag":"a","props":{"href":"https://github.com/cbfinn/maml","rel":["nofollow"]},"children":[{"type":"text","value":"MAML official implementation on Github"}]},{"type":"text","value":". In the "},{"type":"element","tag":"a","props":{"href":"https://github.com/cbfinn/maml/blob/master/maml.py#L79","rel":["nofollow"]},"children":[{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"maml.py"}]}]},{"type":"text","value":" module you can realize that at Learning level, authors also update manually the weights at each step. The same goes for "},{"type":"element","tag":"a","props":{"href":"https://github.com/dragen1860/MAML-Pytorch","rel":["nofollow"]},"children":[{"type":"text","value":"unofficial Pytorch implementations"}]},{"type":"text","value":". Why is this? Well, if you think, in Meta-Learning, the model must learn at 2 levels. I.e. gradients, losses, optimizers, etc must work at 2 levels at the same time, which ML frameworks are not made for. Updating the weights manually in one of both levels is actually a workaround to this issue, so from Pytorch perspective there is no Learning level, and it just knows the updates at Meta-Learning level."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So, before going for the Meta-Learning level we will manually train the same as before but now with manual updates. Note that updating model's parameters is done through the code chunk:"}]},{"type":"element","tag":"pre","props":{"code":"for param, param_key in zip(new_weights, param_keys):\n            model._modules[param_key[0]]._parameters[param_key[1]] = param\n\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"for param, param_key in zip(new_weights, param_keys):\n            model._modules[param_key[0]]._parameters[param_key[1]] = param\n\n"}]}]},{"type":"element","tag":"pre","props":{"code":"model = SimpleNet()\ncriterion = nn.BCEWithLogitsLoss()\nupdate_lr = 0.01\n\nref_label = None\nparam_keys = [(mod, kname) for mod in model._modules for kname in model._modules[mod]._parameters]\nnew_weights = model.parameters()\nfor epoch in range(n_epochs):\n    print(f'Epoch {epoch + 1}')\n    running_loss = 0.0\n    val_loss = 0.0\n    val_accuracy = 0.0\n    for i, data in enumerate(toy_problem_loader, 0):\n        inputs_raw, labels_raw = data\n        inputs = preprocess_inputs(inputs_raw)\n        outputs = model(inputs)\n        if ref_label is None:\n            ref_label = labels_raw[0]\n        labels = process_labels(labels_raw, ref_label)\n        loss = criterion(outputs, labels)\n        grads = torch.autograd.grad(loss, model.parameters())\n        new_weights = list(map(lambda p: p[1] - update_lr * p[0], zip(grads, new_weights)))\n        running_loss += loss.item()\n        accuracy = (((1 - outputs) < outputs).float() == labels).sum() / outputs.shape[0]\n        for param, param_key in zip(new_weights, param_keys):\n            model._modules[param_key[0]]._parameters[param_key[1]] = param\n        print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n    for iv, datav in enumerate(toy_problem_loader_val):\n        inputs_rawv, labels_rawv = datav\n        inputsv = preprocess_inputs(inputs_rawv)\n        outputsv = model(inputsv)\n        labelsv = process_labels(labels_rawv, ref_label)\n        lossv = criterion(outputsv, labelsv[0])\n        val_loss += lossv.item()\n        val_accuracy += (((1 - outputsv) < outputsv).float() == labelsv).sum()\n    print(f'Epoch {epoch + 1}, VALIDATION], Loss: {val_loss / (iv + 1)}, Accuracy: {val_accuracy / (iv + 1)}')\n\nprint('Finished Training')\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"model "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" SimpleNet()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"criterion "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.BCEWithLogitsLoss()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"update_lr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.01\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"param_keys "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" [(mod, kname) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" mod "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model._modules "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" kname "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model._modules[mod]._parameters]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"new_weights "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model.parameters()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":8},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(n_epochs):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":9},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":10},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    running_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":11},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":12},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":13},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" i, data "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(toy_problem_loader, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":14},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        inputs_raw, labels_raw "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" data\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":15},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        inputs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" preprocess_inputs(inputs_raw)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":16},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        outputs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model(inputs)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":17},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"is"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":18},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labels_raw["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":19},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        labels "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" process_labels(labels_raw, ref_label)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":20},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" criterion(outputs, labels)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":21},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        grads "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch.autograd.grad(loss, model.parameters())\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":22},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        new_weights "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"list"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"map"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"lambda"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" p: p["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" update_lr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" p["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"zip"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(grads, new_weights)))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":23},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        running_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" loss.item()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":24},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ((("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs).float() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labels).sum() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs.shape["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":25},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" param, param_key "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"zip"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(new_weights, param_keys):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":26},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            model._modules[param_key["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]]._parameters[param_key["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" param\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":27},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", step "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"i "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":":5d"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"], Loss: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"loss.item()"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", Accuracy: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"accuracy"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":28},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" iv, datav "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(toy_problem_loader_val):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":29},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        inputs_rawv, labels_rawv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" datav\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":30},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        inputsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" preprocess_inputs(inputs_rawv)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":31},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        outputsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model(inputsv)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":32},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        labelsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" process_labels(labels_rawv, ref_label)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":33},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        lossv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" criterion(outputsv, labelsv["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":34},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" lossv.item()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":35},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ((("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputsv) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputsv).float() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labelsv).sum()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":36},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", VALIDATION], Loss: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (iv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", Accuracy: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (iv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":37},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":38},"children":[{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Finished Training'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"So training is also completed correctly this way."}]},{"type":"element","tag":"h3","props":{"id":"meta-learning-training"},"children":[{"type":"text","value":"Meta-Learning training"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"At this point we will directly define the Meta-Learning pipeline as follows:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"At each Meta-epoch, the Meta-train MetaLoader is called at each Meta-train meta-step."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"At each Meta-train meta-step, at each problem is the meta-batch is asked for its DataLoaders"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"For the train DataLoader, at each epoch each step is called and the batch is predicted."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Manually, at this step the model weights are updated"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"At the end of the epoch, a validation is run"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"In the last epoch, the validation loss is computed normally but the model is returned to its original (at the beginning of the problem) state."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"The same is repeated over all the problems in the meta-batch and all final validation losses are averaged."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"A pyorch update is performed at the end of the meta-batch"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Every 1000 meta-steps a Meta-Validation meta-step is performed. The process is the same as in Meta-train but the loss won't update the model (only computed for Meta-training guidance matters)."}]}]},{"type":"element","tag":"pre","props":{"code":"def make_step(model, outputs, labels, update_lr, in_weights):\n    loss = criterion(outputs, labels)\n    grads = torch.autograd.grad(loss, model.parameters())\n    out_weights = list(map(lambda p: p[1] - update_lr * p[0], zip(grads, in_weights)))\n    accuracy = (((1 - outputs) < outputs).float() == labels).sum() / outputs.shape[0]\n    return out_weights, loss, accuracy\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"make_step"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(model, outputs, labels, update_lr, in_weights):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" criterion(outputs, labels)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    grads "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" torch.autograd.grad(loss, model.parameters())\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    out_weights "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"list"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"map"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"lambda"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" p: p["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" update_lr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"*"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" p["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"], "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"zip"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(grads, in_weights)))\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ((("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs).float() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labels).sum() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputs.shape["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"return"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" out_weights, loss, accuracy"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"def update_model(model, new_weights, param_keys):\n    for param, param_key in zip(new_weights, param_keys):\n        model._modules[param_key[0]]._parameters[param_key[1]] = param\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"def"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-762058"},"children":[{"type":"text","value":"update_model"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(model, new_weights, param_keys):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" param, param_key "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"zip"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(new_weights, param_keys):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        model._modules[param_key["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]]._parameters[param_key["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]] "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" param"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"model = SimpleNet()\ncriterion = nn.BCEWithLogitsLoss()\nupdate_lr = 0.01\nmeta_lr = 0.001\nn_epochs = 15\nn_metaepochs = 2\n\nmetaoptimizer = optim.SGD(model.parameters(), lr=meta_lr, momentum=0.9)\nparam_keys = [(mod, kname) for mod in model._modules for kname in model._modules[mod]._parameters]\n\nfor metaepoch in range(n_metaepochs):\n\n    print('===============================')\n    print(f'//           Meta-Epoch {metaepoch + 1}       //')    \n    print('===============================')\n\n    for mi, metabatch in enumerate(metatrain_loader, 0):  #  Meta-step\n        print(f'{mi} updates at Meta-Level')\n\n        running_loss = 0.0  #  At each meta-step, the loss is reset\n\n        initial_weights = model.parameters()\n\n        for pi, problem_loaders in enumerate(metabatch, 0):  #  Problem in the meta-batch\n\n            print(f'- Problem {pi + 1} -')\n\n            problem_loader = problem_loaders['train']\n            problem_loader_val = problem_loaders['val']\n            ref_label = None\n\n            new_weights = initial_weights\n\n            for epoch in range(n_epochs):  #  Epoch in the problem training\n\n                print(f'Epoch {epoch + 1}')\n\n                val_loss = 0.0\n                val_accuracy = 0.0\n\n                for i, data in enumerate(problem_loader, 0):  #  Step in the problem\n\n                    inputs_raw, labels_raw = data\n                    inputs = preprocess_inputs(inputs_raw)\n                    outputs = model(inputs)\n                    if ref_label is None:\n                        ref_label = labels_raw[0]   #  On a new problem (1st step) adjust label mapping\n                    labels = process_labels(labels_raw, ref_label)\n\n                    new_weights, loss, accuracy = make_step(model, outputs, labels, update_lr, new_weights)\n                    update_model(model, new_weights, param_keys)  #  At each step in the problem manually update the model\n\n                    print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n\n                for iv, datav in enumerate(problem_loader_val):  #  At the end of the training process in an epoch of a problem we compute a whole validation\n\n                    inputs_rawv, labels_rawv = datav\n                    inputsv = preprocess_inputs(inputs_rawv)\n                    outputsv = model(inputsv)\n                    labelsv = process_labels(labels_rawv, ref_label)\n\n                    lossv = criterion(outputsv, labelsv[0])  #  Loss in a validation batch\n                    val_loss += lossv.item()\n                    val_accuracy += (((1 - outputsv) < outputsv).float() == labelsv).sum()\n\n                print(f'Epoch {epoch + 1}, VALIDATION], Loss: {val_loss / (iv + 1)}, Accuracy: {val_accuracy / (iv + 1)}')  #  Loss and accuracy averaged for all validation batches in the problem, displayed after whole validation\n\n            running_loss += lossv  #  After all epochs (all training process) in a single problem the validation loss is added\n\n            update_model(model, initial_weights, param_keys)  # After the whole train + validation of a problem and the final loss is added, return the model to its original stage in the meta-step \n        \n        metastep_loss = running_loss / metabatch_size  #  The added validation losses of all problems in the metabatch are averaged\n\n        metaoptimizer.zero_grad()  #  We perform gradient descent at the Meta-Level over the averaged validation loss\n        metastep_loss.backward()\n        metaoptimizer.step()\n\n        if (mi + 1) % 1000 == 0:  #  Meta-validation performed every 1000 meta-steps\n\n            print('META-VALIDATION STEP:')\n\n            for mbvi, metabatch_val in enumerate(metaval_loader):  #  Meta-validation meta-step\n\n                if (mbvi + 1) % 10 == 0:\n\n                    print(f'Validation step {mbvi + 1}')\n                    \n                initial_weights = model.parameters()\n\n                for problem_loaders in metabatch_val:  #  Problem in the meta-validation meta-batch\n\n                    problem_loader = problem_loaders['train']\n                    problem_loader_val = problem_loaders['val']\n                    ref_label = None\n                    new_weights = initial_weights\n\n                    for epoch in range(n_epochs):  #  Epoch in the problem training\n\n                        val_loss = 0.0\n                        val_accuracy = 0.0\n\n                        for i, data in enumerate(problem_loader, 0):  #  Step in the problem\n                            \n                            inputs_raw, labels_raw = data\n                            inputs = preprocess_inputs(inputs_raw)\n                            outputs = model(inputs)\n                            if ref_label is None:\n                                ref_label = labels_raw[0]\n                            labels = process_labels(labels_raw, ref_label)\n\n                            new_weights, loss, accuracy = make_step(model, outputs, labels, update_lr, new_weights)\n                            update_model(model, new_weights, param_keys)  #  Note that we still need to update although being in (Meta-)validation. That is because we are in meta-validation but at the Learning level we are in training stage\n\n                        #    print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n\n                        for iv, datav in enumerate(problem_loader_val):  #  At the end of the training process in an epoch of a problem we compute a whole validation, as in Meta-Train\n\n                            inputs_rawv, labels_rawv = datav\n                            inputsv = preprocess_inputs(inputs_rawv)\n                            outputsv = model(inputsv)\n                            labelsv = process_labels(labels_rawv, ref_label)\n                            \n                            lossv = criterion(outputsv, labelsv[0])\n                            val_loss += lossv.item()\n                            val_accuracy += (((1 - outputsv) < outputsv).float() == labelsv).sum()\n\n                    \n                    if (mbvi + 1) % 10 == 0:\n\n                        print(f'Last epoch, VALIDATION], Loss: {val_loss / (iv + 1)}, Accuracy: {val_accuracy / (iv + 1)}')  # The Meta-Validation only runs for informative matters, so our goal is to have this at the end of each problem (every 10 steps)\n\n                    update_model(model, initial_weights, param_keys)\n\n            print('END OF META-VALIDATION STEP')\n\n\n\n\n\n","language":"python","meta":"","className":"language-python github-light_github-dark"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"span","props":{"class":"line","line":1},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"model "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" SimpleNet()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":2},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"criterion "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" nn.BCEWithLogitsLoss()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":3},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"update_lr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.01\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":4},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"meta_lr "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.001\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":5},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"n_epochs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"15\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":6},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"n_metaepochs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"2\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":7},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":8},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metaoptimizer "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" optim.SGD(model.parameters(), "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"lr"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"meta_lr, "}]},{"type":"element","tag":"span","props":{"class":"ct-157101"},"children":[{"type":"text","value":"momentum"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.9"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":9},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"param_keys "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" [(mod, kname) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" mod "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model._modules "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" kname "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model._modules[mod]._parameters]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":10},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":11},"children":[{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metaepoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(n_metaepochs):\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":12},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":13},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'==============================='"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":14},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'//           Meta-Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"metaepoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"       //'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")    \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":15},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'==============================='"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":16},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":17},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" mi, metabatch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(metatrain_loader, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Meta-step\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":18},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"mi"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":" updates at Meta-Level'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":19},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":20},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        running_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  At each meta-step, the loss is reset\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":21},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":22},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        initial_weights "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model.parameters()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":23},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":24},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" pi, problem_loaders "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(metabatch, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Problem in the meta-batch\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":25},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":26},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'- Problem "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"pi "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":" -'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":27},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":28},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            problem_loader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" problem_loaders["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":29},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            problem_loader_val "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" problem_loaders["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":30},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":31},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":32},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            new_weights "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" initial_weights\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":33},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":34},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(n_epochs):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Epoch in the problem training\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":35},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":36},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":37},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":38},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":39},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":40},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":41},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" i, data "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(problem_loader, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Step in the problem\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":42},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":43},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    inputs_raw, labels_raw "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" data\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":44},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    inputs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" preprocess_inputs(inputs_raw)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":45},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    outputs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model(inputs)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":46},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"is"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":47},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                        ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labels_raw["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]   "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  On a new problem (1st step) adjust label mapping\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":48},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    labels "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" process_labels(labels_raw, ref_label)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":49},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":50},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    new_weights, loss, accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" make_step(model, outputs, labels, update_lr, new_weights)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":51},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    update_model(model, new_weights, param_keys)  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  At each step in the problem manually update the model\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":52},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":53},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", step "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"i "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":":5d"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"], Loss: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"loss.item()"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", Accuracy: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"accuracy"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":54},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":55},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" iv, datav "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(problem_loader_val):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  At the end of the training process in an epoch of a problem we compute a whole validation\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":56},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":57},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    inputs_rawv, labels_rawv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" datav\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":58},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    inputsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" preprocess_inputs(inputs_rawv)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":59},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    outputsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model(inputsv)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":60},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    labelsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" process_labels(labels_rawv, ref_label)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":61},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":62},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    lossv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" criterion(outputsv, labelsv["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Loss in a validation batch\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":63},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" lossv.item()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":64},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ((("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputsv) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputsv).float() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labelsv).sum()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":65},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":66},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", VALIDATION], Loss: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (iv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", Accuracy: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (iv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Loss and accuracy averaged for all validation batches in the problem, displayed after whole validation\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":67},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":68},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            running_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" lossv  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  After all epochs (all training process) in a single problem the validation loss is added\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":69},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":70},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            update_model(model, initial_weights, param_keys)  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"# After the whole train + validation of a problem and the final loss is added, return the model to its original stage in the meta-step \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":71},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":72},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        metastep_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" running_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metabatch_size  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  The added validation losses of all problems in the metabatch are averaged\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":73},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":74},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        metaoptimizer.zero_grad()  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  We perform gradient descent at the Meta-Level over the averaged validation loss\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":75},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        metastep_loss.backward()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":76},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        metaoptimizer.step()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":77},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":78},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (mi "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"%"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1000"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Meta-validation performed every 1000 meta-steps\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":79},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":80},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'META-VALIDATION STEP:'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":81},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":82},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" mbvi, metabatch_val "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(metaval_loader):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Meta-validation meta-step\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":83},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":84},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (mbvi "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"%"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"10"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":85},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":86},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Validation step "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"mbvi "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":87},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":88},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                initial_weights "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model.parameters()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":89},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":90},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" problem_loaders "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" metabatch_val:  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Problem in the meta-validation meta-batch\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":91},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":92},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    problem_loader "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" problem_loaders["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'train'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":93},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    problem_loader_val "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" problem_loaders["}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'val'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":94},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":95},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    new_weights "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" initial_weights\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":96},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":97},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" epoch "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"range"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(n_epochs):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Epoch in the problem training\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":98},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":99},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                        val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":100},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                        val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0.0\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":101},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":102},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" i, data "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(problem_loader, "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Step in the problem\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":103},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":104},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            inputs_raw, labels_raw "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" data\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":105},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            inputs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" preprocess_inputs(inputs_raw)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":106},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            outputs "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model(inputs)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":107},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"is"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"None"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":108},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                                ref_label "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labels_raw["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"]\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":109},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            labels "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" process_labels(labels_raw, ref_label)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":110},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":111},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            new_weights, loss, accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" make_step(model, outputs, labels, update_lr, new_weights)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":112},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            update_model(model, new_weights, param_keys)  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  Note that we still need to update although being in (Meta-)validation. That is because we are in meta-validation but at the Learning level we are in training stage\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":113},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":114},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                        "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#    print(f'Epoch {epoch + 1}, step {i + 1:5d}], Loss: {loss.item()}, Accuracy: {accuracy}')\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":115},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":116},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                        "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"for"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" iv, datav "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"in"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"enumerate"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"(problem_loader_val):  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"#  At the end of the training process in an epoch of a problem we compute a whole validation, as in Meta-Train\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":117},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":118},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            inputs_rawv, labels_rawv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" datav\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":119},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            inputsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" preprocess_inputs(inputs_rawv)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":120},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            outputsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" model(inputsv)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":121},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            labelsv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" process_labels(labels_rawv, ref_label)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":122},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":123},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            lossv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" criterion(outputsv, labelsv["}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"])\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":124},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" lossv.item()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":125},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                            val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" ((("}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"-"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputsv) "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"<"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" outputsv).float() "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" labelsv).sum()\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":126},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":127},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    \n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":128},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"if"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (mbvi "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":") "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"%"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"10"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"=="}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"0"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":":\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":129},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":130},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                        "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"f"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'Last epoch, VALIDATION], Loss: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_loss "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (iv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":", Accuracy: "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"{"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"val_accuracy "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"/"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" (iv "}]},{"type":"element","tag":"span","props":{"class":"ct-149352"},"children":[{"type":"text","value":"+"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"1"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"}"}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")  "}]},{"type":"element","tag":"span","props":{"class":"ct-086898"},"children":[{"type":"text","value":"# The Meta-Validation only runs for informative matters, so our goal is to have this at the end of each problem (every 10 steps)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":131},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":132},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"                    update_model(model, initial_weights, param_keys)\n"}]}]},{"type":"element","tag":"span","props":{"class":"line","line":133},"children":[{"type":"element","tag":"span","props":{},"children":[]}]},{"type":"element","tag":"span","props":{"class":"line","line":134},"children":[{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"            "}]},{"type":"element","tag":"span","props":{"class":"ct-617022"},"children":[{"type":"text","value":"print"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":"("}]},{"type":"element","tag":"span","props":{"class":"ct-952708"},"children":[{"type":"text","value":"'END OF META-VALIDATION STEP'"}]},{"type":"element","tag":"span","props":{"class":"ct-553616"},"children":[{"type":"text","value":")"}]}]}]}]},{"type":"element","tag":"pre","props":{"code":"===============================\n//           Meta-Epoch 1       //\n===============================\n0 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.7687771320343018, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6925913095474243, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6927804350852966, Accuracy: 0.5\n\n\n/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n\n\n\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n1036 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\n1037 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6932497620582581, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 4\nEpoch 4, step     1], Loss: 0.6932467222213745, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6932439208030701, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6932413578033447, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6932388544082642, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931473016738892, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6932364702224731, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 9\nEpoch 9, step     1], Loss: 0.6932342648506165, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6932321190834045, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6932300925254822, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6932281851768494, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.6932263374328613, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6932245492935181, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.693159818649292, Accuracy: 0.875\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.693159818649292, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.693159818649292, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.693159818649292, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.693159818649292, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931470036506653, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471228599548, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931470036506653, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471228599548, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     3], Loss: 0.6931470036506653, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931469440460205, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931470036506653, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471228599548, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471228599548, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931470036506653, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931470036506653, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931472420692444, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931472420692444, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n1038 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1039 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931465268135071, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471228599548, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6929552555084229, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.693013608455658, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931463479995728, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6929985284805298, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6930403709411621, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931462287902832, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6930311918258667, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6929515600204468, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931459903717041, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6929175853729248, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6929798126220703, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6928402781486511, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931451559066772, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931452751159668, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6929152011871338, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931449174880981, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.692875862121582, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6928192377090454, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6924663782119751, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6925125122070312, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931395530700684, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6914534568786621, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471228599548, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     2], Loss: 0.6931257247924805, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6903964877128601, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6930469870567322, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6734169125556946, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6456539630889893, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6456685662269592, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931453347206116, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6456435322761536, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931467950344086, Accuracy: 0.3333333432674408\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931618452072144, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.7013384103775024, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.7013236880302429, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931618452072144, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.7013236880302429, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931618452072144, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.7013384103775024, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931618452072144, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.7013236880302429, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931618452072144, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.7013236880302429, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931618452072144, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.7013236880302429, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.7013383507728577, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931618452072144, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.7013384103775024, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1040 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931450963020325, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931450963020325, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n1041 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931325197219849, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.685472846031189, Accuracy: 0.125\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.685472846031189, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931325197219849, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931324601173401, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931325197219849, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.685472846031189, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6854581832885742, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6854581832885742, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931325197219849, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.685472846031189, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931325197219849, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.685472846031189, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.685472846031189, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6854581832885742, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.685472846031189, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1042 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931456327438354, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.5982619524002075, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931469440460205, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6456738114356995, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931468844413757, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6457263231277466, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931469440460205, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.693146824836731, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6457088589668274, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931469241778055, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6457077860832214, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6456754803657532, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931454539299011, Accuracy: 0.75\nEpoch 4, VALIDATION], Loss: 0.6931469142436981, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931309103965759, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.5982460975646973, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931453943252563, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931469043095907, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931443214416504, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6456587910652161, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6457151770591736, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931468844413757, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6456596255302429, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931452751159668, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6457098126411438, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931468745072683, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.645708441734314, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6456731557846069, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.693132221698761, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931468645731608, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931296586990356, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.5982348322868347, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931437253952026, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6456550359725952, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.645706832408905, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6456537246704102, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931468347708384, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6457046270370483, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6456717252731323, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931255459785461, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.693146824836731, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931438446044922, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931449770927429, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6457033753395081, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.693146804968516, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6456713080406189, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931432485580444, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.693146804968516, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6456672549247742, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931449174880981, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6457016468048096, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931467950344086, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6485647559165955, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6485647559165955, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6485647559165955, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6485647559165955, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6485647559165955, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6485647559165955, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n1043 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 3, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 5, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 5, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 6, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 6, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 7, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 7, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 8, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 9, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 9, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 11, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 12, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 12, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 13, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 13, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 14, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 14, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 15, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 15, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\n"},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"text","value":"===============================\n//           Meta-Epoch 1       //\n===============================\n0 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.7687771320343018, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6925913095474243, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6927804350852966, Accuracy: 0.5\n\n\n/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n\n\n\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n1036 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.8333333134651184\n1037 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6932497620582581, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 4\nEpoch 4, step     1], Loss: 0.6932467222213745, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6932439208030701, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6932413578033447, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931473016738892, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6932388544082642, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931473016738892, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6932364702224731, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 9\nEpoch 9, step     1], Loss: 0.6932342648506165, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6932321190834045, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6932300925254822, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931473016738892, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6932281851768494, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.6932263374328613, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931473016738892, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6932245492935181, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 1.0\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.693159818649292, Accuracy: 0.875\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.693159818649292, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.693159818649292, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.693159818649292, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.693159818649292, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.693159818649292, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931470036506653, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471228599548, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931470036506653, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471228599548, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     3], Loss: 0.6931470036506653, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931469440460205, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931470036506653, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931469440460205, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471228599548, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471228599548, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931470036506653, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931470036506653, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931470036506653, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471228599548, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931472420692444, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931472420692444, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n1038 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1039 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931465268135071, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471228599548, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6929552555084229, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471228599548, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.693013608455658, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931463479995728, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6929985284805298, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6930403709411621, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931462287902832, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6930311918258667, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6929515600204468, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931459903717041, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6929175853729248, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6929798126220703, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6928402781486511, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931451559066772, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931452751159668, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6929152011871338, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931449174880981, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.692875862121582, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6928192377090454, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6924663782119751, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.6925125122070312, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931395530700684, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6914534568786621, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471228599548, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     2], Loss: 0.6931257247924805, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6903964877128601, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6930469870567322, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6734169125556946, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6456539630889893, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6456685662269592, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931453347206116, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6456435322761536, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931467950344086, Accuracy: 0.3333333432674408\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931618452072144, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.7013384103775024, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.7013236880302429, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931618452072144, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.7013236880302429, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.7013236880302429, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931618452072144, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     3], Loss: 0.7013384103775024, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931618452072144, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.7013236880302429, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931618452072144, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931618452072144, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.7013236880302429, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931618452072144, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.7013236880302429, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.7013383507728577, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931618452072144, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.7013384103775024, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1040 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931450963020325, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931450963020325, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931450963020325, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931450963020325, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n1041 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931325197219849, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.685472846031189, Accuracy: 0.125\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.685472846031189, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931325197219849, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931324601173401, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931325197219849, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.685472846031189, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6854581832885742, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6854581832885742, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931325197219849, Accuracy: 0.75\nEpoch 10, step     2], Loss: 0.685472846031189, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931325197219849, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.685472846031189, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.685472846031189, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.685472846031189, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6854581832885742, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.685472846031189, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931325197219849, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n1042 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931456327438354, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.5982619524002075, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931469440460205, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6456738114356995, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931468844413757, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6457263231277466, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931469440460205, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.693146824836731, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6457088589668274, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931469241778055, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6457077860832214, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6456754803657532, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931454539299011, Accuracy: 0.75\nEpoch 4, VALIDATION], Loss: 0.6931469142436981, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931309103965759, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.5982460975646973, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931453943252563, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931469043095907, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931443214416504, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6456587910652161, Accuracy: 0.625\nEpoch 6, step     3], Loss: 0.6457151770591736, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931468844413757, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6456596255302429, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931452751159668, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6457098126411438, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931468745072683, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.645708441734314, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6456731557846069, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.693132221698761, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931468645731608, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931296586990356, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.5982348322868347, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931437253952026, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6456550359725952, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931468447049459, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, step     2], Loss: 0.645706832408905, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6456537246704102, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931468347708384, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6457046270370483, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6456717252731323, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931255459785461, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.693146824836731, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931438446044922, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931449770927429, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6457033753395081, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.693146804968516, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6456713080406189, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931432485580444, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.693146804968516, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6456672549247742, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931449174880981, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6457016468048096, Accuracy: 0.875\nEpoch 15, VALIDATION], Loss: 0.6931467950344086, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.5\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 7 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6485647559165955, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6485647559165955, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     2], Loss: 0.6485647559165955, Accuracy: 0.75\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6485647559165955, Accuracy: 0.75\nEpoch 9, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6485647559165955, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6485647559165955, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6485647559165955, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471725304922, Accuracy: 0.6666666865348816\n- Problem 8 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.1666666716337204\n1043 updates at Meta-Level\n- Problem 1 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 2 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 3 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.875\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\n- Problem 4 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 1, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 2, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 3, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 4, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 5, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 5, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 6, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 6, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 7, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 7, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 8, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 9, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 9, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 10, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 11, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 11, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 12, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 12, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 13, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 13, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 14, step     3], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 14, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 15, step     2], Loss: 0.6931362152099609, Accuracy: 0.0\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.0\nEpoch 15, VALIDATION], Loss: 0.6931325793266296, Accuracy: 0.0\n- Problem 5 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.125\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 14, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\nEpoch 15\nEpoch 15, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 15, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 15, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 15, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.6666666865348816\n- Problem 6 -\nEpoch 1\nEpoch 1, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 1, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 1, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 2\nEpoch 2, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 2, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 2, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 2, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 3\nEpoch 3, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 3, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 3, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 4\nEpoch 4, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 4, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 4, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 5\nEpoch 5, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 5, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 5, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 6\nEpoch 6, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 6, step     2], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 6, step     3], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 6, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 7\nEpoch 7, step     1], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 7, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 8\nEpoch 8, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 8, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 8, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 8, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 9\nEpoch 9, step     1], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 9, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 9, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 9, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 10\nEpoch 10, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 10, step     2], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 10, step     3], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 10, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 11\nEpoch 11, step     1], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 11, step     2], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, step     3], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 11, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 12\nEpoch 12, step     1], Loss: 0.6931471824645996, Accuracy: 0.75\nEpoch 12, step     2], Loss: 0.6931471824645996, Accuracy: 0.375\nEpoch 12, step     3], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 12, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 13\nEpoch 13, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 13, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\nEpoch 13, step     3], Loss: 0.6931471824645996, Accuracy: 0.25\nEpoch 13, VALIDATION], Loss: 0.6931471824645996, Accuracy: 0.3333333432674408\nEpoch 14\nEpoch 14, step     1], Loss: 0.6931471824645996, Accuracy: 0.625\nEpoch 14, step     2], Loss: 0.6931471824645996, Accuracy: 0.5\n"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"As said before, we don't want to check the performance of the approach since we will need deep review and debug of the behaviour (with proper hyperparameter search, etc) and this is out of the scope of this post. However, I am glad to see that I have a running and working Meta-Learning pipeline."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In the next post, my intention is to see make a performance analysis of this and compare it to other approaches."}]},{"type":"element","tag":"h2","props":{"id":"thank-you-again-reader"},"children":[{"type":"text","value":"Thank you again, reader"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This is my second blog post and the first in which I presented code. I had an enjoyable experience with it and I will repeat this format for sure! Actually, in the next post I pretend to expose one more episode about this Meta-Learning topic, in which I may perform some analysis of the apporach results, comparisons, etc. Again, thank you for your attention and we'll meet in the next post!"}]},{"type":"element","tag":"style","props":{},"children":[{"type":"text","value":".github-light_github-dark{color:#24292e;background:#fff;}.dark .github-light_github-dark{color:#e1e4e8;background:#24292e;}.ct-149352{color:#D73A49;}.dark .ct-149352{color:#F97583;}.ct-553616{color:#24292E;}.dark .ct-553616{color:#E1E4E8;}.ct-952708{color:#032F62;}.dark .ct-952708{color:#9ECBFF;}.ct-086898{color:#6A737D;}.ct-157101{color:#E36209;}.dark .ct-157101{color:#FFAB70;}.ct-617022{color:#005CC5;}.dark .ct-617022{color:#79B8FF;}.ct-762058{color:#6F42C1;}.dark .ct-762058{color:#B392F0;}"}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"preliminaries-meta-learning-datasets","depth":2,"text":"Preliminaries: Meta-Learning datasets","children":[{"id":"requirements-of-a-good-meta-learning-dataset","depth":3,"text":"Requirements of a good Meta-Learning dataset"},{"id":"datasets","depth":3,"text":"Datasets"}]},{"id":"experiment-definition","depth":2,"text":"Experiment definition"},{"id":"tools","depth":2,"text":"Tools"},{"id":"code","depth":2,"text":"Code","children":[{"id":"imports-and-setting","depth":3,"text":"Imports and setting"},{"id":"exploring-torchvisions-omniglot-dataset","depth":3,"text":"Exploring torchvision's Omniglot dataset"},{"id":"load-raw-dataset","depth":3,"text":"Load raw dataset"},{"id":"building-the-meta-splits","depth":3,"text":"Building the Meta-Splits"},{"id":"the-meta-level-dataloader","depth":3,"text":"The Meta-level DataLoader"},{"id":"training-a-model-in-a-problem","depth":3,"text":"Training a model in a problem"},{"id":"train-with-manual-gd-algorithm","depth":3,"text":"Train with manual GD algorithm"},{"id":"meta-learning-training","depth":3,"text":"Meta-Learning training"}]},{"id":"thank-you-again-reader","depth":2,"text":"Thank you again, reader"}]}},"_type":"markdown","_id":"content:articles:2022-12-20-meta-learning-implementation.md","_source":"content","_file":"articles/2022-12-20-meta-learning-implementation.md","_extension":"md"}]